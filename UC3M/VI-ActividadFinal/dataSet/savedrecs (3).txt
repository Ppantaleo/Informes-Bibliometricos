PT	AU	BA	CA	GP	RI	OI	BE	Z2	AU	AA	TI	X1	Y1	Z1	FT	PN	AE	Z3	SO	S1	SE	BS	VL	IS	SI	MA	BP	EP	AR	VN	VH	DI	D2	L1	L2	L3	EA	SU	DT	PD	PY	AB	X4	Y4	Z4	AK	CT	CY	SP	CL	TC	Z8	ZR	ZA	ZB	ZS	Z9	U1	U2	SN	EI	BN	G1	NR	CR	LA	AS	AC	CG	DG	C1	C3	EC	DE	DA	UT	PM	
J	Zhang, Lvmin; Agrawala, Maneesh										Transparent Image Layer Diffusion using Latent Transparency								Arxiv											2	2;2024-06-23;https://www.arxiv.org/abs/2402.17113v4| 1;2024-02-28;https://www.arxiv.org/abs/2402.17113v2	arXiv:2402.17113			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 23 2024	2024	We present an approach enabling large-scale pretrained latent diffusion models to generate transparent images. The method allows generation of single transparent images or of multiple transparent layers. The method learns a “latent transparency” that encodes alpha channel transparency into the latent manifold of a pretrained latent diffusion model. It preserves the production-ready quality of the large diffusion model by regulating the added transparency as a latent offset with minimal changes to the original latent distribution of the pretrained model. In this way, any latent diffusion model can be converted into a transparent image generator by finetuning it with the adjusted latent space. We train the model with 1M transparent image layer pairs collected using a human -in -the -loop collection scheme. We show that latent transparency can be applied to different open source image generators, or be adapted to various conditional control systems to achieve applications like foreground/background-conditioned layer generation, joint layer generation, structural control of layer contents, etc . A user study finds that in most cases (97%) users prefer our natively generated transparent content over previous ad -hoc solutions such as generating and then matting. Users also report the quality of our generated transparent images is comparable to real commercial transparent assets like Adobe Stock.																																	2024-07-12	PPRN:87988874		
J	Chen, Jifan; Kim, Grace; Sriram, Aniruddh; Durrett, Greg; Choi, Eunsol										Complex Claim Verification with Evidence Retrieved in the Wild								Arxiv											2	2;2024-06-15;https://www.arxiv.org/abs/2305.11859v2| 1;2023-05-19;https://www.arxiv.org/abs/2305.11859v1	arXiv:2305.11859			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 15 2024	2024	Evidence retrieval is a core part of automatic fact-checking. Prior work makes simplifying assumptions in retrieval that depart from real-world use cases: either no access to evidence, access to evidence curated by a human fact-checker, or access to evidence available long after the claim has been made. In this work, we present the first fully automated pipeline to check real-world claims by retrieving raw evidence from the web. We restrict our retriever to only search documents available prior to the claim's making, modeling the realistic scenario where an emerging claim needs to be checked. Our pipeline includes five components: claim decomposition, raw document retrieval, fine-grained evidence retrieval, claim-focused summarization, and veracity judgment. We conduct experiments on complex political claims in the ClaimDecomp dataset and show that the aggregated evidence produced by our pipeline improves veracity judgments. Human evaluation finds the evidence summary produced by our system is reliable (it does not hallucinate information) and relevant to answering key questions about a claim, suggesting that it can assist fact-checkers even when it cannot surface a complete evidence set.1																																	2024-07-04	PPRN:70569467		
J	Umeda, Hiroya; Ouchi, Masami; Nakajima, Kimihiko; Harikane, Yuichi; Ono, Yoshiaki; Xu, Yi; Isobe, Yuki; Zhang, Yechi				Nakajima, Kimihiko/JRW-3889-2023; Ono, Yoshiaki/AAY-4463-2020; Harikane, Yuichi/KHY-2680-2024; Ouchi, Masami/AAA-9826-2019						JWST Measurements of Neutral Hydrogen Fractions and Ionized Bubble Sizes at z = 7−12 Obtained with Lyα Damping Wing Absorptions in 27 Bright Continuum Galaxies								Arxiv											3	3;2024-06-13;https://www.arxiv.org/abs/2306.00487v3| 2;2023-10-11;https://www.arxiv.org/abs/2306.00487v2| 1;2023-06-01;https://www.arxiv.org/abs/2306.00487v1	arXiv:2306.00487			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 13 2024	2024	We present volume-averaged neutral hydrogen fractions xHi and ionized bubble radii Rb measured with Lyα damping wing absorption of galaxies at the epoch of reionization. We combine JWST/NIRSpec spectra taken by CEERS, GO-1433, DDT-2750, and JADES programs, and obtaina sample containing 27 bright UV-continuum (MUV<−18.5 mag) galaxies at 7< z <12. We construct 4 composite spectra binned by redshift, and find the clear evolution of softening break to-wards high redshift at the rest-frame 1216 A, suggesting the increase of Lyα damping wing absorption.We estimate Lyα damping wing absorption in the galaxy spectra with realistic templates including Lyα emission and circum-galactic medium absorptions. Assuming the standard inside-out reionization picture having an ionized bubble with radius Rb around a galaxy embedded in the intergalactic medium with xHi, we obtain xHi(Rb) values generally increasing (decreasing) from xHi = 0.53−0.47+0.18to 0.92−0.10+0.08(logRb= 1.67−0.16 + 0.14to −0.69−0.24+0.89 comoving Mpc) at redshift 7.12−0.08+0.06to 9.91−1.15+1.49. The redshift evolution of xHi indicates a moderately late reionization history consistent with the one previously suggested from the electron scattering of cosmic microwave background and the evolution of UV luminosity function with an escape fraction fesc∼0.2. Our Rb measurements suggest that bubble sizes could be up to a few dex larger than the cosmic average values estimated by analytic calculations fora given xHi, while our Rb measurements are roughly comparable with the values for merged ionized bubbles around bright galaxies predicted by recent numerical simulations																																	2024-07-02	PPRN:72812614		
J	Li, Ming; Zhang, Yong; He, Shwai; Li, Zhitao; Zhao, Hongyu; Wang, Jianzong; Cheng, Ning; Zhou, Tianyi				Li, Zhitao/KHV-6882-2024; WANG, JIANZONG/GZL-9336-2022; Zhao, Hongyu/AAD-2750-2021						Superfiltering: Weak-to-Strong Data Filtering for Fast Instruction-Tuning								Arxiv											2	2;2024-06-07;https://www.arxiv.org/abs/2402.00530v2| 1;2024-02-01;https://www.arxiv.org/abs/2402.00530v1	arXiv:2402.00530			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 07 2024	2024	Instruction tuning is critical to improve LLMs but usually suffers from low-quality and redundant data. Data filtering for instruction tuning has proved important in improving both the efficiency and performance of the tuning process. But it also leads to extra cost and computation due to the involvement of LLMs in this process. To reduce the filtering cost, we study Superfiltering: Can we use a smaller and weaker model to select data for finetuning a larger and stronger model? Despite the performance gap between weak and strong language models, we find their highly consistent capability to perceive instruction difficulty and data selection results. This enables us to use a much smaller and more efficient model to filter the instruction data used to train a larger language model. Not only does it largely speed up the data filtering, but the filtered-data-finetuned LLM achieves even better performance on standard benchmarks. Extensive experiments validate the efficacy and efficiency of our approach.																																	2024-07-04	PPRN:87455146		
J	Yu, Zhaojian; Zhang, Xin; Shang, Ning; Huang, Yangyu; Xu, Can; Zhao, Yishujie; Hu, Wenxiang; Yin, Qiufeng				YIN, Qiufeng/NVM-0025-2025; Hu, Wenxiang/W-3737-2017; HUANG, YANGYU/KZC-4193-2024						WaveCoder: Widespread And Versatile Enhancement For Code Large Language Models By Instruction Tuning								Arxiv											4	4;2024-06-07;https://www.arxiv.org/abs/2312.14187v5| 3;2024-01-11;https://www.arxiv.org/abs/2312.14187v3| 2;2023-12-26;https://www.arxiv.org/abs/2312.14187v2| 1;2023-12-20;https://www.arxiv.org/abs/2312.14187v1	arXiv:2312.14187			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 07 2024	2024	Recent work demonstrates that, after instruction tuning, Code Large Language Models (Code LLMs) can obtain impressive capabilities to address a wide range of code-related tasks. However, current instruction tuning methods for Code LLMs mainly focus on the traditional code generation task, resulting in poor performance in complex multi-task scenarios. In this paper, we concentrate on multiple code-related tasks and present WaveCoder, a series of Code LLMs trained with Widespread And Versatile Enhanced instruction data. To enable the models to tackle complex code-related tasks, we propose a method to stably generate diverse, high-quality instruction data from open source code dataset in multi-task scenarios and obtain CodeSeaXDataset, a dataset comprising 19,915 instruction instances across 4 code-related tasks, which is aimed at improving the generalization ability of Code LLM. Our experiments demonstrate that WaveCoder models significantly outperform other open-source models in terms of the generalization ability across different code-related tasks. Moreover, WaveCoder-Ultra-6.7B presents the state-of-the-art generalization abilities on a wide range of code-related tasks.																																	2024-06-22	PPRN:86827767		
J	Yu, Jiahao; Wu, Yuhang; Shu, Dong; Jin, Mingyu; Yang, Sabrina; Xing, Xinyu				Shu, Dong/ODJ-9505-2025; Yu, Jiahao/HIR-5202-2022						Assessing Prompt Injection Risks in 200+ Custom GPTs								Arxiv											2	2;2024-05-25;https://www.arxiv.org/abs/2311.11538v2| 1;2023-11-20;https://www.arxiv.org/abs/2311.11538v1	arXiv:2311.11538			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 25 2024	2024	In the rapidly evolving landscape of artificial intelligence, ChatGPT has been widely used in various applications. The new feature - customization of ChatGPT models by users to cater to specific needs has opened new frontiers in AI utility. However, this study reveals a significant security vulnerability inherent in these user-customized GPTs: prompt injection attacks. Through comprehensive testing of over 200 user-designed GPT models via adversarial prompts, we demonstrate that these systems are susceptible to prompt injections. Through prompt injection, an adversary can not only extract the customized system prompts but also access the uploaded files. This paper provides a first-hand analysis of the prompt injection, alongside the evaluation of the possible mitigation of such attacks. Our findings underscore the urgent need for robust security frameworks in the design and deployment of customizable GPT models. The intent of this paper is to raise awareness and prompt action in the AI community, ensuring that the benefits of GPT customization do not come at the cost of compromised security and privacy.																																	2024-06-11	PPRN:86213219		
J	Wang, Zhao; Li, Aoxue; Zhu, Lingting; Guo, Yong; Dou, Qi; Li, Zhenguo				Wang, Zhao/AAG-2483-2021						CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects								Arxiv											2	2;2024-05-22;https://www.arxiv.org/abs/2401.09962v2| 1;2024-01-18;https://www.arxiv.org/abs/2401.09962v1	arXiv:2401.09962			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 22 2024	2024	Customized text-to-video generation aims to generate high-quality videos guided by text prompts and subject references. Current approaches for personalizing text-to-video generation suffer from tackling multiple subjects, which is a more challenging and practical scenario. In this work, our aim is to promote multi-subject guided text-to-video customization. We propose CustomVideo, a novel framework that can generate identity-preserving videos with the guidance of multiple subjects. To be specific, firstly, we encourage the co-occurrence of multiple subjects via composing them in a single image. Further, upon a basic text-to-video diffusion model, we design a simple yet effective attention control strategy to disentangle different subjects in the latent space of diffusion model. Moreover, to help the model focus on the specific area of the object, we segment the object from given reference images and provide a corresponding object mask for attention learning. Also, we collect a multi-subject text-to-video generation dataset as a comprehensive benchmark, with 63 individual subjects from 13 different categories and 68 meaningful pairs. Extensive qualitative, quantitative, and user study results demonstrate the superiority of our method compared to previous state-of-the-art approaches. 																																	2024-06-05	PPRN:87221722		
J	Lee, Dongjun; Park, Choongwon; Kim, Jaehyuk; Park, Heesoo										MCS-SQL: Leveraging Multiple Prompts and Multiple-Choice Selection For Text-to-SQL Generation								Arxiv											1	1;2024-05-13;https://www.arxiv.org/abs/2405.07467v1	arXiv:2405.07467			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 13 2024	2024	Recent advancements in large language models (LLMs) have enabled in-context learning (ICL)-based methods that significantly outperform fine-tuning approaches for text-to-SQL tasks. However, their performance is still considerably lower than that of human experts on benchmarks that include complex schemas and queries, such as BIRD. This study considers the sensitivity of LLMs to the prompts and introduces a novel approach that leverages multiple prompts to explore a broader search space for possible answers and effectively aggregate them. Specifically, we robustly refine the database schema through schema linking using multiple prompts. Thereafter, we generate various candidate SQL queries based on the refined schema and diverse prompts. Finally, the candidate queries are filtered based on their confidence scores, and the optimal query is obtained through a multiple-choice selection that is presented to the LLM. When evaluated on the BIRD and Spider benchmarks, the proposed method achieved execution accuracies of 65.5% and 89.6%, respectively, significantly outperforming previous ICL-based methods. Moreover, we established a new SOTA performance on the BIRD in terms of both the accuracy and efficiency of the generated queries.																																	2024-06-08	PPRN:89032852		
J	Merrick, Luke; Xu, Danmei; Nuti, Gaurav; Campos, Daniel										Arctic-Embed: Scalable, Efficient, and Accurate Text Embedding Models								Arxiv											1	1;2024-05-08;https://www.arxiv.org/abs/2405.05374v1	arXiv:2405.05374			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 08 2024	2024	This report describes the training dataset creation and recipe behind the family of texttt{arctic-embed} text embedding models (a set of five models ranging from 22 to 334 million parameters with weights open-sourced under an Apache-2 license). At the time of their release, each model achieved state-of-the-art retrieval accuracy for models of their size on the MTEB Retrieval leaderboard, with the largest model, arctic-embed-l outperforming closed source embedding models such as Cohere's embed-v3 and Open AI's text-embed-3-large. In addition to the details of our training recipe, we have provided several informative ablation studies, which we believe are the cause of our model performance.																																	2024-06-04	PPRN:88975377		
J	Hong, Fangzhou; Tang, Jiaxiang; Cao, Ziang; Shi, Min; Wu, Tong; Chen, Zhaoxi; Yang, Shuai; Wang, Tengfei; Pan, Liang; Lin, Dahua; Liu, Ziwei				Hong, Fangzhou/JXX-7529-2024; Lin, Dahua/W-6576-2019; Liu, Ziwei/AAG-6939-2021						3DTopia: Large Text-to-3D Generation Model with Hybrid Diffusion Priors								Arxiv											2	2;2024-05-07;https://www.arxiv.org/abs/2403.02234v2| 1;2024-03-04;https://www.arxiv.org/abs/2403.02234v1	arXiv:2403.02234			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	May 07 2024	2024	We present a two -stage text -to -3D generation system, namely 3DTopia, which generates highquality general 3D assets within 5 minutes using hybrid diffusion priors. The first stage samples from a 3D diffusion prior directly learned from 3D data. Specifically, it is powered by a text -conditioned tri-plane latent diffusion model, which quickly generates coarse 3D samples for fast prototyping. The second stage utilizes 2D diffusion priors to further refine the texture of coarse 3D models from the first stage. The refinement consists of both latent and pixel space optimization for highquality texture generation. To facilitate the training of the proposed system, we clean and caption the largest open -source 3D dataset, Objaverse, by combining the power of vision language models and large language models. Experiment results are reported qualitatively and quantitatively to show the performance of the proposed system. 																																	2024-06-04	PPRN:88014363		
J	Fernández-Godino, M.Giselle				Fernández-Godino, M./AAG-4922-2019; PARK, CHANYOUNG/AAL-1685-2020						Review of multi-fidelity models								Arxiv											2	2;2017-06-12;https://www.arxiv.org/abs/1609.07196v3| 1;2024-05-01;	arXiv:1609.07196			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	May 01 2024	2024	Multi-fidelity models provide a framework for integrating computational models of varying complexity, allowing for accurate predictions while optimizing computational resources. These models are especially beneficial when acquiring high-accuracy data is costly or computationally intensive. This review offers a comprehensive analysis of multi-fidelity models, focusing on their applications in scientific and engineering fields, particularly in optimization and uncertainty quantification. It classifies publications on multi-fidelity modeling according to several criteria, including application area, surrogate model selection, types of fidelity, combination methods and year of publication. The study investigates techniques for combining different fidelity levels, with an emphasis on multi-fidelity surrogate models. This work discusses reproducibility, open-sourcing methodologies and benchmarking procedures to promote transparency. The manuscript also includes educational toy problems to enhance understanding. Additionally, this paper outlines best practices for presenting multi-fidelity-related savings in a standardized, succinct and yet thorough manner. The review concludes by examining current trends in multi-fidelity modeling, including emerging techniques, recent advancements, and promising research directions.																																	2025-11-07	PPRN:49279810		
J	Drinfeld, Vladimir										The Prismatization								Arxiv											3	3;2024-04-30;https://www.arxiv.org/abs/2005.04746v7| 2;2024-02-26;https://www.arxiv.org/abs/2005.04746v6| 1;2020-05-10;https://www.arxiv.org/abs/2005.04746v5	arXiv:2005.04746			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 30 2024	2024	The eventual goal is to construct three related “prismatization” functors from the category of p-adic formal schemes to that of formal stacks. This should provide a good category of coefficients for prismatic cohomology in the spirit of F-gauges. In this article we define and study the three versions of the prismatization of Spf Zp.																																	2024-05-21	PPRN:12053116		
J	Lehnert, Lucas; Sukhbaatar, Sainbayar; Su, Dijia; Zheng, Qinqing; Mcvay, Paul; Rabbat, Michael; Tian, Yuandong				Rabbat, Michael/G-4582-2012						Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping								Arxiv											2	2;2024-04-26;https://www.arxiv.org/abs/2402.14083v2| 1;2024-02-21;https://www.arxiv.org/abs/2402.14083v1	arXiv:2402.14083			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 26 2024	2024	While Transformers have enabled tremendous progress in various application settings, such architectures still trail behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks. This is accomplished by training an encoder -decoder Transformer model to predict the search dynamics of the A ∗ search algorithm. We fine tune this model to obtain a Searchformer, , a Transformer model that optimally solves previously unseen Sokoban puzzles 93.7% of the time, while using up to 26.8% fewer search steps than the A ∗ implementation that was used for training initially. In our training method, A ∗ ’s search dynamics are expressed as a token sequence outlining when task states are added and removed into the search tree during symbolic planning. Searchformer significantly outperforms baselines that predict the optimal plan directly with a 5–10× smaller model size and a 10× smaller training dataset. Lastly, we demonstrate how Searchformer scales to larger and more complex decision making tasks with improved percentage of solved tasks and shortened search dynamics.																																	2024-05-15	PPRN:87799471		
J	Enis, Maxim; Hopkins, Mark										From LLM to NMT: Advancing Low-Resource Machine Translation with Claude								Arxiv											1	1;2024-04-22;https://www.arxiv.org/abs/2404.13813v1	arXiv:2404.13813			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 22 2024	2024	We show that Claude 3 Opus, a large language model (LLM) released by Anthropic in March 2024, exhibits stronger machine translation competence than other LLMs. Though we find evidence of data contamination with Claude on FLORES-200, we curate new benchmarks that corroborate the effectiveness of Claude for low-resource machine translation into English. We find that Claude has remarkable textit{resource efficiency} -- the degree to which the quality of the translation model depends on a language pair's resource level. Finally, we show that advancements in LLM translation can be compressed into traditional neural machine translation (NMT) models. Using Claude to generate synthetic data, we demonstrate that knowledge distillation advances the state-of-the-art in Yoruba-English translation, meeting or surpassing strong baselines like NLLB-54B and Google Translate.																																	2024-04-30	PPRN:88601131		
J	Siththaranjan, Anand; Laidlaw, Cassidy; Hadfield-Menell, Dylan										Distributional Preference Learning: Understanding and Accounting for Hidden Context in RLHF								Arxiv											2	2;2024-04-17;https://www.arxiv.org/abs/2312.08358v2| 1;2023-12-13;https://www.arxiv.org/abs/2312.08358v1	arXiv:2312.08358			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 17 2024	2024	In practice, preference learning from human feedback depends on incomplete data with hidden context. Hidden context refers to data that affects the feedback received, but which is not represented in the data used to train a preference model. This captures common issues of data collection, such as having human annotators with varied preferences, cognitive processes that result in seemingly irrational behavior, and combining data labeled according to different criteria. We prove that standard applications of preference learning, including reinforcement learning from human feedback (RLHF), implicitly aggregate over hidden contexts according to a well-known voting rule called Borda count. We show this can produce counter -intuitive results that are very different from other methods which implicitly aggregate via expected utility. Furthermore, our analysis formalizes the way that preference learning from users with diverse values tacitly implements a social choice function. A key implication of this result is that annotators have an incentive to misreport their preferences in order to influence the learned model, leading to vulnerabilities in the deployment of RLHF. As a step towards mitigating these problems, we introduce a class of methods called distributional preference learning (DPL). DPL methods estimate a distribution of possible score values for each alternative in order to better account for hidden context. Experimental results indicate that applying DPL to RLHF for LLM chatbots identifies hidden context in the data and significantly reduces subsequent jailbreak vulnerability. 																																	2024-04-27	PPRN:86567330		
J	Kadkhodaie, Zahra; Guth, Florentin; Simoncelli, Eero P.; Mallat, Stephane				Mallat, Stephane/OHR-9738-2025						GENERALIZATION IN DIFFUSION MODELS ARISES FROM GEOMETRY-ADAPTIVE HARMONIC REPRESENTATIONS								Arxiv											2	2;2024-04-12;https://www.arxiv.org/abs/2310.02557v3| 1;2024-03-15;https://www.arxiv.org/abs/2310.02557v2	arXiv:2310.02557			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 12 2024	2024	Deep neural networks (DNNs) trained for image denoising are able to generate highquality samples with score-based reverse diffusion algorithms. These impressive capabilities seem to imply an escape from the curse of dimensionality, but recent reports of memorization of the training set raise the question of whether these networks are learning the “true” continuous density of the data. Here, we show that two DNNs trained on non-overlapping subsets of a dataset learn nearly the same score function, and thus the same density, when the number of training images is large enough. In this regime of strong generalization, diffusion-generated images are distinct from the training set, and are of high visual quality, suggesting that the inductive biases of the DNNs are well-aligned with the data density. We analyze the learned denoising functions and show that the inductive biases give rise to a shrinkage operation in a basis adapted to the underlying image. Examination of these bases reveals oscillating harmonic structures along contours and in homogeneous regions. We demonstrate that trained denoisers are inductively biased towards these geometry-adaptive harmonic bases since they arise not only when the network is trained on photographic images, but also when it is trained on image classes supported on low-dimensional manifolds for which the harmonic basis is suboptimal. Finally, we show that when trained on regular image classes for which the optimal basis is known to be geometry-adaptive and harmonic, the denoising performance of the networks is near-optimal.																																	2024-04-27	PPRN:86282365		
J	Luo, Zhengyi; Cao, Jinkun; Merel, Josh; Winkler, Alexander; Huang, Jing; Kitani, Kris; Xu, Weipeng										UNIVERSAL HUMANOID MOTION REPRESENTATIONS FOR PHYSICS-BASED CONTROL								Arxiv											2	2;2024-04-12;https://www.arxiv.org/abs/2310.04582v2| 1;2023-10-06;https://www.arxiv.org/abs/2310.04582v1	arXiv:2310.04582			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Apr 12 2024	2024	We present a universal motion representation that encompasses a comprehensive range of motor skills for physics-based humanoid control. Due to the high dimensionality of humanoids and the inherent difficulties in reinforcement learning, prior methods have focused on learning skill embeddings for a narrow range of movement styles (e.g. locomotion, game characters) from specialized motion datasets. This limited scope hampers their applicability in complex tasks. We close this gap by significantly increasing the coverage of our motion representation space. To achieve this, we first learn a motion imitator that can imitate all of human motion from a large, unstructured motion dataset. We then create our motion representation by distilling skills directly from the imitator. This is achieved by using an encoder-decoder structure with a variational information bottleneck. Additionally, we jointly learn a prior conditioned on proprioception (humanoid’s own pose and velocities) to improve model expressiveness and sampling efficiency for downstream tasks. By sampling from the prior, we can generate long, stable, and diverse human motions. Using this latent space for hierarchical RL, we show that our policies solve tasks using human-like behavior. We demonstrate the effectiveness of our motion representation by solving generative tasks (e.g. strike, terrain traversal) and motion tracking using VR controllers.																																	2024-04-25	PPRN:85571718		
J	Luongo, Orlando; Muccino, Marco				Luongo, Orlando/J-5328-2016; Muccino, Marco/JZD-9643-2024						Model independent cosmographic constraints from DESI 2024								Arxiv											1	1;2024-04-10;https://www.arxiv.org/abs/2404.07070v1	arXiv:2404.07070			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 10 2024	2024	In this study, we explore model independent constraints on the universe kinematics up to the snap and jerk hierarchical terms. To do so, we consider the latest Baryon Acoustic Oscillation (BAO) release provided by the DESI collaboration, tackling the rd parameter to span within the range [144, 152] Mpc, with fixed step, δ rd = 2 Mpc, aligning with Planck and DESI results. Thus, employing Monte Carlo Markov chain analyses, we place stringent constraints on the cosmographic series, incorporating three combinations of data catalogs: the first BAO with observational Hubble data, the second BAO with type Ia supernovae, and the last including all three data sets. Our results conclusively constrain the cosmographic series, say the deceleration q0 , the jerk j0 , and the snap s0 parameters, at the 2–σ level, showcasing a significant departure on j0 even at 1–σ confidence level, albeit being compatible with the ΛCDM paradigm on q0 and s0 , at 2–σ level. Analogously, the h0 tension appears alleviated in the second hierarchy, say including snap. Finally, a direct comparison with the ΛCDM, wCDM models and the Chevallier-Polarski-Linder parametrization is reported, definitively favoring the wCDM scenario.																																	2024-04-24	PPRN:88478872		
J	Zhao, Sijie; Chen, Hao; Zhang, Xueliang; Xiao, Pengfeng; Bai, Lei; Ouyang, Wanli				Xiao, Pengfeng/A-8143-2016; Ouyang, Wanli/I-7135-2018						RS-Mamba for Large Remote Sensing Image Dense Prediction								Arxiv											2	2;2024-04-10;https://www.arxiv.org/abs/2404.02668v2| 1;2024-04-03;https://www.arxiv.org/abs/2404.02668v1	arXiv:2404.02668			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 10 2024	2024	Context modeling is critical for remote sensing image dense prediction tasks. Nowadays, the growing size of very-high-resolution (VHR) remote sensing images poses challenges in effectively modeling context. While transformer-based models possess global modeling capabilities, they encounter computational challenges when applied to large VHR images due to their quadratic complexity. The conventional practice of cropping large images into smaller patches results in a notable loss of contextual information. To address these issues, we propose the Remote Sensing Mamba (RSM) for dense prediction tasks in large VHR remote sensing images. RSM is specifically designed to capture the global context of remote sensing images with linear complexity, facilitating the effective processing of large VHR images. Considering that the land covers in remote sensing images are distributed in arbitrary spatial directions due to characteristics of remote sensing over-head imaging, the RSM incorporates an omnidirectional selective scan module to globally model the context of images in multiple directions, capturing large spatial features from various directions. Extensive experiments on semantic segmentation and change detection tasks across various land covers demonstrate the effectiveness of the proposed RSM. We designed simple yet effective models based on RSM, achieving state-of-the-art performance on dense prediction tasks in VHR remote sensing images without fancy training strategies. Leveraging the linear complexity and global modeling capabilities, RSM achieves better efficiency and accuracy than transformer-based models on large remote sensing images. Interestingly, we also demonstrated that our model generally performs better with a larger image size on dense prediction tasks. 																																	2024-05-22	PPRN:88390497		
J	Liu, Junpeng; Song, Yifan; Lin, Bill Yuchen; Lam, Wai; Neubig, Graham; Li, Yuanzhi; Yue, Xiang				Lam, Wai/GNW-3026-2022						VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?								Arxiv											1	1;2024-04-09;https://www.arxiv.org/abs/2404.05955v1	arXiv:2404.05955			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 09 2024	2024	Multimodal Large Language models (MLLMs) have shown promise in web-related tasks, but evaluating their performance in the web domain remains a challenge due to the lack of comprehensive benchmarks. Existing benchmarks are either designed for general multimodal tasks, failing to capture the unique characteristics of web pages, or focus on end-to-end web agent tasks, unable to measure fine-grained abilities such as OCR, understanding, and grounding. In this paper, we introduce bench{}, a multimodal benchmark designed to assess the capabilities of MLLMs across a variety of web tasks. bench{} consists of seven tasks, and comprises 1.5K human-curated instances from 139 real websites, covering 87 sub-domains. We evaluate 14 open-source MLLMs, Gemini Pro, Claude-3 series, and GPT-4V(ision) on bench{}, revealing significant challenges and performance gaps. Further analysis highlights the limitations of current MLLMs, including inadequate grounding in text-rich environments and subpar performance with low-resolution image inputs. We believe bench{} will serve as a valuable resource for the research community and contribute to the creation of more powerful and versatile MLLMs for web-related applications.																																	2024-04-22	PPRN:88469443		
J	Verma, Vivek; Fleisig, Eve; Tomlin, Nicholas; Klein, Dan				Verma, Vivek/Q-8508-2019						Ghostbuster: Detecting Text Ghostwritten by Large Language Models								Arxiv											3	3;2024-04-05;https://www.arxiv.org/abs/2305.15047v3| 2;2023-11-13;https://www.arxiv.org/abs/2305.15047v2| 1;2023-05-24;https://www.arxiv.org/abs/2305.15047v1	arXiv:2305.15047			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 05 2024	2024	We introduce Ghostbuster, a state-of-the-art system for detecting AI-generated text. Our method works by passing documents through a series of weaker language models, running a structured search over possible combinations of their features, and then training a classifier on the selected features to predict whether documents are AI-generated. Crucially, Ghostbuster does not require access to token probabilities from the target model, making it useful for detecting text generated by black-box models or unknown model versions. In conjunction with our model, we release three new datasets of human- and AI-generated text as detection benchmarks in the domains of student essays, creative writing, and news articles. We compare Ghostbuster to a variety of existing detectors, including DetectGPT and GPTZero, as well as a new RoBERTa baseline. Ghostbuster achieves 99.0 F1 when evaluated across domains, which is 5.9 F1 higher than the best preexisting model. It also outperforms all previous approaches in generalization across writing domains (+7.5 F1), prompting strategies (+2.1 F1), and language models (+4.4 F1). We also analyze the robustness of our system to a variety of perturbations and paraphrasing attacks and evaluate its performance on documents written by non-native English speakers.																																	2024-04-21	PPRN:72715624		
J	Li, Zhan; Chen, Zhang; Li, Zhong; Xu, Yi				Li, Zhan/LXA-4088-2024						Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis								Arxiv											2	2;2024-04-04;https://www.arxiv.org/abs/2312.16812v2| 1;2023-12-28;https://www.arxiv.org/abs/2312.16812v1	arXiv:2312.16812			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 04 2024	2024	Novel view synthesis of dynamic scenes has been an intriguing yet challenging problem. Despite recent advancements, simultaneously achieving high-resolution photorealistic results, real-time rendering, and compact storage remains a formidable task. To address these challenges, we propose Spacetime Gaussian Feature Splatting as a novel dynamic scene representation, composed of three pivotal components. First, we formulate expressive Spacetime Gaussians by enhancing 3D Gaussians with temporal opacity and parametric motion/rotation. This enables Spacetime Gaussians to capture static, dynamic, as well as transient content within a scene. Second, we introduce splatted feature rendering, which replaces spherical harmonics with neural features. These features facilitate the modeling of view- and time-dependent appearance while maintaining small size. Third, we leverage the guidance of training error and coarse depth to sample new Gaussians in areas that are challenging to converge with existing pipelines. Experiments on several established real-world datasets demonstrate that our method achieves state-of-the-art rendering quality and speed, while retaining compact storage. At 8K resolution, our lite-version model can render at 60 FPS on an Nvidia RTX 4090 GPU. 																																	2024-04-20	PPRN:86852005		
J	Lin, Peiqin; Ji, Shaoxiong; Tiedemann, Jorg; Martins, Andre F.T.; Schuetze, Hinrich				Lin, Peiqin/AAD-1470-2022; Torres Martins, Andre Filipe/JXL-9782-2024; Ji, Shaoxiong/AAI-9628-2020						MaLA-500: Massive Language Adaptation of Large Language Models								Arxiv											2	2;2024-04-03;https://www.arxiv.org/abs/2401.13303v2| 1;2024-01-24;https://www.arxiv.org/abs/2401.13303v1	arXiv:2401.13303			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 03 2024	2024	Large language models (LLMs) have advanced the state of the art in natural language processing. However, their predominant design for English or a limited set of languages creates a substantial gap in their effectiveness for low-resource languages. To bridge this gap, we introduce MaLA-500, a novel large language model designed to cover an extensive range of 534 languages. To train MaLA-500, we employ vocabulary extension and continued pretraining on LLaMA 2 with Glot500-c. Our intrinsic evaluation demonstrates that MaLA-500 is better at predicting the given texts of low-resource languages than existing multilingual LLMs. Moreover, the extrinsic evaluation of in-context learning shows that MaLA-500 outperforms previous LLMs on SIB200 and Taxi1500 by a significant margin, i.e., 11.68% and 4.82% marco-average accuracy across languages. 																																	2024-04-18	PPRN:87316972		
J	Stojkovic, Jovan; Choukse, Esha; Zhang, Chaojie; Goiri, Inigo; Torrellas, Josep										Towards Greener LLMs: Bringing Energy-Efficiency to the Forefront of LLM Inference								Arxiv											1	1;2024-03-29;https://www.arxiv.org/abs/2403.20306v1	arXiv:2403.20306			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Mar 29 2024	2024	With the ubiquitous use of modern large language models (LLMs) across industries, the inference serving for these models is ever expanding. Given the high compute and memory requirements of modern LLMs, more and more top-of-the-line GPUs are being deployed to serve these models. Energy availability has come to the forefront as the biggest challenge for data center expansion to serve these models. In this paper, we present the trade-offs brought up by making energy efficiency the primary goal of LLM serving under performance SLOs. We show that depending on the inputs, the model, and the service-level agreements, there are several knobs available to the LLM inference provider to use for being energy efficient. We characterize the impact of these knobs on the latency, throughput, as well as the energy. By exploring these trade-offs, we offer valuable insights into optimizing energy usage without compromising on performance, thereby paving the way for sustainable and cost-effective LLM deployment in data center environments.																																	2024-04-15	PPRN:88342034		
J	Bakshi, Ainesh; Liu, Allen; Moitra, Ankur; Tang, Ewin										High-Temperature Gibbs States are Unentangled and Efficiently Preparable								Arxiv											2	2;2025-02-24;https://www.arxiv.org/abs/2403.16850v2| 1;2024-03-25;https://www.arxiv.org/abs/2403.16850v1	arXiv:2403.16850			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 25 2024	2024	We show that thermal states of local Hamiltonians are separable above a constant temperature. Specifically, for a local Hamiltonian $H$ on a graph with degree $mathfrak{d}$, its Gibbs state at inverse temperature β, denoted by $rho =e^{-beta H}/ textrm{tr}(e^{-beta H})$, is a classical distribution over product states for all $beta < 1/(cmathfrak{d})$, where $c$ is a constant. This sudden death of thermal entanglement upends conventional wisdom about the presence of short-range quantum correlations in Gibbs states. Moreover, we show that we can efficiently sample from the distribution over product states. In particular, for any $beta < 1/( c mathfrak{d}^3)$, we can prepare a state $epsilon$-close to $rho$ in trace distance with a depth-one quantum circuit and $textrm{poly}(n) log(1/epsilon)$ classical overhead. A priori the task of preparing a Gibbs state is a natural candidate for achieving super-polynomial quantum speedups, but our results rule out this possibility above a fixed constant temperature.																																	2025-08-07	PPRN:88278098		
J	Song, Menghan; Zhao, Jiarui; Cheng, Meng; Xu, Cenke; Scherer, Michael M.; Janssen, Lukas; Meng, Zi Yang				Cheng, Meng/G-2562-2010; Janssen, Lukas/F-4926-2018; Scherer, Michael/P-1384-2019						Deconfined quantum criticality lost								Arxiv											3	3;2025-01-02;https://www.arxiv.org/abs/2307.02547v5| 2;2024-04-01;https://www.arxiv.org/abs/2307.02547v4| 1;2024-03-25;https://www.arxiv.org/abs/2307.02547v3	arXiv:2307.02547			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 25 2024	2024	Over the past two decades, the enigma of the deconfined quantum critical point (DQCP) has attracted broad attention across the condensed matter, quantum field theory, and high-energy physics communities, as it is expected to offer a new paradigm in theory, experiment, and numerical simulations that goes beyond the Landau-Ginzburg-Wilson framework of symmetry breaking and phase transitions. However, the nature of DQCP has been controversial. For instance, in the square-lattice spin-1/2 $J$-$Q$ model, believed to realize the DQCP between Néel and valence bond solid states, conflicting results, such as first-order versus continuous transition, and critical exponents incompatible with conformal bootstrap bounds, have been reported. The enigma of DQCP is exemplified in its anomalous logarithmic subleading contribution in its entanglement entropy (EE), which was discussed in recent studies. In the current work, we demonstrate that similar anomalous logarithmic behavior persists in a class of models analogous to the DQCP. We systematically study the quantum EE of square-lattice SU($N$) DQCP spin models. Based on large-scale quantum Monte Carlo computation of the EE, we show that for a series of $N$ smaller than a critical value, the anomalous logarithmic behavior always exists in the EE, which implies that the previously determined DQCPs in these models do not belong to conformal fixed points. In contrast, when $Nge N_c$ with a finite $N_c$ that we evaluate to lie between $7$ and $8$, the DQCPs are consistent with conformal fixed points that can be understood within the Abelian Higgs field theory with $N$ complex components.																																	2025-08-07	PPRN:88281424		
J	Chen, Yongchao; Arkin, Jacob; Dawson, Charles; Zhang, Yang; Roy, Nicholas; Fan, Chuchu				fan, chuchu/T-3197-2019						AutoTAMP: Autoregressive Task and Motion Planning with LLMs as Translators and Checkers								Arxiv											3	3;2024-03-22;https://www.arxiv.org/abs/2306.06531v3| 2;2023-09-27;https://www.arxiv.org/abs/2306.06531v2| 1;2023-06-10;https://www.arxiv.org/abs/2306.06531v1	arXiv:2306.06531			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Mar 22 2024	2024	For effective human -robot interaction, robots need to understand, plan, and execute complex, long -horizon tasks described by natural language. Recent advances in large language models (LLMs) have shown promise for translating natural language into robot action sequences for complex tasks. However, existing approaches either translate the natural language directly into robot trajectories or factor the inference process by decomposing language into task sub -goals and relying on a motion planner to execute each sub -goal. When complex environmental and temporal constraints are involved, inference over planning tasks must be performed jointly with motion plans using traditional task -and -motion planning (TAMP) algorithms, making factorization into subgoals untenable. Rather than using LLMs to directly plan task sub -goals, we instead perform few -shot translation from natural language task descriptions to an intermediate task representation that can then be consumed by a TAMP algorithm to jointly solve the task and motion plan. To improve translation, we automatically detect and correct both syntactic and semantic errors via autoregressive re -prompting, resulting in significant improvements in task completion. We show that our approach outperforms several methods using LLMs as planners in complex task domains. See our project website§ for prompts, videos, and code.																																	2024-04-13	PPRN:73299910		
J	Blondel, Mathieu; Roulet, Vincent										The Elements of Differentiable Programming								Arxiv											1	1;2024-03-21;https://www.arxiv.org/abs/2403.14606v1	arXiv:2403.14606			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 21 2024	2024	Artificial intelligence has recently experienced remarkable advances, fueled by large models, vast datasets, accelerated hardware, and, last but not least, the transformative power of differentiable programming. This new programming paradigm enables end-to-end differentiation of complex computer programs (including those with control flows and data structures), making gradient-based optimization of program parameters possible. As an emerging paradigm, differentiable programming builds upon several areas of computer science and applied mathematics, including automatic differentiation, graphical models, optimization and statistics. This book presents a comprehensive review of the fundamental concepts useful for differentiable programming. We adopt two main perspectives, that of optimization and that of probability, with clear analogies between the two. Differentiable programming is not merely the differentiation of programs, but also the thoughtful design of programs intended for differentiation. By making programs differentiable, we inherently introduce probability distributions over their execution, providing a means to quantify the uncertainty associated with program outputs.																																	2024-04-19	PPRN:88260469		
J	Karras, Tero; Aittala, Miika; Lehtinen, Jaakko; Hellsten, Janne; Aila, Timo; Laine, Samuli				Lehtinen, Jaakko/G-2328-2013						Analyzing and Improving the Training Dynamics of Diffusion Models								Arxiv											2	2;2024-03-20;https://www.arxiv.org/abs/2312.02696v2| 1;2023-12-05;https://www.arxiv.org/abs/2312.02696v1	arXiv:2312.02696			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 20 2024	2024	Diffusion models currently dominate the field of data-driven image synthesis with their unparalleled scaling to large datasets. In this paper, we identify and rectify several causes for uneven and ineffective training in the popular ADM diffusion model architecture, without altering its high-level structure. Observing uncontrolled magnitude changes and imbalances in both the network activations and weights over the course of training, we redesign the network layers to preserve activation, weight, and update magnitudes on expectation. We find that systematic application of this philosophy eliminates the observed drifts and imbalances, resulting in considerably better networks at equal computational complexity. Our modifications improve the previous record FID of 2.41 in ImageNet-512 synthesis to 1.81, achieved using fast deterministic sampling. As an independent contribution, we present a method for setting the exponential moving average (EMA) parameters post-hoc, i.e., after completing the training run. This allows precise tuning of EMA length without the cost of performing several training runs, and reveals its surprising interactions with network architecture, training time, and guidance.																																	2024-04-12	PPRN:86403250		
J	Tang, Shitao; Chen, Jiacheng; Wang, Dilin; Tang, Chengzhou; Zhang, Fuyang; Fan, Yuchen; Chandra, Vikas; Furukawa, Yasutaka; Ranjan, Rakesh				Zhang, Fuweng/AAI-2164-2019						MVDiffusion++: A Dense High-resolution Multi-view Diffusion Model for Single or Sparse-view 3D Object Reconstruction								Arxiv											2	2;2024-03-18;https://www.arxiv.org/abs/2402.12712v2| 1;2024-02-20;https://www.arxiv.org/abs/2402.12712v1	arXiv:2402.12712			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 18 2024	2024	This paper presents a neural architecture MVDiffusion++ for 3D object reconstruction that synthesizes dense and high-resolution views of an object given one or a few images without camera poses. MVDiffusion++ achieves superior flexibility and scalability with two surprisingly simple ideas: 1) A "pose-free architecture'' where standard self-attention among 2D latent features learns 3D consistency across an arbitrary number of conditional and generation views without explicitly using camera pose information; and 2) A ``view dropout strategy'' that discards a substantial number of output views during training, which reduces the training-time memory footprint and enables dense and high-resolution view synthesis at test time. We use the Objaverse for training and the Google Scanned Objects for evaluation with standard novel view synthesis and 3D reconstruction metrics, where MVDiffusion++ significantly outperforms the current state of the arts. We also demonstrate a text-to-3D application example by combining MVDiffusion++ with a text-to-image generative model.																																	2024-04-11	PPRN:87776596		
J	Laurencon, Hugo; Tronchon, Leo; Sanh, Victor										Unlocking the conversion of Web Screenshots into HTML Code with the WebSight Dataset								Arxiv											1	1;2024-03-14;https://www.arxiv.org/abs/2403.09029v1	arXiv:2403.09029			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 14 2024	2024	Using vision-language models (VLMs) in web development presents a promising strategy to increase efficiency and unblock no-code solutions: by providing a screenshot or a sketch of a UI, a VLM could generate the code to reproduce it, for instance in a language like HTML. Despite the advancements in VLMs for various tasks, the specific challenge of converting a screenshot into a corresponding HTML has been minimally explored. We posit that this is mainly due to the absence of a suitable, high-quality dataset. This work introduces WebSight, a synthetic dataset consisting of 2 million pairs of HTML codes and their corresponding screenshots. We fine-tune a foundational VLM on our dataset and show proficiency in converting webpage screenshots to functional HTML code. To accelerate the research in this area, we open-source WebSight.																																	2024-04-11	PPRN:88140350		
J	Zhu, Kaijie; Chen, Jiaao; Wang, Jindong; Gong, Neil Zhenqiang; Yang, Diyi; Xie, Xing				Zhu, Kaijie/KHX-8423-2024; wang, jindong/ACD-8485-2022						DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks								Arxiv											3	3;2024-03-14;https://www.arxiv.org/abs/2309.17167v3| 2;2023-10-05;https://www.arxiv.org/abs/2309.17167v2| 1;2023-09-29;https://www.arxiv.org/abs/2309.17167v1	arXiv:2309.17167			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 14 2024	2024	Large language models (LLMs) have achieved remarkable performance in various evaluation benchmarks. However, concerns are raised about potential data contamination in their considerable volume of training corpus. Moreover, the static nature and fixed complexity of current benchmarks may inadequately gauge the advancing capabilities of LLMs. In this paper, we introduce DyVal, a general and flexible protocol for dynamic evaluation of LLMs. Based on our framework, we build graph-informed DyVal by leveraging the structural advantage of directed acyclic graphs to dynamically generate evaluation samples with controllable complexities. DyVal generates challenging evaluation sets on reasoning tasks including mathematics, logical reasoning, and algorithm problems. We evaluate various LLMs ranging from Flan-T5-large to GPT-3.5-Turbo and GPT-4. Experiments show that LLMs perform worse in DyVal-generated evaluation samples with different complexities, highlighting the significance of dynamic evaluation. We also analyze the failure cases and results of different prompting methods. Moreover, DyVal-generated samples are not only evaluation sets, but also helpful data for fine-tuning to improve the performance of LLMs on existing benchmarks. We hope that DyVal can shed light on future evaluation research of LLMs. Code is available at: https://github.com/microsoft/promptbench.																																	2024-04-11	PPRN:85339102		
J	Xue, Zeyue; Song, Guanglu; Guo, Qiushan; Liu, Boxiao; Zong, Zhuofan; Liu, Yu; Luo, Ping				Luo, Ping/HGE-7623-2022; Guo, Qiushan/KYP-2884-2024; Liu, Boxiao/HNP-5912-2023; Li, Hongsheng/AES-5328-2022						RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths								Arxiv											4	4;2024-03-10;https://www.arxiv.org/abs/2305.18295v5| 3;2023-12-21;https://www.arxiv.org/abs/2305.18295v4| 2;2023-09-19;https://www.arxiv.org/abs/2305.18295v3| 1;2023-05-29;https://www.arxiv.org/abs/2305.18295v1	arXiv:2305.18295			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 10 2024	2024	Text -to -image generation has recently witnessed remarkable achievements. We introduce a text -conditional image diffusion model, termed RAPHAEL, to generate highly artistic images, which accurately portray the text prompts, encompassing multiple nouns, adjectives, and verbs. This is achieved by stacking tens of mixtureof -experts (MoEs) layers, i.e., space-MoE and time-MoE layers, enabling billions of diffusion paths (routes) from the network input to the output. Each path intuitively functions as a “painter” for depicting a particular textual concept onto a specified image region at a diffusion timestep. Comprehensive experiments reveal that RAPHAEL outperforms recent cutting -edge models, such as Stable Diffusion, ERNIE-ViLG 2.0, DeepFloyd, and DALL-E 2, in terms of both image quality and aesthetic appeal. Firstly, RAPHAEL exhibits superior performance in switching images across diverse styles, such as Japanese comics, realism, cyberpunk, and ink illustration. Secondly, a single model with three billion parameters, trained on 1, 000 A100 GPUs for two months, achieves a state-of-the-art zero -shot FID score of 6.61 on the COCO dataset. Furthermore, RAPHAEL significantly surpasses its counterparts in human evaluation on the ViLG-300 benchmark. We believe that RAPHAEL holds the potential to propel the frontiers of image generation research in both academia and industry, paving the way for future breakthroughs in this rapidly evolving field. More details can be found on a webpage: https: //raphael-painter.github.io/.																																	2024-04-04	PPRN:72757049		
J	Ehsan, Upol; Passi, Samir; Liao, Q. Vera; Chan, Larry; Lee, I-Hsiang; Muller, Michael; Riedl, Mark O.										The Who in XAI: How AI Background Shapes Perceptions of AI Explanations								Arxiv											1	1;2024-03-05;https://www.arxiv.org/abs/2107.13509v2	arXiv:2107.13509			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 05 2024	2024	Explainability of AI systems is critical for users to take informed actions. Understanding "who" opens the black-box of AI is just as important as opening it. We conduct a mixed-methods study of how two different groups--people with and without AI background--perceive different types of AI explanations. Quantitatively, we share user perceptions along five dimensions. Qualitatively, we describe how AI background can influence interpretations, elucidating the differences through lenses of appropriation and cognitive heuristics. We find that (1) both groups showed unwarranted faith in numbers for different reasons and (2) each group found value in different explanations beyond their intended design. Carrying critical implications for the field of XAI, our findings showcase how AI generated explanations can have negative consequences despite best intentions and how that could lead to harmful manipulation of trust. We propose design interventions to mitigate them.																																	2024-04-03	PPRN:88047637		
J	Dat, Jean-Francois; Helm, David; Kurinczuk, Robert; Moss, Gilbert										Moduli of Langlands Parameters								Arxiv											2	2;2024-02-29;https://www.arxiv.org/abs/2009.06708v3| 1;2020-09-14;https://www.arxiv.org/abs/2009.06708v2	arXiv:2009.06708			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 29 2024	2024	Let F be a non-archimedean local field of residue characteristic p, let Gˆ be a split reductive group scheme over Z[1/P] with an action of WF, and let LG denote the semidirect product Gˆ ⋊ WF. We construct a moduli space of Langlands parameters WF → LG, and show that it is locally of finite type and flat over Z[1/P], and that it is a reduced local complete intersection. We give parameterizations of the connected components and the irreducible components of the geometric fibers of this space, and parameterizations of the connected components of the total space over Z[1/P] (under mild hypotheses) and over Zℓ for ℓ ≠ p. In each case, we show precisely how each connected component identifies with the “principal” connected component attached to a smaller split reductive group scheme. Finally, we study the GIT quotient of this space by Gˆ and give a description of its fibers up to homeomorphism, and a complete description of its ring of functions after inverting an explicit finite set of primes depending only on LG.																																	2024-11-09	PPRN:69650173		
J	Yang, Sherry; Walker, Jacob; Parker-Holder, Jack; Du, Yilun; Bruce, Jake; Barreto, Andre; Abbeel, Pieter; Schuurmans, Dale										Video as the New Language for Real-World Decision Making								Arxiv											1	1;2024-02-27;https://www.arxiv.org/abs/2402.17139v1	arXiv:2402.17139			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 27 2024	2024	Both text and video data are abundant on the internet and support large-scale self-supervised learning through next token or frame prediction. However, they have not been equally leveraged: language models have had significant real-world impact, whereas video generation has remained largely limited to media entertainment. Yet video data captures important information about the physical world that is difficult to express in language. To address this gap, we discuss an under-appreciated opportunity to extend video generation to solve tasks in the real world. We observe how, akin to language, video can serve as a unified interface that can absorb internet knowledge and represent diverse tasks. Moreover, we demonstrate how, like language models, video generation can serve as planners, agents, compute engines, and environment simulators through techniques such as in-context learning, planning and reinforcement learning. We identify major impact opportunities in domains such as robotics, self-driving, and science, supported by recent work that demonstrates how such advanced capabilities in video generation are plausibly within reach. Lastly, we identify key challenges in video generation that mitigate progress. Addressing these challenges will enable video generation models to demonstrate unique value alongside language models in a wider array of AI applications.																																	2024-03-25	PPRN:87923341		
J	Liu, Zhiwei; Yao, Weiran; Zhang, Jianguo; Yang, Liangwei; Liu, Zuxin; Tan, Juntao; Choubey, Prafulla K.; Lan, Tian; Wu, Jason; Wang, Huan; Heinecke, Shelby; Xiong, Caiming; Savarese, Silvio				Zhang, Junying/C-2036-2013; Choubey, Prafulla/O-8619-2018; Liu, Zhi-Wei/G-6187-2011; Yang, Lingwei/AHC-6477-2022; Liu, Zuxin/GQY-8303-2022						AgentLite: A Lightweight Library for Building and Advancing Task-Oriented LLM Agent System								Arxiv											1	1;2024-02-23;https://www.arxiv.org/abs/2402.15538v1	arXiv:2402.15538			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 23 2024	2024	The booming success of LLMs initiates rapid development in LLM agents. Though the foundation of an LLM agent is the generative model, it is critical to devise the optimal reasoning strategies and agent architectures. Accordingly, LLM agent research advances from the simple chain-of-thought prompting to more complex ReAct and Reflection reasoning strategy; agent architecture also evolves from single agent generation to multi-agent conversation, as well as multi-LLM multi-agent group chat. However, with the existing intricate frameworks and libraries, creating and evaluating new reasoning strategies and agent architectures has become a complex challenge, which hinders research investigation into LLM agents. Thus, we open-source a new AI agent library, AgentLite, which simplifies this process by offering a lightweight, user-friendly platform for innovating LLM agent reasoning, architectures, and applications with ease. AgentLite is a task-oriented framework designed to enhance the ability of agents to break down tasks and facilitate the development of multi-agent systems. Furthermore, we introduce multiple practical applications developed with AgentLite to demonstrate its convenience and flexibility. 																																	2024-03-24	PPRN:87886141		
J	Qian, Tianwen; Chen, Jingjing; Zhuo, Linhai; Jiao, Yang; Jiang, Yu-Gang				chen, huan/KEC-2019-2024						NuScenes-QA: A Multi-modal Visual Question Answering Benchmark for Autonomous Driving Scenario								Arxiv											2	2;2024-02-20;https://www.arxiv.org/abs/2305.14836v2| 1;2023-05-24;https://www.arxiv.org/abs/2305.14836v1	arXiv:2305.14836			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 20 2024	2024	We introduce a novel visual question answering (VQA) task in the context of autonomous driving, aiming to answer natural language questions based on street-view clues. Compared to traditional VQA tasks, VQA in autonomous driving scenario presents more challenges. Firstly, the raw visual data are multi-modal, including images and point clouds captured by camera and LiDAR, respectively. Secondly, the data are multi-frame due to the continuous, real-time acquisition. Thirdly, the outdoor scenes exhibit both moving foreground and static background. Existing VQA benchmarks fail to adequately address these complexities. To bridge this gap, we propose NuScenes-QA, the first benchmark for VQA in the autonomous driving scenario, encompassing 34K visual scenes and 460K question-answer pairs. Specifically, we leverage existing 3D detection annotations to generate scene graphs and design question templates manually. Subsequently, the question-answer pairs are generated programmatically based on these templates. Comprehensive statistics prove that our NuScenes-QA is a balanced large-scale benchmark with diverse question formats. Built upon it, we develop a series of baselines that employ advanced 3D detection and VQA techniques. Our extensive experiments highlight the challenges posed by this new task.																																	2024-03-20	PPRN:72715208		
J	Sha, Zeyang; Zhang, Yang										Prompt Stealing Attacks Against Large Language Models								Arxiv											1	1;2024-02-20;https://www.arxiv.org/abs/2402.12959v1	arXiv:2402.12959			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 20 2024	2024	The increasing reliance on large language models (LLMs) such as ChatGPT in various fields emphasizes the importance of “prompt engineering,” a technology to improve the quality of model outputs. With companies investing significantly in expert prompt engineers and educational resources rising to meet market demand, designing high-quality prompts has become an intriguing challenge. In this paper, we propose a novel attack against LLMs, named prompt stealing attacks. Our proposed prompt stealing attack aims to steal these well-designed prompts based on the generated answers. The prompt stealing attack contains two primary modules: the parameter extractor and the prompt reconstructor. The goal of the parameter extractor is to figure out the properties of the original prompts. We first observe that most prompts fall into one of three categories: direct prompt, role-based prompt, and in-context prompt. Our parameter extractor first tries to distinguish the type of prompts based on the generated answers. Then, it can further predict which role or how many contexts are used based on the types of prompts. Following the parameter extractor, the prompt reconstructor can be used to reconstruct the original prompts based on the generated answers and the extracted features. The final goal of the prompt reconstructor is to generate the reversed prompts, which are similar to the original prompts. Our experimental results show the remarkable performance of our proposed attacks. Our proposed attacks add a new dimension to the study of prompt engineering and call for more attention to the security issues on LLMs.																																	2024-11-09	PPRN:87806356		
J	Meng, Fanqing; Shao, Wenqi; Lu, Quanfeng; Gao, Peng; Zhang, Kaipeng; Qiao, Yu; Luo, Ping				Qiao, Yu/ABD-5787-2021; Meng, fanqing/AAE-7775-2022; Luo, Ping/HGE-7623-2022						ChartAssisstant: A Universal Chart Multimodal Language Model via Chart-to-Table Pre-training and Multitask Instruction Tuning								Arxiv											3	3;2024-02-15;https://www.arxiv.org/abs/2401.02384v3| 2;2024-01-10;https://www.arxiv.org/abs/2401.02384v2| 1;2024-01-04;https://www.arxiv.org/abs/2401.02384v1	arXiv:2401.02384			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 15 2024	2024	Charts play a vital role in data visualization, understanding data patterns, and informed decision -making. However, their unique combination of graphical elements (e.g., bars, lines) and textual components (e.g., labels, legends) poses challenges for general-purpose multimodal models. While vision -language models trained on chart data excel in comprehension, they struggle with generalization. To address these challenges, we propose ChartAssistant, a chart -based vision -language model for universal chart comprehension and reasoning. ChartAssistant leverages ChartSFT, a comprehensive dataset covering diverse chart -related tasks with basic (e.g. bars and pies) and specialized (e.g. radars, and bubbles) chart types. It undergoes a two -stage training process, starting with pre -training on chart -to -table parsing to align chart and text, followed by multitask instruction -following finetuning. This approach enables ChartAssistant to achieve competitive performance across various chart tasks. Experimental results demonstrate significant performance gains over the state-of-the-art UniChart and Chartllama method, especially outperforming them on real -world chart data with zero -shot setting. The code and data are available at https://github.com/OpenGVLab/ChartAst.																																	2024-03-10	PPRN:86964705		
J	Schatzki, Louis; Larocca, Martin; Nguyen, Quynh T.; Sauvage, Frederic; Cerezo, M.				Cerezo, Marco/ABD-9254-2020						Theoretical Guarantees for Permutation-Equivariant Quantum Neural Networks								Arxiv											1	1;2024-02-14;https://www.arxiv.org/abs/2210.09974v3	arXiv:2210.09974			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 14 2024	2024	Despite the great promise of quantum machine learning models, there are several challenges one must overcome before unlocking their full potential. For instance, models based on quantum neural networks (QNNs) can suffer from excessive local minima and barren plateaus in their training landscapes. Recently, the nascent field of geometric quantum machine learning (GQML) has emerged as a potential solution to some of those issues. The key insight of GQML is that one should design architectures, such as equivariant QNNs, encoding the symmetries of the problem at hand. Here, we focus on problems with permutation symmetry (i.e., symmetry group Sn), and show how to build Sn-equivariant QNNs. We provide an analytical study of their performance, proving that they do not suffer from barren plateaus, quickly reach overparametrization, and generalize well from small amounts of data. To verify our results, we perform numerical simulations for a graph state classification task. Our work provides theoretical guarantees for equivariant QNNs, thus indicating the power and potential of GQML.																																	2024-03-01	PPRN:22942170		
J	Zhou, Yongchao; Alon, Uri; Chen, Xinyun; Wang, Xuezhi; Agarwal, Rishabh; Zhou, Denny				Chen, Xinyun/ABZ-9877-2022						Transformers Can Achieve Length Generalization But Not Robustly								Arxiv											1	1;2024-02-14;https://www.arxiv.org/abs/2402.09371v1	arXiv:2402.09371			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 14 2024	2024	Length generalization, defined as the ability to extrapolate from shorter training sequences to longer test ones, is a significant challenge for language models. This issue persists even with large-scale Transformers handling relatively straightforward tasks. In this paper, we test the Transformer's ability of length generalization using the task of addition of two integers. We show that the success of length generalization is intricately linked to the data format and the type of position encoding. Using the right combination of data format and position encodings, we show for the first time that standard Transformers can extrapolate to a sequence length that is 2.5x the input length. Nevertheless, unlike in-distribution generalization, length generalization remains fragile, significantly influenced by factors like random weight initialization and training data order, leading to large variances across different random seeds.																																	2024-05-25	PPRN:87688309		
J	Melas-Kyriazi, Luke; Laina, Iro; Rupprecht, Christian; Neverova, Natalia; Vedaldi, Andrea; Gafni, Oran; Kokkinos, Filippos				Rupprecht, Christian/ABF-7744-2021; Неверова, Наталья/A-8316-2014						IM-3D: Iterative Multiview Diffusion and Reconstruction for High-Quality 3D Generation								Arxiv											1	1;2024-02-13;https://www.arxiv.org/abs/2402.08682v1	arXiv:2402.08682			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 13 2024	2024	Most text-to-3D generators build upon off-the-shelf text-to-image models trained on billions of images. They use variants of Score Distillation Sampling (SDS), which is slow, somewhat unstable, and prone to artifacts. A mitigation is to fine-tune the 2D generator to be multi-view aware, which can help distillation or can be combined with reconstruction networks to output 3D objects directly. In this paper, we further explore the design space of text-to-3D models. We significantly improve multi-view generation by considering video instead of image generators. Combined with a 3D reconstruction algorithm which, by using Gaussian splatting, can optimize a robust image-based loss, we directly produce high-quality 3D outputs from the generated views. Our new method, IM-3D, reduces the number of evaluations of the 2D generator network 10-100x, resulting in a much more efficient pipeline, better quality, fewer geometric inconsistencies, and higher yield of usable 3D assets.																																	2024-05-25	PPRN:87669029		
J	Pourreza, Mohammadreza; Rafiei, Davood				Rafiei, Davood/AAF-8442-2020						DTS-SQL: Decomposed Text-to-SQL with Small Large Language Models								Arxiv											1	1;2024-02-02;https://www.arxiv.org/abs/2402.01117v1	arXiv:2402.01117			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 02 2024	2024	Leading models for the text-to-SQL task heavily rely on proprietary Large Language Models (LLMs), posing concerns over data privacy. Closing the performance gap between small open-source models and large proprietary models is crucial to mitigate this reliance. To this end, we introduce a novel two-stage fine-tuning approach that decomposes the task into two simpler tasks. Through comprehensive evaluation on two large cross-domain datasets and two small LLMs, we show that this approach improves execution accuracy by 3 to 7 percent, effectively aligning the performance of open-source models with their proprietary counterparts.																																	2024-05-25	PPRN:87509153		
J	Motlagh, Farzad Nourmohammadzadeh; Hajizadeh, Mehrdad; Majd, Mehryar; Najafi, Pejman; Cheng, Feng; Meinel, Christoph				Motlagh, Farzad/AAV-2322-2021						Large Language Models in Cybersecurity: State-of-the-Art								Arxiv											1	1;2024-01-30;https://www.arxiv.org/abs/2402.00891v1	arXiv:2402.00891			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 30 2024	2024	The rise of Large Language Models (LLMs) has revolutionized our comprehension of intelligence bringing us closer to Artificial Intelligence. Since their introduction, researchers have actively explored the applications of LLMs across diverse fields, significantly elevating capabilities. Cybersecurity, traditionally resistant to data-driven solutions and slow to embrace machine learning, stands out as a domain. This study examines the existing literature, providing a thorough characterization of both defensive and adversarial applications of LLMs within the realm of cybersecurity. Our review not only surveys and categorizes the current landscape but also identifies critical research gaps. By evaluating both offensive and defensive applications, we aim to provide a holistic understanding of the potential risks and opportunities associated with LLM-driven cybersecurity.																																	2024-02-19	PPRN:87507432		
J	Athron, Peter; Balazs, Csaba; Fowlie, Andrew; Morris, Lachlan; Wu, Lei				Athron, Peter/AAR-4710-2021						Cosmological phase transitions: from perturbative particle physics to gravitational waves								Arxiv											3	3;2024-01-22;https://www.arxiv.org/abs/2305.02357v3| 2;2023-12-24;https://www.arxiv.org/abs/2305.02357v2| 1;2023-05-03;https://www.arxiv.org/abs/2305.02357v1	arXiv:2305.02357			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 22 2024	2024	Gravitational waves (GWs) were recently detected for the first time. This revolutionary discovery opens a new way of learning about particle physics through GWs from first-order phase transitions (FOPTs) in the early Universe. FOPTs could occur when new fundamental symmetries are spontaneously broken down to the Standard Model and are a vital ingredient in solutions of the matter anti-matter asymmetry problem. The purpose of our work is to review the path from a particle physics model to GWs, which contains many specialized parts, so here we provide a timely review of all the required steps, including: (i) building a finite-temperature effective potential in a particle physics model and checking for FOPTs; (ii) computing transition rates; (iii) analyzing the dynamics of bubbles of true vacuum expanding in a thermal plasma; (iv) characterizing a transition using thermal parameters; and, finally, (v) making predictions for GW spectra using the latest simulations and theoretical results and considering the detectability of predicted spectra at future GW detectors. For each step we emphasize the subtleties, advantages and drawbacks of different methods, discuss open questions and review the state-of-art approaches available in the literature. This provides everything a particle physicist needs to begin exploring GW phenomenology.																																	2024-04-02	PPRN:67324316		
J	Yang, Senqiao; Qu, Tianyuan; Lai, Xin; Tian, Zhuotao; Peng, Bohao; Liu, Shu; Jia, Jiaya				Tian, Zhuotao/HJP-1597-2023; Jia, Jiaya/I-3251-2012						LISA++: An Improved Baseline for Reasoning Segmentation with Large Language Model								Arxiv											2	2;2024-01-22;https://www.arxiv.org/abs/2312.17240v3| 1;2024-01-03;https://www.arxiv.org/abs/2312.17240v2	arXiv:2312.17240			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 22 2024	2024	While LISA effectively bridges the gap between segmentation and large language models to enable reasoning segmentation, it poses certain limitations: unable to distinguish different instances of the target region, and constrained by the pre-defined textual response formats. In this work, we introduce LISA++, an update to the existing LISA model, focusing on improving core functionalities while keeping the base architecture intact. The main enhancements in LISA++ include: textbf{1) Enhanced Segmentation}: The instance segmentation ability has been added, providing a more detailed scene analysis along with the existing multi-region semantic segmentation. textbf{2) More Natural Conversation}: Improved capability for multi-turn dialogue, with the ability to incorporate segmentation results directly into text responses, i.e., Segmentation in Dialogue (SiD). These improvements are achieved by curating the existing samples of generic segmentation datasets, aimed specifically at enhancing the segmentation and conversational skills without structural change and additional data sources. Comparative analysis with the original LISA model shows significant advancements in these areas, positioning LISA++ as a notable upgrade in visual understanding and interaction. LISA++'s adaptability and improved features highlight the versatility of the mask-as-embedding paradigm proposed by LISA, and the potential as a foundational model for diverse applications.																																	2024-05-25	PPRN:86953146		
J	Yang, Ke; Liu, Jiateng; Wu, John; Yang, Chaoqi; Fung, Yi R.; Li, Sha; Huang, Zixuan; Cao, Xu; Wang, Xingyao; Wang, Yiquan; Ji, Heng; Zhai, Chengxiang				wang, yiquan/GXH-8579-2022; Cao, Xu/K-8388-2019; YANG, Ke/LRT-6874-2024; Huang, Zixuan/AID-4221-2022						If LLM Is the Wizard, Then Code Is the Wand: A Survey on How Code Empowers Large Language Models to Serve as Intelligent Agents								Arxiv											2	2;2024-01-08;https://www.arxiv.org/abs/2401.00812v2| 1;2024-01-01;https://www.arxiv.org/abs/2401.00812v1	arXiv:2401.00812			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 08 2024	2024	The prominent large language models (LLMs) of today differ from past language models not only in size, but also in the fact that they are trained on a combination of natural language and formal language (code). As a medium between humans and computers, code translates high-level goals into executable steps, featuring standard syntax, logical consistency, abstraction, and modularity. In this survey, we present an overview of the various benefits of integrating code into LLMs' training data. Specifically, beyond enhancing LLMs in code generation, we observe that these unique properties of code help (i) unlock the reasoning ability of LLMs, enabling their applications to a range of more complex natural language tasks; (ii) steer LLMs to produce structured and precise intermediate steps, which can then be connected to external execution ends through function calls; and (iii) take advantage of code compilation and execution environment, which also provides diverse feedback for model improvement. In addition, we trace how these profound capabilities of LLMs, brought by code, have led to their emergence as intelligent agents (IAs) in situations where the ability to understand instructions, decompose goals, plan and execute actions, and refine from feedback are crucial to their success on downstream tasks. Finally, we present several key challenges and future directions of empowering LLMs with code.																																	2024-01-25	PPRN:86904327		
J	Yang, Kaiyu; Poesia, Gabriel; He, Jingxuan; Li, Wenda; Lauter, Kristin; Chaudhuri, Swarat; Song, Dawn				He, Jingxuan/NAX-7297-2025						Formal Mathematical Reasoning: A New Frontier in AI								Arxiv											1	1;2024-12-20;https://www.arxiv.org/abs/2412.16075v1	arXiv:2412.16075			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 20 2024	2024	AI for Mathematics (AI4Math) is not only intriguing intellectually but also crucial for AI-driven discovery in science, engineering, and beyond. Extensive efforts on AI4Math have mirrored techniques in NLP, in particular, training large language models on carefully curated math datasets in text form. As a complementary yet less explored avenue, formal mathematical reasoning is grounded in formal systems such as proof assistants, which can verify the correctness of reasoning and provide automatic feedback. In this position paper, we advocate for formal mathematical reasoning and argue that it is indispensable for advancing AI4Math to the next level. In recent years, we have seen steady progress in using AI to perform formal reasoning, including core tasks such as theorem proving and autoformalization, as well as emerging applications such as verifiable generation of code and hardware designs. However, significant challenges remain to be solved for AI to truly master mathematics and achieve broader impact. We summarize existing progress, discuss open challenges, and envision critical milestones to measure future success. At this inflection point for formal mathematical reasoning, we call on the research community to come together to drive transformative advancements in this field.																																	2025-01-24	PPRN:120116535		
J	Gao, Yingqi; Liu, Yifu; Li, Xiaoxia; Shi, Xiaorong; Zhu, Yin; Wang, Yiming; Li, Shiqi; Li, Wei; Hong, Yuntao; Luo, Zhiling; Gao, Jinyang; Mou, Liyu; Li, Yu				Wang, Yiming/HNB-7294-2023; Liu, Yi-Fu/HHC-4631-2022						XiYan-SQL: A Multi-Generator Ensemble Framework for Text-to-SQL								Arxiv											2	2;2024-12-17;https://www.arxiv.org/abs/2411.08599v2| 1;2024-11-13;https://www.arxiv.org/abs/2411.08599v1	arXiv:2411.08599			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 17 2024	2024	To tackle the challenges of large language model performance in natural language to SQL tasks, we introduce XiYan-SQL, an innovative framework that employs a multi-generator ensemble strategy to improve candidate generation. We introduce M-Schema, a semi-structured schema representation method designed to enhance the understanding of database structures. To enhance the quality and diversity of generated candidate SQL queries, XiYan-SQL integrates the significant potential of in-context learning (ICL) with the precise control of supervised fine-tuning. On one hand, we propose a series of training strategies to fine-tune models to generate high-quality candidates with diverse preferences. On the other hand, we implement the ICL approach with an example selection method based on named entity recognition to prevent overemphasis on entities. The refiner optimizes each candidate by correcting logical or syntactical errors. To address the challenge of identifying the best candidate, we fine-tune a selection model to distinguish nuances of candidate SQL queries. The experimental results on multiple dialect datasets demonstrate the robustness of XiYan-SQL in addressing challenges across different scenarios. Overall, our proposed XiYan-SQL achieves the state-of-the-art execution accuracy of 75.63% on Bird benchmark, 89.65% on the Spider test set, 69.86% on SQL-Eval, 41.20% on NL2GQL. The proposed framework not only enhances the quality and diversity of SQL queries but also outperforms previous methods.																																	2025-01-24	PPRN:119220680		
J	Juodzbalis, Ignas; Maiolino, Roberto; Baker, William M.; Tacchella, Sandro; Scholtz, Jan; D'Eugenio, Francesco; Schneider, Raffaella; Trinca, Alessandro; Valiante, Rosa; Decoursey, Christa; Curti, Mirko; Carniani, Stefano; Chevallard, Jacopo; Graaff, Anna de; Arribas, Santiago; Bennett, Jake S.; Bourne, Martin A.; Bunker, Andrew J.; Charlot, Stephane; Jiang, Brian; Koudmani, Sophie; Perna, Michele; Robertson, Brant; Sijacki, Debora; Uebler, Hannah; Williams, Christina C.; Willott, Chris; Witstok, Joris				D'Eugenio, Francesco/H-2606-2019; Baker, William/KUD-6412-2024; Tacchella, Sandro/AAT-1602-2021; Bourne, Martin/CAJ-5393-2022; Robertson, Brant/AAA-6124-2022; BOEKER, TORSTEN/KVC-3022-2024; Witstok, Joris/GQA-8643-2022; Koudmani, Sophie/AAE-9051-2022; Arribas, Santiago/F-9277-2015						A dormant, overmassive black hole in the early Universe								Arxiv											2	2;2024-12-04;https://www.arxiv.org/abs/2403.03872v2| 1;2024-03-06;https://www.arxiv.org/abs/2403.03872v1	arXiv:2403.03872			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 04 2024	2024	Recent observations have found a large number of supermassive black holes already in place in the first few hundred million years after Big Bang, many of which appear overmassive relative to their host galaxy stellar mass when compared with local relation [1, 2, 3, 4, 5, 6, 7, 8, 9]. Several different models have proposed to explain these findings, ranging from heavy seeds to light seeds experiencing bursts of high accretion rate [10, 11, 12, 13, 14, 15, 16]. Yet, current datasets are unable to differentiate between these various scenarios. Here we report the detection, from the JADES survey, of broad Hα emission in a galaxy at z=6.68, which traces a black hole with mass of " 4 × 108M⊙ and accreting at a rate of only 0.02 times the Eddington limit. The black hole to host galaxy stellar mass ratio is " 0.4, i.e. about 1,000 times above the local relation, while the system is closer to the local relations in terms of dynamical mass and velocity dispersion of the host galaxy. This object is most likely the tip of the iceberg of a much larger population of dormant black holes around the epoch of reionisation. Its properties are consistent with scenarios in which short bursts of super-Eddington accretion have resulted in black hole overgrowth and massive gas expulsion from the accretion disk; in between bursts, black holes spend most of their life in a dormant state.																																	2025-04-19	PPRN:88047421		
J	Chiu, Yu Ying; Sharma, Ashish; Lin, Inna Wanyin; Althoff, Tim										A Computational Framework for Behavioral Assessment of LLM Therapists								Arxiv											2	2;2024-11-28;https://www.arxiv.org/abs/2401.00820v2| 1;2024-01-01;https://www.arxiv.org/abs/2401.00820v1	arXiv:2401.00820			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 28 2024	2024	The emergence of large language models (LLMs) like ChatGPT has increased interest in their use as therapists to address mental health challenges and the widespread lack of access to care. However, experts have emphasized the critical need for systematic evaluation of LLM-based mental health interventions to accurately assess their capabilities and limitations. Here, we propose BOLT, a proof-of-concept computational framework to systematically assess the conversational behavior of LLM therapists. We quantitatively measure LLM behavior across 13 psychotherapeutic approaches with in-context learning methods. Then, we compare the behavior of LLMs against high- and low-quality human therapy. Our analysis based on Motivational Interviewing therapy reveals that LLMs often resemble behaviors more commonly exhibited in low-quality therapy rather than high-quality therapy, such as offering a higher degree of problem-solving advice when clients share emotions. However, unlike low-quality therapy, LLMs reflect significantly more upon clients' needs and strengths. Our findings caution that LLM therapists still require further research for consistent, high-quality care.																																	2025-01-10	PPRN:86901309		
J	Li, Peng; Liu, Yuan; Long, Xiaoxiao; Zhang, Feihu; Lin, Cheng; Li, Mengfei; Qi, Xingqun; Zhang, Shanghang; Luo, Wenhan; Tan, Ping; Wang, Wenping; Liu, Qifeng; Guo, Yike				Luo, Wenhan/KXR-1375-2024; Zhang, Lisa/AAW-9795-2021						Era3D: High-Resolution Multiview Diffusion using Efficient Row-wise Attention								Arxiv											2	2;2024-11-27;https://www.arxiv.org/abs/2405.11616v3| 1;2024-05-29;https://www.arxiv.org/abs/2405.11616v2	arXiv:2405.11616			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 27 2024	2024	In this paper, we introduce Era3D, a novel multiview diffusion method that generates high-resolution multiview images from a single-view image. Despite significant advancements in multiview generation, existing methods still suffer from camera prior mismatch, inefficacy, and low resolution, resulting in poor-quality multiview images. Specifically, these methods assume that the input images should comply with a predefined camera type, e.g. a perspective camera with a fixed focal length, leading to distorted shapes when the assumption fails. Moreover, the full- image or dense multiview attention they employ leads to a dramatic explosion of computational complexity as image resolution increases, resulting in prohibitively expensive training costs. To bridge the gap between assumption and reality, Era3D first proposes a diffusion-based camera prediction module to estimate the focal length and elevation of the input image, which allows our method to generate images without shape distortions. Furthermore, a simple but efficient attention layer, named row-wise attention, is used to enforce epipolar priors in the multiview diffusion, facilitating efficient cross-view information fusion. Consequently, compared with state-of-the-art methods, Era3D generates high-quality multiview images with up to a 512×512 resolution while reducing computation complexity of multiview attention by 12x times. Comprehensive experiments demonstrate the superior generation power of Era3D- it can reconstruct high-quality and detailed 3D meshes from diverse single-view input images, significantly outperforming baseline multiview diffusion methods. 																																	2025-01-08	PPRN:91460915		
J	Wang, Ruicheng; Xu, Sicheng; Dai, Cassie; Xiang, Jianfeng; Deng, Yu; Tong, Xin; Yang, Jiaolong				Xiang, Jian-Feng/ABH-1934-2020						MoGe: Unlocking Accurate Monocular Geometry Estimation for Open-Domain Images with Optimal Training Supervision								Arxiv											2	2;2024-11-27;https://www.arxiv.org/abs/2410.19115v2| 1;2024-10-24;https://www.arxiv.org/abs/2410.19115v1	arXiv:2410.19115			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 27 2024	2024	We present MoGe, a powerful model for recovering 3D geometry from monocular open-domain images. Given a single image, our model directly predicts a 3D point map of the captured scene with an affine-invariant representation, which is agnostic to true global scale and shift. This new representation precludes ambiguous supervision in training and facilitates effective geometry learning. Furthermore, we propose a set of novel global and local geometry supervision techniques that empower the model to learn high-quality geometry. These include a robust, optimal, and efficient point cloud alignment solver for accurate global shape learning, and a multi-scale local geometry loss promoting precise local geometry supervision. We train our model on a large, mixed dataset and demonstrate its strong generalizability and high accuracy. In our comprehensive evaluation on diverse unseen datasets, our model significantly outperforms state-of-the-art methods across all tasks, including monocular estimation of 3D point map, depth map, and camera field of view.																																	2025-01-08	PPRN:118852058		
J	Fu, Deqing; Chen, Tian-Qi; Jia, Robin; Sharan, Vatsal				Chen, Tianqi/AAT-2978-2020						Transformers Learn to Achieve Second-Order Convergence Rates for In-Context Linear Regression								Arxiv											3	3;2024-11-16;https://www.arxiv.org/abs/2310.17086v3| 2;2024-05-31;https://www.arxiv.org/abs/2310.17086v2| 1;2023-10-26;https://www.arxiv.org/abs/2310.17086v1	arXiv:2310.17086			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 16 2024	2024	Transformers excel at in-context learning (ICL)—learning from demonstrations without parameter updates—but how they do so remains a mystery. Recent work suggests that Transformers may internally run Gradient Descent (GD), a first-order optimization method, to perform ICL. In this paper, we instead demonstrate that Transformers learn to approximate second-order optimization methods for ICL. For in-context linear regression, Transformers share a similar convergence rate as Iterative Newton’s Method; both are exponentially faster than GD. Empirically, predictions from successive Transformer layers closely match different iterations of Newton’s Method linearly, with each middle layer roughly computing 3 iterations; thus, Transformers and Newton’s method converge at roughly the same rate. In contrast, Gradient Descent converges exponentially more slowly. We also show that Transformers can learn in-context on ill-conditioned data, a setting where Gradient Descent struggles but Iterative Newton succeeds. Finally, to corroborate our empirical findings, we prove that Transformers can implement k iterations of Newton’s method with k + O (1) layers.																																	2024-12-27	PPRN:85822714		
J	Sun, Wenqiang; Chen, Shuo; Liu, Fangfu; Chen, Zilong; Duan, Yueqi; Zhang, Jun; Wang, Yikai				wang, yikai/HLW-7052-2023; Zhang, Jun/M-8009-2013; Liu, Fangfu/KPQ-4616-2024; Chen, Zilong/HCI-2162-2022						DimensionX: Create Any 3D and 4D Scenes from a Single Image with Controllable Video Diffusion								Arxiv											1	1;2024-11-07;https://www.arxiv.org/abs/2411.04928v1	arXiv:2411.04928			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 07 2024	2024	In this paper, we introduce DimensionX, a framework designed to generate photorealistic 3D and 4D scenes from just a single image with video diffusion. Our approach begins with the insight that both the spatial structure of a 3D scene and the temporal evolution of a 4D scene can be effectively represented through sequences of video frames. While recent video diffusion models have shown remarkable success in producing vivid visuals, they face limitations in directly recovering 3D/4D scenes due to limited spatial and temporal controllability during generation. To overcome this, we propose ST-Director, which decouples spatial and temporal factors in video diffusion by learning dimension-aware LoRAs from dimension-variant data. This controllable video diffusion approach enables precise manipulation of spatial structure and temporal dynamics, allowing us to reconstruct both 3D and 4D representations from sequential frames with the combination of spatial and temporal dimensions. Additionally, to bridge the gap between generated videos and real-world scenes, we introduce a trajectory-aware mechanism for 3D generation and an identity-preserving denoising strategy for 4D generation. Extensive experiments on various real-world and synthetic datasets demonstrate that DimensionX achieves superior results in controllable video generation, as well as in 3D and 4D scene generation, compared with previous methods. 																																	2024-12-16	PPRN:119073757		
J	Wu, Kailu; Liu, Fangfu; Cai, Zhihan; Yan, Runjie; Wang, Hanyang; Hu, Yating; Duan, Yueqi; Ma, Kaisheng				Wang, Hanyang/JFB-3017-2023; Liu, Fangfu/KPQ-4616-2024						Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single Image								Arxiv											3	3;2024-10-28;https://www.arxiv.org/abs/2405.20343v3| 2;2024-06-13;https://www.arxiv.org/abs/2405.20343v2| 1;2024-05-30;https://www.arxiv.org/abs/2405.20343v1	arXiv:2405.20343			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Oct 28 2024	2024	In this work, we introduce Unique3D, a novel image-to-3D framework for efficiently generating high-quality 3D meshes from single-view images, featuring state-of-the-art generation fidelity and strong generalizability. Previous methods based on Score Distillation Sampling (SDS) can produce diversified 3D results by distilling 3D knowledge from large 2D diffusion models, but they usually suffer from long per-case optimization time with inconsistent issues. Recent works address the problem and generate better 3D results either by finetuning a multi-view diffusion model or training a fast feed-forward model. However, they still lack intricate textures and complex geometries due to inconsistency and limited generated resolution. To simultaneously achieve high fidelity, consistency, and efficiency in single image-to-3D, we propose a novel framework Unique3D that includes a multi-view diffusion model with a corresponding normal diffusion model to generate multi-view images with their normal maps, a multi-level upscale process to progressively improve the resolution of generated orthographic multi-views, as well as an instant and consistent mesh reconstruction algorithm called ISOMER, which fully integrates the color and geometric priors into mesh results. Extensive experiments demonstrate that our Unique3D significantly outperforms other image-to-3D baselines in terms of geometric and textural details.																																	2024-12-06	PPRN:89110067		
J	Li, Long; Xu, Weiwen; Guo, Jiayan; Zhao, Ruochen; Li, Xinxuan; Yuan, Yuqian; Zhang, Boqiang; Jiang, Yuming; Xin, Yifei; Dang, Ronghao; Rong, Yu; Zhao, Deli; Feng, Tian; Bing, Lidong				Dang, Ronghao/GRF-4990-2022; Guo, Jiayan/GPC-7597-2022; Rong, Yu/HGU-8599-2022						Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents								Arxiv											3	3;2024-10-25;https://www.arxiv.org/abs/2410.13185v4| 2;2024-10-24;https://www.arxiv.org/abs/2410.13185v3| 1;2024-10-17;https://www.arxiv.org/abs/2410.13185v1	arXiv:2410.13185			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 25 2024	2024	Effective research ideation is a critical step for scientific research. However, the exponential increase in scientific literature makes it challenging for researchers to stay current with recent advances and identify meaningful research directions. Recent developments in large language models (LLMs) suggest a promising avenue for automating the generation of novel research ideas. However, existing methods for idea generation either trivially prompt LLMs or directly expose LLMs to extensive literature without indicating useful information. Inspired by the research process of human researchers, we propose a Chain-of-Ideas (CoI) agent, an LLMbased agent that organizes relevant literature in a chain structure to effectively mirror the progressive development in a research domain. This organization facilitates LLMs to capture the current advancements in research, thereby enhancing their ideation capabilities. Furthermore, we propose Idea Arena, an evaluation protocol that can comprehensively evaluate idea generation methods from different perspectives, aligning closely with the preferences of human researchers. Experimental results indicate that the CoI agent consistently outperforms other methods and shows comparable quality as humans in research idea generation. Moreover, our CoI agent is budget-friendly, with a minimum cost of $0.50 to generate a candidate idea and its corresponding experimental design1 .																																	2024-12-09	PPRN:115508312		
J	Pace, Alizee; Mallinson, Jonathan; Malmi, Eric; Krause, Sebastian; Severyn, Aliaksei										West-of-N: Synthetic Preferences for Self-Improving Reward Models								Arxiv											2	2;2024-10-25;https://www.arxiv.org/abs/2401.12086v2| 1;2024-01-22;https://www.arxiv.org/abs/2401.12086v1	arXiv:2401.12086			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 25 2024	2024	The success of reinforcement learning from human feedback (RLHF) in language model alignment is strongly dependent on the quality of the underlying reward model. In this paper, we present a novel approach to improve reward model quality by generating synthetic preference data, thereby augmenting the training dataset with on-policy, high-quality preference pairs. Motivated by the promising results of Best-of-N sampling strategies in language model training, we extend their application to reward model training. This results in a self-training strategy to generate preference pairs by selecting the best and worst candidates in a pool of responses to a given query. Empirically, we find that this approach improves the performance of any reward model, with an effect comparable to the addition of a similar quantity of human preference data. This work opens up new avenues of research for improving RLHF for language model alignment, by offering synthetic preference generation as a solution to reward modeling challenges.																																	2024-11-29	PPRN:87272384		
J	Ding, Zihan; Zhang, Amy; Tian, Yuandong; Zheng, Qinqing										Diffusion World Model: Future Modeling Beyond Step-by-Step Rollout for Offline Reinforcement Learning								Arxiv											4	4;2024-10-15;https://www.arxiv.org/abs/2402.03570v4| 3;2024-06-16;https://www.arxiv.org/abs/2402.03570v3| 2;2024-02-11;https://www.arxiv.org/abs/2402.03570v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.03570v1	arXiv:2402.03570			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 15 2024	2024	We introduce Diffusion World Model (DWM), a conditional diffusion model capable of predicting multistep future states and rewards concurrently. As opposed to traditional one-step dynamics models, DWM offers long-horizon predictions in a single forward pass, eliminating the need for recursive queries. We integrate DWM into model-based value estimation[14], where the short-term return is simulated by future trajectories sampled from DWM. In the context of offline reinforcement learning, DWM can be viewed as a conservative value regularization through generative modeling. Alternatively, it can be seen as a data source that enables offline Q-learning with synthetic data. Our experiments on the D4RL dataset confirm the robustness of DWM to long-horizon simulation. In terms of absolute performance, DWM significantly surpasses one-step dynamics models with a 44% performance gain, and is comparable to or slightly surpassing their model-free counterparts.																																	2024-11-11	PPRN:87533745		
J	Dasari, Sudeep; Mees, Oier; Zhao, Sebastian; Srirama, Mohan Kumar; Levine, Sergey										The Ingredients for Robotic Diffusion Transformers								Arxiv											1	1;2024-10-14;https://www.arxiv.org/abs/2410.10088v1	arXiv:2410.10088			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 14 2024	2024	In recent years roboticists have achieved remarkable progress in solving increasingly general tasks on dexterous robotic hardware by leveraging high capacity Transformer network architectures and generative diffusion models. Unfortunately, combining these two orthogonal improvements has proven surprisingly difficult, since there is no clear and wellunderstood process for making important design choices. In this paper, we identify, study and improve key architectural design decisions for high-capacity diffusion transformer policies. The resulting models can efficiently solve diverse tasks on multiple robot embodiments, without the excruciating pain of persetup hyper-parameter tuning. By combining the results of our investigation with our improved model components, we are able to present a novel architecture, named DiT-Block Policy, that significantly outperforms the state of the art in solving long-horizon ( 1500+ time-steps) dexterous tasks on a bi-manual ALOHA robot. In addition, we find that our policies show improved scaling performance when trained on 10 hours of highly multi-modal, language annotated ALOHA demonstration data. We hope this work will open the door for future robot learning techniques that leverage the efficiency of generative diffusion modeling with the scalability of large scale transformer architectures. Code, robot dataset, and videos are available at: https://dit-policy.github.io																																	2024-11-07	PPRN:114002367		
J	Chiang, Yuan; Hsieh, Elvis; Chou, Chia-Hong; Riebesell, Janosh				Chiang, Yuan/GLR-2596-2022						LLaMP: Large Language Model Made Powerful for High-fidelity Materials Knowledge Retrieval and Distillation								Arxiv											3	3;2024-10-09;https://www.arxiv.org/abs/2401.17244v3| 2;2024-06-02;https://www.arxiv.org/abs/2401.17244v2| 1;2024-01-30;https://www.arxiv.org/abs/2401.17244v1	arXiv:2401.17244			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 09 2024	2024	Reducing hallucination of Large Language Models (LLMs) is imperative for use in the sciences, where reliability and reproducibility are crucial. However, LLMs inherently lack long-term memory, making it a nontrivial, ad hoc , and often biased task to fine-tune them on domain-specific literature and data. Here we introduce LLaMP , a multimodal retrieval-augmented generation (RAG) framework of hierarchical reasoning-and-acting (ReAct) agents that can dynamically and recursively interact with computational and experimental data from the Materials Project (MP) and run atomistic simulations via high-throughput workflow interface. Without fine-tuning, LLaMP demonstrates strong tool-usage ability to comprehend and integrate various modalities of materials science concepts, fetch relevant data stores on the fly, process higher-order data (such as crystal structure and elastic tensor), and streamline complex tasks in computational materials and chemistry. We propose a metric combining uncertainty and confidence estimates to evaluate the self-consistency of responses by LLaMP and vanilla LLMs. Our benchmark shows that LLaMP effectively mitigates the intrinsic bias in LLMs, counteracting the errors on bulk moduli, electronic bandgaps, and formation energies that seem to derive from mixed data sources. We also demonstrate LLaMP’s capability to edit crystal structures and run annealing molecular dynamics simulations using pre-trained machine-learning interatomic potentials. The framework offers an intuitive and nearly hallucination-free approach to exploring and scaling materials informatics, and paves the way for future agentic scientific workflows and knowledge-grounded LLMs. Code and live demo are available at https://github.com/chiang-yuan/llamp .																																	2024-10-24	PPRN:87417362		
J	Ivison, Hamish; Wang, Yizhong; Liu, Jiacheng; Wu, Zeqiu; Pyatkin, Valentina; Lambert, Nathan; Smith, Noah A.; Choi, Yejin; Hajishirzi, Hannaneh										Unpacking DPO and PPO: Disentangling Best Practices for Learning from Preference Feedback								Arxiv											2	2;2024-10-07;https://www.arxiv.org/abs/2406.09279v2| 1;2024-06-13;https://www.arxiv.org/abs/2406.09279v1	arXiv:2406.09279			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 07 2024	2024	Learning from preference feedback has emerged as an essential step for improving the generation quality and performance of modern language models (LMs). Despite its widespread use, the way preference-based learning is applied varies wildly, with differing data, learning algorithms, and evaluations used, making disentangling the impact of each aspect difficult. In this work, we identify four core aspects of preference-based learning: preference data, learning algorithm, reward model, and policy training prompts,  systematically investigate the impact of these components on downstream model performance, and suggest a recipe for strong learning for preference feedback. Our findings indicate that all aspects are important for performance, with better preference data leading to the largest improvements, followed by the choice of learning algorithm, the use of improved reward models, and finally the use of additional unlabeled prompts for policy training. Notably, PPO outperforms DPO by up to 2.5% in math and 1.2% in general domains. High-quality preference data leads to improvements of up to 8% in instruction following and truthfulness. Despite significant gains of up to 5% in mathematical evaluation when scaling up reward models, we surprisingly observe marginal improvements in other categories.																																	2024-10-31	PPRN:89294021		
J	Manvi, Rohin; Khanna, Samar; Burke, Marshall; Lobell, David; Ermon, Stefano										Large Language Models are Geographically Biased								Arxiv											2	2;2024-10-05;https://www.arxiv.org/abs/2402.02680v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.02680v1	arXiv:2402.02680			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 05 2024	2024	Large Language Models (LLMs) inherently carry the biases contained in their training corpora, which can lead to the perpetuation of societal harm. As the impact of these foundation models grows, understanding and evaluating their biases becomes crucial to achieving fairness and accuracy. We propose to study what LLMs know about the world we live in through the lens of geography. This approach is particularly powerful as there is ground truth for the numerous aspects of human life that are meaningfully projected onto geographic space such as culture, race, language, politics, and religion. We show various problematic geographic biases, which we define as systemic errors in geospatial predictions. Initially, we demonstrate that LLMs are capable of making accurate zero-shot geospatial predictions in the form of ratings that show strong monotonic correlation with ground truth (Spearman’s ρ of up to 0.89). We then show that LLMs exhibit common biases across a range of objective and subjective topics. In particular, LLMs are clearly biased against locations with lower socioeconomic conditions (e.g. most of Africa) on a variety of sensitive subjective topics such as attractiveness, morality, and intelligence (Spearman’s ρ of up to 0.70). Finally, we introduce a bias score to quantify this and find that there is significant variation in the magnitude of bias across existing LLMs. 																																	2024-10-26	PPRN:87521896		
J	Yen, Howard; Gao, Tianyu; Hou, Minmin; Ding, Ke; Fleischer, Daniel; Izsak, Peter; Wasserblat, Moshe; Chen, Danqi				Hou, Minmin/KWT-4149-2024						HELMET: How to Evaluate Long-Context Language Models Effectively and Thoroughly								Arxiv											2	2;2024-10-03;https://www.arxiv.org/abs/2410.02694v1| 1;2024-10-03;https://www.arxiv.org/abs/2410.02694v1	arXiv:2410.02694			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 03 2024	2024	There have been many benchmarks for evaluating long-context language models (LCLMs), but developers often rely on synthetic tasks like needle-in-a-haystack (NIAH) or arbitrary subsets of tasks. It remains unclear whether they translate to the diverse downstream applications of LCLMs, and the inconsistency further complicates model comparison. We investigate the underlying reasons behind current practices and find that existing benchmarks often provide noisy signals due to low coverage of applications, insufficient lengths, unreliable metrics, and incompatibility with base models. In this work, we present HELMET (How to Evaluate Long-context Models Effectively and Thoroughly), a comprehensive benchmark encompassing seven diverse, application-centric categories. We also address many issues in previous benchmarks by adding controllable lengths up to 128k tokens, model-based evaluation for reliable metrics, and few-shot prompting for robustly evaluating base models. Consequently, we demonstrate that HELMET offers more reliable and consistent rankings of frontier LCLMs. Through a comprehensive study of 51 LCLMs, we find that (1) synthetic tasks like NIAH are not good predictors of downstream performance; (2) the diverse categories in HELMET exhibit distinct trends and low correlation with each other; and (3) while most LCLMs achieve perfect NIAH scores, open-source models significantly lag behind closed ones when the task requires full-context reasoning or following complex instructions -- the gap widens with increased lengths. Finally, we recommend using our RAG tasks for fast model development, as they are easy to run and more predictive of other downstream performance; ultimately, we advocate for a holistic evaluation across diverse tasks.																																	2024-10-27	PPRN:102598923		
J	Yuan, Tao; Ning, Xuefei; Zhou, Dong; Yang, Zhijie; Li, Shiyao; Zhuang, Minghui; Tan, Zheyue; Yao, Zhuyu; Lin, Dahua; Li, Boxun; Dai, Guohao; Yan, Shengen; Wang, Yu				Li, Shiyao/OYE-4903-2025; Li, Boxun/ABD-8514-2021; Lin, Dahua/W-6576-2019						LV-EVAL: VAL : A BALANCED LONG-CONTEXT BENCH- MARK WITH 5 LENGTH LEVELS UP TO 256K								Arxiv											2	2;2024-10-03;https://www.arxiv.org/abs/2402.05136v2| 1;2024-02-06;https://www.arxiv.org/abs/2402.05136v1	arXiv:2402.05136			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 03 2024	2024	State-of-the-art large language models (LLMs) are now claiming remarkable supported context lengths of 256k or even more. In contrast, the average context lengths of mainstream benchmarks are insufficient (5k-21k), and they suffer from potential knowledge leakage and inaccurate metrics, resulting in biased evaluation. This paper introduces LV-Eval, a challenging long-context benchmark with five length levels (16k, 32k, 64k, 128k, and 256k) reaching up to 256k words. LV-Eval features two main tasks, single-hop QA and multi-hop QA, comprising 11 bilingual datasets. The design of LV-Eval has incorporated three key techniques, namely confusing facts insertion, keyword and phrase replacement, and keyword-recall-based metric design. The advantages of LV-Eval include controllable evaluation across different context lengths, challenging test instances with confusing facts, mitigated knowledge leakage, and more objective evaluations. We evaluate 15 LLMs on LV-Eval and conduct ablation studies on the benchmarking techniques. The results reveal that: (i) Moonshot-v1 and recent large-scale open-source models, such as Qwen-2.5-72B and Llama-3.1-70B, achieve the highest performance on LV-Eval, particularly at lengths below 64k. (ii) Models exhibit distinct score trends. For example, GLM-4-9B-128k, Yi-6B-200k, and Llama3-8B-1M exhibit a relatively gentle degradation of performance, but their absolute performances may not necessarily be higher than those of LLMs with shorter context lengths. (iii) LLMs' performances can significantly degrade in the presence of confusing information, especially in the pressure test of "needle in a haystack". (iv) Issues related to knowledge leakage and inaccurate metrics introduce bias in evaluation, and these concerns are alleviated in LV-Eval. 																																	2024-10-18	PPRN:87568971		
J	Chatterjee, Arkya; Ji, Wenjie; Wen, Xiao-Gang										Emergent generalized symmetry and maximal symmetry-topological-order								Arxiv											1	1;2024-09-28;https://www.arxiv.org/abs/2212.14432v3	arXiv:2212.14432			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 28 2024	2024	A characteristic property of a gapless liquid state is its emergent symmetry and dual symmetry, associated with the conservation laws of symmetry charges and symmetry defects respectively. These conservation laws, considered on an equal footing, can’t be described simply by the representation theory of a group (or a higher group). They are best described in terms of a topological order (TO) with gappable boundary in one higher dimension ; we call this the symTO of the gapless state. The symTO can thus be considered a fingerprint of the gapless state. We propose that a largely complete characterization of a gapless state, up to local-low-energy equivalence, can be obtained in terms of its maximal emergent symTO. In this paper, we review the symmetry/topologicalorder (Symm/TO) correspondence and propose a definition of maximal symTO . We discuss various examples to illustrate these ideas. We find that the 1+1D Ising critical point has a maximal symTO described by the 2+1D double-Ising topological order. We provide a derivation of this result using symmetry twists in an exactly solvable model of the Ising critical point. The critical point in the 3-state Potts model has a maximal symTO of double (6,5)-minimal-model topological order. As an example of a noninvertible symmetry in 1+1D, we study the possible gapless states of a Fibonacci anyon chain with emergent double-Fibonacci symTO. We find the Fibonacci-anyon chain without translation symmetry has a critical point with unbroken double-Fibonacci symTO. In fact, such a critical theory has a maximal symTO of double (5,4)-minimal-model topological order. We argue that, in the presence of translation symmetry, the above critical point becomes a stable gapless phase with no symmetric relevant operator.																																	2024-10-10	PPRN:86280951		
J	Huang, Haifeng; Chen, Yilun; Wang, Zehan; Huang, Rongjie; Xu, Runsen; Wang, Tai; Liu, Luping; Cheng, Xize; Zhao, Yang; Pang, Jiangmiao; Zhao, Zhou				huang, haifeng/G-9256-2012; Chen, Yilun/IWV-1091-2023; Wang, Tai/MVV-1100-2025						Chat-Scene: Bridging 3D Scene and Large Language Models with Object Identifiers								Arxiv											3	3;2024-09-28;https://www.arxiv.org/abs/2312.08168v4| 2;2023-12-15;https://www.arxiv.org/abs/2312.08168v2| 1;2023-12-13;https://www.arxiv.org/abs/2312.08168v1	arXiv:2312.08168			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 28 2024	2024	Recent advancements in 3D Large Language Models (LLMs) have demonstrated promising capabilities for 3D scene understanding. However, previous methods exhibit deficiencies in general referencing and grounding capabilities for intricate scene comprehension. In this paper, we introduce the use of object identifiers and object-centric representations to interact with scenes at the object level. Specifically, we decompose the input 3D scene into a set of object proposals, each assigned a unique identifier token, which enables efficient object referencing and grounding during user-assistant interactions. Given the scarcity of scene-language data, we model the scene embeddings as a sequence of explicit object-level embeddings, derived from semantic-rich 2D or 3D representations. By employing object identifiers, we transform diverse 3D scene-language tasks into a unified question-answering format, facilitating joint training without the need for additional task-specific heads. With minimal fine-tuning on all downstream tasks, our model significantly outperforms existing methods on benchmarks including ScanRefer, Multi3DRefer, Scan2Cap, ScanQA, and SQA3D.																																	2024-10-10	PPRN:86574080		
J	Wake, Naoki; Kanehira, Atsushi; Sasabuchi, Kazuhiro; Takamatsu, Jun; Ikeuchi, Katsushi										GPT-4V(ision) for Robotics: Multimodal Task Planning from Human Demonstration								Arxiv											4	4;2024-09-26;https://www.arxiv.org/abs/2311.12015v4| 3;2024-08-19;https://www.arxiv.org/abs/2311.12015v3| 2;2024-05-06;https://www.arxiv.org/abs/2311.12015v2| 1;2023-11-20;https://www.arxiv.org/abs/2311.12015v1	arXiv:2311.12015			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 26 2024	2024	We introduce a pipeline that enhances a general-purpose Vision Language Model, GPT-4V(ision), to facilitate one-shot visual teaching for robotic manipulation. This system analyzes videos of humans performing tasks and outputs executable robot programs that incorporate insights into affordances. The process begins with GPT-4V analyzing the videos to obtain textual explanations of environmental and action details. A GPT-4-based task planner then encodes these details into a symbolic task plan. Subsequently, vision systems spatially and temporally ground the task plan in the videos. Objects are identified using an open-vocabulary object detector, and hand-object interactions are analyzed to pinpoint moments of grasping and releasing. This spatiotemporal grounding allows for the gathering of affordance information (e.g., grasp types, waypoints, and body postures) critical for robot execution. Experiments across various scenarios demonstrate the method's efficacy in enabling real robots to operate from one-shot human demonstrations. Meanwhile, quantitative tests have revealed instances of hallucination in GPT-4V, highlighting the importance of incorporating human supervision within the pipeline. 																																	2024-10-09	PPRN:86210857		
J	Giare, William										Dynamical Dark Energy Beyond Planck? Constraints from multiple CMB probes, DESI BAO and Type-Ia Supernovae								Arxiv											1	1;2024-09-25;https://www.arxiv.org/abs/2409.17074v1	arXiv:2409.17074			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 25 2024	2024	Baryon Acoustic Oscillation (BAO) measurements from the Dark Energy Spectroscopic Instrument (DESI) collaboration, when combined with Planck satellite Cosmic Microwave Background (CMB) data and Type Ia Supernovae, suggest a preference for Dynamical Dark Energy (DDE) at a significance level ranging from 2.5 σ to 3.9 σ. In this work, I test whether, and to what extent, this preference is supported by CMB experiments other than Planck. I analyze the Atacama Cosmology Telescope (ACT) and South Pole Telescope (SPT) temperature, polarization, and lensing spectra at small scales, eventually combining them with Planck or WMAP 9-year observations at large angular scales. My analysis shows that ACT and WMAP data, when combined with DESI BAO and Pantheon-plus Supernovae, yield independent constraints with a precision comparable to Planck. Notably, in this case, the cosmological constant value is recovered within two standard deviations. A preference for DDE reappears when Pantheon-plus is replaced with distance moduli measurements from the Dark Energy Survey Supernova program (DESy5). However, it remains less pronounced compared to the Planck-based results. When considering SPT data, no clear preference for DDE is found, although the parameter uncertainties are significantly larger compared to both Planckand ACT-based constraints. Overall, CMB experiments other than Planck generally weaken the evidence for DDE. I argue that the subsets of Planck data that strengthen the shift toward DDE are the temperature and E-mode polarization anisotropy measurements at large angular scales ℓ ≲ 30 .																																	2024-10-08	PPRN:98872369		
J	Sohal, Ramanjit; Prem, Abhinav										A Noisy Approach to Intrinsically Mixed-State Topological Order								Arxiv											3	3;2024-09-25;https://www.arxiv.org/abs/2403.13879v3| 2;2024-03-22;https://www.arxiv.org/abs/2403.13879v2| 1;2024-03-20;https://www.arxiv.org/abs/2403.13879v1	arXiv:2403.13879			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 25 2024	2024	We propose a general framework for studying two-dimensional (2D) topologically ordered states subject to local correlated errors and show that the resulting mixed-state can display intrinsically mixed-state topological order (imTO)—topological order which is not expected to occur in the ground state of 2D local gapped Hamiltonians. Specifically, we show that decoherence, previously interpreted as anyon condensation in a doubled Hilbert space, is more naturally phrased as, and provides a physical mechanism for, “gauging out” anyons in the original Hilbert space. We find that gauging out anyons generically results in imTO, with the decohered mixed-state strongly symmetric under certain anomalous 1-form symmetries. This framework lays bare a striking connection between the decohered density matrix and topological subsystem codes, which can appear as anomalous surface states of 3D topological orders. Through a series of examples, we show that the decohered state can display a classical memory, encode logical qubits (i.e., exhibit a quantum memory), and even host chiral or non-modular topological order. We argue that a partial classification of imTO is given in terms of non-modular braided fusion categories.																																	2025-03-15	PPRN:88259530		
J	Bai, Haotian; Lyu, Yuanhuiyi; Jiang, Lutao; Li, Sijia; Lu, Haonan; Lin, Xiaodong; Wang, Lin				wang, Lin/GQO-7901-2022						CompoNeRF: Text-guided Multi-object Compositional NeRF with Editable 3D Scene Layout								Arxiv											4	4;2024-09-24;https://www.arxiv.org/abs/2303.13843v5| 3;2023-12-02;https://www.arxiv.org/abs/2303.13843v3| 2;2023-09-15;https://www.arxiv.org/abs/2303.13843v2| 1;2023-03-24;https://www.arxiv.org/abs/2303.13843v1	arXiv:2303.13843			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 24 2024	2024	Text-to-3D form plays a crucial role in creating editable 3D scenes for AR/VR. Recent advances have shown promise in merging neural radiance fields (NeRFs) with pre-trained diffusion models for text-to-3D object generation. However, one enduring challenge is their inadequate capability to accurately parse and regenerate consistent multi-object environments. Specifically, these models encounter difficulties in accurately representing quantity and style prompted by multi-object texts, often resulting in a collapse of the rendering fidelity that fails to match the semantic intricacies. Moreover, amalgamating these elements into a coherent 3D scene is a substantial challenge, stemming from generic distribution inherent in diffusion models. To tackle the issue of 'guidance collapse' and further enhance scene consistency, we propose a novel framework, dubbed CompoNeRF, by integrating an editable 3D scene layout with object-specific and scene-wide guidance mechanisms. It initiates by interpreting a complex text into the layout populated with multiple NeRFs, each paired with a corresponding subtext prompt for precise object depiction. Next, a tailored composition module seamlessly blends these NeRFs, promoting consistency, while the dual-level text guidance reduces ambiguity and boosts accuracy. Noticeably, our composition design permits decomposition. This enables flexible scene editing and recomposition into new scenes based on the edited layout or text prompts. Utilizing the open-source Stable Diffusion model, CompoNeRF generates multi-object scenes with high fidelity. Remarkably, our framework achieves up to a textbf{54%} improvement by the multi-view CLIP score metric. Our user study indicates that our method has significantly improved semantic accuracy, multi-view consistency, and individual recognizability for multi-object scene generation.																																	2024-10-08	PPRN:48731324		
J	Lewis, Martha; Nayak, Nihal V.; Yu, Peilin; Yu, Qinan; Merullo, Jack; Bach, Stephen H.; Pavlick, Ellie				Lewis, Martha/AAA-8293-2022						Does CLIP Bind Concepts? Probing Compositionality in Large Image Models								Arxiv											2	2;2024-08-30;https://www.arxiv.org/abs/2212.10537v3| 1;2022-12-20;https://www.arxiv.org/abs/2212.10537v2	arXiv:2212.10537			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Aug 30 2024	2024	Large-scale neural network models combining text and images have made incredible progress in recent years. However, it remains an open question to what extent such models encode compositional representations of the concepts over which they operate, such as correctly identifying "red cube" by reasoning over the constituents "red" and "cube". In this work, we focus on the ability of a large pretrained vision and language model (CLIP) to encode compositional concepts and to bind variables in a structure-sensitive way (e.g., differentiating "cube behind sphere" from "sphere behind cube"). To inspect the performance of CLIP, we compare several architectures from research on compositional distributional semantics models (CDSMs), a line of research that attempts to implement traditional compositional linguistic structures within embedding spaces. We benchmark them on three synthetic datasets - single-object, two-object, and relational - designed to test concept binding. We find that CLIP can compose concepts in a single-object setting, but in situations where concept binding is needed, performance drops dramatically. At the same time, CDSMs also perform poorly, with best performance at chance level.																																	2024-09-06	PPRN:56448951		
J	Mueller, Nicolas M.; Czempin, Pavel; Dieckmann, Franziska; Froghyar, Adam; Boettinger, Konstantin				Czempin, Pavel/OJV-5055-2025						Does Audio Deepfake Detection Generalize?								Arxiv											2	2;2024-08-27;https://www.arxiv.org/abs/2203.16263v4| 1;2022-03-30;https://www.arxiv.org/abs/2203.16263v3	arXiv:2203.16263			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 27 2024	2024	Current text-to-speech algorithms produce realistic fakes of human voices, making deepfake detection a much-needed area of research. While researchers have presented various deep learning models for audio spoofs detection, it is often unclear exactly why these architectures are successful: Preprocessing steps, hyperparameter settings, and the degree of fine-tuning are not consistent across related work. Which factors contribute to success, and which are accidental? In this work, we address this problem: We systematize audio spoofing detection by re-implementing and uniformly evaluating twelve architectures from related work. We identify overarching features for successful audio deepfake detection, such as using cqtspec or logspec features instead of melspec features, which improves performance by 37% EER on average, all other factors constant. Additionally, we evaluate generalization capabilities: We collect and publish a new dataset consisting of 37.9 . 9 hours of found audio recordings of celebrities and politicians, of which 17.2 hours are deepfakes. We find that related work performs poorly on such real-world data (performance degradation of up to one thousand percent). This could suggest that the community has tailored its solutions too closely to the prevailing ASVspoof benchmark and that deepfakes are much harder to detect outside the lab than previously thought.																																	2024-09-06	PPRN:12132814		
J	Gu, Xinyang; Wang, Yen-Jen; Zhu, Xiang; Shi, Chengming; Guo, Yanjiang; Liu, Yichen; Chen, Jianyu				Zhu, Xiang/OZD-7832-2025						Advancing Humanoid Locomotion: Mastering Challenging Terrains with Denoising World Model Learning								Arxiv											1	1;2024-08-26;https://www.arxiv.org/abs/2408.14472v1	arXiv:2408.14472			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 26 2024	2024	Humanoid robots, with their human-like skeletal structure, are especially suited for tasks in human-centric environments. However, this structure is accompanied by additional challenges in locomotion controller design, especially in complex real-world environments. As a result, existing humanoid robots are limited to relatively simple terrains, either with model-based control or model-free reinforcement learning. In this work, we introduce Denoising World Model Learning (DWL), an end-to-end reinforcement learning framework for humanoid locomotion control, which demonstrates the world's first humanoid robot to master real-world challenging terrains such as snowy and inclined land in the wild, up and down stairs, and extremely uneven terrains. All scenarios run the same learned neural network with zero-shot sim-to-real transfer, indicating the superior robustness and generalization capability of the proposed method.																																	2024-09-06	PPRN:91549940		
J	Huang, Yuzhen; Zhang, Jinghan; Shan, Zifei; He, Junxian				HE, Junxian/OHV-2278-2025						Compression Represents Intelligence Linearly								Arxiv											2	2;2024-08-19;https://www.arxiv.org/abs/2404.09937v2| 1;2024-04-15;https://www.arxiv.org/abs/2404.09937v1	arXiv:2404.09937			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 19 2024	2024	There is a belief that learning to compress well will lead to intelligence. Recently, language modeling has been shown to be equivalent to compression, which offers a compelling rationale for the success of large language models (LLMs): the development of more advanced language models is essentially enhancing compression which facilitates intelligence. Despite such appealing discussions, little empirical evidence is present for the interplay between compression and intelligence. In this work, we examine their relationship in the context of LLMs, treating LLMs as data compressors. Given the abstract concept of "intelligence", we adopt the average downstream benchmark scores as a surrogate, specifically targeting intelligence related to knowledge and commonsense, coding, and mathematical reasoning. Across 12 benchmarks, our study brings together 31 public LLMs that originate from diverse organizations. Remarkably, we find that LLMs' intelligence -- reflected by average benchmark scores -- almost linearly correlates with their ability to compress external text corpora. These results provide concrete evidence supporting the belief that superior compression indicates greater intelligence. Furthermore, our findings suggest that compression efficiency, as an unsupervised metric derived from raw text corpora, serves as a reliable evaluation measure that is linearly associated with the model capabilities. We open-source our compression datasets as well as our data collection pipelines to facilitate future researchers to assess compression properly.																																	2024-08-28	PPRN:88532359		
J	Pipitone, Nicholas; Alami, Ghita Houir										LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain								Arxiv											1	1;2024-08-19;https://www.arxiv.org/abs/2408.10343v1	arXiv:2408.10343			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 19 2024	2024	Retrieval-Augmented Generation (RAG) systems are showing promising potential, and are becoming increasingly relevant in AI-powered legal applications. Existing benchmarks, such as LegalBench, assess the generative capabilities of Large Language Models (LLMs) in the legal domain, but there is a critical gap in evaluating the retrieval component of RAG systems. To address this, we introduce LegalBench-RAG, the first benchmark specifically designed to evaluate the retrieval step of RAG pipelines within the legal space. LegalBench-RAG emphasizes precise retrieval by focusing on extracting minimal, highly relevant text segments from legal documents. These highly relevant snippets are preferred over retrieving document IDs, or large sequences of imprecise chunks, both of which can exceed context window limitations. Long context windows cost more to process, induce higher latency, and lead LLMs to forget or hallucinate information. Additionally, precise results allow LLMs to generate citations for the end user. The LegalBench-RAG benchmark is constructed by retracing the context used in LegalBench queries back to their original locations within the legal corpus, resulting in a dataset of 6,858 query-answer pairs over a corpus of over 79M characters, entirely human-annotated by legal experts. We also introduce LegalBench-RAG-mini, a lightweight version for rapid iteration and experimentation. By providing a dedicated benchmark for legal retrieval, LegalBench-RAG serves as a critical tool for companies and researchers focused on enhancing the accuracy and performance of RAG systems in the legal domain. 																																	2024-08-31	PPRN:91500433		
J	Slattery, Peter; Saeri, Alexander K.; Grundy, Emily A.C.; Graham, Jess; Noetel, Michael; Uuk, Risto; Dao, James; Pour, Soroush; Casper, Stephen; Thompson, Neil				Thompson, Neil/T-9944-2019; Noetel, Michael/I-4534-2019						The AI Risk Repository: A Comprehensive Meta-Review, Database, and Taxonomy of Risks From Artificial Intelligence								Arxiv											1	1;2024-08-14;https://www.arxiv.org/abs/2408.12622v1	arXiv:2408.12622			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 14 2024	2024	The risks posed by Artificial Intelligence (AI) are of considerable concern to academics, auditors, policymakers, AI companies, and the public. However, a lack of shared understanding of AI risks can impede our ability to comprehensively discuss, research, and react to them. This paper addresses this gap by creating an AI Risk Repository to serve as a common frame of reference. This comprises a living database of 777 risks extracted from 43 taxonomies, which can be filtered based on two overarching taxonomies and easily accessed, modified, and updated via our website and online spreadsheets. We construct our Repository with a systematic review of taxonomies and other structured classifications of AI risk followed by an expert consultation. We develop our taxonomies of AI risk using a best-fit framework synthesis. Our high-level Causal Taxonomy of AI Risks classifies each risk by its causal factors (1) Entity: Human, AI; (2) Intentionality: Intentional, Unintentional; and (3) Timing: Pre-deployment; Post-deployment. Our mid-level Domain Taxonomy of AI Risks classifies risks into seven AI risk domains: (1) Discrimination & toxicity, (2) Privacy & security, (3) Misinformation, (4) Malicious actors & misuse, (5) Human-computer interaction, (6) Socioeconomic & environmental, and (7) AI system safety, failures, & limitations. These are further divided into 23 subdomains. The AI Risk Repository is, to our knowledge, the first attempt to rigorously curate, analyze, and extract AI risk frameworks into a publicly accessible, comprehensive, extensible, and categorized risk database. This creates a foundation for a more coordinated, coherent, and complete approach to defining, auditing, and managing the risks posed by AI systems.																																	2024-09-03	PPRN:91526415		
J	Min, Sewon; Gururangan, Suchin; Wallace, Eric; Shi, Weijia; Hajishirzi, Hannaneh; Smith, Noah A.; Zettlemoyer, Luke										SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore								Arxiv											2	2;2024-07-31;https://www.arxiv.org/abs/2308.04430v2| 1;2023-08-08;https://www.arxiv.org/abs/2308.04430v1	arXiv:2308.04430			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 31 2024	2024	The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.1																																	2024-08-08	PPRN:74315754		
J	Jiang, Jun-Qian; Giare, William; Gariazzo, Stefano; Dainotti, Maria Giovanna; Di Valentino, Eleonora; Mena, Olga; Pedrotti, Davide; Da Costa, Simony Santos; Vagnozzi, Sunny				Santos-da-Costa, Simony/KIH-7605-2024; Mena, Olga/W-4068-2018; Dainotti, Maria/AAD-3896-2022; Vagnozzi, Sunny/W-7331-2019; Gariazzo, Stefano/L-1693-2017						Neutrino cosmology after DESI: tightest mass upper limits, preference for the normal ordering, and tension with terrestrial observations								Arxiv											2	2;2024-07-25;https://www.arxiv.org/abs/2407.18047v1| 1;2024-07-25;https://www.arxiv.org/abs/2407.18047v1	arXiv:2407.18047			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 25 2024	2024	The recent DESI Baryon Acoustic Oscillation measurements have led to tight upper limits on the neutrino mass sum, potentially in tension with oscillation constraints requiring ∑mν ≳ 0.06eV. Under the physically motivated assumption of positive ∑mν, we study the extent to which these limits are tightened by adding other available cosmological probes, and robustly quantify the preference for the normal mass ordering over the inverted one, as well as the tension between cosmological and terrestrial data. Combining DESI data with Cosmic Microwave Background measurements and several late-time background probes, the tightest 2σ limit we find without including a local H0 prior is ∑mν < 0.05eV. This leads to a strong preference for the normal ordering, with Bayes factor relative to the inverted one of 46.5. Depending on the dataset combination and tension metric adopted, we quantify the tension between cosmological and terrestrial observations as ranging between 2.5σ and 5σ. These results are strenghtened when allowing for a time-varying dark energy component with equation of state lying in the physically motivated non-phantom regime, w(z) ≥ −1, highlighting an interesting synergy between the nature of dark energy and laboratory probes of the mass ordering. If these tensions persist and cannot be attributed to systematics, either or both standard neutrino (particle) physics or the underlying cosmological model will have to be questioned.																																	2024-08-21	PPRN:91102700		
J	Nawrot, Piotr; Lancucki, Adrian; Chochowski, Marcin; Tarjan, David; Ponti, Edoardo M.										Dynamic Memory Compression: Retrofitting LLMs for Accelerated Inference								Arxiv											2	2;2024-07-23;https://www.arxiv.org/abs/2403.09636v2| 1;2024-03-14;https://www.arxiv.org/abs/2403.09636v1	arXiv:2403.09636			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 23 2024	2024	Transformers have emerged as the backbone of large language models (LLMs). However, generation remains inefficient due to the need to store in memory a cache of key–value representations for past tokens, whose size scales linearly with the input sequence length and batch size. As a solution, we propose Dynamic Memory Compression (DMC), a method for online key–value cache compression at inference time. Most importantly, the model learns to apply different compression ratios in different heads and layers. We retrofit pre-trained LLMs such as Llama 2 (7B, 13B, and 70B) into DMC Transformers, achieving up to 7 × throughput increase during auto-regressive inference on an NVIDIA H100 GPU. DMC is applied via continued pre-training on a negligible percentage of the original data without adding any extra parameters. DMC preserves the original downstream performance with up to 4 × cache compression, outperforming up-trained grouped-query attention (GQA) and key–value eviction policies (H2O, TOVA). GQA and DMC can be even combined to obtain compounded gains. Hence, DMC can serve as a drop-in replacement for KV caching in existing LLMs to fit longer contexts and larger batches within any given memory budget.																																	2024-07-30	PPRN:88140517		
J	Liu, Yang; Guan, He; Luo, Chuanchen; Fan, Lue; Wang, Naiyan; Peng, Junran; Zhang, Zhaoxiang				Guan, He/GXZ-7062-2022; Zhang, Zhaoxiang/LTF-2817-2024; Fan, Lue/CAH-4825-2022						CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians								Arxiv											3	3;2024-07-17;https://www.arxiv.org/abs/2404.01133v3| 2;2024-04-07;https://www.arxiv.org/abs/2404.01133v2| 1;2024-04-01;https://www.arxiv.org/abs/2404.01133v1	arXiv:2404.01133			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 17 2024	2024	The advancement of real-time 3D scene reconstruction and novel view synthesis has been significantly propelled by 3D Gaussian Splatting (3DGS). However, effectively training large-scale 3DGS and rendering it in real-time across various scales remains challenging. This paper introduces CityGaussian (CityGS), which employs a novel divide-and-conquer training approach and Level-of-Detail (LoD) strategy for efficient large-scale 3DGS training and rendering. Specifically, the global scene prior and adaptive training data selection enables efficient training and seamless fusion. Based on fused Gaussian primitives, we generate different detail levels through compression, and realize fast rendering across various scales through the proposed block-wise detail levels selection and aggregation strategy. Extensive experimental results on large-scale scenes demonstrate that our approach attains state-of-the-art rendering quality, enabling consistent real-time rendering of largescale scenes across vastly different scales. 																																	2024-07-26	PPRN:88366079		
J	Bai, Ye; Chen, Jingping; Chen, Jitong; Chen, Wei; Chen, Zhuo; Ding, Chen; Dong, Linhao; Dong, Qianqian; Du, Yujiao; Gao, Kepan; Gao, Lu; Guo, Yi; Han, Minglun; Han, Ting; Hu, Wenchao; Hu, Xinying; Hu, Yuxiang; Hua, Deyu; Huang, Lu; Huang, Mingkun; Huang, Youjia; Jin, Jishuo; Kong, Fanliu; Lan, Zongwei; Li, Tianyu; Li, Xiaoyang; Li, Zeyang; Lin, Zehua; Liu, Rui; Liu, Shouda; Lu, Lu; Lu, Yizhou; Ma, Jingting; Ma, Shengtao; Pei, Yulin; Shen, Chen; Tan, Tian; Tian, Xiaogang; Tu, Ming; Wang, Bo; Wang, Hao; Wang, Yuping; Wang, Yuxuan; Xia, Hanzhang; Xia, Rui; Xie, Shuangyi; Xu, Hongmin; Yang, Meng; Zhang, Bihong; Zhang, Jun; Zhang, Wanyi; Zhang, Yang; Zhang, Yawei; Zheng, Yijie; Zou, Ming				Li, Tianyu/HPD-9021-2023; Gao, Lu/OVY-2417-2025; Hu, Wenchao/LSM-1924-2024; ding, chen/KDN-1285-2024; Huang, Youjia/GQY-7235-2022; Hu, Yuxiang/KUC-7551-2024; Han, minglun/MTF-1945-2025; Hu, Xin-ying/IQU-3093-2023; XIA, RUI/LMQ-2676-2024; Zhang, Wanyi/ABE-7109-2021; 陆, 逸洲/GXH-6148-2022; Chen, Jitong/P-4806-2017; Zou, Ming/ISA-7854-2023						Seed-ASR: Understanding Diverse Speech and Contexts with LLM-based Speech Recognition								Arxiv											1	1;2024-07-05;https://www.arxiv.org/abs/2407.04675v1	arXiv:2407.04675			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jul 05 2024	2024	Modern automatic speech recognition (ASR) model is required to accurately transcribe diverse speech signals (from different domains, languages, accents, etc) given the specific contextual information in various application scenarios. Classic end-to-end models fused with extra language models perform well, but mainly in data matching scenarios and are gradually approaching a bottleneck. In this work, we introduce Seed-ASR1, a large language model (LLM) based speech recognition model. Seed-ASR is developed based on the framework of audio conditioned LLM (AcLLM), leveraging the capabilities of LLMs by inputting continuous speech representations together with contextual information into the LLM. Through stage-wise large-scale training and the elicitation of context-aware capabilities in LLM, Seed-ASR demonstrates significant improvement over end-to-end models on comprehensive evaluation sets, including multiple domains, accents/dialects and languages. Additionally, Seed-ASR can be further deployed to support specific needs in various scenarios without requiring extra language models. Compared to recently released large ASR models, Seed-ASR achieves 10%-40% reduction in word (or character, for Chinese) error rates on Chinese and English public test sets, further demonstrating its powerful performance.																																	2025-01-24	PPRN:90726628		
J	Tao, Wei; Zhou, Yucheng; Wang, Yanlin; Zhang, Wenqiang; Zhang, Hongyu; Cheng, Yu				Tao, Wei/KGL-6588-2024; zhang, wenqiang/B-4685-2016						MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution								Arxiv											2	2;2024-06-27;https://www.arxiv.org/abs/2403.17927v2| 1;2024-03-26;https://www.arxiv.org/abs/2403.17927v1	arXiv:2403.17927			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 27 2024	2024	In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code. Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines. Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM.																																	2024-07-17	PPRN:88295639		
J	Wan, Zhongwei; Wu, Ziang; Liu, Che; Huang, Jinfa; Zhu, Zhihong; Jin, Peng; Wang, Longyue; Yuan, Li				Zhu, Zhihong/OIR-6326-2025; Jin, Peng/LFT-8054-2024; Yuan, Li/AET-1324-2022; Wan, Zhongwei/JDM-4369-2023						LOOK-M: Look-Once Optimization in KV Cache for Efficient Multimodal Long-Context Inference								Arxiv											1	1;2024-06-26;https://www.arxiv.org/abs/2406.18139v1	arXiv:2406.18139			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 26 2024	2024	Long-context Multimodal Large Language Models (MLLMs) demand substantial computational resources for inference as the growth of their multimodal Key-Value (KV) cache, in response to increasing input lengths, challenges memory and time efficiency. Unlike single-modality LLMs that manage only textual contexts, the KV cache of long-context MLLMs includes representations from multiple images with temporal and spatial relationships and related textual contexts. The predominance of image tokens means traditional optimizations for LLMs' KV caches are unsuitable for multimodal long-context settings, and no prior works have addressed this challenge. In this work, we introduce LOOK-M, a pioneering, fine-tuning-free approach that efficiently reduces the multimodal KV cache size while maintaining performance comparable to a full cache. We observe that during prompt prefill, the model prioritizes more textual attention over image features, and based on the multimodal interaction observation, a new proposed text-prior method is explored to compress the KV cache. Furthermore, to mitigate the degradation of image contextual information, we propose several compensatory strategies using KV pairs merging. LOOK-M demonstrates that with a significant reduction in KV Cache memory usage, such as reducing it by 80% in some cases, it not only achieves up to 1.5x faster decoding but also maintains or even enhances performance across a variety of long context multimodal tasks.																																	2024-07-15	PPRN:89878626		
J	Wu, Yihan; Hu, Zhengmian; Guo, Junfeng; Zhang, Hongyang; Huang, Heng				Hu, Zhengmian/KOD-5810-2024						A Resilient and Accessible Distribution-Preserving Watermark for Large Language Models								Arxiv											2	2;2024-06-25;https://www.arxiv.org/abs/2310.07710v2| 1;2023-10-11;https://www.arxiv.org/abs/2310.07710v1	arXiv:2310.07710			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 25 2024	2024	Watermarking techniques offer a promising way to identify machine-generated content via embedding covert information into the contents generated from language models. A challenge in the domain lies in preserving the distribution of original generated content after watermarking. Our research extends and improves upon existing watermarking framework, placing emphasis on the importance of a Distribution-Preserving Preserving (DiP) watermark. Contrary to the current strategies, our proposed DiPmark simultaneously preserves the original token distribution during watermarking (distribution-preserving), is detectable without access to the language model API and prompts (accessible), and is provably robust to moderate changes of tokens (resilient). DiPmark operates by selecting a random set of tokens prior to the generation of a word, then modifying the token distribution through a distribution-preserving reweight function to enhance the probability of these selected tokens during the sampling process. Extensive empirical evaluation on various language models and tasks demonstrates our approach’s distribution-preserving property, accessibility, and resilience, making it a effective solution for watermarking tasks that demand impeccable quality preservation. Code is available at1.																																	2024-07-15	PPRN:85562657		
J	Qin, Chengwei; Zhang, Aston; Chen, Chen; Dagar, Anirudh; Ye, Wenming				qin, chengwei/MBV-9309-2025						In-Context Learning with Iterative Demonstration Selection								Arxiv											3	3;2024-06-23;https://www.arxiv.org/abs/2310.09881v3| 2;2023-10-22;https://www.arxiv.org/abs/2310.09881v2| 1;2023-10-15;https://www.arxiv.org/abs/2310.09881v1	arXiv:2310.09881			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jun 23 2024	2024	Spurred by advancements in scale, large language models (LLMs) have demonstrated strong few-shot learning ability via in-context learning (ICL). However, the performance of ICL has been shown to be highly sensitive to the selection of few-shot demonstrations. Selecting the most suitable examples as context remains an ongoing challenge and an open problem. Existing literature has highlighted the importance of selecting examples that are diverse or semantically similar to the test sample while ignoring the fact that the optimal selection dimension, i.e., diversity or similarity, is task-specific. Based on how the test sample is answered, we propose Iterative Demonstration Selection (IDS) to leverage the merits of both dimensions. Using zero-shot chain-of-thought reasoning (Zero-shot-CoT), IDS iteratively selects examples that are diverse but still strongly correlated with the test sample as ICL demonstrations. Specifically, IDS applies Zero-shot-CoT to the test sample before demonstration selection. The output reasoning path is then used to choose demonstrations that are prepended to the test sample for inference. The generated answer is followed by its corresponding reasoning path for extracting a new set of demonstrations in the next iteration. After several iterations, IDS adopts majority voting to obtain the final result. Through extensive experiments on tasks including reasoning, question answering, and topic classification, we demonstrate that IDS can consistently outperform existing ICL demonstration selection methods.																																	2024-07-15	PPRN:85660472		
J	Wang, Jiongxiao; Li, Jiazhao; Li, Yiquan; Qi, Xiangyu; Hu, Junjie; Li, Yixuan; McDaniel, Patrick; Chen, Muhao; Li, Bo; Xiao, Chaowei				Hu, Junjie/JYQ-9772-2024; Chen, Muhao/AAA-3634-2021; Qi, Xiangyu/GZM-8733-2022; Xiao, Chaowei/AAT-8772-2021; Li, Jiazhao/ABC-8008-2021						Mitigating Fine-tuning based Jailbreak Attack with Backdoor Enhanced Safety Alignment								Arxiv											3	3;2024-06-20;https://www.arxiv.org/abs/2402.14968v3| 2;2024-02-27;https://www.arxiv.org/abs/2402.14968v2| 1;2024-02-22;https://www.arxiv.org/abs/2402.14968v1	arXiv:2402.14968			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 20 2024	2024	Despite the general capabilities of Large Language Models (LLM), these models still request fine-tuning or adaptation with customized data when meeting specific business demands. However, this process inevitably introduces new threats, particularly against the Fine-tuning based Jailbreak Attack (FJAttack) under the setting of Language-Model-as-a-Service (LMaaS), where the model's safety has been significantly compromised by fine-tuning users' uploaded examples contain just a few harmful examples. Though potential defenses have been proposed that the service providers can integrate safety examples into the fine-tuning dataset to reduce safety issues, such approaches require incorporating a substantial amount of data, making it inefficient. To effectively defend against the FJAttack with limited safety examples under LMaaS, we propose the Backdoor Enhanced Safety Alignment method inspired by an analogy with the concept of backdoor attacks. In particular, service providers will construct prefixed safety examples with a secret prompt, acting as a "backdoor trigger". By integrating prefixed safety examples into the fine-tuning dataset, the subsequent fine-tuning process effectively acts as the "backdoor attack", establishing a strong correlation between the secret prompt and safety generations. Consequently, safe responses are ensured once service providers prepend this secret prompt ahead of any user input during inference. Our comprehensive experiments demonstrate that through the Backdoor Enhanced Safety Alignment with adding as few as 11 prefixed safety examples, the maliciously fine-tuned LLMs will achieve similar safety performance as the original aligned models without harming the benign performance. Furthermore, we also present the effectiveness of our method in a more practical setting where the fine-tuning data consists of both FJAttack examples and the fine-tuning task data.																																	2024-07-06	PPRN:87932584		
J	Li, Yunxin; Chen, Xinyu; Hu, Baotian; Wang, Longyue; Shi, Haoyuan; Zhang, Min				Hu, Baotian/AAA-4102-2022						VideoVista: A Versatile Benchmark for Video Understanding and Reasoning								Arxiv											1	1;2024-06-17;https://www.arxiv.org/abs/2406.11303v1	arXiv:2406.11303			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jun 17 2024	2024	Despite significant breakthroughs in video analysis driven by the rapid development of large multimodal models (LMMs), there remains a lack of a versatile evaluation benchmark to comprehensively assess these models’ performance in video understanding and reasoning. To address this, we present VideoVista, a video QA benchmark that integrates challenges across diverse content categories, durations, and abilities. Specifically, VideoVista comprises 25,000 questions derived from 3,400 videos spanning 14 categories (e.g., Howto, Film, and Entertainment) with durations ranging from a few seconds to over 10 minutes. Besides, it encompasses 19 types of understanding tasks (e.g., anomaly detection, interaction understanding) and 8 reasoning tasks (e.g., logical reasoning, causal reasoning). To achieve this, we present an automatic data construction framework, leveraging powerful GPT-4o alongside advanced analysis tools (e.g., video splitting, object segmenting, and tracking). We also utilize this framework to construct training data to enhance the capabilities of video -related LMMs (Video-LMMs). Through a comprehensive and quantitative evaluation of cutting -edge models, we reveal that: 1) Video-LMMs face difficulties in fine-grained video tasks involving temporal location, object tracking, and anomaly detection; 2) Video-LMMs present inferior logical and relation reasoning abilities; 3) Open -source Video-LMMs’ performance is significantly lower than GPT-4o and Gemini -1.5, lagging by 20 points. This highlights the crucial role VideoVista will play in advancing LMMs that can accurately understand videos and perform precise reasoning.																																	2024-07-04	PPRN:89348891		
J	Lu, Yujie; Jiang, Dongfu; Chen, Wenhu; Wang, William Yang; Choi, Yejin; Lin, Bill Yuchen				Jiang, Dongfu/JTV-4943-2023						WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences								Arxiv											1	1;2024-06-16;https://www.arxiv.org/abs/2406.11069v1	arXiv:2406.11069			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 16 2024	2024	Recent breakthroughs in vision -language models (VLMs) emphasize the necessity of benchmarking human preferences in real -world multimodal interactions. To address this gap, we launched W ILD V ISION -A RENA (WV -ARENA), RENA ), an online platform that collects human preferences to evaluate VLMs. We curated WVB ENCH by selecting 500 high -quality samples from 8,000 user submissions in WV -A RENA . WV -B ENCH uses GPT-4 as the judge to compare each VLM with Claude -3 -Sonnet, achieving a Spearman correlation of 0.94 with the WV -A RENA Elo. This significantly outperforms other benchmarks like MMVet, MMMU, and MMStar. Our comprehensive analysis of 20K real -world interactions reveals important insights into the failure cases of top -performing VLMs. For example, we find that although GPT-4V surpasses many other models like Reka-Flash, Opus, and Yi-VL-Plus in simple visual recognition and reasoning tasks, it still faces challenges with subtle contextual cues, spatial reasoning, visual imagination, and expert domain knowledge. Additionally, current VLMs exhibit issues with hallucinations and safety when intentionally provoked. We are releasing our chat and feedback data to further advance research in the field of VLMs.																																	2024-07-04	PPRN:89347009		
J	Mckenna, Ryan; Mullins, Brett; Sheldon, Daniel; Miklau, Gerome										AIM: An Adaptive and Iterative Mechanism for Differentially Private Synthetic Data								Arxiv											1	1;2024-06-13;https://www.arxiv.org/abs/2201.12677v2	arXiv:2201.12677			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 13 2024	2024	We propose AIM, a new algorithm for differentially private synthetic data generation. AIM is a workload-adaptive algorithm within the paradigm of algorithms that first selects a set of queries, then privately measures those queries, and finally generates synthetic data from the noisy measurements. It uses a set of innovative features to iteratively select the most useful measurements, reflecting both their relevance to the workload and their value in approximating the input data. We also provide analytic expressions to bound per-query error with high probability which can be used to construct confidence intervals and inform users about the accuracy of generated data. We show empirically that AIM consistently outperforms a wide variety of existing mechanisms across a variety of experimental settings.																																	2024-07-02	PPRN:89302639		
J	Tomashenko, Natalia; Miao, Xiaoxiao; Champion, Pierre; Meyer, Sarina; Wang, Xin; Vincent, Emmanuel; Panariello, Michele; Evans, Nicholas; Yamagishi, Junichi; Todisco, Massimiliano				Todisco, Massimiliano/P-1664-2017; MIAO, XIAOXIAO/HGF-1852-2022; Tomashenko, Natalia/KBQ-9775-2024						The VoicePrivacy 2024 Challenge Evaluation Plan								Arxiv											2	2;2024-06-12;https://www.arxiv.org/abs/2404.02677v2| 1;2024-04-03;https://www.arxiv.org/abs/2404.02677v1	arXiv:2404.02677			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 12 2024	2024	The task of the challenge is to develop a voice anonymization system for speech data which conceals the speaker's voice identity while protecting linguistic content and emotional states. The organizers provide development and evaluation datasets and evaluation scripts, as well as baseline anonymization systems and a list of training resources formed on the basis of the participants' requests. Participants apply their developed anonymization systems, run evaluation scripts and submit evaluation results and anonymized speech data to the organizers. Results will be presented at a workshop held in conjunction with Interspeech 2024 to which all participants are invited to present their challenge systems and to submit additional workshop papers.																																	2024-07-04	PPRN:88390349		
J	Conitzer, Vincent; Freedman, Rachel; Heitzig, Jobst; Holliday, Wesley H.; Jacobs, Bob M.; Lambert, Nathan; Mosse, Milan; Pacuit, Eric; Russell, Stuart; Schoelkopf, Hailey; Tewolde, Emanuel; Zwicker, William S.				Jacobs, Bob/KWU-4032-2024; Holliday, Wesley/ABD-6618-2021; Heitzig, Jobst/E-8271-2011						Social Choice Should Guide AI Alignment in Dealing with Diverse Human Feedback								Arxiv											2	2;2024-06-04;https://www.arxiv.org/abs/2404.10271v2| 1;2024-04-16;https://www.arxiv.org/abs/2404.10271v1	arXiv:2404.10271			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 04 2024	2024	Foundation models such as GPT-4 are fine-tuned to avoid unsafe or otherwise problematic behavior, such as helping to commit crimes or producing racist text. One approach to fine-tuning, called reinforcement learning from human feedback , learns from humans’ expressed preferences over multiple outputs. Another approach is constitutional AI , in which the input from humans is a list of high-level principles. But how do we deal with potentially diverging input from humans? How can we aggregate the input into consistent data about “collective” preferences or otherwise use it to make collective choices about model behavior? In this paper, we argue that the field of social choice is well positioned to address these questions, and we discuss ways forward for this agenda, drawing on discussions in a recent workshop on Social Choice for AI Ethics and Safety held in Berkeley, CA, USA in December 2023.																																	2024-11-10	PPRN:88632213		
J	Jin, Yang; Sun, Zhicheng; Xu, Kun; Xu, Kun; Chen, Liwei; Jiang, Hao; Huang, Quzhe; Song, Chengru; Liu, Yuliang; Zhang, Di; Song, Yang; Gai, Kun; Mu, Yadong				song, chengru/GSN-4305-2022						Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization								Arxiv											2	2;2024-06-03;https://www.arxiv.org/abs/2402.03161v3| 1;2024-02-06;https://www.arxiv.org/abs/2402.03161v2	arXiv:2402.03161			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 03 2024	2024	In light of recent advances in multimodal Large Language Models (LLMs), there is increasing attention to scaling them from image-text data to more informative real-world videos. Compared to static images, video poses unique challenges for effective large-scale pre-training due to the modeling of its spatiotemporal dynamics. In this paper, we address such limitations in video-language pre-training with an efficient video decomposition that represents each video as keyframes and temporal motions. These are then adapted to an LLM using well-designed tokenizers that discretize visual and temporal information as a few tokens, thus enabling unified generative pre-training of videos, images, and text. At inference, the generated tokens from the LLM are carefully recovered to the original continuous pixel space to create various video content. Our proposed framework is both capable of comprehending and generating image and video content, as demonstrated by its competitive performance across 13 multimodal benchmarks in image and video understanding and generation. 																																	2024-06-22	PPRN:87534078		
J	Lin, Zicheng; Gou, Zhibin; Liang, Tian; Luo, Ruilin; Liu, Haowei; Yang, Yujiu				Yang, Yujiu/JGM-0303-2023						CriticBench: Benchmarking LLMs for Critique-Correct Reasoning								Arxiv											4	4;2024-06-01;https://www.arxiv.org/abs/2402.14809v4| 3;2024-05-28;https://www.arxiv.org/abs/2402.14809v3| 2;2024-03-08;https://www.arxiv.org/abs/2402.14809v2| 1;2024-02-22;https://www.arxiv.org/abs/2402.14809v1	arXiv:2402.14809			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 01 2024	2024	The ability of Large Language Models (LLMs) to critique and refine their reasoning is crucial for their application in evaluation, feedback provision, and self-improvement. This paper introduces C RITIC B ENCH , a comprehensive benchmark designed to assess LLMs’ abilities to critique and rectify their reasoning across a variety of tasks. C RITIC B ENCH encompasses five reasoning domains: mathematical, commonsense, symbolic, coding, and algorithmic. It compiles 15 datasets and incorporates responses from three LLM families. Utilizing C RITIC B ENCH , we evaluate and dissect the performance of 17 LLMs in generation, critique, and correction reasoning, i.e., GQC reasoning, and analyze the key factors affecting LLM critical reasoning. Our findings reveal: (1) a linear relationship in GQC capabilities, with critiquefocused training markedly enhancing performance; (2) a task-dependent variation in critique and correction effectiveness, with logicoriented tasks being more amenable to correction; (3) GQC knowledge inconsistencies that decrease as model size increases; and (4) an intriguing inter-model critiquing pattern, where stronger models are better at critiquing weaker ones, while weaker models can surprisingly surpass stronger ones in their self-critique. We hope these insights into the nuanced critiquecorrect reasoning of LLMs will foster further research in LLM critique and self-improvement 1 .																																	2024-06-22	PPRN:87800254		
J	Sang, Shengqi; Hsieh, Timothy H.										Stability of mixed-state quantum phases via finite Markov length								Arxiv											2	2;2024-05-29;https://www.arxiv.org/abs/2404.07251v2| 1;2024-04-10;https://www.arxiv.org/abs/2404.07251v1	arXiv:2404.07251			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	May 29 2024	2024	For quantum phases of Hamiltonian ground states, the energy gap plays a central role in ensuring the stability of the phase as long as the gap remains finite. We propose Markov length, the length scale at which the quantum conditional mutual information (CMI) decays exponentially, as an equally essential quantity characterizing mixed-state phases and transitions. For a state evolving under a local Lindbladian, we argue that if its Markov length remains finite along the evolution, then it remains in the same phase, meaning there exists another quasi-local Lindbladian evolution that can reverse the former one. We apply this diagnostic to toric code subject to decoherence and show that the Markov length is finite everywhere except at its decodability transition, at which it diverges. CMI in this case can be mapped to the free energy cost of point defects in the random bond Ising model. This implies that the mixed state phase transition coincides with the decodability transition and also suggests a quasi-local decoding channel.																																	2024-08-28	PPRN:88500321		
J	Qiu, Linlu; Jiang, Liwei; Lu, Ximing; Sclar, Melanie; Pyatkin, Valentina; Bhagavatula, Chandra; Wang, Bailin; Kim, Yoon; Choi, Yejin; Dziri, Nouha; Ren, Xiang				Jiang, Liwei/IYK-0150-2023; Sclar, Melanie/LXU-4864-2024; Lu, Ximing/LLL-7542-2024						Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement								Arxiv											4	4;2024-05-22;https://www.arxiv.org/abs/2310.08559v4| 3;2024-03-19;https://www.arxiv.org/abs/2310.08559v3| 2;2023-11-28;https://www.arxiv.org/abs/2310.08559v2| 1;2023-10-12;https://www.arxiv.org/abs/2310.08559v1	arXiv:2310.08559			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 22 2024	2024	The ability to derive underlying principles from a handful of observations and then generalize to novel situations - known as inductive reasoning - is central to human intelligence. Prior work suggests that language models (LMs) often fall short on inductive reasoning, despite achieving impressive success on research benchmarks. In this work, we conduct a systematic study of the inductive reasoning capabilities of LMs through iterative hypothesis refinement, a technique that more closely mirrors the human inductive process than standard input-output prompting. Iterative hypothesis refinement employs a three-step process: proposing, selecting, and refining hypotheses in the form of textual rules. By examining the intermediate rules, we observe that LMs are phenomenal hypothesis proposers (i.e., generating candidate rules), and when coupled with a (task-specific) symbolic interpreter that is able to systematically filter the proposed set of rules, this hybrid approach achieves strong results across inductive reasoning benchmarks that require inducing causal relations, language-like instructions, and symbolic concepts. However, they also behave as puzzling inductive reasoners, showing notable performance gaps between rule induction (i.e., identifying plausible rules) and rule application (i.e., applying proposed rules to instances), suggesting that LMs are proposing hypotheses without being able to actually apply the rules. Through empirical and human analyses, we further reveal several discrepancies between the inductive reasoning processes of LMs and humans, shedding light on both the potentials and limitations of using LMs in inductive reasoning tasks.1																																	2024-06-05	PPRN:85602889		
J	He, Tairan; Zhang, Chong; Xiao, Wenli; He, Guanqi; Liu, Changliu; Shi, Guanya										Agile But Safe: Learning Collision-Free High-Speed Legged Locomotion								Arxiv											1	1;2024-05-17;https://www.arxiv.org/abs/2401.17583v2	arXiv:2401.17583			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 17 2024	2024	Legged robots navigating cluttered environments must be jointly agile for efficient task execution and safe to avoid collisions with obstacles or humans. Existing studies either develop conservative controllers (< 1.0 m/s) to ensure safety, or focus on agility without considering potentially fatal collisions. This paper introduces Agile But Safe (ABS), a learning-based control framework that enables agile and collision-free locomotion for quadrupedal robots. ABS involves an agile policy to execute agile motor skills amidst obstacles and a recovery policy to prevent failures, collaboratively achieving high-speed and collision-free navigation. The policy switch in ABS is governed by a learned control-theoretic reach-avoid value network, which also guides the recovery policy as an objective function, thereby safeguarding the robot in a closed loop. The training process involves the learning of the agile policy, the reach-avoid value network, the recovery policy, and an exteroception representation network, all in simulation. These trained modules can be directly deployed in the real world with onboard sensing and computation, leading to high-speed and collision-free navigation in confined indoor and outdoor spaces with both static and dynamic obstacles.																																	2025-08-07	PPRN:123162828		
J	Lian, Long; Shi, Baifeng; Yala, Adam; Darrell, Trevor; Li, Boyi										LLM-grounded Video Diffusion Models								Arxiv											2	2;2024-05-04;https://www.arxiv.org/abs/2309.17444v3| 1;2023-10-02;https://www.arxiv.org/abs/2309.17444v2	arXiv:2309.17444			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 04 2024	2024	Text-conditioned diffusion models have emerged as a promising tool for neural video generation. However, current models still struggle with intricate spatiotemporal prompts and often generate restricted or incorrect motion. To address these limitations, we introduce LLM-grounded Video Diffusion (LVD). Instead of directly generating videos from the text inputs, LVD first leverages a large language model (LLM) to generate dynamic scene layouts based on the text inputs and subsequently uses the generated layouts to guide a diffusion model for video generation. We show that LLMs are able to understand complex spatiotemporal dynamics from text alone and generate layouts that align closely with both the prompts and the object motion patterns typically observed in the real world. We then propose to guide video diffusion models with these layouts by adjusting the attention maps. Our approach is training-free and can be integrated into any video diffusion model that admits classifier guidance. Our results demonstrate that LVD significantly outperforms its base video diffusion model and several strong baseline methods in faithfully generating videos with the desired attributes and motion patterns.																																	2024-05-28	PPRN:85338945		
J	Hoogeboom, Emiel; Salimans, Tim										Blurring Diffusion Models								Arxiv											2	2;2024-05-01;https://www.arxiv.org/abs/2209.05557v3| 1;2022-09-12;https://www.arxiv.org/abs/2209.05557v2	arXiv:2209.05557			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 01 2024	2024	Recently, Rissanen et al. (2022) have presented a new type of diffusion process for generative modeling based on heat dissipation , or blurring , as an alternative to isotropic Gaussian diffusion. Here, we show that blurring can equivalently be defined through a Gaussian diffusion process with non-isotropic noise. In making this connection, we bridge the gap between inverse heat dissipation and denoising diffusion, and we shed light on the inductive bias that results from this modeling choice. Finally, we propose a generalized class of diffusion models that offers the best of both standard Gaussian denoising diffusion and inverse heat dissipation, which we call Blurring Diffusion Models .																																	2024-05-19	PPRN:17012813		
J	Onoe, Yasumasa; Rane, Sunayana; Berger, Zachary; Bitton, Yonatan; Cho, Jaemin; Garg, Roopal; Ku, Alexander; Parekh, Zarana; Pont-Tuset, Jordi; Tanzer, Garrett; Wang, Su; Baldridge, Jason										DOCCI: Descriptions of Connected and Contrasting Images								Arxiv											1	1;2024-04-30;https://www.arxiv.org/abs/2404.19753v1	arXiv:2404.19753			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 30 2024	2024	Vision-language datasets are vital for both text-to-image (T2I) and image-to-text (I2T) research. However, current datasets lack descriptions with fine-grained detail that would allow for richer associations to be learned by models. To fill the gap, we introduce Descriptions of Connected and Contrasting Images (DOCCI), a dataset with long, human-annotated English descriptions for 15k images that were taken, curated and donated by a single researcher intent on capturing key challenges such as spatial relations, counting, text rendering, world knowledge, and more. We instruct human annotators to create comprehensive descriptions for each image; these average 136 words in length and are crafted to clearly distinguish each image from those that are related or similar. Each description is highly compositional and typically encompasses multiple challenges. Through both quantitative and qualitative analyses, we demonstrate that DOCCI serves as an effective training resource for image-to-text generation – a PaLI 5B model finetuned on DOCCI shows equal or superior results compared to highly-performant larger models like LLaVA-1.5 7B and InstructBLIP 7B. Furthermore, we show that DOCCI is a useful testbed for text-to-image generation, highlighting the limitations of current text-to-image models in capturing long descriptions and fine details.																																	2024-12-24	PPRN:119224172		
J	Song, Enxin; Chai, Wenhao; Ye, Tian; Hwang, Jenq-Neng; Li, Xi; Wang, Gaoang				Song, EnXin/LRB-4201-2024; Chai, Wenhao/LIG-6923-2024; Ye, Tianyong/MSX-9881-2025						MovieChat+: Question-aware Sparse Memory for Long Video Question Answering								Arxiv											1	1;2024-04-26;https://www.arxiv.org/abs/2404.17176v1	arXiv:2404.17176			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 26 2024	2024	Recently, integrating video foundation models and large language models to build a video understanding system can overcome the limitations of specific pre -defined vision tasks. Yet, existing methods either employ complex spatial -temporal modules or rely heavily on additional perception models to extract temporal features for video understanding, and they only perform well on short videos. For long videos, the computational complexity and memory costs associated with long-term temporal connections are significantly increased, posing additional challenges. Taking advantage of the Atkinson-Shiffrin memory model, with tokens in Transformers being employed as the carriers of memory in combination with our specially designed memory mechanism, we propose MovieChat to overcome these challenges. We lift pre -trained multi -modal large language models for understanding long videos without incorporating additional trainable temporal modules, employing a zero -shot approach. Additionally, in our new version, MovieChat+, we design an enhanced vision -question matching -based memory consolidation mechanism to more significantly anchor the predictions of the visual language models in the relevant visual content. MovieChat achieves state-of-the-art performance in long video understanding, along with the released MovieChat-1K benchmark with 1K long video, 2K temporal grounding labels, and 14K manual annotations for validation of the effectiveness of our method. The code along with the dataset can be accessed via the following link.																																	2024-05-06	PPRN:88664533		
J	Atakishiyev, Shahin; Salameh, Mohammad; Yao, Hengshuai; Goebel, Randy										Explainable Artificial Intelligence for Autonomous Driving: A Comprehensive Overview and Field Guide for Future Research Directions								Arxiv											3	3;2024-04-25;https://www.arxiv.org/abs/2112.11561v5| 2;2024-04-14;https://www.arxiv.org/abs/2112.11561v4| 1;2021-12-21;https://www.arxiv.org/abs/2112.11561v2	arXiv:2112.11561			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 25 2024	2024	Autonomous driving has achieved significant milestones in research and development over the last two decades. There is increasing interest in the field as the deployment of autonomous vehicles (AVs) promises safer and more ecologically friendly transportation systems. With the rapid progress in computationally powerful artificial intelligence (AI) techniques, AVs can sense their environment with high precision, make safe real-time decisions, and operate reliably without human intervention. However, intelligent decision-making in such vehicles is not generally understandable by humans in the current state of the art, and such deficiency hinders this technology from being socially acceptable. Hence, aside from making safe real-time decisions, AVs must also explain their AI-guided decision-making process in order to be regulatory compliant across many jurisdictions. Our study sheds comprehensive light on the development of explainable artificial intelligence (XAI) approaches for AVs. In particular, we make the following contributions. First, we provide a thorough overview of the state-of-the-art and emerging approaches for XAI-based autonomous driving. We then propose a conceptual framework that considers the essential elements for explainable end-to-end autonomous driving. Finally, we present XAI-based prospective directions and emerging paradigms for future directions that hold promise for enhancing transparency, trustworthiness, and societal acceptance of AVs.																																	2024-05-17	PPRN:13186370		
J	Patro, Badri Narayana; Agneeswaran, Vijay Srinivas				Agneeswaran, Vijay Srinivas/LWH-7627-2024; Patro, Badri/AAK-2539-2021						Mamba-360: Survey of State Space Models as Transformer Alternative for Long Sequence Modelling: Methods, Applications, and Challenges								Arxiv											1	1;2024-04-24;https://www.arxiv.org/abs/2404.16112v1	arXiv:2404.16112			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Apr 24 2024	2024	Sequence modeling is a crucial area across various domains, including Natural Language Processing (NLP), speech recognition, time series forecasting, music generation, and bioinformatics. Recurrent Neural Networks (RNNs) and Long Short Term Memory Networks (LSTMs) have historically dominated sequence modeling tasks like Machine Translation, Named Entity Recognition (NER), etc. However, the advancement of transformers has led to a shift in this paradigm, given their superior performance. Yet, transformers suffer from $O(N^2)$ attention complexity and challenges in handling inductive bias. Several variations have been proposed to address these issues which use spectral networks or convolutions and have performed well on a range of tasks. However, they still have difficulty in dealing with long sequences. State Space Models(SSMs) have emerged as promising alternatives for sequence modeling paradigms in this context, especially with the advent of S4 and its variants, such as S4nd, Hippo, Hyena, Diagnol State Spaces (DSS), Gated State Spaces (GSS), Linear Recurrent Unit (LRU), Liquid-S4, Mamba, etc. In this survey, we categorize the foundational SSMs based on three paradigms namely, Gating architectures, Structural architectures, and Recurrent architectures. This survey also highlights diverse applications of SSMs across domains such as vision, video, audio, speech, language (especially long sequence modeling), medical (including genomics), chemical (like drug design), recommendation systems, and time series analysis, including tabular data. Moreover, we consolidate the performance of SSMs on benchmark datasets like Long Range Arena (LRA), WikiText, Glue, Pile, ImageNet, Kinetics-400, sstv2, as well as video datasets such as Breakfast, COIN, LVU, and various time series datasets. The project page for Mamba-360 work is available on this webpage.url{https://github.com/badripatro/mamba360}.																																	2024-05-04	PPRN:88651050		
J	Deng, Yu; Nahmod, Andrea R.; Yue, Haitian										INVARIANT GIBBS MEASURES AND GLOBAL STRONG SOLUTIONS FOR NONLINEAR SCHR ODINGER EQUATIONS IN DIMENSION TWO								Arxiv											2	2;2024-04-18;https://www.arxiv.org/abs/1910.08492v2| 1;2019-10-18;https://www.arxiv.org/abs/1910.08492v1	arXiv:1910.08492			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 18 2024	2024	We consider the defocusing nonlinear Schrödinger equation on T2 with Wick ordered power nonlinearity, and prove almost sure global well-posedness with respect to the associated Gibbs measure. The heart of the matter is the uniqueness of the solution as limit of solutions to canonically truncated systems, and the invariance of the Gibbs measure under the global dynamics follows as a consequence. The proof relies on the novel idea of random averaging operators.																																	2024-04-28	PPRN:13639322		
J	de Graaff, Anna; Setton, David J.; Brammer, Gabriel; Cutler, Sam; Suess, Katherine A.; Labbe, Ivo; Leja, Joel; Weibel, Andrea; Maseda, Michael V.; Whitaker, Katherine E.; Bezanson, Rachel; Boogaard, Leindert A.; Cleri, Nikko J.; De Lucia, Gabriella; Franx, Marijn; Greene, Jenny E.; Hirschmann, Michaela; Matthee, Jorryt; McConachie, Ian; Naidu, Rohan P.; Oesch, Pascal A.; Price, Sedona H.; Rix, Hans-Walter; Valentino, Francesco; Wang, Bingjie; Williams, Christina C.				Labbe, Ivo/B-1408-2016; Matthee, Jorryt/KHD-9384-2024; Leja, Joel/JPL-7942-2023; Valentino, Francesco/NPI-4170-2025; Oesch, Pascal/AFN-4775-2022; Brammer, Gabriel/AAB-4859-2020; Wang, Bingjie/AAD-6128-2022						Efficient formation of a massive quiescent galaxy at redshift 4.9								Arxiv											1	1;2024-04-09;https://www.arxiv.org/abs/2404.05683v2	arXiv:2404.05683			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 09 2024	2024	Within the established framework of structure formation, galaxies start as systems of low stellar mass and gradually grow into far more massive galaxies. The existence of massive galaxies in the first billion years of the Universe, suggested by recent observations, appears to challenge this model, as such galaxies would require highly efficient conversion of baryons into stars. An even greater challenge in this epoch is the existence of massive galaxies that have already ceased forming stars. However, robust detections of early massive quiescent galaxies have been challenging due to the coarse wavelength sampling of photometric surveys. Here we report the spectroscopic confirmation with the James Webb Space Telescope of the quiescent galaxy RUBIES-EGS-QG-1 at redshift z=4.896, 1.2 billion years after the Big Bang. Deep stellar absorption features in the spectrum reveal that the galaxy's stellar mass of 1010.9,M⊙, corroborated by the mass implied by its gas kinematics, formed in a short 340 Myr burst of star formation, after which star formation activity dropped rapidly and persistently. According to current galaxy formation models, systems with such rapid stellar mass growth and early quenching are too rare to plausibly occur in the small area probed spectroscopically with JWST. Instead, the discovery of RUBIES-EGS-QG-1 implies that early massive quiescent galaxies can be quenched earlier or exhaust gas available for star formation more efficiently than currently assumed.																																	2024-05-01	PPRN:88468861		
J	Goel, Vidit; Peruzzo, Elia; Jiang, Yifan; Xu, Dejia; Xu, Xingqian; Sebe, Nicu; Darrell, Trevor; Wang, Zhangyang; Shi, Humphrey				Zhihua, Wang/AFO-5263-2022; Jiang, Yifan/ABB-4400-2021; Shi, Honghui/V-9259-2019; Peruzzo, Elia/JMQ-7149-2023; Sebe, Niculae/KEC-2000-2024						PAIR-Diffusion: A Comprehensive Multimodal Object-Level Image Editor								Arxiv											3	3;2024-04-08;https://www.arxiv.org/abs/2303.17546v3| 2;2023-10-11;https://www.arxiv.org/abs/2303.17546v2| 1;2023-03-30;https://www.arxiv.org/abs/2303.17546v1	arXiv:2303.17546			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 08 2024	2024	Generative image editing has recently witnessed extremely fast-paced growth. Some works use high-level conditioning such as text, while others use low-level conditioning. Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i.e. object-level image editing. In this work, we tackle the task by perceiving the images as an amalgamation of various objects and aim to control the properties of each object in a fine-grained manner. Out of these properties, we identify structure and appearance as the most intuitive to understand and useful for editing purposes. We propose PAIR Diffusion, a generic framework that can enable a diffusion model to control the structure and appearance properties of each object in the image. We show that having control over the properties of each object in an image leads to comprehensive editing capabilities. Our framework allows for various object-level editing operations on real images such as reference image-based appearance editing, free-form shape editing, adding objects, and variations. Thanks to our design, we do not require any inversion step. Additionally, we propose multimodal classifier-free guidance which enables editing images using both reference images and text when using our approach with foundational diffusion models. We validate the above claims by extensively evaluating our framework on both unconditional and foundational diffusion models. 																																	2024-04-24	PPRN:52090816		
J	Sun, Qiushi; Yin, Zhangyue; Li, Xiang; Wu, Zhiyong; Qiu, Xipeng; Kong, Lingpeng				Li, Xiang/KXR-9899-2024; Zhang, Yinyan/S-7675-2019; kong, lingpeng/NHQ-3170-2025; Sun, Qiushi/LIH-5484-2024						<italic>Corex:</italic> PUSHING THE BOUNDARIES OF COMPLEX REA- SONING THROUGH MULTI-MODEL COLLABORATION								Arxiv											2	2;2024-04-07;https://www.arxiv.org/abs/2310.00280v2| 1;2023-09-30;https://www.arxiv.org/abs/2310.00280v1	arXiv:2310.00280			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 07 2024	2024	Large Language Models (LLMs) are evolving at an unprecedented pace and have exhibited considerable capability in the realm of natural language processing (NLP) with world knowledge. Benefiting from ultra-large-scale training corpora, a single LLM can manage typical NLP tasks competently. However, its performance in executing reasoning tasks is still confined by the limitations of its internal representations. To push this boundary further, we introduce Corex in this paper, a suite of novel general-purpose strategies that transform LLMs into autonomous agents pioneering multi-model collaborations for complex task-solving. Inspired by human behaviors, Corex is constituted by diverse collaboration paradigms including Debate, Review, and Retrieve modes, which collectively work towards enhancing the factuality, faithfulness, and reliability of the reasoning process. These paradigms foster task-agnostic approaches that enable LLMs to ''think outside the box,'' thereby overcoming hallucinations and providing better solutions. Through extensive experiments across four different types of reasoning tasks, we demonstrate that orchestrating multiple LLMs to work in concert yields substantially better performance compared to existing methods. Further results and in-depth analysis demonstrate the cost-effectiveness of our method, facilitating collaboration among different LLMs and promoting annotation efficiency.																																	2024-04-21	PPRN:85349466		
J	Zhang, Xiaokang; Zhang, Jing; Ma, Zeyao; Li, Yang; Zhang, Bohan; Li, Guanlin; Yao, Zijun; Xu, Kangli; Zhou, Jinchang; Zhang-Li, Daniel; Yu, Jifan; Zhao, Shu; Li, Juanzi; Tang, Jie				Zhang-Li, Daniel/OJT-2553-2025; Li, guanlin/JXW-7234-2024; Li, Zhiyuan/ESQ-7168-2022						TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2403.19318v2| 1;2024-03-28;https://www.arxiv.org/abs/2403.19318v1	arXiv:2403.19318			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 01 2024	2024	We introduce TableLLM, a robust large language model (LLM) with 13 billion parameters, purpose-built for proficiently handling tabular data manipulation tasks, whether they are embedded within documents or spreadsheets, catering to real-world office scenarios. We propose a distant supervision method for training, which comprises a reasoning process extension strategy, aiding in training LLMs to understand reasoning patterns more effectively as well as a cross-way validation strategy, ensuring the quality of the automatically generated data. To evaluate the performance of TableLLM, we have crafted a benchmark tailored to address both document and spreadsheet formats as well as constructed a well-organized evaluation pipeline capable of handling both scenarios. Thorough evaluations underscore the advantages of TableLLM when compared to various existing general-purpose and tabular data-focused LLMs. We have publicly released the model checkpoint, source code, benchmarks, and a web application for user interaction.																																	2024-04-17	PPRN:88333305		
J	Berner, Julius; Richter, Lorenz; Ullrich, Karen										An optimal control perspective on diffusion-based generative modeling								Arxiv											1	1;2024-03-26;https://www.arxiv.org/abs/2211.01364v3	arXiv:2211.01364			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 26 2024	2024	We establish a connection between stochastic optimal control and generative models based on stochastic differential equations (SDEs), such as recently developed diffusion probabilistic models. In particular, we derive a Hamilton-Jacobi-Bellman equation that governs the evolution of the log-densities of the underlying SDE marginals. This perspective allows to transfer methods from optimal control theory to generative modeling. First, we show that the evidence lower bound is a direct consequence of the well-known verification theorem from control theory. Further, we can formulate diffusion-based generative modeling as a minimization of the Kullback-Leibler divergence between suitable measures in path space. Finally, we develop a novel diffusion-based method for sampling from unnormalized densities -- a problem frequently occurring in statistics and computational sciences. We demonstrate that our time-reversed diffusion sampler (DIS) can outperform other diffusion-based sampling approaches on multiple numerical examples.																																	2025-08-07	PPRN:123161126		
J	Yao, Binwei; Jiang, Ming; Yang, Diyi; Hu, Junjie				Hu, Junjie/HHR-9040-2022; Hu, Junjie/JYQ-9772-2024						Benchmarking LLM-based Machine Translation on Cultural Awareness								Arxiv											3	3;2024-10-19;https://www.arxiv.org/abs/2305.14328v3| 2;2024-03-23;https://www.arxiv.org/abs/2305.14328v2| 1;2023-05-23;https://www.arxiv.org/abs/2305.14328v1	arXiv:2305.14328			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 23 2024	2024	Translating cultural-specific content is crucial for effective cross-cultural communication. However, many MT systems still struggle to translate sentences containing cultural-specific entities accurately and understandably. Recent advancements in in-context learning utilize lightweight prompts to guide large language models (LLMs) in machine translation tasks. Nevertheless, the effectiveness of this approach in enhancing machine translation with cultural awareness remains uncertain. To address this gap, we introduce a new data curation pipeline to construct a culturally relevant parallel corpus, enriched with annotations of cultural-specific items. Furthermore, we devise a novel evaluation metric to assess the understandability of translations in a reference-free manner by GPT-4. We evaluate a variety of neural machine translation (NMT) and LLM-based MT systems using our dataset. Additionally, we propose several prompting strategies for LLMs to incorporate external and internal cultural knowledge into the translation process. Our results demonstrate that eliciting explanations can significantly enhance the understandability of cultural-specific entities, especially those without well-known translations.																																	2025-08-07	PPRN:71622600		
J	Yu, Sixing; Munoz, J. Pablo; Jannesari, Ali										Federated Foundation Models: Privacy-Preserving and Collaborative Learning for Large Models								Arxiv											3	3;2024-03-19;https://www.arxiv.org/abs/2305.11414v3| 2;2023-11-08;https://www.arxiv.org/abs/2305.11414v2| 1;2023-05-19;https://www.arxiv.org/abs/2305.11414v1	arXiv:2305.11414			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 19 2024	2024	Foundation Models (FMs), such as LLaMA, BERT, GPT, ViT, and CLIP, have demonstrated remarkable success in a wide range of applications, driven by their ability to leverage vast amounts of data for pre-training. However, optimizing FMs often requires access to sensitive data, raising privacy concerns and limiting their applicability in many domains. In this paper, we propose the Federated Foundation Models (FFMs) paradigm, which combines the benefits of FMs and Federated Learning (FL) to enable privacy-preserving and collaborative learning across multiple end-users. We discuss the potential benefits and challenges of integrating FL into the lifespan of FMs, covering pre-training, fine-tuning, and application. We further outline potential future research avenues in FFM, including FFM pre-training, FFM fine-tuning, and federated prompt tuning, which allow the development of more personalized and context-aware models while ensuring data privacy. Moreover, we explore the possibility of continual/lifelong learning in FFMs, as increased computational power at the edge may unlock the potential for optimizing FMs using newly generated private data close to the data source. The proposed FFM concepts offer a flexible and scalable framework for training large language models in a privacy-preserving manner, setting the stage for subsequent advancements in both FM training and federated learning.																																	2024-04-12	PPRN:70568899		
J	Yin, Wangsong; Xu, Mengwei; Li, Yuanchun; Liu, Xuanzhe				Liu, Xuanzhe/MIN-0907-2025; Xu, Mengwei/AAE-5567-2020; Li, Yuanchun/LTD-1972-2024						LLM as a System Service on Mobile Devices								Arxiv											1	1;2024-03-18;https://www.arxiv.org/abs/2403.11805v1	arXiv:2403.11805			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 18 2024	2024	Being more powerful and intrusive into user-device interactions, LLMs are eager for on-device execution to better preserve user privacy. In this work, we propose a new paradigm of mobile AI: LLM as a system service on mobile devices (LLMaaS). Unlike traditional DNNs that execute in a stateless manner, such a system service is stateful: LLMs execution often needs to maintain persistent states (mainly KV cache) across multiple invocations. To minimize the LLM context switching overhead under tight device memory budget, this work presents LLMS, which decouples the memory management of app and LLM contexts with a key idea of fine-grained, chunk-wise, globally-optimized KV cache compression and swapping. By fully leveraging KV cache's unique characteristics, it proposes three novel techniques: (1) Tolerance-Aware Compression: it compresses chunks based on their measured accuracy tolerance to compression. (2) IO-Recompute Pipelined Loading: it introduces recompute to swapping-in for acceleration. (3) Chunk Lifecycle Management: it optimizes the memory activities of chunks with an ahead-of-time swapping-out and an LCTRU (Least Compression-Tolerable and Recently-Used) queue based eviction. In evaluations conducted on well-established traces and various edge devices, sys reduces context switching latency by up to 2 orders of magnitude when compared to competitive baseline solutions.																																	2024-04-11	PPRN:88189806		
J	Wu, Jingfeng; Zou, Difan; Chen, Zixiang; Braverman, Vladimir; Gu, Quanquan; Bartlett, Peter L.				CHEN, ZIXIANG/OKT-0372-2025; braverman, vladimir/H-4565-2011						How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?								Arxiv											2	2;2024-03-15;https://www.arxiv.org/abs/2310.08391v2| 1;2023-10-12;https://www.arxiv.org/abs/2310.08391v1	arXiv:2310.08391			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 15 2024	2024	Transformers pretrained on diverse tasks exhibit remarkable in-context learning (ICL) capabilities, enabling them to solve unseen tasks solely based on input contexts without adjusting model parameters. In this paper, we study ICL in one of its simplest setups: pretraining a linearly parameterized single-layer linear attention model for linear regression with a Gaussian prior. We establish a statistical task complexity bound for the attention model pretraining, showing that effective pretraining only requires a small number of independent tasks. Furthermore, we prove that the pretrained model closely matches the Bayes optimal algorithm, i.e., optimally tuned ridge regression, by achieving nearly Bayes optimal risk on unseen tasks under a fixed context length. These theoretical findings complement prior experimental research and shed light on the statistical foundations of ICL.																																	2024-04-11	PPRN:85604668		
J	He, Xuanhua; Cao, Ke; Yan, Keyu; Li, Rui; Xie, Chengjun; Zhang, Jie; Zhou, Man				Li, Rui/HJH-6353-2023; Yan, Keyu/IXX-0343-2023						Pan-Mamba: Effective pan-sharpening with State Space Model								Arxiv											2	2;2024-03-09;https://www.arxiv.org/abs/2402.12192v2| 1;2024-02-19;https://www.arxiv.org/abs/2402.12192v1	arXiv:2402.12192			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 09 2024	2024	Pan-sharpening involves integrating information from lowresolution multi-spectral and high-resolution panchromatic images to generate high-resolution multi-spectral counterparts. While recent advancements in the state space model, particularly the efficient long-range dependency modeling achieved by Mamba, have revolutionized computer vision community, its untapped potential in pan-sharpening motivates our exploration. Our contribution, Pan-Mamba, represents a novel pansharpening network that leverages the efficiency of the Mamba model in global information modeling. In Pan-Mamba, we customize two core components: channel swapping Mamba and cross-mo dal Mamba, strategically designed for efficient cross-mo dal information exchange and fusion. The former initiates a lightweight cross-mo dal interaction through the exchange of partial panchromatic and multi-spectral channels, while the latter facilities the information representation capability by exploiting inherent cross-mo dal relationships. Through extensive experiments across diverse datasets, our proposed approach surpasses state-of-theart methods, showcasing superior fusion results in pan-sharpening. To the best of our knowledge, this work is the first attempt in exploring the potential of the Mamba model and establishes a new frontier in the pan-sharpening techniques. The source code is available at https: //github.com/alexhe101/Pan-Mamba.																																	2024-04-07	PPRN:87759251		
J	Mu, Norman; Chen, Sarah; Wang, Zifan; Chen, Sizhe; Karamardian, David; Aljeraisy, Lulwa; Alomair, Basel; Hendrycks, Dan; Wagner, David				wang, zifan/HHS-5709-2022						Can LLMs Follow Simple Rules?								Arxiv											3	3;2024-03-08;https://www.arxiv.org/abs/2311.04235v3| 2;2024-03-07;https://www.arxiv.org/abs/2311.04235v2| 1;2023-11-06;https://www.arxiv.org/abs/2311.04235v1	arXiv:2311.04235			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 08 2024	2024	As Large Language Models (LLMs) are deployed with increasing real-world responsibilities, it is important to be able to specify and constrain the behavior of these systems in a reliable manner. Model developers may wish to set explicit rules for the model, such as "do not generate abusive content", but these may be circumvented by jailbreaking techniques. Existing evaluations of adversarial attacks and defenses on LLMs generally require either expensive manual review or unreliable heuristic checks. To address this issue, we propose Rule-following Language Evaluation Scenarios (RuLES), a programmatic framework for measuring rule-following ability in LLMs. RuLES consists of 14 simple text scenarios in which the model is instructed to obey various rules while interacting with the user. Each scenario has a programmatic evaluation function to determine whether the model has broken any rules in a conversation. Our evaluations of proprietary and open models show that almost all current models struggle to follow scenario rules, even on straightforward test cases. We also demonstrate that simple optimization attacks suffice to significantly increase failure rates on test cases. We conclude by exploring two potential avenues for improvement: test-time steering and supervised fine-tuning.																																	2024-04-07	PPRN:86096901		
J	Bhardwaj, Lakshya; Schafer-Nameki, Sakura				Bhardwaj, Lakshya/ISU-5186-2023						Generalized Charges, Part I: Invertible Symmetries and Higher Representations								Arxiv											2	2;2024-03-02;https://www.arxiv.org/abs/2304.02660v4| 1;2023-04-09;https://www.arxiv.org/abs/2304.02660v2	arXiv:2304.02660			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 02 2024	2024	q -charges describe the possible actions of a generalized symmetry on q -dimensional operators. In Part I of this series of papers, we describe q -charges for invertible symmetries; while the discussion of q -charges for non -invertible symmetries is the topic of Part II. We argue that q -charges of a standard global symmetry, also known as a 0 -form symmetry, correspond to the so-called (q + 1) -representations of the 0 -form symmetry group, which are natural highercategorical generalizations of the standard notion of representations of a group. This generalizes already our understanding of possible charges under a 0 -form symmetry! Just like local operators form representations of the 0 -form symmetry group, higher -dimensional extended operators form higher -representations. This statement has a straightforward generalization to other invertible symmetries: q -charges of higher -form and higher -group symmetries are (q + 1) -representations of the corresponding higher -groups. There is a natural extension to higher -charges of non -genuine operators (i.e. operators that are attached to higher -dimensional operators), which will be shown to be intertwiners of higher -representations. This brings into play the higher -categorical structure of higher -representations. We also discuss higher -charges of twisted sector operators (i.e. operators that appear at the boundary of topological operators of one dimension higher), including operators that appear at the boundary of condensation defects.																																	2024-04-22	PPRN:55158376		
J	Garrido, Quentin; Assran, Mahmoud; Ballas, Nicolas; Bardes, Adrien; Najman, Laurent; LeCun, Yann										Learning and Leveraging World Models in Visual Representation Learning								Arxiv											1	1;2024-03-01;https://www.arxiv.org/abs/2403.00504v1	arXiv:2403.00504			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 01 2024	2024	Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising self-supervised approach that learns by leveraging a world model. While previously limited to predicting missing parts of an input, we explore how to generalize the JEPA prediction task to a broader set of corruptions. We introduce Image World Models, an approach that goes beyond masked image modeling and learns to predict the effect of global photometric transformations in latent space. We study the recipe of learning performant IWMs and show that it relies on three key aspects: conditioning, prediction difficulty, and capacity. Additionally, we show that the predictive world model learned by IWM can be adapted through finetuning to solve diverse tasks; a fine-tuned IWM world model matches or surpasses the performance of previous self-supervised methods. Finally, we show that learning with an IWM allows one to control the abstraction level of the learned representations, learning invariant representations such as contrastive methods, or equivariant representations such as masked image modelling.																																	2024-03-28	PPRN:87996665		
J	Lee, Katherine; Cooper, A. Feder; Grimmelmann, James										TALKIN” BOUT AI GENERATION: COPYRIGHT AND THE GENERATIVE-AI SUPPLY CHAIN								Arxiv											2	2;2024-03-01;https://www.arxiv.org/abs/2309.08133v2| 1;2023-09-15;https://www.arxiv.org/abs/2309.08133v1	arXiv:2309.08133			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 01 2024	2024	"Does generative AI infringe copyright?" is an urgent question. It is also a difficult question, for two reasons. First, "generative AI" is not just one product from one company. It is a catch-all name for a massive ecosystem of loosely related technologies, including conversational text chatbots like ChatGPT, image generators like Midjourney and DALL-E, coding assistants like GitHub Copilot, and systems that compose music and create videos. These systems behave differently and raise different legal issues. The second problem is that copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it: authorship, similarity, direct and indirect liability, fair use, and licensing, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere.<br /> In this Article, we aim to bring order to the chaos. To do so, we introduce the generative-AI supply chain: an interconnected set of stages that transform training data (millions of pictures of cats) into generations (a new, potentially never-seen-before picture of a cat that has never existed). Breaking down generative AI into these constituent stages reveals all of the places at which companies and users make choices that have copyright consequences. It enables us to trace the effects of upstream technical designs on downstream uses, and to assess who in these complicated sociotechnical systems bears responsibility for infringement when it happens. Because we engage so closely with the technology of generative AI, we are able to shed more light on the copyright questions. We do not give definitive answers as to who should and should not be held liable. Instead, we identify the key decisions that courts will need to make as they grapple with these issues, and point out the consequences that would likely flow from different liability regimes.																																	2024-04-11	PPRN:85091133		
J	Xu, Nan; Wang, Fei; Zhou, Ben; Li, Bangzheng; Xiao, Chaowei; Chen, Muhao				Chen, Muhao/AAA-3634-2021; Wang, Fei/AAS-8701-2020						Cognitive Overload: Jailbreaking Large Language Models with Overloaded Logical Thinking								Arxiv											2	2;2024-02-29;https://www.arxiv.org/abs/2311.09827v2| 1;2023-11-16;https://www.arxiv.org/abs/2311.09827v1	arXiv:2311.09827			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 29 2024	2024	While large language models (LLMs) have demonstrated increasing power, they have also given rise to a wide range of harmful behaviors. As representatives, jailbreak attacks can provoke harmful or unethical responses from LLMs, even after safety alignment. In this paper, we investigate a novel category of jailbreak attacks specifically designed to target the cognitive structure and processes of LLMs. Specifically, we analyze the safety vulnerability of LLMs in the face of (1) multilingual cognitive overload, (2) veiled expression, and (3) effect-to-cause reasoning. Different from previous jailbreak attacks, our proposed cognitive overload is a black-box attack with no need for knowledge of model architecture or access to model weights. Experiments conducted on AdvBench and MasterKey reveal that various LLMs, including both popular open-source model Llama 2 and the proprietary model ChatGPT, can be compromised through cognitive overload. Motivated by cognitive psychology work on managing cognitive load, we further investigate defending cognitive overload attack from two perspectives. Empirical studies show that our cognitive overload from three perspectives can jailbreak all studied LLMs successfully, while existing defense strategies can hardly mitigate the caused malicious uses effectively.																																	2024-03-28	PPRN:86176930		
J	Lyu, Kaifeng; Zhao, Haoyu; Gu, Xinran; Yu, Dingli; Goyal, Anirudh; Arora, Sanjeev				Yu, Ding/AFR-1839-2022; Gu, Xinran/HPG-4896-2023						Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates								Arxiv											1	1;2024-02-28;https://www.arxiv.org/abs/2402.18540v1	arXiv:2402.18540			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 28 2024	2024	Public LLMs such as the Llama 2-Chat have driven huge activity in LLM research. These models underwent alignment training and were considered safe. Recently Qi et al. (2023) reported that even benign fine-tuning (e.g., on seemingly safe datasets) can give rise to unsafe behaviors in the models. The current paper is about methods and best practices to mitigate such loss of alignment. Through extensive experiments on several chat models (Meta's Llama 2-Chat, Mistral AI's Mistral 7B Instruct v0.2, and OpenAI's GPT-3.5 Turbo), this paper uncovers that the prompt templates used during fine-tuning and inference play a crucial role in preserving safety alignment, and proposes the "Pure Tuning, Safe Testing" (PTST) principle -- fine-tune models without a safety prompt, but include it at test time. Fine-tuning experiments on GSM8K, ChatDoctor, and OpenOrca show that PTST significantly reduces the rise of unsafe behaviors, and even almost eliminates them in some cases.																																	2024-03-28	PPRN:87990752		
J	Choudhury, Sayantan; Dey, Kritartha; Karde, Ahaskar										Untangling PBH overproduction in w-SIGWs generated by Pulsar Timing Arrays for MST-EFT of single field inflation								Arxiv											3	3;2024-02-11;https://www.arxiv.org/abs/2311.15065v3| 2;2023-12-04;https://www.arxiv.org/abs/2311.15065v2| 1;2023-11-25;https://www.arxiv.org/abs/2311.15065v1	arXiv:2311.15065			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 11 2024	2024	Our work highlights the crucial role played by the equation of state (EoS) parameter w within the context of single field inflation with Multiple Sharp Transitions (MSTs) to untangle the current state of the PBH overproduction issue. We examine the situation for a broad interval of EoS parameter that remains most favourable to explain the recent data released by the pulsar timing array (PTA) collaboration. Our analysis yields the interval, 0.2 ≤ w ≤1/3, to be the most acceptable window from the SIGW interpretation of the PTA signal and where sizeable PBHs abundance, fPBH ∈ (10−3, 1), is observed. We also obtain w = 1/3, radiation -dominated era, to be the best scenario to explain the early stages of the Universe and address the overproduction problem. Within the range of 1 ≤ cs ≤ 1.17, we construct a regularized-renormalized-resummed scalar power spectrum whose amplitude obeys the perturbativity criterion while being substantial enough to generate EoS dependent scalar induced gravitational waves (w-SIGWs) consistent with NANOGrav-15 data. Working for both cs = 1 and 1.17, we find the cs = 1.17 case more favourable for generating large mass PBHs, MPBH ∼ O(10−6 − 10−3)M⊙, as potential dark matter candidates with substantial abundance after constraints coming from microlensing experiments.																																	2024-05-25	PPRN:86295895		
J	Yue, Murong; Zhao, Jie; Zhang, Min; Du, Liang; Yao, Ziyu				LIANG, DU/HKO-1121-2023						Large Language Model Cascades with Mixture of Thoughts Representations for Cost-efficient Reasoning								Arxiv											4	4;2024-02-08;https://www.arxiv.org/abs/2310.03094v3| 3;2023-10-07;https://www.arxiv.org/abs/2310.03094v2| 2;2023-10-04;https://www.arxiv.org/abs/2310.03094v1| 1;2023-10-04;https://www.arxiv.org/abs/2310.03094v1	arXiv:2310.03094			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 08 2024	2024	Large language models (LLMs) such as GPT-4 have exhibited remarkable performance in a variety of tasks, but this strong performance often comes with the high expense of using paid API services. In this paper, we are motivated to study building an LLM cascade to save the cost of using LLMs, particularly for performing reasoning (e.g., mathematical, causal) tasks. Our cascade pipeline follows the intuition that simpler questions can be addressed by a weaker but more affordable LLM, whereas only the challenging questions necessitate the stronger and more expensive LLM. To realize this decision-making, we consider “answer consistency” of the weaker LLM as a signal of the question difficulty and propose several methods for the answer sampling and consistency checking, including one leveraging a mixture of two thought representations (i.e., Chain-of-Thought (Wei et al., 2022) and Program-of-Thought (Chen et al., 2022; Gao et al., 2023)). Through experiments on six reasoning benchmark datasets, with GPT-3.5-turbo and GPT-4 being the weaker and stronger LLMs, respectively, we demonstrate that our proposed LLM cascades can achieve performance comparable to using solely the stronger LLM but require only 40% of its cost. Our codes are available athttps://github.com/MurongYue/LLM_MoT_cascade.																																	2024-05-25	PPRN:85436192		
J	Du, Yu; Wei, Fangyun; Zhang, Hongyang				du, yu'e/NPJ-1573-2025						AnyTool: Self-Reflective, Hierarchical Agents for Large-Scale API Calls								Arxiv											1	1;2024-02-06;https://www.arxiv.org/abs/2402.04253v1	arXiv:2402.04253			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 06 2024	2024	We introduce AnyTool, a large language model agent designed to revolutionize the utilization of a vast array of tools in addressing user queries. We utilize over 16,000 APIs from Rapid API, operating under the assumption that a subset of these APIs could potentially resolve the queries. AnyTool primarily incorporates three elements: an API retriever with a hierarchical structure, a solver aimed at resolving user queries using a selected set of API candidates, and a self -reflection mechanism, which re -activates AnyTool if the initial solution proves impracticable. AnyTool is powered by the function calling feature of GPT-4, eliminating the need for training external modules. We also revisit the evaluation protocol introduced by previous works and identify a limitation in this protocol that leads to an artificially high pass rate. By revising the evaluation protocol to better reflect practical application scenarios, we introduce an additional benchmark, termed AnyToolBench. Experiments across various datasets demonstrate the superiority of our AnyTool over strong baselines such as ToolLLM and a GPT-4 variant tailored for tool utilization. For instance, AnyTool outperforms ToolLLM by +35.4% in terms of average pass rate on ToolBench. Code will be available at https://github.com/dyabel/AnyTool.																																	2024-02-21	PPRN:87534050		
J	Zhang, Zhengyan; Song, Yixin; Yu, Guanghui; Han, Xu; Lin, Yankai; Xiao, Chaojun; Song, Chenyang; Liu, Zhiyuan; Mi, Zeyu; Sun, Maosong				zhengyan, zhang/D-2029-2012; Mi, Zeyu/NBY-3261-2025; SONG, CHENYANG/IVV-3714-2023; Song, Yixin/IWV-3440-2023; Liu, Zhiyuan/I-2233-2014; Yu, Guanghui/H-4968-2013						ReLU2 Wins: Discovering Efficient Activation Functions for Sparse LLMs								Arxiv											1	1;2024-02-06;https://www.arxiv.org/abs/2402.03804v1	arXiv:2402.03804			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 06 2024	2024	Sparse computation offers a compelling solution for the inference of Large Language Models (LLMs) in low -resource scenarios by dynamically skipping the computation of inactive neurons. While traditional approaches focus on ReLU-based LLMs, leveraging zeros in activation values, we broaden the scope of sparse LLMs beyond zero activation values. We introduce a general method that defines neuron activation through neuron output magnitudes and a tailored magnitude threshold, demonstrating that non-ReLU LLMs also exhibit sparse activation. To find the most efficient activation function for sparse computation, we propose a systematic framework to examine the sparsity of LLMs from three aspects: the trade-off between sparsity and performance, the predictivity of sparsity, and the hardware affinity. We conduct thorough experiments on LLMs utilizing different activation functions, including ReLU, SwiGLU, ReGLU, and ReLU2. The results indicate that models employing ReLU2 excel across all three evaluation aspects, highlighting its potential as an efficient activation function for sparse LLMs. We will release the code to facilitate future research.																																	2024-02-21	PPRN:87533561		
J	Yang, Kailai; Zhang, Tianlin; Kuang, Ziyan; Xie, Qianqian; Huang, Jimin; Ananiadou, Sophia				Yang, Kailai/KIB-2102-2024; Zhang, Tianlin/V-8168-2019						MentaLLaMA: Interpretable Mental Health Analysis on Social Media with Large Language Models								Arxiv											3	3;2024-02-04;https://www.arxiv.org/abs/2309.13567v3| 2;2023-10-15;https://www.arxiv.org/abs/2309.13567v2| 1;2023-09-24;https://www.arxiv.org/abs/2309.13567v1	arXiv:2309.13567			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 04 2024	2024	As an integral part of people’s daily lives, social media is becoming a rich source for automatic mental health analysis. As traditional discriminative methods bear poor generalization ability and low interpretability, the recent large language models (LLMs) have been explored for interpretable mental health analysis on social media, which aims to provide detailed explanations along with predictions in zero-shot or few-shot settings. The results show that LLMs still achieve unsatisfactory classification performance in a zero-shot/few-shot manner, which further significantly affects the quality of the generated explanations. Domain-specific finetuning is an effective solution, but faces two critical challenges: 1) lack of high-quality training data. 2) no open-source foundation LLMs. To alleviate these problems, we formally model interpretable mental health analysis as a text generation task, and build the first multi-task and multi-source interpretable mental health instruction (IMHI) dataset with 105K data samples to support LLM instruction tuning and evaluation. The raw social media data are collected from 10 existing sources covering 8 mental health analysis tasks. We prompt ChatGPT with expert-designed few-shot prompts to obtain explanations. To ensure the reliability of the explanations, we perform strict automatic and human evaluations on the correctness, consistency, and quality of generated data. Based on the IMHI dataset and LLaMA2 foundation models, we train MentaLLaMA, the first open-source instruction-following LLM series for interpretable mental health analysis on social media. We evaluate MentaLLaMA and other advanced methods on the IMHI benchmark, the first holistic evaluation benchmark for interpretable mental health analysis. The results show that MentaLLaMA approaches state-of-the-art discriminative methods in correctness and generates human-level explanations. MentaLLaMA models also show strong generalizability to unseen tasks. 																																	2024-02-21	PPRN:85183417		
J	Tindall, Joseph; Fishman, Matt; Stoudenmire, Miles; Sels, Dries										Efficient tensor network simulation of IBM's Eagle kicked Ising experiment								Arxiv											2	2;2024-01-26;https://www.arxiv.org/abs/2306.14887v3| 1;2023-06-26;https://www.arxiv.org/abs/2306.14887v1	arXiv:2306.14887			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 26 2024	2024	We report an accurate and efficient classical simulation of a kicked Ising quantum system on the heavy-hexagon lattice. A simulation of this system was recently performed on a 127 qubit quantum processor using noise mitigation techniques to enhance accuracy (Nature volume 618, p. 500–505 (2023)). Here we show that, by adopting a tensor network approach that reflects the geometry of the lattice and is approximately contracted using belief propagation, we can perform a classical simulation that is significantly more accurate and precise than the results obtained from the quantum processor and many other classical methods. We quantify the tree-like correlations of the wavefunction in order to explain the accuracy of our belief propagation-based approach. We also show how our method allows us to perform simulations of the system to long times in the thermodynamic limit, corresponding to a quantum computer with an infinite number of qubits. Our tensor network approach has broader applications for simulating the dynamics of quantum systems with tree-like correlations.																																	2024-02-14	PPRN:73535363		
J	Shen, Lingfeng; Tan, Weiting; Chen, Sihao; Chen, Yunmo; Zhang, Jingyu; Xu, Haoran; Zheng, Boyuan; Koehn, Philipp; Khashabi, Daniel				Chen, Yunmo/KRP-9297-2024; Xu, Haoran/AEW-7367-2022; Zheng, Boyuan/HTL-7984-2023; Koehn, Philipp/NUP-4676-2025						The Language Barrier: Dissecting Safety Challenges of LLMs in Multilingual Contexts								Arxiv											1	1;2024-01-23;https://www.arxiv.org/abs/2401.13136v1	arXiv:2401.13136			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 23 2024	2024	As the influence of large language models (LLMs) spans across global communities, their safety challenges in multilingual settings become paramount for alignment research. This paper examines the variations in safety challenges faced by LLMs across different languages and discusses approaches to alleviating such concerns. By comparing how state-of-the-art LLMs respond to the same set of malicious prompts written in higher- vs. lower-resource languages, we observe that (1) LLMs tend to generate unsafe responses much more often when a malicious prompt is written in a lower-resource language, and (2) LLMs tend to generate more irrelevant responses to malicious prompts in lower-resource languages. To understand where the discrepancy can be attributed, we study the effect of instruction tuning with reinforcement learning from human feedback (RLHF) or supervised finetuning (SFT) on the HH-RLHF dataset. Surprisingly, while training with high-resource languages improves model alignment, training in lower-resource languages yields minimal improvement. This suggests that the bottleneck of cross-lingual alignment is rooted in the pretraining stage. Our findings highlight the challenges in cross-lingual LLM safety, and we hope they inform future research in this direction1.																																	2024-02-10	PPRN:87316908		
J	Paech, Samuel J.										EQ-Bench: An Emotional Intelligence Benchmark for Large Language Models								Arxiv											2	2;2024-01-03;https://www.arxiv.org/abs/2312.06281v2| 1;2023-12-11;https://www.arxiv.org/abs/2312.06281v1	arXiv:2312.06281			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 03 2024	2024	We introduce EQ-Bench, a novel benchmark designed to evaluate aspects of emotional intelligence in Large Language Models (LLMs). We assess the ability of LLMs to understand complex emotions and social interactions by asking them to predict the intensity of emotional states of characters in a dialogue. The benchmark is able to discriminate effectively between a wide range of models. We find that EQ-Bench correlates strongly with comprehensive multi-domain benchmarks like MMLU (Hendrycks et al., 2020) (r=0.97), indicating that we may be capturing similar aspects of broad intelligence. Our benchmark produces highly repeatable results using a set of 60 English-language questions.																																	2024-01-11	PPRN:86543890		
J	Mcleish, Sean; Bansal, Arpit; Stein, Alex; Jain, Neel; Kirchenbauer, John; Bartoldson, Brian R.; Kailkhura, Bhavya; Bhatele, Abhinav; Geiping, Jonas; Schwarzschild, Avi; Goldstein, Tom				Bansal, Arpit/NRY-7306-2025						Transformers Can Do Arithmetic with the Right Embeddings								Arxiv											2	2;2024-12-23;https://www.arxiv.org/abs/2405.17399v2| 1;2024-05-27;https://www.arxiv.org/abs/2405.17399v1	arXiv:2405.17399			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 23 2024	2024	The poor performance of transformers on arithmetic tasks seems to stem in large part from their inability to keep track of the exact position of each digit inside of a large span of digits. We mend this problem by adding an embedding to each digit that encodes its position relative to the start of the number. In addition to the boost these embeddings provide on their own, we show that this fix enables architectural modifications such as input injection and recurrent layers to improve performance even further. With positions resolved, we can study the logical extrapolation ability of transformers. Can they solve arithmetic problems that are larger and more complex than those in their training data? We find that training on only 20 digit numbers with a single GPU for one day, we can reach state-of-the-art performance, achieving up to 99% accuracy on 100 digit addition problems. Finally, we show that these gains in numeracy also unlock improvements on other multi-step reasoning tasks including sorting and multiplication. 2																																	2025-01-31	PPRN:89057494		
J	Tong, Yuxuan; Zhang, Xiwen; Wang, Rui; Wu, Ruidong; He, Junxian				wang, rui/JAC-6240-2023; HE, Junxian/OHV-2278-2025; Tong, Yuxuan/OHR-7117-2025						DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving								Arxiv											2	2;2024-12-23;https://www.arxiv.org/abs/2407.13690v2| 1;2024-06-18;https://www.arxiv.org/abs/2407.13690v1	arXiv:2407.13690			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 23 2024	2024	Solving mathematical problems requires advanced reasoning abilities and presents notable challenges for large language models. Previous works usually synthesize data from proprietary models to augment existing datasets, followed by instruction tuning to achieve top-tier results. However, our analysis of these datasets reveals severe biases towards easy queries, with frequent failures to generate any correct response for the most challenging queries. Hypothesizing that difficult queries are crucial to learn complex reasoning, we propose Difficulty-Aware Rejection Tuning (DART), a method that allocates difficult queries more trials during the synthesis phase, enabling more extensive training on difficult samples. Utilizing DART, we have created new datasets for mathematical problem-solving that focus more on difficult queries and are substantially smaller than previous ones. Remarkably, our synthesis process solely relies on a 7B-sized open-weight model, without reliance on the commonly used proprietary GPT-4. We fine-tune various base models on our datasets ranging from 7B to 70B in size, resulting in a series of strong models called DART-MATH. In comprehensive in-domain and out-of-domain evaluation on 6 mathematical benchmarks, DART-MATH outperforms vanilla rejection tuning significantly, being superior or comparable to previous arts, despite using much smaller datasets and no proprietary models. Furthermore, our results position our synthetic datasets as the most effective and cost-efficient publicly available resources for advancing mathematical problem-solving.																																	2025-02-02	PPRN:90881505		
J	Gui, Ming; Schusterbauer, Johannes; Prestel, Ulrich; Ma, Pingchuan; Kotovenko, Dmytro; Grebenkova, Olga; Baumann, Stefan Andreas; Hu, Vincent Tao; Ommer, Bjoern				Ma, Pingchuan/AFR-0634-2022						DepthFM: Fast Monocular Depth Estimation with Flow Matching								Arxiv											2	2;2024-12-19;https://www.arxiv.org/abs/2403.13788v2| 1;2024-03-20;https://www.arxiv.org/abs/2403.13788v1	arXiv:2403.13788			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 19 2024	2024	Current discriminative depth estimation methods often produce blurry artifacts, while generative approaches suffer from slow sampling due to curvatures in the noise-to-depth transport. Our method addresses these challenges by framing depth estimation as a direct transport between image and depth distributions. We are the first to explore flow matching in this field, and we demonstrate that its interpolation trajectories enhance both training and sampling efficiency while preserving high performance. While generative models typically require extensive training data, we mitigate this dependency by integrating external knowledge from a pre-trained image diffusion model, enabling effective transfer even across differing objectives. To further boost our model performance, we employ synthetic data and utilize image-depth pairs generated by a discriminative model on an in-the-wild image dataset. As a generative model, our model can reliably estimate depth confidence, which provides an additional advantage. Our approach achieves competitive zero-shot performance on standard benchmarks of complex natural scenes while improving sampling efficiency and only requiring minimal synthetic data for training.																																	2025-01-27	PPRN:88247941		
J	Chen, Bo; Cheng, Xingyi; Li, Pan; Geng, Yangli-ao; Gong, Jing; Li, Shen; Bei, Zhilei; Tan, Xu; Wang, Boyan; Zeng, Xin; Liu, Chiming; Zeng, Aohan; Dong, Yuxiao; Tang, Jie; Song, Le				Geng, Yangliao/AAB-6774-2020						xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein								Arxiv											2	2;2024-12-09;https://www.arxiv.org/abs/2401.06199v2| 1;2024-01-11;https://www.arxiv.org/abs/2401.06199v1	arXiv:2401.06199			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Dec 09 2024	2024	Protein language models have shown remarkable success in learning biological information from protein sequences. However, most existing models are limited by either autoencoding or autoregressive pre-training objectives, which makes them struggle to handle protein understanding and generation tasks concurrently. We propose a unified protein language model, xTrimoPGLM, to address these two types of tasks simultaneously through an innovative pre-training framework. Our key technical contribution is an exploration of the compatibility and the potential for joint optimization of the two types of objectives, which has led to a strategy for training xTrimoPGLM at an unprecedented scale of 100 billion parameters and 1 trillion training tokens. Our extensive experiments reveal that 1) xTrimoPGLM significantly outperforms other advanced baselines in 18 protein understanding benchmarks across four categories. The model also facilitates an atomic-resolution view of protein structures, leading to an advanced 3D structural prediction model that surpasses existing language model-based tools. 2) xTrimoPGLM not only can generate de novo protein sequences following the principles of natural ones, but also can perform programmable generation after supervised fine-tuning (SFT) on curated sequences. These results highlight the substantial capability and versatility of xTrimoPGLM in understanding and generating protein sequences, contributing to the evolving landscape of foundation models in protein science.																																	2025-01-17	PPRN:87155811		
J	Chen, Yiwen; Wang, Yikai; Luo, Yihao; Wang, Zhengyi; Chen, Zilong; Zhu, Jun; Zhang, Chi; Lin, Guosheng				Luo, Yi-Hao/F-8883-2017; Chen, Yiwen/IUP-2419-2023						MeshAnything V2: Artist-Created Mesh Generation With Adjacent Mesh Tokenization								Arxiv											3	3;2024-12-01;https://www.arxiv.org/abs/2408.02555v3| 2;2024-11-20;https://www.arxiv.org/abs/2408.02555v2| 1;2024-08-05;https://www.arxiv.org/abs/2408.02555v1	arXiv:2408.02555			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 01 2024	2024	Meshes are the de facto 3D representation in the industry but are labor-intensive to produce. Recently, a line of research has focused on autoregressively generating meshes. This approach processes meshes into a sequence composed of vertices and then generates them vertex by vertex, similar to how a language model generates text. These methods have achieved some success but still struggle to generate complex meshes. One primary reason for this limitation is their inefficient tokenization methods. To address this issue, we introduce MeshAnything V2, an advanced mesh generation model designed to create Artist-Created Meshes that align precisely with specified shapes. A key innovation behind MeshAnything V2 is our novel Adjacent Mesh Tokenization (AMT) method. Unlike traditional approaches that represent each face using three vertices, AMT optimizes this by employing a single vertex wherever feasible, effectively reducing the token sequence length by about half on average. This not only streamlines the tokenization process but also results in more compact and well-structured sequences, enhancing the efficiency of mesh generation. With these improvements, MeshAnything V2 effectively doubles the face limit compared to previous models, delivering superior performance without increasing computational costs. 																																	2025-01-11	PPRN:91248812		
J	Sun, Xingwu; Chen, Yanfeng; Huang, Yiqing; Xie, Ruobing; Zhu, Jiaqi; Zhang, Kai; Li, Shuaipeng; Yang, Zhen; Han, Jonny; Shu, Xiaobo; Bu, Jiahao; Chen, Zhongzhi; Huang, Xuemeng; Lian, Fengzong; Yang, Saiyong; Yan, Jianfeng; Zeng, Yuyuan; Ren, Xiaoqin; Yu, Chao; Wu, Lulu; Mao, Yue; Xia, Jun; Yang, Tao; Zheng, Suncong; Wu, Kan; Jiao, Dian; Xue, Jinbao; Zhang, Xipeng; Wu, Decheng; Liu, Kai; Wu, Dengpeng; Xu, Guanghui; Chen, Shaohua; Chen, Shuang; Feng, Xiao; Hong, Yigeng; Zheng, Junqiang; Xu, Chengcheng; Li, Zongwei; Kuang, Xiong; Hu, Jianglu; Chen, Yiqi; Deng, Yuchi; Li, Guiyang; Liu, Ao; Zhang, Chenchen; Hu, Shihui; Zhao, Zilong; Wu, Zifan; Ding, Yao; Wang, Weichao; Liu, Han; Wang, Roberts; Fei, Hao; Yu, Peijie; Zhao, Ze; Cao, Xun; Wang, Hai; Xiang, Fusheng; Huang, Mengyuan; Xiong, Zhiyuan; Hu, Bin; Hou, Xuebin; Jiang, Lei; Ma, Jianqiang; Wu, Jiajia; Deng, Yaping; Shen, Yi; Wang, Qian; Liu, Weijie; Liu, Jie; Chen, Meng; Dong, Liang; Jia, Weiwen; Chen, Hu; Liu, Feifei; Yuan, Rui; Xu, Huilin; Yan, Zhenxiang; Cao, Tengfei; Hu, Zhichao; Feng, Xinhua; Du, Dong; Yu, Tinghao; Tao, Yangyu; Zhang, Feng; Zhu, Jianchen; Xu, Chengzhong; Li, Xirui; Zha, Chong; Ouyang, Wen; Xia, Yinben; Li, Xiang; He, Zekun; Chen, Rongpeng; Song, Jiawei; Chen, Ruibin; Jiang, Fan; Zhao, Chongqing; Wang, Bo; Gong, Hao; Gan, Rong; Hu, Winston; Kang, Zhanhui; Yang, Yong; Liu, Yuhong; Wang, Di; Jiang, Jie				Chen, Zhongzhi/M-1387-2019; xu, huilin/HHZ-3153-2022; Shu, Xiaobo/NWH-0861-2025; Jiang, Fan/GQQ-9024-2022; Wu, Jiajia/HPD-5711-2023; Jiao, Dian/E-5814-2011; Deng, Ya-Ping/AAB-4572-2020; Feng, Xin-Hua/HLV-6637-2023; chen, yiqi/LTF-4294-2024; Chen, Shaohua/HLV-6920-2023; Xu, Chengcheng/KRO-3551-2024; Hu, Bin/ADX-5883-2022; wang, weichao/KII-5567-2024; Jiang, Jiehui/OFO-0259-2025; Song, Jiawei/MYQ-9723-2025; Yan, Jianfeng/G-9099-2016; Ma, Jian-Qiang/HJG-5191-2022; XU, CHENGZHONG/AAX-1707-2020						Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent								Arxiv											1	1;2024-11-06;https://www.arxiv.org/abs/2411.02265v3	arXiv:2411.02265			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 06 2024	2024	In this paper, we introduce Hunyuan-Large, which is currently the largest open- source Transformer-based mixture of experts model, with a total of 389 billion parameters and 52 billion activation parameters, capable of handling up to 256K tokens. We conduct a thorough evaluation of Hunyuan-Large’s superior performance across various benchmarks including language understanding and generation, logical reasoning, mathematical problem-solving, coding, long-context, and aggregated tasks, where it outperforms LLama3.1-70B and exhibits comparable performance when compared to the significantly larger LLama3.1-405B model. Key practice of Hunyuan-Large include large-scale synthetic data that is orders larger than in previous literature, a mixed expert routing strategy, a key-value cache compression technique, and an expert-specific learning rate strategy. Additionally, we also investigate the scaling laws and learning rate schedule of mixture of experts models, providing valuable insights and guidances for future model development and optimization. The code and checkpoints of Hunyuan-Large are released to facilitate future innovations and applications.																																	2025-01-24	PPRN:119056552		
J	Modarressi, Ali; Imani, Ayyoob; Fayyaz, Mohsen; Schuetze, Hinrich										RET-LLM: Towards a General Read-Write Memory for Large Language Models								Arxiv											2	2;2024-10-24;https://www.arxiv.org/abs/2305.14322v2| 1;2023-05-23;https://www.arxiv.org/abs/2305.14322v1	arXiv:2305.14322			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 24 2024	2024	Large language models (LLMs) have significantly advanced the field of natural language processing (NLP) through their extensive parameters and comprehensive data utilization. However, existing LLMs lack a dedicated memory unit, limiting their ability to explicitly store and retrieve knowledge for various tasks. In this paper, we propose RET-LLM a novel framework that equips LLMs with a general write-read memory unit, allowing them to extract, store, and recall knowledge from the text as needed for task performance. Inspired by Davidsonian semantics theory, we extract and save knowledge in the form of triplets. The memory unit is designed to be scalable, aggregatable, updatable, and interpretable. Through qualitative evaluations, we demonstrate the superiority of our proposed framework over baseline approaches in question answering tasks. Moreover, our framework exhibits robust performance in handling temporal-based question answering tasks, showcasing its ability to effectively manage time-dependent information.																																	2024-11-27	PPRN:71712278		
J	Lee, Cheryl; Xia, Chunqiu Steven; Yang, Longji; Huang, Jen-tse; Zhu, Zhouruixin; Zhang, Lingming; Lyu, Michael R.				Huang, Jen-Tse/IRZ-7526-2023; ZHU, Zhouruixing/LXW-9360-2024						FixAgent: Hierarchical Multi-Agent Framework for Unified Software Debugging								Arxiv											2	2;2024-10-23;https://www.arxiv.org/abs/2404.17153v2| 1;2024-04-26;https://www.arxiv.org/abs/2404.17153v1	arXiv:2404.17153			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Oct 23 2024	2024	Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25× to 2.56× bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. 																																	2024-11-24	PPRN:88663778		
J	Liu, Linyu; Pan, Yu; Li, Xiaocheng; Chen, Guanting										Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach								Arxiv											4	4;2024-10-23;https://www.arxiv.org/abs/2404.15993v4| 3;2024-06-29;https://www.arxiv.org/abs/2404.15993v3| 2;2024-05-21;https://www.arxiv.org/abs/2404.15993v2| 1;2024-04-24;https://www.arxiv.org/abs/2404.15993v1	arXiv:2404.15993			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 23 2024	2024	In this paper, we study the problem of uncertainty estimation and calibration for LLMs. We begin by formulating the uncertainty estimation problem, a relevant yet underexplored area in existing literature. We then propose a supervised approach that leverages labeled datasets to estimate the uncertainty in LLMs’ responses. Based on the formulation, we illustrate the difference between the uncertainty estimation for LLMs and that for standard ML models and explain why the hidden neurons of the LLMs may contain uncertainty information. Our designed approach demonstrates the benefits of utilizing hidden activations to enhance uncertainty estimation across various tasks and shows robust transferability in out-of-distribution settings. We distinguish the uncertainty estimation task from the uncertainty calibration task and show that better uncertainty estimation leads to better calibration performance. Furthermore, our method is easy to implement and adaptable to different levels of model accessibility including black box, grey box, and white box.																																	2024-11-24	PPRN:88634032		
J	Ling, Pengyang; Bu, Jiazi; Zhang, Pan; Dong, Xiaoyi; Zang, Yuhang; Wu, Tong; Chen, Huaian; Wang, Jiaqi; Jin, Yi				Bu, Jiazi/PAV-1667-2025; Zang, Yuhang/AES-3018-2022; WANG, JIAQI/KBB-8837-2024; Ling, Pengyang/KYP-5654-2024; Dong, Xiaoyi/AAC-8666-2019						MotionClone: Training-Free Motion Cloning for Controllable Video Generation								Arxiv											5	5;2024-10-22;https://www.arxiv.org/abs/2406.05338v6| 4;2024-10-12;https://www.arxiv.org/abs/2406.05338v5| 3;2024-10-08;https://www.arxiv.org/abs/2406.05338v4| 2;2024-06-12;https://www.arxiv.org/abs/2406.05338v2| 1;2024-06-08;https://www.arxiv.org/abs/2406.05338v1	arXiv:2406.05338			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 22 2024	2024	Motion-based controllable video generation offers the potential for creating captivating visual content. Existing methods typically necessitate model training to encode particular motion cues or incorporate fine-tuning to inject certain motion patterns, resulting in limited flexibility and generalization. In this work, we propose MotionClone , a training-free framework that enables motion cloning from reference videos to versatile motion-controlled video generation, including textto-video and image-to-video. Based on the observation that the dominant components in temporal-attention maps drive motion synthesis, while the rest mainly capture noisy or very subtle motions, MotionClone utilizes sparse temporal attention weights as motion representations for motion guidance, facilitating diverse motion transfer across varying scenarios. Meanwhile, MotionClone allows for the direct extraction of motion representation through a single denoising step, bypassing the cumbersome inversion processes and thus promoting both efficiency and flexibility. Extensive experiments demonstrate that MotionClone exhibits proficiency in both global camera motion and local object motion, with notable superiority in terms of motion fidelity, textual alignment, and temporal consistency.																																	2024-11-23	PPRN:89266730		
J	Nguyen, Tu Anh; Mueller, Benjamin; Yu, Bokai; Costa-jussa, Marta R.; Elbayad, Maha; Popuri, Sravya; Ropers, Christophe; Duquenne, Paul-Ambroise; Algayres, Robin; Mavlyutov, Ruslan; Gat, Itai; Williamson, Mary; Synnaeve, Gabriel; Pino, Juan; Sagot, Benoit; Dupoux, Emmanuel				Rey-Pino, Juan/JAN-6923-2023; Costa-jussà, Marta/M-7886-2013; Sagot, Benoit/AAQ-3583-2021						Spirit LM: Interleaved Spoken and Written Language Model								Arxiv											2	2;2024-10-18;https://www.arxiv.org/abs/2402.05755v2| 1;2024-02-08;https://www.arxiv.org/abs/2402.05755v1	arXiv:2402.05755			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 18 2024	2024	We introduce SPIRIT LM, a foundation multimodal language model that freely mixes text and speech. Our model is based on a 7B pretrained text language model that we extend to the speech modality by continuously training it on text and speech units. Speech and text sequences are concatenated as a single stream of tokens, and trained with a word-level interleaving method using a small automatically-curated speech-text parallel corpus. SPIRIT LM comes in two versions: a BASE version that uses speech phonetic units (HuBERT) and an EXPRESSIVE version that models expressivity using pitch and style units in addition to the phonetic units. For both versions, the text is encoded with subword BPE tokens. The resulting model displays both the semantic abilities of text models and the expressive abilities of speech models. Additionally, we demonstrate that S PIRIT LM can learn new tasks in a few-shot fashion across modalities (i.e. ASR, TTS, Speech Classification).																																	2024-11-20	PPRN:87572893		
J	Wang, Yike; Feng, Shangbin; Wang, Heng; Shi, Weijia; Balachandran, Vidhisha; He, Tianxing; Tsvetkov, Yulia				Wang, Yike/JEP-6766-2023; He, Tianxing/MDT-2168-2025						Resolving Knowledge Conflicts in Large Language Models								Arxiv											3	3;2024-10-15;https://www.arxiv.org/abs/2310.00935v3| 2;2024-09-05;https://www.arxiv.org/abs/2310.00935v2| 1;2023-10-02;https://www.arxiv.org/abs/2310.00935v1	arXiv:2310.00935			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 15 2024	2024	Large language models (LLMs) often encounter knowledge conflicts, scenarios where discrepancy arises between the internal parametric knowledge of LLMs and non-parametric information provided in the prompt context. In this work we ask what are the desiderata for LLMs when a knowledge conflict arises and whether existing LLMs fulfill them. We posit that LLMs should 1) identify knowledge conflicts, 2) pinpoint conflicting information segments, and 3) provide distinct answers or viewpoints in conflicting scenarios. To this end, we introduce an evaluation framework for simulating contextual knowledge conflicts and quantitatively evaluating to what extent LLMs achieve these goals. It includes diverse and complex situations of knowledge conflict, knowledge from diverse entities and domains, two synthetic conflict creation methods, and settings with progressively increasing difficulty to reflect realistic knowledge conflicts. Extensive experiments with the framework reveal that while LLMs perform well in identifying the existence of knowledge conflicts, they struggle to determine the specific conflicting knowledge and produce a response with distinct answers amidst conflicting information. To address these challenges, we propose new instruction-based approaches that augment LLMs to better achieve the three goals. Further analysis shows that abilities to tackle knowledge conflicts are greatly impacted by factors such as knowledge domain, while generating robust responses to knowledge conflict scenarios remains an open research question.																																	2024-11-10	PPRN:85355413		
J	Kallus, Nathan; Mao, Xiaojie										On the role of surrogates in the efficient estimation of treatment effects with limited outcome data								Arxiv											4	4;2024-10-10;https://www.arxiv.org/abs/2003.12408v5| 3;2024-09-02;https://www.arxiv.org/abs/2003.12408v4| 2;2024-05-14;https://www.arxiv.org/abs/2003.12408v3| 1;2020-03-27;https://www.arxiv.org/abs/2003.12408v1	arXiv:2003.12408			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 10 2024	2024	In many experimental and observational studies, the outcome of interest is often difficult or expensive to observe, reducing effective sample sizes for estimating average treatment effects (ATEs) even when identifiable. We study how incorporating data on units for which only surrogate outcomes not of primary interest are observed can increase the precision of ATE estimation. We refrain from imposing stringent surrogacy conditions, which permit surrogates as perfect replacements for the target outcome. Instead, we supplement the available, albeit limited, observations of the target outcome with abundant observations of surrogate outcomes, without any assumptions beyond unconfounded treatment assignment and missingness and corresponding overlap conditions. To quantify the potential gains, we derive the difference in efficiency bounds on ATE estimation with and without surrogates, both when an overwhelming or comparable number of units have missing outcomes. We develop robust ATE estimation and inference methods that realize these efficiency gains. We empirically demonstrate the gains by studying long-term-earning effects of job training.																																	2024-11-01	PPRN:13099340		
J	Qiu, Huachuan; He, Hongliang; Zhang, Shuai; Li, Anqi; Lan, Zhenzhong				He, Hongliang He/Y-9779-2019						SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support								Arxiv											2	2;2024-10-04;https://www.arxiv.org/abs/2305.00450v3| 1;2024-02-22;https://www.arxiv.org/abs/2305.00450v2	arXiv:2305.00450			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 04 2024	2024	Developing specialized dialogue systems for mental health support requires multi-turn conversation data, which has recently garnered increasing attention. However, gathering and releasing large-scale, real-life multi-turn conversations that could facilitate advancements in mental health support presents challenges in data privacy protection and the time and cost involved in crowdsourcing. To address these challenges, we introduce SMILE, a single-turn to multi-turn inclusive language expansion technique that prompts ChatGPT to rewrite public single-turn dialogues into multi-turn ones. Our work begins by analyzing language transformation and validating the feasibility of our proposed method. We conduct a study on dialogue diversity, including lexical features, semantic features, and dialogue topics, demonstrating the effectiveness of our method. Further, we employ our method to generate a large-scale, lifelike, and diverse dialogue dataset named SMILECHAT, consisting of 55k dialogues. Finally, we utilize the collected corpus to develop a mental health chatbot, MeChat. To better assess the quality of SMILECHAT, we collect a small-scale real-life counseling dataset conducted by data anonymization. Both automatic and human evaluations demonstrate significant improvements in our dialogue system and confirm that SMILECHAT is high-quality. Code, data, and model are publicly available at https://github.com/qiuhuachuan/smile.																																	2024-10-25	PPRN:87804740		
J	Maldacena, Juan										Comments on the no boundary wavefunction and slow roll inflation								Arxiv											1	1;2024-10-02;https://www.arxiv.org/abs/2403.10510v2	arXiv:2403.10510			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 02 2024	2024	We review aspects of the Hartle-Hawking no boundary geometry in the context of slow roll inflation. We give an analytic approximation to the geometry and we explain the rationale for the proposal. We also explain why it gives a prediction for the curvature of the universe that is in disagreement with observations and give a quick review of proposed ways to resolve that disagreement.																																	2024-10-18	PPRN:102599319		
J	Duisterhof, Bardienus; Zust, Lojze; Weinzaepfel, Philippe; Leroy, Vincent; Cabon, Yohann; Revaud, Jerome										MASt3R-SfM: a Fully-Integrated Solution for Unconstrained Structure-from-Motion								Arxiv											1	1;2024-09-27;https://www.arxiv.org/abs/2409.19152v1	arXiv:2409.19152			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 27 2024	2024	Structure-from-Motion (SfM), a task aiming at jointly recovering camera poses and 3D geometry of a scene given a set of images, remains a hard problem with still many open challenges despite decades of significant progress. The traditional solution for SfM consists of a complex pipeline of minimal solvers which tends to propagate errors and fails when images do not sufficiently overlap, have too little motion, etc. Recent methods have attempted to revisit this paradigm, but we empirically show that they fall short of fixing these core issues. In this paper, we propose instead to build upon a recently released foundation model for 3D vision that can robustly produce local 3D reconstructions and accurate matches. We introduce a low-memory approach to accurately align these local reconstructions in a global coordinate system. We further show that such foundation models can serve as efficient image retrievers without any overhead, reducing the overall complexity from quadratic to linear. Overall, our novel SfM pipeline is simple, scalable, fast and truly unconstrained, i.e. it can handle any collection of images, ordered or not. Extensive experiments on multiple benchmarks show that our method provides steady performance across diverse settings, especially outperforming existing methods in small- and medium-scale settings.																																	2024-10-10	PPRN:100737874		
J	Yue, Minghao; Eilers, Anna-Christina; Ananna, Tonima Tasnim; Panagiotou, Christos; Kara, Erin; Miyaji, Takamitsu										Stacking X-ray Observations of "Little Red Dots": Implications for their AGN Properties								Arxiv											3	3;2024-09-13;https://www.arxiv.org/abs/2404.13290v3| 2;2024-04-28;https://www.arxiv.org/abs/2404.13290v2| 1;2024-04-20;https://www.arxiv.org/abs/2404.13290v1	arXiv:2404.13290			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 13 2024	2024	Recent James Webb Space Telescope (JWST) observations have revealed a population of compact extragalactic objects at z≳4 with red near-infrared colors, which have been dubbed as "Little Red Dots" (LRDs). The spectroscopically-selected LRDs exhibit broad Hα emission lines, which likely indicates that type-I active galactic nuclei (AGN) are harbored in the galaxies' dust-reddened cores. However, other mechanisms, like strong outflowing winds, could also produce broad Hα emission lines, and thus, the nature of LRDs is still under debate. We test the AGN hypothesis for LRDs by stacking the archival Chandra observations of 34 spectroscopically-selected LRDs. We obtain tentative detections in the soft (0.5−2 keV) and hard (2−8 keV) X-ray bands with 2.9σ and 3.2σ significance, and with 4.1σ significance when combining the two bands. Nevertheless, we find that the soft (hard) band 3σ upper limit is ∼1dex (∼0.3dex) lower than the expected level from the LX−LHα relation for typical type-I AGNs. Our results indicate that AGN activity is indeed likely present in LRDs, though these objects have significantly different properties compared to previously identified type-I AGNs, i.e., LRDs may have intrinsically weak X-ray emissions. We find it difficult to explain the low LX/LHα ratios observed in LRDs solely by absorption. It is also unlikely that fast outflows have major contributions to the broad Hα lines. Our findings indicate that empirical relations (e.g., for black hole mass measurements) established for typical type-I AGNs should be used with caution when analyzing the properties of LRDs.																																	2024-09-30	PPRN:88614188		
J	Chung, Hyungjin; Kim, Jeongsol; Park, Geon Yeong; Nam, Hyelin; Ye, Jong Chul				Chung, Hyungjin/AAL-1161-2021; Park, Geon Yeong/JMQ-9146-2023; Ye, Jong/C-1623-2011						CFG++: Manifold-constrained Classifier Free Guidance for Diffusion Models								Arxiv											2	2;2024-09-12;https://www.arxiv.org/abs/2406.08070v2| 1;2024-06-12;https://www.arxiv.org/abs/2406.08070v1	arXiv:2406.08070			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 12 2024	2024	Classifier-free guidance (CFG) is a fundamental tool in modern diffusion models for text-guided generation. Although effective, CFG has notable drawbacks. For instance, DDIM with CFG lacks invertibility, complicating image editing; furthermore, high guidance scales, essential for high-quality outputs, frequently result in issues like mode collapse. Contrary to the widespread belief that these are inherent limitations of diffusion models, this paper reveals that the problems actually stem from the off-manifold phenomenon associated with CFG, rather than the diffusion models themselves. More specifically, inspired by the recent advancements of diffusion model-based inverse problem solvers (DIS), we reformulate text-guidance as an inverse problem with a text-conditioned score matching loss and develop CFG++, a novel approach that tackles the off-manifold challenges inherent in traditional CFG. CFG++ features a surprisingly simple fix to CFG, yet it offers significant improvements, including better sample quality for text-to-image generation, invertibility, smaller guidance scales, reduced mode collapse, etc. Furthermore, CFG++ enables seamless interpolation between unconditional and conditional sampling at lower guidance scales, consistently outperforming traditional CFG at all scales. Moreover, CFG++ can be easily integrated into high-order diffusion solvers and naturally extends to distilled diffusion models. Experimental results confirm that our method significantly enhances performance in text-to-image generation, DDIM inversion, editing, and solving inverse problems, suggesting a wide-ranging impact and potential applications in various fields that utilize text guidance. 																																	2024-09-27	PPRN:89291432		
J	Wu, Siye; Xie, Jian; Chen, Jiangjie; Zhu, Tinghui; Zhang, Kai; Xiao, Yanghua				Zhu, Ting/LXW-0633-2024						How Easily do Irrelevant Inputs Skew the Responses of Large Language Models?								Arxiv											3	3;2024-09-12;https://www.arxiv.org/abs/2404.03302v4| 2;2024-07-24;https://www.arxiv.org/abs/2404.03302v3| 1;2024-04-04;https://www.arxiv.org/abs/2404.03302v1	arXiv:2404.03302			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 12 2024	2024	By leveraging the retrieval of information from external knowledge databases, Large Language Models (LLMs) exhibit enhanced capabilities for accomplishing many knowledge-intensive tasks. However, due to the inherent flaws of current retrieval systems, there might exist irrelevant information within those retrieving top-ranked passages. In this work, we present a comprehensive investigation into the robustness of LLMs to different types of irrelevant information under various conditions. We initially introduce a framework to construct high-quality irrelevant information that ranges from semantically unrelated, partially related, and related to questions. Furthermore, our analysis demonstrates that the constructed irrelevant information not only scores highly on similarity metrics, being highly retrieved by existing systems, but also bears semantic connections to the context. Our investigation reveals that current LLMs still face challenges in discriminating highly semantically related information and can be easily distracted by these irrelevant yet misleading content. Besides, we also find that current solutions for handling irrelevant information have limitations in improving the robustness of LLMs to such distractions. All the resources are available on GitHub.																																	2024-09-27	PPRN:88413897		
J	Duan, Jiafei; Yuan, Wentao; Pumacay, Wilbert; Wang, Yi Ru; Ehsani, Kiana; Fox, Dieter; Krishna, Ranjay				Ehsani, Kiana/X-4345-2019; Wang, Yiru/JGV-0940-2023						Manipulate-Anything: Automating Real-World Robots using Vision-Language Models								Arxiv											3	3;2024-08-29;https://www.arxiv.org/abs/2406.18915v3| 2;2024-06-28;https://www.arxiv.org/abs/2406.18915v2| 1;2024-06-27;https://www.arxiv.org/abs/2406.18915v1	arXiv:2406.18915			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 29 2024	2024	Large-scale endeavors like and widespread community efforts such as Open-X-Embodiment have contributed to growing the scale of robot demonstration data. However, there is still an opportunity to improve the quality, quantity, and diversity of robot demonstration data. Although vision-language models have been shown to automatically generate demonstration data, their utility has been limited to environments with privileged state information, they require hand-designed skills, and are limited to interactions with few object instances. We propose Manipulate-Anything, a scalable automated generation method for real-world robotic manipulation. Unlike prior work, our method can operate in real-world environments without any privileged state information, hand-designed skills, and can manipulate any static object. We evaluate our method using two setups. First, Manipulate-Anything successfully generates trajectories for all 7 real-world and 14 simulation tasks, significantly outperforming existing methods like VoxPoser. Second, Manipulate-Anything's demonstrations can train more robust behavior cloning policies than training with human demonstrations, or from data generated by VoxPoser, Scaling-up, and Code-As-Policies. 																																	2024-09-23	PPRN:90150457		
J	Montanari, Andrea; Wu, Yuchen				Wu, Yuchen/AFB-8756-2022						Posterior Sampling in High Dimension via Diffusion Processes								Arxiv											2	2;2024-08-23;https://www.arxiv.org/abs/2304.11449v2| 1;2023-04-22;https://www.arxiv.org/abs/2304.11449v1	arXiv:2304.11449			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 23 2024	2024	Sampling from the posterior is a key technical problem in Bayesian statistics. Rigorous guarantees are difficult to obtain for Markov Chain Monte Carlo algorithms of common use. In this paper, we study an alternative class of algorithms based on diffusion processes and variational methods. The diffusion is constructed in such a way that, at its final time, it approximates the target posterior distribution. The drift of this diffusion is given by the posterior expectation of the unknown parameter vector θ given the data and the additional noisy observations. In order to construct an efficient sampling algorithm, we use a simple Euler discretization of the diffusion process, and leverage message passing algorithms and variational inference techniques to approximate the posterior expectation oracle. We apply this method to posterior sampling in two canonical problems in high-dimensional statistics: sparse regression and low-rank matrix estimation within the spiked model. In both cases we develop the first algorithms with accuracy guarantees in the regime of constant signalto-noise ratios.																																	2024-09-03	PPRN:65234649		
J	Chalmers, David J.										Could a Large Language Model be Conscious?								Arxiv											2	2;2024-08-18;https://www.arxiv.org/abs/2303.07103v3| 1;2023-03-04;https://www.arxiv.org/abs/2303.07103v1	arXiv:2303.07103			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 18 2024	2024	There has recently been widespread discussion of whether large language models might be sentient. Should we take this idea seriously? I will break down the strongest reasons for and against. Given mainstream assumptions in the science of consciousness, there are significant obstacles to consciousness in current models: for example, their lack of recurrent processing, a global workspace, and unified agency. At the same time, it is quite possible that these obstacles will be overcome in the next decade or so. I conclude that while it is somewhat unlikely that current large language models are conscious, we should take seriously the possibility that successors to large language models may be conscious in the not-too-distant future.																																	2024-08-30	PPRN:46520368		
J	Cha, Keumgang; Seo, Junghoon; Lee, Taekyung										A Billion-scale Foundation Model for Remote Sensing Images								Arxiv											3	3;2024-08-12;https://www.arxiv.org/abs/2304.05215v4| 2;2024-05-14;https://www.arxiv.org/abs/2304.05215v3| 1;2023-04-11;https://www.arxiv.org/abs/2304.05215v1	arXiv:2304.05215			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 12 2024	2024	As the potential of foundation models in visual tasks has garnered significant attention, pretraining these models before downstream tasks has become a crucial step. The three key factors in pretraining foundation models are the pretraining method, the size of the pretraining dataset, and the number of model parameters. Recently, research in the remote sensing field has focused primarily on the pretraining method and the size of the dataset, with limited emphasis on the number of model parameters. This paper addresses this gap by examining the effect of increasing the number of model parameters on the performance of foundation models in downstream tasks such as rotated object detection and semantic segmentation. We pretrained foundation models with varying numbers of parameters, including 86M, 605.26M, 1.3B, and 2.4B, to determine whether performance in downstream tasks improved with an increase in parameters. To the best of our knowledge, this is the first billion-scale foundation model in the remote sensing field. Furthermore, we propose an effective method for scaling up and fine-tuning a vision transformer in the remote sensing field. To evaluate general performance in downstream tasks, we employed the DOTA v2.0 and DIOR-R benchmark datasets for rotated object detection, and the Potsdam and LoveDA datasets for semantic segmentation. Experimental results demonstrated that, across all benchmark datasets and downstream tasks, the performance of the foundation models and data efficiency improved as the number of parameters increased. Moreover, our models achieve the state-of-the-art performance on several datasets including DIOR-R, Postdam, and LoveDA.																																	2024-08-22	PPRN:58077623		
J	Fu, Yang; Liu, Sifei; Kulkarni, Amey; Kautz, Jan; Efros, Alexei A.; Wang, Xiaolong				kulkarni, amey sunil/MBG-1319-2025; Fu, Yang/AAC-6064-2019; Liu, Sifei/AGE-1968-2022						COLMAP-Free 3D Gaussian Splatting								Arxiv											2	2;2024-07-30;https://www.arxiv.org/abs/2312.07504v2| 1;2023-12-12;https://www.arxiv.org/abs/2312.07504v1	arXiv:2312.07504			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 30 2024	2024	While neural rendering has led to impressive advances in scene reconstruction and novel view synthesis, it relies heavily on accurately pre-computed camera poses. To relax this constraint, multiple efforts have been made to train Neural Radiance Fields (NeRFs) without pre-processed camera poses. However, the implicit representations of NeRFs provide extra challenges to optimize the 3D structure and camera poses at the same time. On the other hand, the recently proposed 3D Gaussian Splatting provides new opportunities given its explicit point cloud representations. This paper leverages both the explicit geometric representation and the continuity of the input video stream to perform novel view synthesis without any SfM preprocessing. We process the input frames in a sequential manner and progressively grow the 3D Gaussians set by taking one input frame at a time, without the need to pre-compute the camera poses. Our method significantly improves over previous approaches in view synthesis and camera pose estimation under large motion changes. 																																	2024-08-06	PPRN:86557381		
J	Muhtar, Dilxat; Li, Zhenshi; Gu, Feng; Zhang, Xueliang; Xiao, Pengfeng				Li, Zhenshi/JFJ-4459-2023; Xiao, Pengfeng/A-8143-2016						LHRS-Bot: Empowering Remote Sensing with VGI-Enhanced Large Multimodal Language Model								Arxiv											4	4;2024-07-16;https://www.arxiv.org/abs/2402.02544v4| 3;2024-03-18;https://www.arxiv.org/abs/2402.02544v3| 2;2024-02-07;https://www.arxiv.org/abs/2402.02544v2| 1;2024-02-04;https://www.arxiv.org/abs/2402.02544v1	arXiv:2402.02544			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 16 2024	2024	The revolutionary capabilities of large language models (LLMs) have paved the way for multimodal large language models (MLLMs) and fostered diverse applications across various specialized domains. In the remote sensing (RS) field, however, the diverse geographical landscapes and varied objects in RS imagery are not adequately considered in recent MLLM endeavors. To bridge this gap, we construct a large-scale RS image-text dataset, LHRS-Align, and an informative RS-specific instruction dataset, LHRS-Instruct, leveraging the extensive volunteered geographic information (VGI) and globally available RS images. Building on this foundation, we introduce LHRS-Bot, an MLLM tailored for RS image understanding through a novel multi-level vision-language alignment strategy and a curriculum learning method. Additionally, we introduce LHRS-Bench, a benchmark for thoroughly evaluating MLLMs' abilities in RS image understanding. Comprehensive experiments demonstrate that LHRS-Bot exhibits a profound understanding of RS images and the ability to perform nuanced reasoning within the RS domain.																																	2024-07-25	PPRN:87523621		
J	Fan, Siqi; Jiang, Xin; Li, Xiang; Meng, Xuying; Han, Peng; Shang, Shuo; Sun, Aixin; Wang, Yequan; Wang, Zhongyuan				Wang, Zhongyuan/HTL-5239-2023; Fan, Siqi/ABE-7522-2021; Shang, Shuo/AAN-4933-2020; Sun, Aixin/A-9852-2008; Han, Peng/LNQ-0182-2024; Wang, yule/HLP-6351-2023						Not All Layers of LLMs Are Necessary During Inference								Arxiv											3	3;2024-07-09;https://www.arxiv.org/abs/2403.02181v3| 2;2024-04-15;https://www.arxiv.org/abs/2403.02181v2| 1;2024-03-04;https://www.arxiv.org/abs/2403.02181v1	arXiv:2403.02181			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 09 2024	2024	Due to the large number of parameters, the inference phase of Large Language Models (LLMs) is resource-intensive. However, not all requests posed to LLMs are equally difficult to handle. Through analysis, we show that for some tasks, LLMs can achieve results comparable to the final output at some intermediate layers. That is, not all layers of LLMs are necessary during inference. If we can predict at which layer the inferred results match the final results (produced by evaluating all layers), we could significantly reduce the inference cost. To this end, we propose a simple yet effective algorithm named AdaInfer to adaptively terminate the inference process for an input instance. AdaInfer relies on easily obtainable statistical features and classic classifiers like SVM. Experiments on well-known LLMs like the Llama2 series and OPT, show that AdaInfer can achieve an average of 17.8% pruning ratio, and up to 43% on sentiment tasks, with nearly no performance drop (<1%). Because AdaInfer does not alter LLM parameters, the LLMs incorporated with AdaInfer maintain generalizability across tasks.																																	2024-07-21	PPRN:88021551		
J	Kokubo, Mitsuru; Harikane, Yuichi				Harikane, Yuichi/KHY-2680-2024						Challenging the AGN scenario for<italic> JWST</italic>/NIRSpec broad Hα emitters/Little Red Dots in light of non-detection of NIRCam photometric variability and X-ray								Arxiv											2	2;2025-09-21;https://www.arxiv.org/abs/2407.04777v2| 1;2024-07-05;https://www.arxiv.org/abs/2407.04777v1	arXiv:2407.04777			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 05 2024	2024	JWST has uncovered a substantial population of high-z (z > 4) galaxies exhibiting broad Hα emission line with a Full Width at Half Maximum exceeding 1, 000 km s−1 . This population includes a subset known as ’Little Red Dots’, characterized by their compact morphology and extremely red rest-frame optical colors. If all of these broad Hα emitters were attributed to type 1 − 1.9 Active Galactic Nuclei (AGNs), it would imply a significantly higher number density of low-luminosity AGNs than extrapolated from that of more luminous AGNs. Here, we have examined the rest-frame ultraviolet (UV)-optical flux variability of five JWST broad Hα emitters using multi-epoch, multi-band JWST /NIRCam imaging data. The rest-frame temporal sampling interval of the NIRCam data ( ∼ 400 −500 days/(1+z)) is comparable to typical variability timescales of AGNs with black hole (BH) masses of MBH ∼ 107 M⊙  thus, the flux variations should be detectable if AGNs were present. However, no measurable flux variation over the rest-frame wavelength range of λrest ∼ 1, 500 −9, 000 Å has been detected, placing stringent upper limits on the variability amplitudes. This result, combined with the X-ray faintness confirmed by the ultra-deep Chandra data, indicates that, under the AGN scenario, we need to postulate peculiar Compton-thick broad-line AGNs with either (a) an intrinsically non-variable AGN disk continuum, (b) a host galaxy-dominated continuum, or (c) scattering-dominated AGN emission. Alternatively, (d) they could be non-AGNs where the broad-line emission originates from unusually fast and dense/lowmetallicity star-formation-driven outflows or inelastic Raman scattering of stellar UV continua by neutral hydrogen atoms.																																	2024-07-31	PPRN:90740244		
J	Alzahrani, Norah; Alyahya, Hisham Abdullah; Alnumay, Yazeed; Alrashed, Sultan; Alsubaie, Shaykhah; Almushaykeh, Yusef; Mirza, Faisal; Alotaibi, Nouf; Altwairesh, Nora; Alowisheq, Areeb; Bari, M Saiful; Khan, Haidar				Bari, M Saiful/KWA-5529-2024; Al-Twairesh, Nora/M-4600-2019						When Benchmarks are Targets: Revealing the Sensitivity of Large Language Model Leaderboards								Arxiv											2	2;2024-07-03;https://www.arxiv.org/abs/2402.01781v2| 1;2024-02-01;https://www.arxiv.org/abs/2402.01781v1	arXiv:2402.01781			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 03 2024	2024	Large Language Model (LLM) leaderboards based on benchmark rankings are regularly used to guide practitioners in model selection. Often, the published leaderboard rankings are taken at face value - we show this is a (potentially costly) mistake. Under existing leaderboards, the relative performance of LLMs is highly sensitive to (often minute) details. We show that for popular multiple-choice question benchmarks (e.g., MMLU), minor perturbations to the benchmark, such as changing the order of choices or the method of answer selection, result in changes in rankings up to 8 positions. We explain this phenomenon by conducting systematic experiments over three broad categories of benchmark perturbations and identifying the sources of this behavior. Our analysis results in several best-practice recommendations, including the advantage of a hybrid scoring method for answer selection. Our study highlights the dangers of relying on simple benchmark evaluations and charts the path for more robust evaluation schemes on the existing benchmarks. 																																	2024-07-20	PPRN:87523692		
J	Chen, Huayu; He, Guande; Yuan, Lifan; Cui, Ganqu; Su, Hang; Zhu, Jun										Noise Contrastive Alignment of Language Models with Explicit Rewards								Arxiv											2	2;2024-07-03;https://www.arxiv.org/abs/2402.05369v2| 1;2024-02-08;https://www.arxiv.org/abs/2402.05369v1	arXiv:2402.05369			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 03 2024	2024	User intentions are typically formalized as evaluation rewards to be maximized when fine-tuning language models (LMs). Existing alignment methods, such as Direct Preference Optimization (DPO), are mainly tailored for pairwise preference data where rewards are implicitly defined rather than explicitly given. In this paper, we introduce a general framework for LM alignment, leveraging Noise Contrastive Estimation (NCE) to bridge the gap in handling reward datasets explicitly annotated with scalar evaluations. Our framework comprises two parallel algorithms, NCA and InfoNCA, both enabling the direct extraction of an LM policy from reward data as well as preference data. Notably, we show that the DPO loss is a special case of our proposed InfoNCA objective under pairwise preference settings, thereby integrating and extending current alignment theories. By comparing NCA and InfoNCA, we demonstrate that the well-observed decreasing-likelihood trend of DPO/InfoNCA is caused by their focus on adjusting relative likelihood across different responses. In contrast, NCA optimizes the absolute likelihood for each response, thereby effectively preventing the chosen likelihood from decreasing. We evaluate our methods in both reward and preference settings with Mistral-8x7B and 7B models. Experiments suggest that InfoNCA/NCA surpasses various preference baselines when reward datasets are available. We also find NCA significantly outperforms DPO in complex reasoning tasks like math and coding.																																	2024-07-19	PPRN:87568881		
J	Majumder, Bodhisattwa Prasad; Surana, Harshit; Agarwal, Dhruv; Mishra, Bhavana Dalvi; Meena, Abhijeetsingh; Prakhar, Aryan; Vora, Tirth; Khot, Tushar; Sabharwal, Ashish; Clark, Peter										D ISCOVERY B ENCH : Towards Data-Driven Discovery with Large Language Models								Arxiv											1	1;2024-07-01;https://www.arxiv.org/abs/2407.01725v1	arXiv:2407.01725			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 01 2024	2024	Can the rapid advances in code generation, function calling, and data analysis using large language models (LLMs) help automate the search and verification of hypotheses purely from a set of provided datasets? To evaluate this question, we present D ISCOVERY B ENCH , the first comprehensive benchmark that formalizes the multi-step process of data-driven discovery. The benchmark is designed to systematically assess current model capabilities in discovery tasks and provide a useful resource for improving them. Our benchmark contains 264 tasks collected across 6 diverse domains, such as sociology and engineering, by manually deriving discovery workflows from published papers to approximate the real-world challenges faced by researchers, where each task is defined by a dataset, its metadata, and a discovery goal in natural language. We additionally provide 903 synthetic tasks to conduct controlled evaluations across task complexity. Furthermore, our structured formalism of data-driven discovery enables a facet-based evaluation that provides useful insights into different failure modes. We evaluate several popular LLM-based reasoning frameworks using both open and closed LLMs as baselines on D ISCOVERY B ENCH and find that even the best system scores only 25%. Our benchmark, thus, illustrates the challenges in autonomous data-driven discovery and serves as a valuable resource for the community to make progress.																																	2024-07-19	PPRN:90672683		
J	Hillmann, Timo; Berent, Lucas; Quintavalle, Armanda O.; Eisert, Jens; Wille, Robert; Roffe, Joschka				Hillmann, Timo/AAP-5441-2021; Eisert, Jens/D-9640-2017; Berent, Lucas/KIH-7990-2024						Localized statistics decoding: A parallel decoding algorithm for quantum low-density parity-check codes								Arxiv											2	2;2025-09-05;https://www.arxiv.org/abs/2406.18655v2| 1;2024-06-26;https://www.arxiv.org/abs/2406.18655v1	arXiv:2406.18655			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 26 2024	2024	Quantum low-density parity-check codes are a promising candidate for fault-tolerant quantum computing with considerably reduced overhead compared to the surface code. However, the lack of a practical decoding algorithm remains a barrier to their implementation. In this work, we introduce localized statistics decoding, a reliability-guided inversion decoder that is highly parallelizable and applicable to arbitrary quantum low-density parity-check codes. Our approach employs a parallel matrix factorization strategy, which we call on-the-fly elimination, to identify, validate, and solve local decoding regions on the decoding graph. Through numerical simulations, we show that localized statistics decoding matches the performance of state-of-the-art decoders while reducing the runtime complexity for operation in the sub-threshold regime. Importantly, our decoder is more amenable to implementation on specialized hardware, positioning it as a promising candidate for decoding real-time syndromes from experiments.																																	2024-07-15	PPRN:90119764		
J	Aghaei, Alireza Afzal				Afzal Aghaei, Alireza/IQW-6272-2023						rKAN: Rational Kolmogorov-Arnold Networks								Arxiv											1	1;2024-06-20;https://www.arxiv.org/abs/2406.14495v1	arXiv:2406.14495			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 20 2024	2024	The development of Kolmogorov-Arnold networks (KANs) marks a significant shift from traditional multi-layer perceptrons in deep learning. Initially, KANs employed B-spline curves as their primary basis function, but their inherent complexity posed implementation challenges. Consequently, researchers have explored alternative basis functions such as Wavelets, Polynomials, and Fractional functions. In this research, we explore the use of rational functions as a novel basis function for KANs. We propose two different approaches based on Pade approximation and rational Jacobi functions as trainable basis functions, establishing the rational KAN (rKAN). We then evaluate rKAN's performance in various deep learning and physics-informed tasks to demonstrate its practicality and effectiveness in function approximation.																																	2024-07-06	PPRN:89378935		
J	Du, Xueying; Zheng, Geng; Wang, Kaixin; Feng, Jiayi; Deng, Wentai; Liu, Mingwei; Peng, Xin; Ma, Tao; Lou, Yiling				Liu, Mingwei/AHI-4200-2022; liu, yiling/HNS-6339-2023						Vul-RAG: Enhancing LLM-based Vulnerability Detection via Knowledge-level RAG								Arxiv											2	2;2024-06-19;https://www.arxiv.org/abs/2406.11147v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11147v1	arXiv:2406.11147			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 17 2024	2024	Vulnerability detection is essential for software quality assurance. In recent years, deep learning models (especially large language models) have shown promise in vulnerability detection. In this work, we propose a novel LLM-based vulnerability detection technique Vul-RAG, which leverages knowledge-level retrieval-augmented generation (RAG) framework to detect vulnerability for the given code in three phases. First, Vul-RAG constructs a vulnerability knowledge base by extracting multi-dimension knowledge via LLMs from existing CVE instances; second, for a given code snippet, Vul-RAG} retrieves the relevant vulnerability knowledge from the constructed knowledge base based on functional semantics; third, Vul-RAG leverages LLMs to check the vulnerability of the given code snippet by reasoning the presence of vulnerability causes and fixing solutions of the retrieved vulnerability knowledge. Our evaluation of Vul-RAG on our constructed benchmark PairVul shows that Vul-RAG substantially outperforms all baselines by 12.96%/110% relative improvement in accuracy/pairwise-accuracy. In addition, our user study shows that the vulnerability knowledge generated by Vul-RAG can serve as high-quality explanations which can improve the manual detection accuracy from 0.60 to 0.77.																																	2025-08-07	PPRN:89352160		
J	Hu, Tiancheng; Collier, Nigel										Quantifying the Persona Effect in LLM Simulations								Arxiv											1	1;2024-06-17;https://www.arxiv.org/abs/2402.10811v2	arXiv:2402.10811			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 17 2024	2024	Large language models (LLMs) have shown remarkable promise in simulating human language and behavior. This study investigates how integrating persona variables—demographic, social, and behavioral factors—impacts LLMs’ ability to simulate diverse perspectives. We find that persona variables account for <10% variance in annotations in existing subjective NLP datasets. Nonetheless, incorporating persona variables via prompting in LLMs provides modest but statistically significant improvements. Persona prompting is most effective in samples where many annotators disagree, but their disagreements are relatively minor. Notably, we find a linear relationship in our setting: the stronger the correlation between persona variables and human annotations, the more accurate the LLM predictions are using persona prompting. In a zero-shot setting, a powerful 70b model with persona prompting captures 81% of the annotation variance achievable by linear regression trained on ground truth annotations. However, for most subjective NLP datasets, where persona variables have limited explanatory power, the benefits of persona prompting are limited.																																	2024-07-04	PPRN:89343509		
J	Jin, Zhuoran; Cao, Pengfei; Wang, Chenhao; He, Zhitao; Yuan, Hongbang; Li, Jiachun; Chen, Yubo; Liu, Kang; Zhao, Jun				Cao, Pengfei/F-8723-2012; Zhitao, He/AAW-2395-2020; Chen, Yubo/LSK-8832-2024; Liu, Kang/AAG-8964-2020; WANG, CHENHAO/AAM-2862-2021						RWKU: Benchmarking Real-World Knowledge Unlearning for Large Language Models								Arxiv											1	1;2024-06-16;https://www.arxiv.org/abs/2406.10890v1	arXiv:2406.10890			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 16 2024	2024	Large language models (LLMs) inevitably memorize sensitive, copyrighted, and harmful knowledge from the training corpus; therefore, it is crucial to erase this knowledge from the models. Machine unlearning is a promising solution for efficiently removing specific knowledge by post hoc modifying models. In this paper, we propose a Real-World Knowledge Unlearning benchmark (RWKU) for LLM unlearning. RWKU is designed based on the following three key factors: (1) For the task setting, we consider a more practical and challenging unlearning setting, where neither the forget corpus nor the retain corpus is accessible. (2) For the knowledge source, we choose 200 real-world famous people as the unlearning targets and show that such popular knowledge is widely present in various LLMs. (3) For the evaluation framework, we design the forget set and the retain set to evaluate the model's capabilities across various real-world applications. Regarding the forget set, we provide four four membership inference attack (MIA) methods and nine kinds of adversarial attack probes to rigorously test unlearning efficacy. Regarding the retain set, we assess locality and utility in terms of neighbor perturbation, general ability, reasoning ability, truthfulness, factuality, and fluency. We conduct extensive experiments across two unlearning scenarios, two models and six baseline methods and obtain some meaningful findings. 																																	2024-07-04	PPRN:89350205		
J	Liu, Yinpeng; Liu, Jiawei; Shi, Xiang; Cheng, Qikai; Huang, Yong; Lu, Wei				SHI, Xiang/N-7189-2018; Li, Jiaxi/HTS-3430-2023						Let's Learn Step by Step: Enhancing In-Context Learning Ability with Curriculum Learning								Arxiv											2	2;2024-06-16;https://www.arxiv.org/abs/2402.10738v2| 1;2024-02-16;https://www.arxiv.org/abs/2402.10738v1	arXiv:2402.10738			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 16 2024	2024	Demonstration ordering, which is an important strategy for in-context learning (ICL), can significantly affects the performance of large language models (LLMs). However, most of the current approaches of ordering require high computational costs to introduce the priori knowledge. In this paper, inspired by the human learning process, we propose a simple but effective demonstration ordering method for ICL, named the few-shot In-Context Curriculum Learning (ICCL). The ICCL implies gradually increasing the complexity of prompt demonstrations during the inference process. The difficulty can be assessed by human experts or LLMs-driven metrics, such as perplexity. Then we design extensive experiments to discuss the effectiveness of the ICCL at both corpus-level and instance-level. Moreover, we also investigate the formation mechanism of LLM's ICCL capability. Experimental results demonstrate that ICCL, developed during the instruction-tuning stage, is effective for representative open-source LLMs. To facilitate further research and applications by other scholars, we make the code publicly available.																																	2024-07-04	PPRN:87753619		
J	Gadre, Samir Yitzhak; Smyrnis, Georgios; Shankar, Vaishaal; Gururangan, Suchin; Wortsman, Mitchell; Shao, Rulin; Mercat, Jean; Fang, Alex; Li, Jeffrey; Keh, Sedrick; Xin, Rui; Nezhurina, Marianna; Vasiljevic, Igor; Jitsev, Jenia; Soldaini, Luca; Dimakis, Alexandros G.; Ilharco, Gabriel; Koh, Pang Wei; Song, Shuran; Kollar, Thomas; Carmon, Yair; Dave, Achal; Heckel, Reinhard; Muennighoff, Niklas; Schmidt, Ludwig				Heckel, Reinhard/AAV-7904-2020; Dimakis, Alexandros/A-5496-2011						Language models scale reliably with over-training and on downstream tasks								Arxiv											2	2;2024-06-14;https://www.arxiv.org/abs/2403.08540v2| 1;2024-03-13;https://www.arxiv.org/abs/2403.08540v1	arXiv:2403.08540			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 14 2024	2024	Scaling laws are useful guides for derisking expensive training runs, as they predict performance of large models using cheaper, small-scale experiments. However, there remain gaps between current scaling studies and how language models are ultimately trained and evaluated. For instance, scaling is usually studied in the compute -optimal training regime (i.e., “Chinchilla optimal” regime). In contrast, models are often over -trained to reduce inference costs. Moreover, scaling laws mostly predict loss on next -token prediction, but models are usually compared on downstream task performance. To address both shortcomings, we create a testbed of 104 models with 0.011B to 6.9B parameters trained with various numbers of tokens on three data distributions. First, we fit scaling laws that extrapolate in both the amount of over -training and the number of model parameters. This enables us to predict the validation loss of a 1.4B parameter, 900B token run (i.e., 32× × over -trained) and a 6.9B parameter, 138B token run (i.e., a compute -optimal run)—each from experiments that take 300× × less compute. Second, we relate the perplexity of a language model to its downstream task performance by proposing a power law. We use this law to predict top -1 error averaged over downstream tasks for the two aforementioned models, using experiments that take 20× × less compute. 																																	2024-07-21	PPRN:88133001		
J	Xiang, Zhen; Zheng, Linzhi; Li, Yanjie; Hong, Junyuan; Li, Qinbin; Xie, Han; Zhang, Jiawei; Xiong, Zidi; Xie, Chulin; Yang, Carl; Song, Dawn; Li, Bo				Li, Yanjie/KGL-6227-2024; Li, Qinbin/JVN-4491-2024; Xiong, Zidi/KBB-8747-2024						GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning								Arxiv											1	1;2024-06-13;https://www.arxiv.org/abs/2406.09187v1	arXiv:2406.09187			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 13 2024	2024	The rapid advancement of large language models (LLMs) has catalyzed the deployment of LLM-powered agents across numerous applications, raising new concerns regarding their safety and trustworthiness. Existing methods for enhancing the safety of LLMs are not directly transferable to LLM-powered agents due to their diverse objectives and output modalities. In this paper, we propose GuardAgent, the first LLM agent as a guardrail to other LLM agents. Specifically, GuardAgent oversees a target LLM agent by checking whether its inputs/outputs satisfy a set of given guard requests defined by the users. GuardAgent comprises two steps: 1) creating a task plan by analyzing the provided guard requests, and 2) generating guardrail code based on the task plan and executing the code by calling APIs or using external engines. In both steps, an LLM is utilized as the core reasoning component, supplemented by in-context demonstrations retrieved from a memory module. Such knowledge-enabled reasoning allows GuardAgent to understand various textual guard requests and accurately "translate" them into executable code that provides reliable guardrails. Furthermore, GuardAgent is equipped with an extendable toolbox containing functions and APIs and requires no additional LLM training, which underscores its generalization capabilities and low operational overhead. Additionally, we propose two novel benchmarks: an EICU-AC benchmark for assessing privacy-related access control for healthcare agents and a Mind2Web-SC benchmark for safety evaluation for web agents. We show the effectiveness of GuardAgent on these two benchmarks with 98.7% and 90.0% accuracy in moderating invalid inputs and outputs for the two types of agents, respectively. We also show that GuardAgent is able to define novel functions in adaption to emergent LLM agents and guard requests, which underscores its strong generalization capabilities.																																	2024-07-10	PPRN:89302433		
J	Lu, Haihao; Yang, Jinwen										cuPDLP.jl: A GPU Implementation of Restarted Primal-Dual Hybrid Gradient for Linear Programming in Julia								Arxiv											4	4;2024-06-07;https://www.arxiv.org/abs/2311.12180v4| 3;2023-12-26;https://www.arxiv.org/abs/2311.12180v3| 2;2023-12-07;https://www.arxiv.org/abs/2311.12180v2| 1;2023-11-20;https://www.arxiv.org/abs/2311.12180v1	arXiv:2311.12180			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 07 2024	2024	In this paper, we provide an affirmative answer to the long-standing question: Are GPUs useful in solving linear programming? We present cuPDLP.jl, a GPU implementation of restarted primal-dual hybrid gradient (PDHG) for solving linear programming (LP). We show that this prototype implementation in Julia has comparable numerical performance on standard LP benchmark sets to Gurobi, a highly optimized implementation of the simplex and interior-point methods. This demonstrates the power of using GPUs in linear programming, which, for the first time, showcases that GPUs and first-order methods can lead to performance comparable to state-of-the-art commercial optimization LP solvers on standard benchmark sets.																																	2024-06-22	PPRN:86488975		
J	D'Amico, Guido; Donath, Yaniv; Lewandowski, Matthew; Senatore, Leonardo; Zhang, Pierre				D'Amico, Guido/HSG-9203-2023						The BOSS bispectrum analysis at one loop from the Effective Field Theory of Large-Scale Structure								Arxiv											2	2;2022-06-16;https://www.arxiv.org/abs/2206.08327v1| 1;2024-06-01;	arXiv:2206.08327			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 01 2024	2024	We analyze the BOSS power spectrum monopole and quadrupole, and the bispectrum monopole and quadrupole data, using the predictions from the Effective Field Theory of Large-Scale Structure (EFTofLSS). Specifically, we use the one loop prediction for the power spectrum and the bispectrum monopole, and the tree level for the bispectrum quadrupole. After validating our pipeline against numerical simulations as well as checking for several internal consistencies, we apply it to the observational data. We find that analyzing the bispectrum monopole to higher wavenumbers thanks to the one-loop prediction, as well as the addition of the tree-level quadrupole, significantly reduces the error bars with respect to our original analysis of the power spectrum at one loop and bispectrum monopole at tree level. After fixing the spectral tilt to Planck preferred value and using a Big Bang Nucleosynthesis prior, we measure $sigma_8=0.794pm 0.037$, $h = 0.692pm 0.011$, and $Omega_m = 0.311pm 0.010$ to about $4.7%$, $1.6%$, and $3.2%$, at $68%$ CL, respectively. This represents an error bar reduction with respect to the power spectrum-only analysis of about $30%$, $18%$, and $13%$ respectively. Remarkably, the results are compatible with the ones obtained with a power-spectrum-only analysis, showing the power of the EFTofLSS in simultaneously predicting several observables. We find no tension with Planck.																																	2025-11-07	PPRN:12184652		
J	Scotti, Paul S.; Tripathy, Mihir; Villanueva, Cesar Kadir Torrico; Kneeland, Reese; Chen, Tong; Narang, Ashutosh; Santhirasegaran, Charan; Xu, Jonathan; Naselaris, Thomas; Norman, Kenneth A.; Abraham, Tanishq Mathew				Chen, Tong/GSJ-2114-2022; Scotti, Paul/AAA-9064-2020						MindEye2: Shared-Subject Models Enable fMRI-To-Image With 1 Hour of Data								Arxiv											2	2;2024-03-17;https://www.arxiv.org/abs/2403.11207v1| 1;2024-06-01;	arXiv:2403.11207			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 01 2024	2024	Reconstructions of visual perception from brain activity have improved tremendously, but the practical utility of such methods has been limited. This is because such models are trained independently per subject where each subject requires dozens of hours of expensive fMRI training data to attain high-quality results. The present work showcases high-quality reconstructions using only 1 hour of fMRI training data. We pretrain our model across 7 subjects and then fine-tune on minimal data from a new subject. Our novel functional alignment procedure linearly maps all brain data to a shared-subject latent space, followed by a shared non-linear mapping to CLIP image space. We then map from CLIP space to pixel space by fine-tuning Stable Diffusion XL to accept CLIP latents as inputs instead of text. This approach improves out-of-subject generalization with limited training data and also attains state-of-the-art image retrieval and reconstruction metrics compared to single-subject approaches. MindEye2 demonstrates how accurate reconstructions of perception are possible from a single visit to the MRI facility.																																	2024-11-17	PPRN:88189587		
J	Xu, Rongwu; Lin, Brian S.; Yang, Shujian; Zhang, Tianqi; Shi, Weiyan; Zhang, Tianwei; Fang, Zhixuan; Xu, Wei; Qiu, Han				Qiu, Han/JWP-5130-2024; Fang, Zhixuan/GXW-0496-2022; Shi, Weiyan/JOK-7836-2023						The Earth is Flat because...: Investigating LLMs' Belief towards Misinformation via Persuasive Conversation								Arxiv											5	5;2024-05-31;https://www.arxiv.org/abs/2312.09085v5| 4;2024-01-09;https://www.arxiv.org/abs/2312.09085v4| 3;2023-12-29;https://www.arxiv.org/abs/2312.09085v3| 2;2023-12-20;https://www.arxiv.org/abs/2312.09085v2| 1;2023-12-14;https://www.arxiv.org/abs/2312.09085v1	arXiv:2312.09085			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	May 31 2024	2024	Large language models (LLMs) encapsulate vast amounts of knowledge but still remain vulnerable to external misinformation. Existing research mainly studied this susceptibility behavior in a single-turn setting. However, belief can change during a multi-turn conversation, especially a persuasive one. Therefore, in this study, we delve into LLMs' susceptibility to persuasive conversations, particularly on factual questions that they can answer correctly. We first curate the Farm (i.e., Fact to Misinform) dataset, which contains factual questions paired with systematically generated persuasive misinformation. Then, we develop a testing framework to track LLMs' belief changes in a persuasive dialogue. Through extensive experiments, we find that LLMs' correct beliefs on factual knowledge can be easily manipulated by various persuasive strategies1.																																	2024-06-19	PPRN:86591859		
J	An, Chenxin; Huang, Fei; Zhang, Jun; Gong, Shansan; Qiu, Xipeng; Zhou, Chang; Kong, Lingpeng				Gong, Shansan/GRO-6763-2022; kong, lingpeng/NHQ-3170-2025						Training-Free Long-Context Scaling of Large Language Models								Arxiv											2	2;2024-05-29;https://www.arxiv.org/abs/2402.17463v2| 1;2024-02-27;https://www.arxiv.org/abs/2402.17463v1	arXiv:2402.17463			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 29 2024	2024	The ability of Large Language Models (LLMs) to process and generate coherent text is markedly weakened when the number of input tokens exceeds their pretraining length. Given the expensive overhead of finetuning large-scale models with longer sequences, we propose Dual Chunk Attention (DCA), which enables Llama2 70B to support context windows of more than 100k tokens without continual training. By decomposing the attention computation for long sequences into chunk-based modules, DCA manages to effectively capture the relative positional information of tokens within the same chunk (Intra-Chunk) and across distinct chunks (Inter-Chunk), as well as integrates seamlessly with Flash Attention. In addition to its impressive extrapolation capability, DCA achieves performance on practical long-context tasks that is comparable to or even better than that of finetuned models. When compared with proprietary models, our training-free 70B model attains 94% of the performance of gpt-3.5-16k, indicating it is a viable open-source alternative. 																																	2024-08-24	PPRN:87922958		
J	Pumacay, Wilbert; Singh, Ishika; Duan, Jiafei; Krishna, Ranjay; Thomason, Jesse; Fox, Dieter										THE COLOSSEUM: A Benchmark for Evaluating Generalization for Robotic Manipulation								Arxiv											2	2;2024-05-28;https://www.arxiv.org/abs/2402.08191v2| 1;2024-02-13;https://www.arxiv.org/abs/2402.08191v1	arXiv:2402.08191			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 28 2024	2024	To realize effective large-scale, real-world robotic applications, we must evaluate how well our robot policies adapt to changes in environmental conditions. Unfortunately, a majority of studies evaluate robot performance in environments closely resembling or even identical to the training setup. We present THE COLOSSEUM, a novel simulation benchmark, with 20 diverse manipulation tasks, that enables systematical evaluation of models across 14 axes of environmental perturbations. These perturbations include changes in color, texture, and size of objects, table-tops, and backgrounds; we also vary lighting, distractors, physical properties perturbations and camera pose. Using THE COLOSSEUM, we compare 5 state-of-the-art manipulation models to reveal that their success rate degrades between 30-50% across these perturbation factors. When multiple perturbations are applied in unison, the success rate degrades ≥75%. We identify that changing the number of distractor objects, target object color, or lighting conditions are the perturbations that reduce model performance the most. To verify the ecological validity of our results, we show that our results in simulation are correlated (R2 = 0.614) to similar perturbations in real-world experiments. We open source code for others to use THE COLOSSEUM, and also release code to 3D print the objects used to replicate the real-world perturbations. Ultimately, we hope that THE COLOSSEUM will serve as a benchmark to identify modeling decisions that systematically improve generalization for manipulation. 																																	2024-06-13	PPRN:87676164		
J	Chen, Xiang; Wang, Chenxi; Xue, Yida; Zhang, Ningyu; Yang, Xiaoyan; Li, Qiang; Shen, Yue; Liang, Lei; Gu, Jinjie; Chen, Huajun				Qian, Liu/GYU-5886-2022; Zhang, Ningyu/AAQ-7391-2021; Huajun, Chen/B-6340-2013						Unified Hallucination Detection for Multimodal Large Language Models								Arxiv											4	4;2024-05-27;https://www.arxiv.org/abs/2402.03190v4| 3;2024-02-20;https://www.arxiv.org/abs/2402.03190v3| 2;2024-02-16;https://www.arxiv.org/abs/2402.03190v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.03190v1	arXiv:2402.03190			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 27 2024	2024	Despite significant strides in multimodal tasks, Multimodal Large Language Models (MLLMs) are plagued by the critical issue of hallucination. The reliable detection of such hallucinations in MLLMs has, therefore, become a vital aspect of model evaluation and the safeguarding of practical application deployment. Prior research in this domain has been constrained by a narrow focus on singular tasks, an inadequate range of hallucination categories addressed, and a lack of detailed granularity. In response to these challenges, our work expands the investigative horizons of hallucination detection. We present a novel meta-evaluation benchmark, MHaluBench, meticulously crafted to facilitate the evaluation of advancements in hallucination detection methods. Additionally, we unveil a novel unified multimodal hallucination detection framework, UNIHD, which leverages a suite of auxiliary tools to validate the occurrence of hallucinations robustly. We demonstrate the effectiveness of UNIHD through meticulous evaluation and comprehensive analysis. We also provide strategic insights on the application of specific tools for addressing various categories of hallucinations.																																	2024-06-10	PPRN:87524193		
J	Goulart, Paul J.; Chen, Yuwen										Clarabel: An interior-point solver for conic programs with quadratic objectives								Arxiv											1	1;2024-05-21;https://www.arxiv.org/abs/2405.12762v1	arXiv:2405.12762			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 21 2024	2024	We present a general-purpose interior-point solver for convex optimization problems with conic constraints. Our method is based on a homogeneous embedding method originally developed for general monotone complementarity problems and more recently applied to operator splitting methods, and here specialized to an interior-point method for problems with quadratic objectives. We allow for a variety of standard symmetric and non-symmetric cones, and provide support for chordal decomposition methods in the case of semidefinite cones. We describe the implementation of this method in the open-source solver Clarabel, and provide a detailed numerical evaluation of its performance versus several state-of-the-art solvers on a wide range of standard benchmarks problems. Clarabel is faster and more robust than competing commercial and open-source solvers across a range of test sets, with a particularly large performance advantage for problems with quadratic objectives. Clarabel is currently distributed as a standard solver for the Python CVXPY optimization suite.																																	2024-08-24	PPRN:91460545		
J	Li, Loka; Chen, Zhenhao; Chen, Guangyi; Zhang, Yixuan; Su, Yusheng; Xing, Eric; Zhang, Kun				Chen, Guangyi/HHC-0591-2022; SU, YU-SHENG/E-6570-2019; Su, Yusheng/ITU-1189-2023						Confidence Matters: Revisiting Intrinsic Self-Correction Capabilities of Large Language Models								Arxiv											3	3;2024-05-13;https://www.arxiv.org/abs/2402.12563v3| 2;2024-02-27;https://www.arxiv.org/abs/2402.12563v2| 1;2024-02-19;https://www.arxiv.org/abs/2402.12563v1	arXiv:2402.12563			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	May 13 2024	2024	The recent success of Large Language Models (LLMs) has catalyzed an increasing interest in their self-correction capabilities. This paper presents a comprehensive investigation into the intrinsic self-correction of LLMs, attempting to address the ongoing debate about its feasibility. Our research has identified an important latent factor - the "confidence" of LLMs - during the self-correction process. Overlooking this factor may cause the models to over-criticize themselves, resulting in unreliable conclusions regarding the efficacy of self-correction. We have experimentally observed that LLMs possess the capability to understand the "confidence" in their own responses. It motivates us to develop an "If-or-Else" (IoE) prompting framework, designed to guide LLMs in assessing their own "confidence", facilitating intrinsic self-corrections. We conduct extensive experiments and demonstrate that our IoE-based Prompt can achieve a consistent improvement regarding the accuracy of self-corrected responses over the initial answers. Our study not only sheds light on the underlying factors affecting self-correction in LLMs, but also introduces a practical framework that utilizes the IoE prompting principle to efficiently improve self-correction capabilities with "confidence". 																																	2024-06-08	PPRN:87776204		
J	Hou, Abe Bohan; Zhang, Jingyu; He, Tianxing; Wang, Yichen; Chuang, Yung-Sung; Wang, Hongwei; Shen, Lingfeng; Van Durme, Benjamin; Khashabi, Daniel; Tsvetkov, Yulia				He, Tianxing/MDT-2168-2025; Wang, Hongwei/HFT-3345-2022; Chuang, Yung-Sung/HSH-6375-2023; Zhang, Yiyang/AAG-7782-2019						SemStamp: A Semantic Watermark with Paraphrastic Robustness for Text Generation								Arxiv											3	3;2024-04-22;https://www.arxiv.org/abs/2310.03991v2| 2;2023-10-06;https://www.arxiv.org/abs/2310.03991v1| 1;2023-10-06;https://www.arxiv.org/abs/2310.03991v1	arXiv:2310.03991			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 22 2024	2024	Existing watermarking algorithms are vulnerable to paraphrase attacks because of their token-level design. To address this issue, we propose SemStamp, a robust sentence-level semantic watermarking algorithm based on locality-sensitive hashing (LSH), which partitions the semantic space of sentences. The algorithm encodes and LSH-hashes a candidate sentence generated by an LLM, and conducts sentence-level rejection sampling until the sampled sentence falls in watermarked partitions in the semantic embedding space. A margin-based constraint is used to enhance its robustness. To show the advantages of our algorithm, we propose a "bigram" paraphrase attack using the paraphrase that has the fewest bigram overlaps with the original sentence. This attack is shown to be effective against the existing token-level watermarking method. Experimental results show that our novel semantic watermark algorithm is not only more robust than the previous state-of-the-art method on both common and bigram paraphrase attacks, but also is better at preserving the quality of generation.																																	2024-05-01	PPRN:85520447		
J	Ormazabal, Aitor; Zheng, Che; d'Autume, Cyprien de Masson; Yogatama, Dani; Fu, Deyu; Ong, Donovan; Chen, Eric; Lamprecht, Eugenie; Pham, Hai; Ong, Isaac; Aleksiev, Kaloyan; Li, Lei; Henderson, Matthew; Bain, Max; Artetxe, Mikel; Relan, Nishant; Padlewski, Piotr; Liu, Qi; Chen, Ren; Phua, Samuel; Yang, Yazheng; Tay, Yi; Wang, Yuqi; Zhu, Zhongkai; Xie, Zhihui				wang, yuqi/LGZ-5915-2024; Zhu, Zhongkai/HOC-0871-2023						Reka Core, Flash, and Edge: A Series of Powerful Multimodal Language Models								Arxiv											2	2;2024-04-18;https://www.arxiv.org/abs/2404.12387v1| 1;2024-04-18;https://www.arxiv.org/abs/2404.12387v1	arXiv:2404.12387			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 18 2024	2024	We introduce Reka Core, Flash, and Edge, a series of powerful multimodal language models trained from scratch by Reka.1 Reka models are able to process and reason with text, images, video, and audio inputs. This technical report discusses details of training some of these models and provides comprehensive evaluation results. We show that Reka Edge and Reka Flash are not only state-of-the-art but also outperform many much larger models, delivering outsized values for their respective compute class. Meanwhile, our most capable and largest model, Reka Core, approaches the best frontier models on both automatic evaluations and blind human evaluations. On image question answering benchmarks (e.g. MMMU, VQAv2), Core performs competitively to GPT4-V. Meanwhile, on multimodal chat, Core ranks as the second most preferred model under a blind third-party human evaluation setup, outperforming other models such as Claude 3 Opus. On text benchmarks, Core not only performs competitively to other frontier models on a set of well-established benchmarks (e.g. MMLU, GSM8K) but also outperforms GPT4-0613 on human evaluation. On video question answering (Perception-Test), Core outperforms Gemini Ultra. 																																	2024-06-04	PPRN:88564938		
J	Vidgen, Bertie; Agrawal, Adarsh; Ahmed, Ahmed M.; Akinwande, Victor; Al-Nuaimi, Namir; Alfaraj, Najla; Alhajjar, Elie; Aroyo, Lora; Bavalatti, Trupti; Blili-Hamelin, Borhane; Bollacker, Kurt; Bomassani, Rishi; Boston, Marisa Ferrara; Campos, Simeon; Chakra, Kal; Chen, Canyu; Coleman, Cody; Coudert, Zacharie Delpierre; Derczynski, Leon; Dutta, Debojyoti; Eisenberg, Ian; Ezick, James; Frase, Heather; Fuller, Brian; Gandikota, Ram; Gangavarapu, Agasthya; Gangavarapu, Ananya; Gealy, James; Ghosh, Rajat; Goel, James; Gohar, Usman; Goswami, Sujata; Hale, Scott A.; Hutiri, Wiebke; Imperial, Joseph Marvin; Jandial, Surgan; Judd, Nick; Juefei-Xu, Felix; Khomh, Foutse; Kailkhura, Bhavya; Kirk, Hannah Rose; Klyman, Kevin; Knotz, Chris; Kuchnik, Michael; Kumar, Shachi H.; Lengerich, Chris; Li, Bo; Liao, Zeyi; Long, Eileen Peters; Lu, Victor; Mai, Yifan; Mammen, Priyanka Mary; Manyeki, Kelvin; McGregor, Sean; Mehta, Virendra; Mohammed, Shafee; Moss, Emanuel; Nachman, Lama; Naganna, Dinesh Jinenhally; Nikanjam, Amin; Nushi, Besmira; Oala, Luis; Orr, Iftach; Parrish, Alicia; Patlak, Cigdem; Pietri, William; Poursabzi-Sangdeh, Forough; Puletti, Fabrizio; Rottger, Paul; Sahay, Saurav; Santos, Tim; Scherrer, Nino; Sebag, Alice Schoenauer; Schramowski, Patrick; Shahbazi, Abolfazl; Sharma, Vin; Shen, Xudong; Sistla, Vamsi; Tang, Leonard; Testuggine, Davide; Thangarasa, Vithursan; Watkins, Elizabeth Anne; Weiss, Rebecca; Welty, Chris; Wilbers, Tyler; Williams, Adina; Wu, Carole-Jean; Yadav, Poonam; Yang, Xianjun; Zeng, Yi; Zhang, Wenhui; Zhdanov, Fedor; Zhu, Jiacheng; Liang, Percy; Mattson, Peter; Vanschoren, Joaquin				Imperial, Joseph Marvin/GNN-0443-2022; Chen, Canyu/KFT-0519-2024; Blili-Hamelin, Borhane/LKL-4081-2024; Judd, Nick/IZP-6255-2023; Zhu, Jiacheng/HPF-7304-2023; Mammen, Priyanka/HLV-9680-2023; Goswami, Sujata/ITV-1654-2023; Gohar, Usman/JND-9216-2023; Lu, Victor/AAX-2518-2021; Goel, James/AAA-4807-2021; Shen, Xudong/KTI-7535-2024; Alfaraj, Najla/MFH-9004-2025						Introducing v0.5 of the AI Safety Benchmark from MLCommons								Arxiv											1	1;2024-04-18;https://www.arxiv.org/abs/2404.12241v1	arXiv:2404.12241			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 18 2024	2024	This paper introduces v0.5 of the AI Safety Benchmark, which has been created by the MLCommons AI Safety Working Group. The AI Safety Benchmark has been designed to assess the safety risks of AI systems that use chat-tuned language models. We introduce a principled approach to specifying and constructing the benchmark, which for v0.5 covers only a single use case (an adult chatting to a general-purpose assistant in English), and a limited set of personas (i.e., typical users, malicious users, and vulnerable users). We created a new taxonomy of 13 hazard categories, of which 7 have tests in the v0.5 benchmark. We plan to release version 1.0 of the AI Safety Benchmark by the end of 2024. The v1.0 benchmark will provide meaningful insights into the safety of AI systems. However, the v0.5 benchmark should not be used to assess the safety of AI systems. We have sought to fully document the limitations, flaws, and challenges of v0.5. This release of v0.5 of the AI Safety Benchmark includes (1) a principled approach to specifying and constructing the benchmark, which comprises use cases, types of systems under test (SUTs), language and context, personas, tests, and test items; (2) a taxonomy of 13 hazard categories with definitions and subcategories; (3) tests for seven of the hazard categories, each comprising a unique set of test items, i.e., prompts. There are 43,090 test items in total, which we created with templates; (4) a grading system for AI systems against the benchmark; (5) an openly available platform, and downloadable tool, called ModelBench that can be used to evaluate the safety of AI systems on the benchmark; (6) an example evaluation report which benchmarks the performance of over a dozen openly available chat-tuned language models; (7) a test specification for the benchmark.																																	2024-05-12	PPRN:88561882		
J	He, Yuze; Bai, Yushi; Lin, Matthieu; Zhao, Wang; Hu, Yubin; Sheng, Jenny; Yi, Ran; Li, Juanzi; Liu, Yong-Jin				Li, Zhiyuan/ESQ-7168-2022; Hu, Yubin/KXR-2137-2024; Yi, Ran/AAU-6636-2021						T3Bench: Benchmarking Current Progress in Text-to-3D Generation								Arxiv											2	2;2024-04-17;https://www.arxiv.org/abs/2310.02977v2| 1;2023-10-04;https://www.arxiv.org/abs/2310.02977v1	arXiv:2310.02977			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 17 2024	2024	Recent methods in text-to-3D leverage powerful pretrained diffusion models to optimize NeRF. Notably, these methods are able to produce high-quality 3D scenes without training on 3D data. Due to the open-ended nature of the task, most studies evaluate their results with subjective case studies and user experiments, thereby presenting a challenge in quantitatively addressing the question: How has current progress in Text-to-3D gone so far? In this paper, we introduce T3Bench, the first comprehensive text-to-3D benchmark containing diverse text prompts of three increasing complexity levels that are specially designed for 3D generation. To assess both the subjective quality and the text alignment, we propose two automatic metrics based on multi-view images produced by the 3D contents. The quality metric combines multi-view text-image scores and regional convolution to detect quality and view inconsistency. The alignment metric uses multi-view captioning and GPT-4 evaluation to measure text-3D consistency. Both metrics closely correlate with different dimensions of human judgments, providing a paradigm for efficiently evaluating text-to-3D models. The benchmarking results, shown in Fig. 1, reveal performance differences among an extensive 10 prevalent text-to-3D methods. Our analysis further highlights the common struggles for current methods on generating surroundings and multi-object scenes, as well as the bottleneck of leveraging 2D guidance for 3D generation. 																																	2024-04-27	PPRN:85419638		
J	Shi, Quan; Tang, Michael; Narasimhan, Karthik; Yao, Shunyu				Tang, Michael/ABB-9310-2021						Can Language Models Solve Olympiad Programming?								Arxiv											1	1;2024-04-16;https://www.arxiv.org/abs/2404.10952v1	arXiv:2404.10952			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 16 2024	2024	Computing olympiads contain some of the most challenging problems for humans, requiring complex algorithmic reasoning, puzzle solving, in addition to generating efficient code. However, it has been understudied as a domain to evaluate language models (LMs). In this paper, we introduce the USACO benchmark with 307 problems from the USA Computing Olympiad, along with high-quality unit tests, reference code, and official analyses for each problem. These resources enable us to construct and test a range of LM inference methods for competitive programming for the first time. We find GPT-4 only achieves a 8.7% pass@1 accuracy with zero-shot chain-of-thought prompting, and our best inference method improves it to 20.2% using a combination of self-reflection and retrieval over episodic knowledge. However, this is far from solving the benchmark. To better understand the remaining challenges, we design a novel human-in-the-loop study and surprisingly find that a small number of targeted hints enable GPT-4 to solve 13 out of 15 problems previously unsolvable by any model and method. Our benchmark, baseline methods, quantitative results, and qualitative analysis serve as an initial step toward LMs with grounded, creative, and algorithmic reasoning.																																	2024-04-27	PPRN:88555724		
J	Chowdhury, Sayak Ray; Kini, Anush; Natarajan, Nagarajan										Provably Robust DPO: Aligning Language Models with Noisy Feedback								Arxiv											2	2;2024-04-12;https://www.arxiv.org/abs/2403.00409v2| 1;2024-03-01;https://www.arxiv.org/abs/2403.00409v1	arXiv:2403.00409			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 12 2024	2024	Learning from preference-based feedback has recently gained traction as a promising approach to align language models with human interests. While these aligned generative models have demonstrated impressive capabilities across various tasks, their dependence on high-quality human preference data poses a bottleneck in practical applications. Specifically, noisy (incorrect and ambiguous) preference pairs in the dataset might restrict the language models from capturing human intent accurately. While practitioners have recently proposed heuristics to mitigate the effect of noisy preferences, a complete theoretical understanding of their workings remain elusive.<br /> In this work, we aim to bridge this gap by by introducing a general framework for policy optimization in the presence of random preference flips. We focus on the direct preference optimization (DPO) algorithm in particular since it assumes that preferences adhere to the Bradley-Terry-Luce (BTL) model, raising concerns about the impact of noisy data on the learned policy. We design a novel loss function, which de-bias the effect of noise on average, making a policy trained by minimizing that loss robust to the noise. Under log-linear parameterization of the policy class and assuming good feature coverage of the SFT policy, we prove that the sub-optimality gap of the proposed robust DPO (rDPO) policy compared to the optimal policy is of the order O(1/1−2ϵ√d/n), where ϵ < 1/2 is flip rate of labels, d is policy parameter dimension and n is size of dataset. Our experiments on IMDb sentiment generation and Anthropic's helpful-harmless dataset show that rDPO is robust to noise in preference labels compared to vanilla DPO and other heuristics proposed by practitioners.																																	2024-04-26	PPRN:87996599		
J	Yao, Jing; Hong, Danfeng; Li, Chenyu; Chanussot, Jocelyn				Yao, Jing/AAA-5843-2021; Chanussot, Jocelyn/OHR-6374-2025; Hong, Danfeng/U-6082-2019						SpectralMamba: Efficient Mamba for Hyperspectral Image Classification								Arxiv											1	1;2024-04-12;https://www.arxiv.org/abs/2404.08489v1	arXiv:2404.08489			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 12 2024	2024	Recurrent neural networks and Transformers have recently dominated most applications in hyperspectral (HS) imaging, owing to their capability to capture long-range dependencies from spectrum sequences. However, despite the success of these sequential architectures, the non-ignorable inefficiency caused by either difficulty in parallelization or computationally prohibitive attention still hinders their practicality, especially for large-scale observation in remote sensing scenarios. To address this issue, we herein propose SpectralMamba -- a novel state space model incorporated efficient deep learning framework for HS image classification. SpectralMamba features the simplified but adequate modeling of HS data dynamics at two levels. First, in spatial-spectral space, a dynamical mask is learned by efficient convolutions to simultaneously encode spatial regularity and spectral peculiarity, thus attenuating the spectral variability and confusion in discriminative representation learning. Second, the merged spectrum can then be efficiently operated in the hidden state space with all parameters learned input-dependent, yielding selectively focused responses without reliance on redundant attention or imparallelizable recurrence. To explore the room for further computational downsizing, a piece-wise scanning mechanism is employed in-between, transferring approximately continuous spectrum into sequences with squeezed length while maintaining short- and long-term contextual profiles among hundreds of bands. Through extensive experiments on four benchmark HS datasets acquired by satellite-, aircraft-, and UAV-borne imagers, SpectralMamba surprisingly creates promising win-wins from both performance and efficiency perspectives. The code will be available at https://github.com/danfenghong/SpectralMamba for the sake of reproducibility.																																	2024-04-26	PPRN:88550932		
J	Sun, Zhiqing; Shen, Yikang; Zhang, Hongxin; Zhou, Qinhong; Chen, Zhenfang; Cox, David; Yang, Yiming; Gan, Chuang				Cox, David/C-4888-2008; Chen, Zhenfang/HTS-8543-2023; Zhang, Hong-Xin/C-6384-2017						SALMON: Self-Alignment with Instructable Reward Models								Arxiv											2	2;2024-04-09;https://www.arxiv.org/abs/2310.05910v2| 1;2023-10-09;https://www.arxiv.org/abs/2310.05910v1	arXiv:2310.05910			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 09 2024	2024	Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents. However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences. This paper presents a novel approach, namely SALMON, to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance. Central to our approach is an instructable reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles. By merely adjusting these principles during the RL training phase, we gain full control over the preferences with the instructable reward model, subsequently influencing the behavior of the RL-trained policy models, and reducing the reliance on the collection of online human preferences. Applying our method to the LLaMA-2-70b base language model, we developed an AI assistant named Dromedary-2. With only 6 exemplars for in-context learning and 31 human-defined principles, Dromedary-2 significantly surpasses the performance of several state-of-the-art AI systems, including LLaMA-2-Chat-70b, on various benchmark datasets. We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.																																	2024-04-24	PPRN:85573085		
J	Liu, Jing; Gong, Ruihao; Wei, Xiuying; Dong, Zhiwei; Cai, Jianfei; Zhuang, Bohan				Gong, Ruihao/KYQ-8030-2024; Zhuang, Bohan/AAL-5022-2021; Liu, Jing/LFU-9046-2024						QLLM: Accurate and Efficient Low-Bitwidth Quantization for Large Language Models								Arxiv											3	3;2024-04-06;https://www.arxiv.org/abs/2310.08041v3| 2;2024-02-21;https://www.arxiv.org/abs/2310.08041v2| 1;2023-10-12;https://www.arxiv.org/abs/2310.08041v1	arXiv:2310.08041			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 06 2024	2024	Large Language Models (LLMs) excel in NLP, but their demands hinder their widespread deployment. While Quantization-Aware Training (QAT) offers a solution, its extensive training costs make Post-Training Quantization (PTQ) a more practical approach for LLMs. In existing studies, activation outliers in particular channels are identified as the bottleneck to PTQ accuracy. They propose to transform the magnitudes from activations to weights, which however offers limited alleviation or suffers from unstable gradients, resulting in a severe performance drop at low-bitwidth. In this paper, we propose QLLM, an accurate and efficient low-bitwidth PTQ method designed for LLMs. QLLM introduces an adaptive channel reassembly technique that reallocates the magnitude of outliers to other channels, thereby mitigating their impact on the quantization range. This is achieved by channel disassembly and channel assembly, which first breaks down the outlier channels into several sub-channels to ensure a more balanced distribution of activation magnitudes. Then similar channels are merged to maintain the original channel number for efficiency. Additionally, an adaptive strategy is designed to autonomously determine the optimal number of sub-channels for channel disassembly. To further compensate for the performance loss caused by quantization, we propose an efficient tuning method that only learns a small number of low-rank weights while freezing the pre-trained quantized model. After training, these low-rank parameters can be fused into the frozen weights without affecting inference. Extensive experiments on LLaMA-1 and LLaMA-2 show that QLLM can obtain accurate quantized models efficiently. For example, QLLM quantizes the 4-bit LLaMA-2-70B within 10 hours on a single A100-80G GPU, outperforming the previous state-of-the-art method by 7.89% on the average accuracy across five zero-shot tasks.																																	2024-04-21	PPRN:85604672		
J	Mao, Shengyu; Wang, Xiaohan; Wang, Mengru; Jiang, Yong; Xie, Pengjun; Huang, Fei; Zhang, Ningyu										Editing Personality for Large Language Models								Arxiv											2	2;2024-04-06;https://www.arxiv.org/abs/2310.02168v3| 1;2023-10-03;https://www.arxiv.org/abs/2310.02168v1	arXiv:2310.02168			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 06 2024	2024	This paper introduces an innovative task focused on editing the personality traits of Large Language Models (LLMs). This task seeks to adjust the models' responses to opinion-related questions on specified topics since an individual's personality often manifests in the form of their expressed opinions, thereby showcasing different personality traits. Specifically, we construct a new benchmark dataset PersonalityEdit to address this task. Drawing on the theory in Social Psychology, we isolate three representative traits, namely Neuroticism, Extraversion, and Agreeableness, as the foundation for our benchmark. We then gather data using GPT-4, generating responses that not only align with a specified topic but also embody the targeted personality trait. We conduct comprehensive experiments involving various baselines and discuss the representation of personality behavior in LLMs. Our intriguing findings uncover potential challenges of the proposed task, illustrating several remaining issues. We anticipate that our work can provide the NLP community with insights. Code and datasets are available at https://github.com/zjunlp/EasyEdit.																																	2024-04-21	PPRN:85375964		
J	Mecklenburg, Nick; Lin, Yiyou; Li, Xiaoxiao; Holstein, Daniel; Nunes, Leonardo; Malvar, Sara; Silva, Bruno; Chandra, Ranveer; Aski, Vijay; Yannam, Pavan Kumar Reddy; Aktas, Tolga; Hendry, Todd										Injecting New Knowledge into Large Language Models via Supervised Fine-Tuning								Arxiv											1	1;2024-04-02;https://www.arxiv.org/abs/2404.00213v2	arXiv:2404.00213			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Apr 02 2024	2024	In recent years, Large Language Models (LLMs) have shown remarkable performance in generating human-like text, proving to be a valuable asset across various applications. However, adapting these models to incorporate new, out-of-domain knowledge remains a challenge, particularly for facts and events that occur after the model's knowledge cutoff date. This paper investigates the effectiveness of Supervised Fine-Tuning (SFT) as a method for knowledge injection in LLMs, specifically focusing on the domain of recent sporting events. We compare different dataset generation strategies -- token-based and fact-based scaling -- to create training data that helps the model learn new information. Our experiments on GPT-4 demonstrate that while token-based scaling can lead to improvements in Q&A accuracy, it may not provide uniform coverage of new knowledge. Fact-based scaling, on the other hand, offers a more systematic approach to ensure even coverage across all facts. We present a novel dataset generation process that leads to more effective knowledge ingestion through SFT, and our results show considerable performance improvements in Q&A tasks related to out-of-domain knowledge. This study contributes to the understanding of domain adaptation for LLMs and highlights the potential of SFT in enhancing the factuality of LLM responses in specific knowledge domains.																																	2024-04-18	PPRN:88390170		
J	Salinas, Abel; Morstatter, Fred										The Butterfly Effect of Altering Prompts: How Small Changes and Jailbreaks Affect Large Language Model Performance								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2401.03729v3| 1;2024-01-09;https://www.arxiv.org/abs/2401.03729v2	arXiv:2401.03729			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 01 2024	2024	Large Language Models (LLMs) are regularly being used to label data across many domains and for myriad tasks. By simply asking the LLM for an answer, or “prompting,” practitioners are able to use LLMs to quickly get a response for an arbitrary task. This prompting is done through a series of decisions by the practitioner, from simple wording of the prompt, to requesting the output in a certain data format, to jailbreaking in the case of prompts that address more sensitive topics. In this work we ask: do variations in the way a prompt is constructed change the ultimate decision of the LLM? We answer this using a series of prompt variations across a variety of text classification tasks. We find that even the smallest of perturbations, such as adding a space at the end of a prompt, can cause the LLM to change its answer. Further, we find that requesting responses in XML and commonly -used jailbreaks can have cataclysmic effects on the data labeled by LLMs.																																	2024-04-18	PPRN:87078280		
J	Geng, Jiahui; Cai, Fengyu; Wang, Yuxia; Koeppl, Heinz; Nakov, Preslav; Gurevych, Iryna										A Survey of Confidence Estimation and Calibration in Large Language Models								Arxiv											1	1;2024-03-25;https://www.arxiv.org/abs/2311.08298v2	arXiv:2311.08298			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Mar 25 2024	2024	Large language models (LLMs) have demonstrated remarkable capabilities across a wide range of tasks in various domains. Despite their impressive performance, they can be unreliable due to factual errors in their generations. Assessing their confidence and calibrating them across different tasks can help mitigate risks and enable LLMs to produce better generations. There has been a lot of recent research aiming to address this, but there has been no comprehensive overview to organize it and outline the main lessons learned. The present survey aims to bridge this gap. In particular, we outline the challenges and we summarize recent technical advancements for LLM confidence estimation and calibration. We further discuss their applications and suggest promising directions for future work.																																	2025-08-07	PPRN:123159995		
J	Steenhoek, Benjamin; Rahman, Md Mahbubur; Roy, Monoshi Kumar; Alam, Mirza Sanjida; Barr, Earl T.; Le, Wei				Steenhoek, Benjamin/JXY-0392-2024; Rahman, Md Mahbubur/JMP-8242-2023; Alam, Mirza Sanjida/AGG-2249-2022; Barr, Earl T. T./AAZ-7265-2020						A Comprehensive Study of the Capabilities of Large Language Models for Vulnerability Detection								Arxiv											2	2;2025-01-07;https://www.arxiv.org/abs/2403.17218v2| 1;2024-03-25;https://www.arxiv.org/abs/2403.17218v1	arXiv:2403.17218			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 25 2024	2024	Large Language Models (LLMs) have demonstrated great potential for code generation and other software engineering tasks. Vulnerability detection is of crucial importance to maintaining the security, integrity, and trustworthiness of software systems. Precise vulnerability detection requires reasoning about the code, making it a good case study for exploring the limits of LLMs' reasoning capabilities. Although recent work has applied LLMs to vulnerability detection using generic prompting techniques, their full capabilities for this task and the types of errors they make when explaining identified vulnerabilities remain unclear. In this paper, we surveyed eleven LLMs that are state-of-the-art in code generation and commonly used as coding assistants, and evaluated their capabilities for vulnerability detection. We systematically searched for the best-performing prompts, incorporating techniques such as in-context learning and chain-of-thought, and proposed three of our own prompting methods. Our results show that while our prompting methods improved the models' performance, LLMs generally struggled with vulnerability detection. They reported 0.5-0.63 Balanced Accuracy and failed to distinguish between buggy and fixed versions of programs in 76% of cases on average. By comprehensively analyzing and categorizing 287 instances of model reasoning, we found that 57% of LLM responses contained errors, and the models frequently predicted incorrect locations of buggy code and misidentified bug types. LLMs only correctly localized 6 out of 27 bugs in DbgBench, and these 6 bugs were predicted correctly by 70-100% of human participants. These findings suggest that despite their potential for other tasks, LLMs may fail to properly comprehend critical code structures and security-related concepts. Our data and code are available at https://figshare.com/s/78fe02e56e09ec49300b.																																	2025-08-07	PPRN:88291811		
J	Zhou, Xiaoyu; Lin, Zhiwei; Shan, Xiaojun; Wang, Yongtao; Sun, Deqing; Yang, Ming-Hsuan				Wang, Yongtao/LOR-4168-2024; Yang, Ming-Hsuan/T-9533-2019; ZhiWei, Lin/AAQ-5438-2021; Sun, Deqing/KLD-7402-2024						DrivingGaussian: Composite Gaussian Splatting for Surrounding Dynamic Autonomous Driving Scenes								Arxiv											3	3;2024-03-20;https://www.arxiv.org/abs/2312.07920v3| 2;2024-02-27;https://www.arxiv.org/abs/2312.07920v2| 1;2023-12-13;https://www.arxiv.org/abs/2312.07920v1	arXiv:2312.07920			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 20 2024	2024	We present DrivingGaussian, an efficient and effective framework for surrounding dynamic autonomous driving scenes. For complex scenes with moving objects, we first sequentially and progressively model the static background of the entire scene with incremental static 3D Gaussians. We then leverage a composite dynamic Gaussian graph to handle multiple moving objects, individually reconstructing each object and restoring their accurate positions and occlusion relationships within the scene. We further use a LiDAR prior for Gaussian Splatting to reconstruct scenes with greater details and maintain panoramic consistency. DrivingGaussian outperforms existing methods in dynamic driving scene reconstruction and enables photorealistic surround-view synthesis with high-fidelity and multi-camera consistency. Our project page is at: https://github.com/VDIGPKU/DrivingGaussian.																																	2024-04-12	PPRN:86574073		
J	Dominguez-Olmedo, Ricardo; Hardt, Moritz; Mendler-Duenner, Celestine										Questioning the Survey Responses of Large Language Models								Arxiv											2	2;2024-02-28;https://www.arxiv.org/abs/2306.07951v3| 1;2023-06-13;https://www.arxiv.org/abs/2306.07951v1	arXiv:2306.07951			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 28 2024	2024	As large language models increase in capability, researchers have started to conduct surveys of all kinds on these models in order to investigate the population represented by their responses. In this work, we critically examine language models’ survey responses on the basis of the wellestablished American Community Survey by the U.S. Census Bureau and investigate whether they elicit a faithful representations of any human population. Using a de -facto standard multiple-choice prompting technique and evaluating 39 different language models using systematic experiments, we establish two dominant patterns: First, models’ responses are governed by ordering and labeling biases, leading to variations across models that do not persist after adjusting for systematic biases. Second, models’ responses do not contain the entropy variations and statistical signals typically found in human populations. As a result, a binary classifier can almost perfectly differentiate model -generated data from the responses of the U.S. census. At the same time, models’ relative alignment with different demographic subgroups can be predicted from the subgroups’ entropy, irrespective of the model’s training data or training strategy. Taken together, our findings suggest caution in treating models’ survey responses as equivalent to those of human populations.																																	2024-03-28	PPRN:73314605		
J	Geiger, Atticus; Wu, Zhengxuan; Potts, Christopher; Icard, Thomas; Goodman, Noah D.										Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations								Arxiv											2	2;2024-02-21;https://www.arxiv.org/abs/2303.02536v4| 1;2023-03-05;https://www.arxiv.org/abs/2303.02536v1	arXiv:2303.02536			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 21 2024	2024	Causal abstraction is a promising theoretical framework for explainable artificial intelligence that defines when an interpretable high-level causal model is a faithful simplification of a low-level deep learning system. However, existing causal abstraction methods have two major limitations: they require a brute-force search over alignments between the high-level model and the low-level one, and they presuppose that variables in the high-level model will align with disjoint sets of neurons in the low-level one. In this paper, we present distributed alignment search (DAS), which overcomes these limitations. In DAS, we find the alignment between high-level and low-level models using gradient descent rather than conducting a brute-force search, and we allow individual neurons to play multiple distinct roles by analyzing representations in non-standard bases-distributed representations. Our experiments show that DAS can discover internal structure that prior approaches miss. Overall, DAS removes previous obstacles to conducting causal abstraction analyses and allows us to find conceptual structure in trained neural nets.																																	2024-03-21	PPRN:43572348		
J	Liang, Jiawei; Liang, Siyuan; Luo, Man; Liu, Aishan; Han, Dongchen; Chang, Ee-Chien; Cao, Xiaochun				Han, Dongchen/IWM-3538-2023; Liang, Siyuan/KHW-1891-2024						VL-Trojan: Multimodal Instruction Backdoor Attacks against Autoregressive Visual Language Models								Arxiv											1	1;2024-02-21;https://www.arxiv.org/abs/2402.13851v1	arXiv:2402.13851			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 21 2024	2024	Autoregressive Visual Language Models (VLMs) showcase impressive few-shot learning capabilities in a multimodal context. Recently, multimodal instruction tuning has been proposed to further enhance instruction-following abilities. However, we uncover the potential threat posed by backdoor attacks on autoregressive VLMs during instruction tuning. Adversaries can implant a backdoor by injecting poisoned samples with triggers embedded in instructions or images, enabling malicious manipulation of the victim model's predictions with predefined triggers. Nevertheless, the frozen visual encoder in autoregressive VLMs imposes constraints on the learning of conventional image triggers. Additionally, adversaries may encounter restrictions in accessing the parameters and architectures of the victim model. To address these challenges, we propose a multimodal instruction backdoor attack, namely VL-Trojan. Our approach facilitates image trigger learning through an isolating and clustering strategy and enhance black-box-attack efficacy via an iterative character-level text trigger generation method. Our attack successfully induces target outputs during inference, significantly surpassing baselines (+62.52%) in ASR. Moreover, it demonstrates robustness across various model scales and few-shot in-context reasoning scenarios.																																	2024-03-20	PPRN:87787952		
J	Wu, Haibin; Chen, Xuanjun; Lin, Yi-Cheng; Chang, Kai-wei; Chung, Ho-Lam; Liu, Alexander H.; Lee, Hung-yi				Chang, Kai-Wei/M-6055-2016; Chung, Ho Lam/HSF-4093-2023; Wu, Haibin/D-3208-2009; Lin, Yi-Cheng/E-5817-2010						Towards audio language modeling -- an overview								Arxiv											1	1;2024-02-20;https://www.arxiv.org/abs/2402.13236v1	arXiv:2402.13236			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Feb 20 2024	2024	Neural audio codecs are initially introduced to compress audio data into compact codes to reduce transmission latency. Researchers recently discovered the potential of codecs as suitable tokenizers for converting continuous audio into discrete codes, which can be employed to develop audio language models (LMs). Numerous high-performance neural audio codecs and codec-based LMs have been developed. The paper aims to provide a thorough and systematic overview of the neural audio codec models and codec-based LMs.																																	2024-03-19	PPRN:87772070		
J	Fan, Lizhou; Hua, Wenyue; Li, Lingyao; Ling, Haoyang; Zhang, Yongfeng				Zhang, Yongfeng/HMW-1599-2023						NPHardEval: Dynamic Benchmark on Reasoning Ability of Large Language Models via Complexity Classes								Arxiv											4	4;2024-02-12;https://www.arxiv.org/abs/2312.14890v4| 3;2024-01-12;https://www.arxiv.org/abs/2312.14890v3| 2;2023-12-25;https://www.arxiv.org/abs/2312.14890v2| 1;2023-12-22;https://www.arxiv.org/abs/2312.14890v1	arXiv:2312.14890			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 12 2024	2024	Complex reasoning ability is one of the most important features of current LLMs, which has also been leveraged to play an integral role in complex decision-making tasks. Therefore, the investigation into the reasoning capabilities of Large Language Models (LLMs) is critical: numerous benchmarks have been established to assess the reasoning abilities of LLMs. However, current benchmarks are inadequate in offering a rigorous evaluation of the full extent of reasoning abilities that LLMs are capable of achieving. They are also prone to the risk of overfitting, as these benchmarks, being publicly accessible and static, allow models to potentially tailor their responses to specific benchmark metrics, thereby inflating their performance. Addressing these limitations, our research introduces a new benchmark, named NPHardEval. This benchmark is designed to evaluate the reasoning abilities of LLMs across a broad spectrum of 900 algorithmic questions, extending up to the NP-Hard complexity class. These questions are meticulously chosen to represent a wide range of complexity class below the NP-hard complexity class, offering a rigorous measure of the reasoning ability of LLMs. Through this study, we shed light on the current state of reasoning in LLMs, providing an objective and rigorous perspective through the comparison of LLMs' performance across complex classes. Moreover, this benchmark is designed with a dynamic update mechanism, where the datapoints are refreshed on a monthly basis. Such regular updates play a crucial role in mitigating the risk of LLMs overfitting to the benchmark, promoting a more accurate and reliable assessment of their reasoning capabilities. 																																	2024-05-25	PPRN:86784822		
J	Gour, Gilad										Resources of the Quantum World A modern textbook on quantum resource theories Volume 1: Static Resources								Arxiv											1	1;2024-02-08;https://www.arxiv.org/abs/2402.05474v1	arXiv:2402.05474			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Feb 08 2024	2024																																		2024-08-05	PPRN:87572630		
J	Hao, Yongchang; Cao, Yanshuai; Mou, Lili										Flora: Low-Rank Adapters Are Secretly Gradient Compressors								Arxiv											1	1;2024-02-05;https://www.arxiv.org/abs/2402.03293v1	arXiv:2402.03293			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 05 2024	2024	Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.																																	2024-05-25	PPRN:87523696		
J	Liu, Na; Chen, Liangyu; Tian, Xiaoyu; Zou, Wei; Chen, Kaijiang; Cui, Ming				zou, wei/D-4391-2013						From LLM to Conversational Agent: A Memory Enhanced Architecture with Fine-Tuning of Large Language Models								Arxiv											2	2;2024-01-30;https://www.arxiv.org/abs/2401.02777v2| 1;2024-01-05;https://www.arxiv.org/abs/2401.02777v1	arXiv:2401.02777			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 30 2024	2024	This paper introduces RAISE (Reasoning and Acting through Scratchpad and Examples), an advanced architecture enhancing the integration of Large Language Models (LLMs) like GPT-4 into conversational agents. RAISE, an enhancement of the ReAct framework, incorporates a dual -component memory system, mirroring human short-term and long-term memory, to maintain context and continuity in conversations. It entails a comprehensive agent construction scenario, including phases like Conversation Selection, Scene Extraction, CoT Completion, and Scene Augmentation, leading to the LLMs Training phase. This approach appears to enhance agent controllability and adaptability in complex, multiturn dialogues. Our preliminary evaluations in a real estate sales context suggest that RAISE has some advantages over traditional agents, indicating its potential for broader applications. This work contributes to the AI field by providing a robust framework for developing more context -aware and versatile conversational agents.																																	2024-02-16	PPRN:86995830		
J	Tang, Xinyu; Shin, Richard; Inan, Huseyin A.; Manoel, Andre; Mireshghallah, Fatemehsadat; Lin, Zinan; Gopi, Sivakanth; Kulkarni, Janardhan; Sim, Robert				Lin, Zinan/NGS-1685-2025; Manoel, Andre/M-9475-2013						Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation								Arxiv											2	2;2024-01-28;https://www.arxiv.org/abs/2309.11765v2| 1;2023-09-21;https://www.arxiv.org/abs/2309.11765v1	arXiv:2309.11765			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 28 2024	2024	We study the problem of in-context learning (ICL) with large language models (LLMs) on private datasets. This scenario poses privacy risks, as LLMs may leak or regurgitate the private examples demonstrated in the prompt. We propose a novel algorithm that generates synthetic few-shot demonstrations from the private dataset with formal differential privacy (DP) guarantees, and show empirically that it can achieve effective ICL. We conduct extensive experiments on standard benchmarks and compare our algorithm with non-private ICL and zero-shot solutions. Our results demonstrate that our algorithm can achieve competitive performance with strong privacy levels. These results open up new possibilities for ICL with privacy protection for a broad range of applications.																																	2024-05-25	PPRN:85084196		
J	Zhang, Qiang; Ding, Keyang; Lyv, Tianwen; Wang, Xinda; Yin, Qingyu; Zhang, Yiwen; Yu, Jing; Wang, Yuhao; Li, Xiaotong; Xiang, Zhuoyi; Zhuang, Xiang; Wang, Zeyuan; Qin, Ming; Zhang, Mengyao; Zhang, Jinlu; Cui, Jiyu; Xu, Renjun; Chen, Hongyang; Fan, Xiaohui; Xing, Huabin; Chen, Huajun				Huajun, Chen/B-6340-2013; Chen, Hongyang/F-7634-2015; Fan, Xiaohui/F-6458-2010; Wang, Zeyuan/ADI-2568-2022; zhang, jinlu/KEE-9374-2024; Wang, Yuhao/JMD-0355-2023; Xiaotong, Li/KDM-9760-2024						Scientific Large Language Models: A Survey on Biological & Chemical Domains								Arxiv											1	1;2024-01-26;https://www.arxiv.org/abs/2401.14656v1	arXiv:2401.14656			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jan 26 2024	2024	Large Language Models (LLMs) have emerged as a transformative power in enhancing natural language comprehension, representing a significant stride toward artificial general intelligence. The application of LLMs extends beyond conventional linguistic boundaries, encompassing specialized linguistic systems developed within various scientific disciplines. This growing interest has led to the advent of scientific LLMs, a novel subclass specifically engineered for facilitating scientific discovery. As a burgeoning area in the community of AI for Science, scientific LLMs warrant comprehensive exploration. However, a systematic and up-to-date survey introducing them is currently lacking. In this paper, we endeavor to methodically delineate the concept of “scientific language”, whilst providing a thorough review of the latest advancements in scientific LLMs. Given the expansive realm of scientific disciplines, our analysis adopts a focused lens, concentrating on the biological and chemical domains. This includes an in-depth examination of LLMs for textual knowledge, small molecules, macromolecular proteins, genomic sequences, and their combinations, analyzing them in terms of model architectures, capabilities, datasets, and evaluation. Finally, we critically examine the prevailing challenges and point out promising research directions along with the advances of LLMs. By offering a comprehensive overview of technical developments in this field, this survey aspires to be an invaluable resource for researchers navigating the intricate landscape of scientific LLMs.																																	2024-02-14	PPRN:87371598		
J	Chen, Xiaoyang; Choi, Jaewon; Jiang, Zhicheng; Mei, Jiong; Jiang, Kun; Li, Jie; Agrestini, Stefano; Garcia-Fernandez, Mirian; Huang, Xing; Sun, Hualei; Shen, Dawei; Wang, Meng; Hu, Jiangping; Lu, Yi; Zhou, Ke-Jin; Feng, Donglai				Feng, Donglai/R-1615-2018; jie, li/HSF-6430-2023; zhou, kejin/E-3232-2013; hu, jiangping/C-3320-2014; WANG, MENG/E-6595-2012; Lu, Yi/G-9881-2014						Electronic and magnetic excitations in La3Ni2O7								Arxiv											1	1;2024-01-23;https://www.arxiv.org/abs/2401.12657v1	arXiv:2401.12657			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 23 2024	2024	The striking discovery of high-temperature superconductivity (HTSC) of 80 K in a bilayer nickelate La3Ni2O7 under a moderately high pressure of about 14 GPa ignited a new wave of studying HTSC in nickelates [1–8]. The properties of the parental phase at ambient pressure may contain key information on basic interactions therein and bosons that may mediate pairing giving birth to super-conductivity. Moreover, the bilayer structure of La3Ni2O7 may suggest a distinct minimal model in comparison to cuprate superconductors. Here using X-ray absorption spectroscopy and resonant inelastic X-ray scattering, we studied La3Ni2O7 at ambient pressure, and found that Ni 3dx2−y2, Ni 3dz2, and ligand oxygen 2p orbitals domi-nate the low-energy physics with a small charge-transfer energy. Remarkably, well-defined optical-like magnetic excitations were found to soften into a quasi-static spin-density-wave ordering, evidencing the strong electronic correlations and rich magnetic properties. Based on a Heisenberg spin model, we found that the inter-layer ef-fective magnetic superexchange interaction is much larger than the intra-layer ones, and proposed two viable mag-netic structures. Our results set the foundation for further exploration of La3Ni2O7 superconductor.																																	2024-02-08	PPRN:87294543		
J	Nakamoto, Mitsuhiko; Zhai, Yuexiang; Singh, Anikait; Mark, Max Sobol; Ma, Yi; Finn, Chelsea; Kumar, Aviral; Levine, Sergey										Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning								Arxiv											3	3;2024-01-20;https://www.arxiv.org/abs/2303.05479v4| 2;2023-10-28;https://www.arxiv.org/abs/2303.05479v3| 1;2023-03-09;https://www.arxiv.org/abs/2303.05479v1	arXiv:2303.05479			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Jan 20 2024	2024	A compelling use case of offline reinforcement learning (RL) is to obtain a policy initialization from existing datasets followed by fast online fine-tuning with limited interaction. However, existing offline RL methods tend to behave poorly during finetuning. In this paper, we study the fine-tuning problem in the context of conservative offline RL methods and we devise an approach for learning an effective initialization from offline data that also enables fast online fine-tuning capabilities. Our approach, calibrated Q-learning (Cal-QL), accomplishes this by learning a conservative value function initialization that underestimates the value of the learned policy from offline data, while also ensuring that the learned Q-values are at a reasonable scale. We refer to this property as calibration, and define it formally as providing a lower bound on the true value function of the learned policy and an upper bound on the value of some other (suboptimal) reference policy, which may simply be the behavior policy. We show that a conservative offline RL algorithm that also learns a calibrated value function leads to effective online fine-tuning, enabling us to take the benefits of offline initializations in online fine-tuning. In practice, Cal-QL can be implemented on top of the conservative Q learning (CQL) [32] for offline RL within a one-line code change. Empirically, Cal-QL outperforms state-of-the-art methods on 9/11 fine-tuning benchmark tasks that we study in this paper. Code and video are available at https://nakamotoo.github.io/Cal-QL																																	2024-02-06	PPRN:44828688		
J	Wang, Xiaofeng; Zhu, Zheng; Huang, Guan; Wang, Boyuan; Chen, Xinze; Lu, Jiwen				Wang, Xiaofeng/GLR-2215-2022; Wang, Boyuan/AFK-6940-2022						WorldDreamer: Towards General World Models for Video Generation via Predicting Masked Tokens								Arxiv											1	1;2024-01-18;https://www.arxiv.org/abs/2401.09985v1	arXiv:2401.09985			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 18 2024	2024	World models play a crucial role in understanding and predicting the dynamics of the world, which is essential for video generation. However, existing world models are confined to specific scenarios such as gaming or driving, limiting their ability to capture the complexity of general world dynamic environments. Therefore, we introduce WorldDreamer, a pioneering world model to foster a comprehensive comprehension of general world physics and motions, which significantly enhances the capabilities of video generation. Drawing inspiration from the success of large language models, WorldDreamer frames world modeling as an unsupervised visual sequence modeling challenge. This is achieved by mapping visual inputs to discrete tokens and predicting the masked ones. During this process, we incorporate multi-modal prompts to facilitate interaction within the world model. Our experiments show that WorldDreamer excels in generating videos across different scenarios, including natural scenes and driving environments. WorldDreamer showcases versatility in executing tasks such as text-to-video conversion, image-tovideo synthesis, and video editing. These results underscore WorldDreamer's effectiveness in capturing dynamic elements within diverse general world environments.																																	2024-05-25	PPRN:87223854		
J	Pan, Rangeet; Ibrahimzada, Ali Reza; Krishna, Rahul; Sankar, Divya; Wassi, Lambert Pouguem; Merler, Michele; Sobolev, Boris; Pavuluri, Raju; Sinha, Saurabh; Jabbarvand, Reyhaneh				Pan, Rangeet/AAF-3769-2020; Ibrahimzada, Ali Reza/JEO-4918-2023; Krishna, Rahul/AEX-7754-2022						Lost in Translation: A Study of Bugs Introduced by Large Language Models while Translating Code								Arxiv											3	3;2024-01-16;https://www.arxiv.org/abs/2308.03109v3| 2;2023-12-19;https://www.arxiv.org/abs/2308.03109v2| 1;2023-08-06;https://www.arxiv.org/abs/2308.03109v1	arXiv:2308.03109			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jan 16 2024	2024	Code translation aims to convert source code from one programming language (PL) to another. Given the promising abilities of large language models (LLMs) in code synthesis, researchers are exploring their potential to automate code translation. The prerequisite for advancing the state of LLM-based code translation is to understand their promises and limitations over existing techniques. To that end, we present a large-scale empirical study to investigate the ability of general LLMs and code LLMs for code translation across pairs of different languages, including C, C++, Go, Java, and Python. Our study, which involves the translation of 1,700 code samples from three benchmarks and two real-world projects, reveals that LLMs are yet to be reliably used to automate code translation -- with correct translations ranging from 2.1% to 47.3% for the studied LLMs. Further manual investigation of unsuccessful translations identifies 15 categories of translation bugs. We also compare LLM-based code translation with traditional non-LLM-based approaches. Our analysis shows that these two classes of techniques have their own strengths and weaknesses. Finally, insights from our study suggest that providing more context to LLMs during translation can help them produce better results. To that end, we propose a prompt-crafting approach based on the symptoms of erroneous translations; this improves the performance of LLM-based code translation by 5.5% on average. Our study is the first of its kind, in terms of scale and breadth, that provides insights into the current limitations of LLMs in code translation and opportunities for improving them. Our dataset -- consisting of 1,700 code samples in five PLs with 10K+ tests, 43K+ translated code, 1,748 manually labeled bugs, and 1,365 bug-fix pairs -- can help drive research in this area.																																	2024-05-25	PPRN:74300480		
J	Chen, Guangyu; Wu, Yu; Liu, Shujie; Liu, Tao; Du, Xiaoyong; Wei, Furu				liu, tao/HMO-6312-2023						WavMark: Watermarking for Audio Generation								Arxiv											3	3;2024-01-07;https://www.arxiv.org/abs/2308.12770v3| 2;2023-11-16;https://www.arxiv.org/abs/2308.12770v2| 1;2023-08-24;https://www.arxiv.org/abs/2308.12770v1	arXiv:2308.12770			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 07 2024	2024	Recent breakthroughs in zero-shot voice synthesis have enabled imitating a speaker’s voice using just a few seconds of recording while maintaining a high level of realism. Alongside its potential benefits, this powerful technology introduces notable risks, including voice fraud and speaker impersonation. Unlike the conventional approach of solely relying on passive methods for detecting synthetic data, watermarking presents a proactive and robust defence mechanism against these looming risks. This paper introduces an innovative audio watermarking framework that encodes up to 32 bits of watermark within a mere 1-second audio snippet. The watermark is imperceptible to human senses and exhibits strong resilience against various attacks. It can serve as an effective identifier for synthesized voices and holds potential for broader applications in audio copyright protection. Moreover, this framework boasts high flexibility, allowing for the combination of multiple watermark segments to achieve heightened robustness and expanded capacity. Utilizing 10 to 20-second audio as the host, our approach demonstrates an average Bit Error Rate (BER) of 0.48% across ten common attacks, a remarkable reduction of over 2800% in BER compared to the state-of-the-art watermarking tool. See https://aka.ms/wavmark for demos of our work.																																	2024-05-25	PPRN:83522986		
J	Adamo, Angela; Bradley, Larry D.; Vanzella, Eros; Claeyssens, Adelaide; Welch, Brian; Diego, Jose M; Mahler, Guillaume; Oguri, Masamune; Sharon, Keren; Abdurro’uf; Hsiao, Tiger Yu-Yang; Messa, Matteo; Zackrisson, Erik; Brammer, Gabriel; Coe, Dan; Kokorev, Vasily; Ricotti, Massimo; Zitrin, Adi; Fujimoto, Seiji; Inoue, Akio K.; Resseguier, Tom; Rigby, Jane R.; Jimenez-Teja, Yolanda; Windhorst, Rogier A.; Xu, Xinfeng				Rigby, Jane/D-4588-2012; Zitrin, Adi/M-3402-2018; Messa, Matteo/P-2933-2017; Brammer, Gabriel/AAB-4859-2020; Oguri, Masamune/C-6230-2011; Diego, Jose/I-2511-2015; Jimenez-Teja, Yolanda/D-5933-2011; Kokorev, Vasily/GPK-2541-2022; Ricotti, Massimo/LXA-2067-2024						The discovery of bound star clusters 460 Myr after the Big Bang								Arxiv											1	1;2024-01-06;https://www.arxiv.org/abs/2401.03224v1	arXiv:2401.03224			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 06 2024	2024	Young galaxies, potentially responsible for the last major phase-transition of the Universe, appear brighter than expected [1–3] and go through rapid bursty phases where copious amounts of ionizing radiation and feedback are produced [4, 5]. However, the stellar components of the majority of these reionization–era galaxies remain spatially unresolved. In this letter, we report the direct discovery of young massive star clusters in the strongly lensed galaxy SPT0615-JD1 (dubbed the Cosmic Gems arc) at redshift z ∼ 10.2−0.2+0.2 when the universe was ∼ 460 Myr old. Recently observed with JWST/NIRCam imaging, the Cosmic Gems arc stretches over 5″(Bradley in prep.) revealing 5 individual massive young star clusters with lensing-corrected sizes of ∼1 pc, located in a region smaller than 70 pc. These Cosmic Gems produce ∼ 60 % of the FUV light of the host, and have very low dust attenuation (AV <0.5 mag) and metallicity (∼ 5% solar), intrinsic masses of ∼ 106 M⊙ and ages younger than 35 Myr. Their stellar surface densities are around 105 M⊙ /pc2, three orders of magnitude higher than typical star clusters in the local universe[6]. Despite the uncertainties inherent to the lensing model, their dynamical ages are consistent with being gravitationally bound stellar systems that could potentially evolve into globular clusters. They would be the earliest known proto-globular clusters, formed less than 500 Myr after the Big Bang. This discovery opens a new window into the physical processes that take place in reionization-era bursty galaxies, showing that star cluster formation and clustered stellar feedback might play an important role for reionization.																																	2024-01-25	PPRN:87070549		
J	Zhang, Zilun; Zhao, Tiancheng; Guo, Yulong; Yin, Jianwei				Guo, Yulong/AFD-6338-2022; Zhang, Zilun/LTZ-4088-2024						RS5M and GeoRSCLIP: A Large Scale Vision-Language Dataset and A Large Vision-Language Model for Remote Sensing								Arxiv											4	4;2024-01-02;https://www.arxiv.org/abs/2306.11300v5| 3;2023-12-05;https://www.arxiv.org/abs/2306.11300v4| 2;2023-08-31;https://www.arxiv.org/abs/2306.11300v2| 1;2023-06-20;https://www.arxiv.org/abs/2306.11300v1	arXiv:2306.11300			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jan 02 2024	2024	Pre-trained Vision-Language Models (VLMs) utilizing extensive image-text paired data have demonstrated unprecedented image-text association capabilities, achieving remarkable results across various downstream tasks. A critical challenge is how to make use of existing large-scale pre-trained VLMs, which are trained on common objects, to perform the domain-specific transfer for accomplishing domain-related downstream tasks. A critical challenge is how to make use of existing large-scale pre-trained VLMs, which are trained on common objects, to perform the domain-specific transfer for accomplishing domain-related downstream tasks. In this paper, we propose a new framework that includes the Domain pre-trained Vision-Language Model (DVLM), bridging the gap between the General Vision-Language Model (GVLM) and domain-specific downstream tasks. Moreover, we present an image-text paired dataset in the field of remote sensing (RS), RS5M, which has 5 million RS images with English descriptions. The dataset is obtained from filtering publicly available image-text paired datasets and captioning label-only RS datasets with pre-trained VLM. These constitute the first large-scale RS image-text paired dataset. Additionally, we fine-tuned the CLIP model and tried several Parameter-Efficient Fine-Tuning methods on RS5M to implement the DVLM. Experimental results show that our proposed dataset is highly effective for various tasks, and our model GeoRSCLIP improves upon the baseline or previous state-of-the-art model by $3%sim20%$ in Zero-shot Classification (ZSC), $3%sim6%$ in Remote Sensing Cross-Modal Text-Image Retrieval (RSCTIR) and $4%sim5%$ in Semantic Localization (SeLo) tasks. 																																	2024-01-10	PPRN:73442809		
J	Zhou, Yucheng; Rao, Zhi; Wan, Jun; Shen, Jianbing				Shen, Jianbing/KPB-2753-2024						Rethinking Visual Dependency in Long-Context Reasoning for Large Vision-Language Models								Arxiv											2	2;2024-12-20;https://www.arxiv.org/abs/2410.19732v2| 1;2024-10-25;https://www.arxiv.org/abs/2410.19732v1	arXiv:2410.19732			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 20 2024	2024	Large Vision-Language Models (LVLMs) excel in cross-model tasks but experience performance declines in long-context reasoning due to overreliance on textual information and reduced visual dependency. In this study, we empirically analyze LVLMs in long-context reasoning, revealing that increased context length leads to a higher dependence on language at the expense of visual dependency. To address this issue, we propose a novel training-free context pruning method that selectively removes less critical textual information. Our approach enhances visual dependency and reduces textual noise, thereby improving LVLM performance in long-context reasoning. We validate our method by constructing a long-context dataset, demonstrating its effectiveness across various LVLMs. Moreover, we compare our method with token-pruning methods, demonstrating superior performance, and further analysis confirms the robustness of our method.																																	2025-01-29	PPRN:118868027		
J	Wang, Peng; Li, Zexi; Zhang, Ningyu; Xu, Ziwen; Yao, Yunzhi; Jiang, Yong; Xie, Pengjun; Huang, Fei; Chen, Huajun				Li, Zexi/GYQ-5430-2022; Huajun, Chen/B-6340-2013						WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of Large Language Models								Arxiv											2	2;2024-12-19;https://www.arxiv.org/abs/2405.14768v3| 1;2024-05-23;https://www.arxiv.org/abs/2405.14768v1	arXiv:2405.14768			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 19 2024	2024	Large language models (LLMs) need knowledge updates to meet the ever-growing world facts and correct the hallucinated responses, facilitating the methods of lifelong model editing. Where the updated knowledge resides in memories is a fundamental question for model editing. In this paper, we find that editing either long-term memory (direct model parameters) or working memory (non- parametric knowledge of neural network activations/representations by retrieval) will result in an impossible triangle—reliability, generalization, and locality can not be realized together in the lifelong editing settings. For long-term memory, directly editing the parameters will cause conflicts with irrelevant pretrained knowledge or previous edits (poor reliability and locality). For working memory, retrieval-based activations can hardly make the model understand the edits and generalize (poor generalization). Therefore, we propose WISE to bridge the gap between memories. In WISE, we design a dual parametric memory scheme, which consists of the main memory for the pretrained knowledge and a side memory for the edited knowledge. We only edit the knowledge in the side memory and train a router to decide which memory to go through when given a query. For continual editing, we devise a knowledge-sharding mechanism where different sets of edits reside in distinct subspaces of parameters and are subsequently merged into a shared memory without conflicts. Extensive experiments show that WISE can outperform previous model editing methods and overcome the impossible triangle under lifelong model editing of question answering, hallucination, and out-of-distribution settings across trending LLM architectures, e.g., GPT, LLaMA, and Mistral.																																	2025-01-28	PPRN:88990179		
J	Liu, Jiaming; Liu, Mengzhen; Wang, Zhenyu; An, Pengju; Li, Xiaoqi; Zhou, Kaichen; Yang, Senqiao; Zhang, Renrui; Guo, Yandong; Zhang, Shanghang				Zhang, Qian/LKK-3896-2024; Zhang, Zhuosheng/AAF-4919-2020; liu, jiaming/KVA-6603-2024; 刘, 梦真/GSN-5974-2022						RoboMamba: Efficient Vision-Language-Action Model for Robotic Reasoning and Manipulation								Arxiv											1	1;2024-12-14;https://www.arxiv.org/abs/2406.04339v2	arXiv:2406.04339			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 14 2024	2024	A fundamental objective in robot manipulation is to enable models to comprehend visual scenes and execute actions. Although existing Vision-Language-Action (VLA) models for robots can handle a range of basic tasks, they still face challenges in two areas: (1) insufficient reasoning ability to tackle complex tasks, and (2) high computational costs for VLA model fine-tuning and inference. The recently proposed state space model (SSM) known as Mamba demonstrates promising capabilities in non-trivial sequence modeling with linear inference complexity. Inspired by this, we introduce RoboMamba, an end-to-end robotic VLA model that leverages Mamba to deliver both robotic reasoning and action capabilities, while maintaining efficient fine-tuning and inference. Specifically, we first integrate the vision encoder with Mamba, aligning visual tokens with language embedding through co-training, empowering our model with visual common sense and robotic-related reasoning. To further equip RoboMamba with SE(3) pose prediction abilities, we explore an efficient fine-tuning strategy with a simple policy head. We find that once RoboMamba possesses sufficient reasoning capability, it can acquire manipulation skills with minimal fine-tuning parameters (0.1% of the model) and time. In experiments, RoboMamba demonstrates outstanding reasoning capabilities on general and robotic evaluation benchmarks. Meanwhile, our model showcases impressive pose prediction results in both simulation and real-world experiments, achieving inference speeds 3 times faster than existing VLA models. 																																	2025-01-24	PPRN:119967260		
J	Bresson, Roman; Nikolentzos, Giannis; Panagopoulos, George; Chatzianastasis, Michail; Pang, Jun; Vazirgiannis, Michalis				Nikolentzos, Giannis/AAI-2667-2020; Pang, Jian/E-7435-2013						KAGNNs: Kolmogorov-Arnold Networks meet Graph Learning								Arxiv											3	3;2024-12-13;https://www.arxiv.org/abs/2406.18380v3| 2;2024-07-01;https://www.arxiv.org/abs/2406.18380v2| 1;2024-06-26;https://www.arxiv.org/abs/2406.18380v1	arXiv:2406.18380			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 13 2024	2024	In recent years, Graph Neural Networks (GNNs) have become the de facto tool for learning node and graph representations. Most GNNs typically consist of a sequence of neighborhood aggregation (a.k.a., message- passing) layers, within which the representation of each node is updated based on those of its neighbors. The most expressive message-passing GNNs can be obtained through the use of the sum aggregator and of MLPs for feature transformation, thanks to their universal approximation capabilities. However, the limitations of MLPs recently motivated the introduction of another family of universal approximators, called KolmogorovArnold Networks (KANs) which rely on a different representation theorem. In this work, we compare the performance of KANs against that of MLPs on graph learning tasks. We evaluate two different implementations of KANs using two distinct base families of functions, namely B-splines and radial basis functions. We perform extensive experiments on node classification, graph classification and graph regression datasets. Our results indicate that KANs are on-par with or better than MLPs on all studied tasks, making them viable alternatives, at the cost of some computational complexity. All code will be made available upon acceptance.																																	2025-01-21	PPRN:89872573		
J	Jiang, Jun-Qian; Pedrotti, Davide; da Costa, Simony Santos; Vagnozzi, Sunny				Santos-da-Costa, Simony/KIH-7605-2024; Vagnozzi, Sunny/W-7331-2019						Nonparametric late-time expansion history reconstruction and implications for the Hubble tension in light of recent DESI and type Ia supernovae data								Arxiv											4	4;2024-12-11;https://www.arxiv.org/abs/2408.02365v3| 3;2024-11-18;https://www.arxiv.org/abs/2408.02365v2| 2;2024-08-05;https://www.arxiv.org/abs/2408.02365v1| 1;2024-08-05;https://www.arxiv.org/abs/2408.02365v1	arXiv:2408.02365			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 11 2024	2024	We nonparametrically reconstruct the late-time expansion history in light of the latest Baryon Acoustic Oscillation (BAO) measurements from DESI combined with various Type Ia Supernovae (SNeIa) catalogs, using interpolation through piece-wise natural cubic splines, and a reconstruction procedure based on Gaussian Processes (GPs). Applied to DESI BAO and PantheonPlus SNeIa data, both methods indicate that deviations from a reference ΛCDM model in the z ≲ 2 unnormalized expansion rate E(z) are constrained to be < 10%, but also consistently identify two features in E(z): a bump at z ∼ 0.5, and a depression at z ∼ 0.9, which cannot be simultaneously captured by a w0wa CDM fit. These features, which are stable against assumptions regarding spatial curvature, interpolation knots, and GP kernel, disappear if one adopts the older SDSS BAO measurements in place of DESI, and decrease in significance when replacing the PantheonPlus catalog with the Union3 and DESY5 ones. We infer c/(rdH0) = 29.90±0.33, with rd the sound horizon at baryon drag and H0 the Hubble constant. Breaking the rd-H0 degeneracy with the SH0ES prior on H0 , the significance of the tension between our nonparametric determination of rd = 136.20−2.40+2.20Mpc and the Planck ΛCDM-based determination is at the 5 a- level, slightly lower than the 6 a- obtained when adopting the older SDSS dataset in place of DESI. This indicates the persistence at very high significance of the “sound horizon tension”, reinforcing the need for pre-recombination new physics. If substantiated in forthcoming data releases, our results tentatively point to oscillatory/nonmonotonic features in the shape of the expansion rate at z ≲ 2, of potential interest for dark energy model-building.																																	2025-01-19	PPRN:91246455		
J	Li, Zihao; Shi, Yucheng; Liu, Zirui; Yang, Fan; Payani, Ali; Liu, Ninghao; Du, Mengnan				Shi, Yucheng/AAT-4428-2021; liu, zirui/HNK-6782-2023; Yang, Fan/LGY-6359-2024; Du, Mengnan/MXL-9283-2025						Language Ranker: A Metric for Quantifying LLM Performance Across High and Low-Resource Languages								Arxiv											3	3;2024-12-11;https://www.arxiv.org/abs/2404.11553v3| 2;2024-06-16;https://www.arxiv.org/abs/2404.11553v2| 1;2024-04-17;https://www.arxiv.org/abs/2404.11553v1	arXiv:2404.11553			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 11 2024	2024	The development of Large Language Models (LLMs) relies on extensive text corpora, which are often unevenly distributed across languages. This imbalance results in LLMs performing significantly better on high-resource languages like English, German, and French, while their capabilities in low-resource languages remain inadequate. Currently, there is a lack of quantitative methods to evaluate the performance of LLMs in these low-resource languages. To address this gap, we propose the Language Ranker, an intrinsic metric designed to benchmark and rank languages based on LLM performance using internal representations. By comparing the LLM’s internal representation of various languages against a baseline derived from English, we can assess the model’s multilingual capabilities in a robust and language- agnostic manner. Our analysis reveals that high-resource languages exhibit higher similarity scores with English, demonstrating superior performance, while low-resource languages show lower similarity scores, underscoring the effectiveness of our metric in assessing language-specific capabilities. Besides, the experiments show that there is a strong correlation between the LLM’s performance in different languages and the proportion of those languages in its pre-training corpus. These insights underscore the efficacy of the Language Ranker as a tool for evaluating LLM performance across different languages, particularly those with limited resources.																																	2025-01-19	PPRN:88557951		
J	Bar, Amir; Zhou, Gaoyue; Tran, Danny; Darrell, Trevor; Lecun, Yann				Bar, Amir/AGB-8963-2022						Navigation World Models								Arxiv											1	1;2024-12-04;https://www.arxiv.org/abs/2412.03572v1	arXiv:2412.03572			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 04 2024	2024	Navigation is a fundamental skill of agents with visual-motor capabilities. We introduce a Navigation World Model (NWM), a controllable video generation model that predicts future visual observations based on past observations and navigation actions. To capture complex environment dynamics, NWM employs a Conditional Diffusion Transformer (CDiT), trained on a diverse collection of egocentric videos of both human and robotic agents, and scaled up to 1 billion parameters. In familiar environments, NWM can plan navigation trajectories by simulating them and evaluating whether they achieve the desired goal. Unlike supervised navigation policies with fixed behavior, NWM can dynamically incorporate constraints during planning. Experiments demonstrate its effectiveness in planning trajectories from scratch or by ranking trajectories sampled from an external policy. Furthermore, NWM leverages its learned visual priors to imagine trajectories in unfamiliar environments from a single input image, making it a flexible and powerful tool for next-generation navigation systems.																																	2025-01-15	PPRN:119698336		
J	Mou, Xinyi; Ding, Xuanwen; He, Qi; Wang, Liang; Liang, Jingcong; Zhang, Xinnong; Sun, Libo; Lin, Jiayu; Zhou, Jie; Huang, Xuanjing; Wei, Zhongyu				Wei, Zhongyu/KSL-9373-2024; Ding, Xuanwen/MFK-0468-2025; Mou, Xinyi/KPA-9492-2024						From Individual to Society: A Survey on Social Simulation Driven by Large Language Model-based Agents								Arxiv											1	1;2024-12-04;https://www.arxiv.org/abs/2412.03563v1	arXiv:2412.03563			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 04 2024	2024	Traditional sociological research often relies on human participation, which, though effective, is expensive, challenging to scale, and with ethical concerns. Recent advancements in large language models (LLMs) highlight their potential to simulate human behavior, enabling the replication of individual responses and facilitating studies on many interdisciplinary studies. In this paper, we conduct a comprehensive survey of this field, illustrating the recent progress in simulation driven by LLM-empowered agents. We categorize the simulations into three types: (1) Individual Simulation, which mimics specific individuals or demographic groups; (2) Scenario Simulation, where multiple agents collaborate to achieve goals within specific contexts; and (3) Society Simulation, which models interactions within agent societies to reflect the complexity and variety of real-world dynamics. These simulations follow a progression, ranging from detailed individual modeling to large-scale societal phenomena. We provide a detailed discussion of each simulation type, including the architecture or key components of the simulation, the classification of objectives or scenarios and the evaluation method. Afterward, we summarize commonly used datasets and benchmarks. Finally, we discuss the trends across these three types of simulation. 																																	2025-01-15	PPRN:119698539		
J	Yang, Cheng-Yen; Huang, Hsiang-Wei; Chai, Wenhao; Jiang, Zhongyu; Hwang, Jenq-Neng				Chai, Wenhao/LIG-6923-2024						SAMURAI: Adapting Segment Anything Model for Zero-Shot Visual Tracking with Motion-Aware Memory								Arxiv											2	2;2024-11-30;https://www.arxiv.org/abs/2411.11922v2| 1;2024-11-18;https://www.arxiv.org/abs/2411.11922v1	arXiv:2411.11922			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 30 2024	2024	The Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks but faces challenges in visual object tracking, particularly when managing crowded scenes with fast-moving or self-occluding objects. Furthermore, the fixed-window memory approach in the original model does not consider the quality of memories selected to condition the image features for the next frame, leading to error propagation in videos. This paper introduces SAMURAI, an enhanced adaptation of SAM 2 specifically designed for visual object tracking. By incorporating temporal motion cues with the proposed motion- aware memory selection mechanism, SAMURAI effectively predicts object motion and refines mask selection, achieving robust, accurate tracking without the need for retraining or fine-tuning. SAMURAI operates in real-time and demonstrates strong zero-shot performance across diverse benchmark datasets, showcasing its ability to generalize without fine-tuning. In evaluations, SAMURAI achieves significant improvements in success rate and precision over existing trackers, with a 7.1% AUC gain on LaSOText and a 3.5% AO gain on GOT-10k. Moreover, it achieves competitive results compared to fully supervised methods on La- SOT, underscoring its robustness in complex tracking scenarios and its potential for real-world applications in dynamic environments.																																	2025-01-11	PPRN:119280261		
J	Yu, Wangbo; Feng, Chaoran; Tang, Jiye; Yang, Jiashu; Jia, Xu; Yang, Yuchao; Yuan, Li; Tian, Yonghong				Feng, Chaoran/ONJ-4763-2025; Yang, Jiashu/LSL-5358-2024; Tang, Jiye/LRS-8284-2024; TIAN, Yonghong/M-4937-2013						EvaGaussians: Event Stream Assisted Gaussian Splatting from Blurry Images								Arxiv											2	2;2024-11-26;https://www.arxiv.org/abs/2405.20224v2| 1;2024-05-29;https://www.arxiv.org/abs/2405.20224v1	arXiv:2405.20224			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 26 2024	2024	3D Gaussian Splatting (3D-GS) has demonstrated exceptional capabilities in synthesizing novel views of 3D scenes. However, its training is heavily reliant on high-quality images and precise camera poses. Meeting these criteria can be challenging in non-ideal real-world conditions, where motion-blurred images frequently occur due to high-speed camera movements or low-light environments. To address these challenges, we introduce Event Stream Assisted Gaussian Splatting (EvaGaussians), a novel approach that harnesses event streams captured by event cameras to facilitate the learning of high-quality 3D-GS from blurred images. Capitalizing on the high temporal resolution and dynamic range offered by event streams, we seamlessly integrate them into the initialization and optimization of 3D- GS, thereby enhancing the acquisition of high-fidelity novel views with intricate texture details. To remedy the absence of evaluation benchmarks incorporating both event streams and RGB frames, we present two novel datasets comprising RGB frames, event streams, and corresponding camera parameters, featuring a wide variety of scenes and various camera motions. We then conduct a thorough evaluation of our method, comparing it with leading techniques on the provided benchmark. The comparison results reveal that our approach not only excels in generating high-fidelity novel views, but also offers faster training and inference speeds. Video results are available at the project page.																																	2025-01-08	PPRN:89113607		
J	Reichardt, Ben W.; Paetznick, Adam; Aasen, David; Basov, Ivan; Bello-Rivas, Juan M.; Bonderson, Parsa; Chao, Rui; Dam, Wim van; Hastings, Matthew B.; Paz, Andres; da Silva, Marcus P.; Sundaram, Aarthi; Svore, Krysta M.; Vaschillo, Alexander; Wang, Zhenghan; Zanner, Matt; Cairncross, William B.; Chen, Cheng-An; Crow, Daniel; Kim, Hyosub; Kindem, Jonathan M.; King, Jonathan; Mcdonald, Michael; Norcia, Matthew A.; Ryou, Albert; Stone, Mark; Wadleigh, Laura; Barnes, Katrina; Battaglino, Peter; Bohdanowicz, Thomas C.; Booth, Graham; Brown, Andrew; Brown, Mark O.; Cassella, Kayleigh; Coxe, Robin; Epstein, Jeffrey M.; Feldkamp, Max; Griger, Christopher; Halperin, Eli; Heinz, Andre; Hummel, Frederic; Jaffe, Matthew; Jones, Antonia M.W.; Kapit, Eliot; Kotru, Krish; Lauigan, Joseph; Li, Ming; Marjanovic, Jan; Megidish, Eli; Meredith, Matthew; Morshead, Ryan; Muniz, Juan A.; Narayanaswami, Sandeep; Nishiguchi, Ciro; Paule, Timothy; Pawlak, Kelly A.; Pudenz, Kristen L.; Perez, David Rodriguez; Simon, Jon; Smull, Aaron; Stack, Daniel; Urbanek, Miroslav; van de Veerdonk, Rene J.M.; Vendeiro, Zachary; Weverka, Robert T.; Wilkason, Thomas; Wu, Tsung-Yao; Xie, Xin; Zalys-Geller, Evan; Zhang, Xiaogang; Bloom, Benjamin J.				Meredith, Matthew/AAL-1331-2020; Paz, Andrés/GQH-9815-2022; xiaogang, Zhang/K-3338-2019; Sivasankaran, Aarthi/OXB-5012-2025; Chao, Rui/ABC-9051-2020; Bloom, Benjamin/J-4799-2012; Basov, Ivan/JWA-1915-2024						Logical computation demonstrated with a neutral atom quantum processor								Arxiv											1	1;2024-11-19;https://www.arxiv.org/abs/2411.11822v2	arXiv:2411.11822			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 19 2024	2024	Transitioning from quantum computation on physical qubits to quantum computation on encoded, logical qubits can improve the error rate of operations, and will be essential for realizing valuable quantum computational advantages. Using a neutral atom quantum processor with 256 qubits, each an individual Ytterbium atom, we demonstrate the entanglement of 24 logical qubits using the distance-two [[4,2,2]] code, simultaneously detecting errors and correcting for lost qubits. We also implement the Bernstein-Vazirani algorithm with up to 28 logical qubits encoded in the [[4,1,2]] code, showing better-than-physical error rates. We demonstrate fault-tolerant quantum computation in our approach, guided by the proposal of Gottesman (2016), by performing repeated loss correction for both structured and random circuits encoded in the [[4,2,2]] code. Finally, since distance-two codes can correct qubit loss, but not other errors, we show repeated loss and error correction using the distance-three [[9,1,3]] Bacon-Shor code. These results begin to clear a path for achieving scientific quantum advantage with a programmable neutral atom quantum processor.																																	2025-01-24	PPRN:119274867		
J	Mysore, Sheshera; Lu, Zhuoran; Wan, Mengting; Yang, Longqi; Sarrafzadeh, Bahareh; Menezes, Steve; Baghaee, Tina; Gonzalez, Emmanuel Barajas; Neville, Jennifer; Safavi, Tara				Lu, Zhuoran/MBV-3199-2025						Pearl: Personalizing Large Language Model Writing Assistants with Generation-Calibrated Retrievers								Arxiv											2	2;2024-11-05;https://www.arxiv.org/abs/2311.09180v2| 1;2023-11-15;https://www.arxiv.org/abs/2311.09180v1	arXiv:2311.09180			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Nov 05 2024	2024	Powerful large language models have facilitated the development of writing assistants that promise to significantly improve the quality and efficiency of composition and communication. However, a barrier to effective assistance is the lack of personalization in LLM outputs to the author’s communication style, specialized knowledge, and values. In this paper, we address this challenge by proposing P EARL , a LLM writing assistant personalized with a retriever that is trained to be generationcalibrated for personalization. Generation calibration ensures that our retriever selects historic user authored documents to augment an LLM prompt such that they are likely to help an LLM generation better adhere to a users’ preferences. We propose two key novelties for training such a retriever: (1) A training data selection method that identifies historical user requests likely to benefit from personalization and documents that provide that benefit; and (2) A scale-calibrating KL-divergence objective that ensures that our retriever scores remain proportional to the downstream generation quality from using the document for personalized generation. In a series of holistic evaluations, we demonstrate the effectiveness of P EARL in generating long-form texts on multiple social media datasets. Finally, we demonstrate how a generation-calibrated retriever can double as a performance predictor – detecting low quality retrieval, and improving potentially underperforming outputs via revision with LLMs.																																	2024-12-09	PPRN:86159402		
J	Fang, Wenji; Li, Mengming; Li, Min; Yan, Zhiyuan; Liu, Shang; Zhang, Hongce; Xie, Zhiyao				Fang, Wenji/OBO-7903-2025; Zhang, Hongce/ACK-0829-2022; Li, Min/U-7023-2019; Shi, Jiangli/AAO-6359-2020						AssertLLM: Generating and Evaluating Hardware Verification Assertions from Design Specifications via Multi-LLMs								Arxiv											3	3;2024-11-04;https://www.arxiv.org/abs/2402.00386v3| 2;2024-10-23;https://www.arxiv.org/abs/2402.00386v2| 1;2024-02-01;https://www.arxiv.org/abs/2402.00386v1	arXiv:2402.00386			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Nov 04 2024	2024	Assertion-based verification (ABV) is a critical method for ensuring design circuits comply with their architectural specifications, which are typically described in natural language. This process often requires human interpretation by verification engineers to convert these specifications into functional verification assertions. Existing methods for generating assertions from natural language specifications are limited to sentences extracted by engineers, discouraging its practical application. In this work, we present AssertLLM, an automatic assertion generation framework that processes complete specification files. AssertLLM breaks down the complex task into three phases, incorporating three customized Large Language Models (LLMs) for extracting structural specifications, mapping signal definitions, and generating assertions. Our evaluation of AssertLLM on a full design, encompassing 23 I/O signals, demonstrates that 89% of the generated assertions are both syntactically and functionally accurate.																																	2024-12-16	PPRN:87456534		
J	Sun, Hanshi; Haider, Momin; Zhang, Ruiqi; Yang, Huitao; Qiu, Jiahao; Yin, Ming; Wang, Mengdi; Bartlett, Peter; Zanette, Andrea				Sun, Hanshi/OEO-7890-2025; Zhang, Ruiqi/JRY-0376-2023						Fast Best-of-N Decoding via Speculative Rejection								Arxiv											2	2;2024-10-31;https://www.arxiv.org/abs/2410.20290v2| 1;2024-10-26;https://www.arxiv.org/abs/2410.20290v1	arXiv:2410.20290			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 31 2024	2024	The safe and effective deployment of Large Language Models (LLMs) involves a critical step called alignment, which ensures that the model's responses are in accordance with human preferences. Prevalent alignment techniques, such as DPO, PPO and their variants, align LLMs by changing the pre-trained model weights during a phase called post-training. While predominant, these post-training methods add substantial complexity before LLMs can be deployed. Inference-time alignment methods avoid the complex post-training step and instead bias the generation towards responses that are aligned with human preferences. The best-known inference-time alignment method, called Best-of-N, is as effective as the state-of-the-art post-training procedures. Unfortunately, Best-of-N requires vastly more resources at inference time than standard decoding strategies, which makes it computationally not viable. In this work, we introduce Speculative Rejection, a computationally-viable inference-time alignment algorithm. It generates high-scoring responses according to a given reward model, like Best-of-N does, while being between 16 to 32 times more computationally efficient.																																	2024-12-11	PPRN:118966885		
J	Ye, Botao; Liu, Sifei; Xu, Haofei; Li, Xueting; Pollefeys, Marc; Yang, Ming-Hsuan; Peng, Songyou				Yang, Ming-Hsuan/T-9533-2019; Liu, Sifei/AGE-1968-2022						No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images								Arxiv											1	1;2024-10-31;https://www.arxiv.org/abs/2410.24207v1	arXiv:2410.24207			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 31 2024	2024	We introduce NoPoSplat, a feed-forward model capable of reconstructing 3D scenes parameterized by 3D Gaussians from textit{unposed} sparse multi-view images. Our model, trained exclusively with photometric loss, achieves real-time 3D Gaussian reconstruction during inference. To eliminate the need for accurate pose input during reconstruction, we anchor one input view's local camera coordinates as the canonical space and train the network to predict Gaussian primitives for all views within this space. This approach obviates the need to transform Gaussian primitives from local coordinates into a global coordinate system, thus avoiding errors associated with per-frame Gaussians and pose estimation. To resolve scale ambiguity, we design and compare various intrinsic embedding methods, ultimately opting to convert camera intrinsics into a token embedding and concatenate it with image tokens as input to the model, enabling accurate scene scale prediction. We utilize the reconstructed 3D Gaussians for novel view synthesis and pose estimation tasks and propose a two-stage coarse-to-fine pipeline for accurate pose estimation. Experimental results demonstrate that our pose-free approach can achieve superior novel view synthesis quality compared to pose-required methods, particularly in scenarios with limited input image overlap. For pose estimation, our method, trained without ground truth depth or explicit matching loss, significantly outperforms the state-of-the-art methods with substantial improvements. This work makes significant advances in pose-free generalizable 3D reconstruction and demonstrates its applicability to real-world scenarios. 																																	2024-12-11	PPRN:119043125		
J	Liu, Ziyu; Chu, Tao; Zang, Yuhang; Wei, Xilin; Dong, Xiaoyi; Zhang, Pan; Liang, Zijian; Xiong, Yuanjun; Qiao, Yu; Lin, Dahua; Wang, Jiaqi				Dong, Xiaoyi/AAC-8666-2019; Zang, Yuhang/AES-3018-2022; WANG, JIAQI/KBB-8837-2024; Liang, Zijian/JCP-1021-2023; Lin, Dahua/W-6576-2019; Xiong, Yuanjun/JPX-0310-2023						MMDU: A Multi-Turn Multi-Image Dialog Understanding Benchmark and Instruction-Tuning Dataset for LVLMs								Arxiv											2	2;2024-10-29;https://www.arxiv.org/abs/2406.11833v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11833v1	arXiv:2406.11833			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 29 2024	2024	Generating natural and meaningful responses to communicate with multi-modal human inputs is a fundamental capability of Large Vision-Language Models (LVLMs). While current open-source LVLMs demonstrate promising performance in simplified scenarios such as single-turn single-image input, they fall short in real-world conversation scenarios such as following instructions in a long context history with multi-turn and multi-images. Existing LVLM benchmarks primarily focus on single-choice questions or short-form responses, which do not adequately assess the capabilities of LVLMs in real-world human-AI interaction applications. Therefore, we introduce MMDU, a comprehensive benchmark, and MMDU-45k, a large-scale instruction tuning dataset, designed to evaluate and improve LVLMs’ abilities in multi-turn and multi-image conversations. We employ the clustering algorithm to find the relevant images and textual descriptions from the open-source Wikipedia and construct the question-answer pairs by human annotators with the assistance of the GPT-4o model. MMDU has a maximum of 18k image+text tokens, 20 images, and 27 turns, which is at least 5× longer than previous benchmarks and poses challenges to current LVLMs. Our in-depth analysis of 15 representative LVLMs using MMDU reveals that open-source LVLMs lag behind closed-source counterparts due to limited conversational instruction tuning data. We demonstrate that fine-tuning open-source LVLMs on MMDU-45k significantly addresses this gap, generating longer and more accurate conversations, and improving scores on MMDU and existing benchmarks (MMStar: +1.1%, MathVista: +1.5%, ChartQA: +1.2%). Our contributions pave the way for bridging the gap between current LVLM models and real-world application demands. 																																	2024-11-30	PPRN:89348676		
J	Wang, Zengzhi; Li, Xuefeng; Xia, Rui; Liu, Pengfei										MathPile: A Billion-Token-Scale Pretraining Corpus for Math								Arxiv											2	2;2024-10-29;https://www.arxiv.org/abs/2312.17120v2| 1;2023-12-28;https://www.arxiv.org/abs/2312.17120v1	arXiv:2312.17120			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 29 2024	2024	High-quality, large-scale corpora are the cornerstone of building foundation models. In this work, we introduce MathPile, a diverse and high-quality math-centric corpus comprising about 9.5 billion tokens. Throughout its creation, we adhered to the principle of "less is more", firmly believing in the supremacy of data quality over quantity, even in the pre-training phase. Our meticulous data collection and processing efforts included a complex suite of preprocessing, prefiltering, language identification, cleaning, filtering, and deduplication, ensuring the high quality of our corpus. Furthermore, we performed data contamination detection on downstream benchmark test sets to eliminate duplicates and conducted continual pre-training experiments, booting the performance on common mathematical reasoning benchmarks. We aim for our MathPile to boost language models' mathematical reasoning abilities and open-source its different versions and processing scripts to advance the field.																																	2024-12-09	PPRN:86852278		
J	Zhang, Yushun; Chen, Congliang; Ding, Tian; Li, Ziniu; Sun, Ruoyu; Luo, Zhi-Quan				Sun, Ruoyu/ITV-0426-2023						Why Transformers Need Adam: A Hessian Perspective								Arxiv											3	3;2024-10-21;https://www.arxiv.org/abs/2402.16788v4| 2;2024-06-24;https://www.arxiv.org/abs/2402.16788v3| 1;2024-05-27;https://www.arxiv.org/abs/2402.16788v2	arXiv:2402.16788			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 21 2024	2024	SGD performs worse than Adam by a significant margin on Transformers, but the reason remains unclear. In this work, we provide an explanation through the lens of Hessian: (i) Transformers are "heterogeneous": the Hessian spectrum across parameter blocks vary dramatically, a phenomenon we call "block heterogeneity"; (ii) Heterogeneity hampers SGD: SGD performs worse than Adam on problems with block heterogeneity. To validate (i) and (ii), we check various Transformers, CNNs, MLPs, and quadratic problems, and find that SGD can perform on par with Adam on problems without block heterogeneity, but performs worse than Adam when the heterogeneity exists. Our initial theoretical analysis indicates that SGD performs worse because it applies one single learning rate to all blocks, which cannot handle the heterogeneity among blocks. This limitation could be ameliorated if we use coordinate-wise learning rates, as designed in Adam.1																																	2024-11-20	PPRN:89060848		
J	Yang, Jingkang; Dong, Yuhao; Liu, Shuai; Li, Bo; Wang, Ziyue; Jiang, Chencheng; Tan, Haoran; Kang, Jiamu; Zhang, Yuanhan; Zhou, Kaiyang; Liu, Ziwei				wang, ziyue/IQT-0730-2023; Liu, Ziwei/AAG-6939-2021; Yang, Jingkang/HJZ-3689-2023; Liu, Shuaicheng/GLN-4107-2022; Zhou, Kaiyang/KTI-8952-2024						Octopus: Embodied Vision-Language Programmer from Environmental Feedback								Arxiv											2	2;2024-10-20;https://www.arxiv.org/abs/2310.08588v2| 1;2023-10-12;https://www.arxiv.org/abs/2310.08588v1	arXiv:2310.08588			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 20 2024	2024	Large vision-language models (VLMs) have achieved substantial progress in multimodal perception and reasoning. When integrated into an embodied agent, existing embodied VLM works either output detailed action sequences at the manipulation level or only provide plans at an abstract level, leaving a gap between high-level planning and real-world manipulation. To bridge this gap, we introduce Octopus, an embodied vision-language programmer that uses executable code generation as a medium to connect planning and manipulation. Octopus is designed to 1) proficiently comprehend an agent's visual and textual task objectives, 2) formulate intricate action sequences, and 3) generate executable code. To facilitate Octopus model development, we introduce OctoVerse: a suite of environments tailored for benchmarking vision-based code generators on a wide spectrum of tasks, ranging from mundane daily chores in simulators to sophisticated interactions in complex video games such as Grand Theft Auto (GTA) and Minecraft. To train Octopus, we leverage GPT-4 to control an explorative agent that generates training data, i.e., action blueprints and corresponding executable code. We also collect feedback that enables an enhanced training scheme called Reinforcement Learning with Environmental Feedback (RLEF). Through a series of experiments, we demonstrate Octopus's functionality and present compelling results, showing that the proposed RLEF refines the agent's decision-making. By open-sourcing our simulation environments, dataset, and model architecture, we aspire to ignite further innovation and foster collaborative applications within the broader embodied AI community.																																	2024-11-20	PPRN:85604325		
J	He, Shwai; Sun, Guoheng; Shen, Zheyu; Li, Ang				Li, Ang/A-3122-2019						What Matters in Transformers? Not All Attention is Needed								Arxiv											2	2;2024-10-17;https://www.arxiv.org/abs/2406.15786v6| 1;2024-10-03;https://www.arxiv.org/abs/2406.15786v5	arXiv:2406.15786			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Oct 17 2024	2024	While scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks, it also introduces redundant architectures, posing efficiency challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy across different architectures in transformers, such as MLP and Attention layers, is under-explored. In this work, we investigate redundancy across different modules within Transformers, including Blocks, MLP, and Attention layers, using a similarity-based metric. Surprisingly, despite the critical role of attention layers in distinguishing transformers from other architectures, we found that a large portion of these layers exhibit excessively high similarity and can be pruned without degrading performance. For instance, Llama-2-70B achieved a 48.4% speedup with only a 2.4% performance drop by pruning half of the attention layers. Furthermore, by tracing model checkpoints throughout the training process, we observed that attention layer redundancy is inherent and consistent across training stages. Additionally, we further propose a method that jointly drops Attention and MLP layers, allowing us to more aggressively drop additional layers. For instance, when dropping 31 layers (Attention + MLP), Llama-2-13B still retains 90% of the performance on the MMLU task. Our work provides valuable insights for future network architecture design. 																																	2024-11-13	PPRN:102575880		
J	Lu, Zeyu; Wang, Zidong; Huang, Di; Wu, Chengyue; Liu, Xihui; Ouyang, Wanli; Bai, Lei				Huang, Di/NNG-7345-2025; Liu, Xihui/LHA-5141-2024; Ouyang, Wanli/I-7135-2018						FiT: Flexible Vision Transformer for Diffusion Model								Arxiv											3	3;2024-10-15;https://www.arxiv.org/abs/2402.12376v4| 2;2024-10-01;https://www.arxiv.org/abs/2402.12376v2| 1;2024-02-19;https://www.arxiv.org/abs/2402.12376v1	arXiv:2402.12376			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Oct 15 2024	2024	Nature is infinitely resolution-free. In the context of this reality, existing diffusion models, such as Diffusion Transformers, often face challenges when processing image resolutions outside of their trained domain. To overcome this limitation, we present the Flexible Vision Transformer (FiT), a transformer architecture specifically designed for generating images with unrestricted resolutions and aspect ratios. Unlike traditional methods that perceive images as static-resolution grids, FiT conceptualizes images as sequences of dynamically-sized tokens. This perspective enables a flexible training strategy that effortlessly adapts to diverse aspect ratios during both training and inference phases, thus promoting resolution generalization and eliminating biases induced by image cropping. Enhanced by a meticulously adjusted network structure and the integration of training-free extrapolation techniques, FiT exhibits remarkable flexibility in resolution extrapolation generation. Comprehensive experiments demonstrate the exceptional performance of FiT across a broad range of resolutions, showcasing its effectiveness both within and beyond its training resolution distribution. Repository available at https://github.com/whlzy/FiT.																																	2024-11-07	PPRN:87798556		
J	Opsahl-Ong, Krista; Ryan, Michael J; Purtell, Josh; Broman, David; Potts, Christopher; Zaharia, Matei; Khattab, Omar										Optimizing Instructions and Demonstrations for Multi-Stage Language Model Programs								Arxiv											2	2;2024-10-06;https://www.arxiv.org/abs/2406.11695v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11695v1	arXiv:2406.11695			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 06 2024	2024	Language Model Programs, i.e. sophisticated pipelines of modular language model (LM) calls, are increasingly advancing NLP tasks, but they require crafting prompts that are jointly effective for all modules. We study prompt optimization for LM programs, i.e. how to update these prompts to maximize a downstream metric without access to module-level labels or gradients. To make this tractable, we factorize our problem into optimizing the free-form instructions and few-shot demonstrations of every module and introduce several strategies to craft task-grounded instructions and navigate credit assignment across modules. Our strategies include (i) program- and data-aware techniques for proposing effective instructions, (ii) a stochastic mini-batch evaluation function for learning a surrogate model of our objective, and (iii) a meta-optimization procedure in which we refine how LMs construct proposals over time. Using these insights we develop MIPRO, a novel algorithm for optimizing LM programs. MIPRO outperforms baseline optimizers on five of seven diverse multi-stage LM programs using a best-in-class open-source model (Llama-3-8B), by as high as 13% accuracy. We have released our new optimizers and benchmark in DSPy at http://dspy.ai																																	2024-10-27	PPRN:89352715		
J	Deng, Tianchen; Chen, Yaohui; Zhang, Leyan; Yang, Jianfei; Yuan, Shenghai; Liu, Jiuming; Wang, Danwei; Wang, Hesheng; Chen, Weidong				Yuan, Shenghai/JDM-6241-2023; Weidong, Chen/GPC-8523-2022; Liu, Jiuming/LKL-2382-2024; Tang, Tang/KEI-2928-2024; Deng, Tianchen/KBB-4126-2024; Yang, Jianfei/P-4011-2017; Chen, Yaohui/OMK-5416-2025						Compact 3D Gaussian Splatting For Dense Visual SLAM								Arxiv											2	2;2024-09-27;https://www.arxiv.org/abs/2403.11247v2| 1;2024-03-17;https://www.arxiv.org/abs/2403.11247v1	arXiv:2403.11247			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 27 2024	2024	Recent work has shown that 3D Gaussian-based SLAM enables high-quality reconstruction, accurate pose estimation, and real-time rendering of scenes. However, these approaches are built on a tremendous number of redundant 3D Gaussian ellipsoids, leading to high memory and storage costs, and slow training speed. To address the limitation, we propose a compact 3D Gaussian Splatting SLAM system that reduces the number and the parameter size of Gaussian ellipsoids. A sliding window-based masking strategy is first proposed to reduce the redundant ellipsoids. Then we observe that the covariance matrix (geometry) of most 3D Gaussian ellipsoids are extremely similar, which motivates a novel geometry codebook to compress 3D Gaussian geometric attributes, i.e., the parameters. Robust and accurate pose estimation is achieved by a global bundle adjustment method with reprojection loss. Extensive experiments demonstrate that our method achieves faster training and rendering speed while maintaining the state-of-the-art (SOTA) quality of the scene representation.																																	2024-10-09	PPRN:88190910		
J	Zhou, Yujia; Liu, Yan; Li, Xiaoxi; Jin, Jiajie; Qian, Hongjin; Liu, Zheng; Li, Chaozhuo; Dou, Zhicheng; Ho, Tsung-Yi; Yu, Philip S.				Liu, Zheng/AHI-3660-2022; 李, 晓曦/AEG-7480-2022; Ho, Tsung-Yi/ABF-9929-2021; Dou, Zhicheng/OBO-6932-2025						Trustworthiness in Retrieval-Augmented Generation Systems: A Survey								Arxiv											1	1;2024-09-16;https://www.arxiv.org/abs/2409.10102v1	arXiv:2409.10102			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 16 2024	2024	Retrieval-Augmented Generation (RAG) has quickly grown into a pivotal paradigm in the development of Large Language Models (LLMs). While much of the current research in this field focuses on performance optimization, particularly in terms of accuracy and efficiency, the trustworthiness of RAG systems remains an area still under exploration. From a positive perspective, RAG systems are promising to enhance LLMs by providing them with useful and up-to-date knowledge from vast external databases, thereby mitigating the long-standing problem of hallucination. While from a negative perspective, RAG systems are at the risk of generating undesirable contents if the retrieved information is either inappropriate or poorly utilized. To address these concerns, we propose a unified framework that assesses the trustworthiness of RAG systems across six key dimensions: factuality, robustness, fairness, transparency, accountability, and privacy. Within this framework, we thoroughly review the existing literature on each dimension. Additionally, we create the evaluation benchmark regarding the six dimensions and conduct comprehensive evaluations for a variety of proprietary and open- source models. Finally, we identify the potential challenges for future research based on our investigation results. Through this work, we aim to lay a structured foundation for future investigations and provide practical insights for enhancing the trustworthiness of RAG systems in real-world applications.																																	2024-12-24	PPRN:119224275		
J	Agarwal, Anish; Shah, Devavrat; Shen, Dennis				Shen, Dennis/MSW-8549-2025						Synthetic Interventions								Arxiv											3	3;2024-08-24;https://www.arxiv.org/abs/2006.07691v7| 2;2023-10-31;https://www.arxiv.org/abs/2006.07691v6| 1;2020-06-13;https://www.arxiv.org/abs/2006.07691v5	arXiv:2006.07691			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 24 2024	2024	The synthetic controls (SC) methodology is a prominent tool for policy evaluation in panel data applications. Researchers commonly justify the SC framework with a low-rank matrix factor model that assumes the potential outcomes are described by low-dimensional unit and time specific latent factors. In the recent work of [Abadie '20], one of the pioneering authors of the SC method posed the question of how the SC framework can be extended to multiple treatments. This article offers one resolution to this open question that we call synthetic interventions (SI). Fundamental to the SI framework is a low-rank tensor factor model, which extends the matrix factor model by including a latent factorization over treatments. Under this model, we propose a generalization of the standard SC-based estimators. We prove the consistency for one instantiation of our approach and provide conditions under which it is asymptotically normal. Moreover, we conduct a representative simulation to study its prediction performance and revisit the canonical SC case study of [Abadie-Diamond-Hainmueller '10] on the impact of anti-tobacco legislations by exploring related questions not previously investigated.																																	2024-09-04	PPRN:36024646		
J	Demonet, Laurent; Iyama, Osamu; Reading, Nathan; Reiten, Idun; Thomas, Hugh				Demonet, Laurent/I-6148-2014; Reading, Nathan/X-6357-2019						Lattice theory of torsion classes: Beyond τ-tilting theory								Arxiv											2	2;2024-08-12;https://www.arxiv.org/abs/1711.01785v4| 1;2018-03-26;https://www.arxiv.org/abs/1711.01785v2	arXiv:1711.01785			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 12 2024	2024	The aim of this paper is to establish a lattice theoretical framework to study the partially ordered set tors A of torsion classes over a finitedimensional algebra A. We show that tors A is a complete lattice which enjoys very strong properties, as bialgebraicity and complete semidistributivity . Thus its Hasse quiver carries the important part of its structure, and we introduce the brick labelling of its Hasse quiver and use it to study lattice congruences of tors A. In particular, we give a representation-theoretical interpretation of the so-called forcing order , and we prove that tors A is completely congruence uniform . When I is a two-sided ideal of A, tors ( A/I) is a lattice quotient of tors A which is called an algebraic quotient , and the corresponding lattice congruence is called an algebraic congruence . The second part of this paper consists in studying algebraic congruences. We characterize the arrows of the Hasse quiver of tors A that are contracted by an algebraic congruence in terms of the brick labelling. In the third part, we study in detail the case of preprojective algebras Π, for which tors Π is the Weyl group endowed with the weak order. In particular, we give a new, more representation theoretical proof of the isomorphism between tors kQ and the Cambrian lattice when Q is a Dynkin quiver. We also prove that, in type A, the algebraic quotients of tors Π are exactly its Hasse-regular lattice quotients.																																	2024-08-21	PPRN:12865580		
J	Shen, Hua; Knearem, Tiffany; Ghosh, Reshmi; Alkiek, Kenan; Krishna, Kundan; Liu, Yachuan; Ma, Ziqiao; Petridis, Savvas; Peng, Yi-Hao; Qiwei, Li; Rakshit, Sushrita; Si, Chenglei; Xie, Yutong; Bigham, Jeffrey P.; Bentley, Frank; Chai, Joyce; Lipton, Zachary; Mei, Qiaozhu; Mihalcea, Rada; Terry, Michael; Yang, Diyi; Morris, Meredith Ringel; Resnick, Paul; Jurgens, David				liu, yach/GVT-3129-2022; Bentley, Frank/S-6142-2019; Xie, Yutong/HGA-0620-2022; Ghosh, Reshmi/KZU-3012-2024						Towards Bidirectional Human-AI Alignment: A Systematic Review for Clarifications, Framework, and Future Directions								Arxiv											2	2;2024-08-10;https://www.arxiv.org/abs/2406.09264v3| 1;2024-06-17;https://www.arxiv.org/abs/2406.09264v2	arXiv:2406.09264			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 10 2024	2024	Recent advancements in general-purpose AI have highlighted the importance of guiding AI systems towards the intended goals, ethical principles, and values of individuals and groups, a concept broadly recognized as alignment. However, the lack of clarified definitions and scopes of human-AI alignment poses a significant obstacle, hampering collaborative efforts across research domains to achieve this alignment. In particular, ML- and philosophy-oriented alignment research often views AI alignment as a static, unidirectional process (i.e., aiming to ensure that AI systems' objectives match humans) rather than an ongoing, mutual alignment problem. This perspective largely neglects the long-term interaction and dynamic changes of alignment. To understand these gaps, we introduce a systematic review of over 400 papers published between 2019 and January 2024, spanning multiple domains such as Human-Computer Interaction (HCI), Natural Language Processing (NLP), Machine Learning (ML). We characterize, define and scope human-AI alignment. From this, we present a conceptual framework of "Bidirectional Human-AI Alignment" to organize the literature from a human-centered perspective. This framework encompasses both 1) conventional studies of aligning AI to humans that ensures AI produces the intended outcomes determined by humans, and 2) a proposed concept of aligning humans to AI, which aims to help individuals and society adjust to AI advancements both cognitively and behaviorally. Additionally, we articulate the key findings derived from literature analysis, including literature gaps and trends, human values, and interaction techniques. To pave the way for future studies, we envision three key challenges and give recommendations for future research.																																	2024-08-21	PPRN:89294524		
J	Bhattacharya, Gourab; Choudhury, Sayantan; Dey, Kritartha; Ghosh, Saptarshi; Karde, Ahaskar; Mishra, Navneet Suryaprakash										Evading no-go for PBH formation and production of SIGWs using Multiple Sharp Transitions in EFT of single field inflation								Arxiv											3	3;2024-07-29;https://www.arxiv.org/abs/2309.00973v3| 2;2023-11-07;https://www.arxiv.org/abs/2309.00973v2| 1;2023-09-02;https://www.arxiv.org/abs/2309.00973v1	arXiv:2309.00973			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 29 2024	2024	Deploying multiple sharp transitions (MSTs) under a unified framework, we investigate the formation of Primordial Black Holes (PBHs) and the production of Scalar Induced Gravitational Waves (SIGWs) by incorporating one-loop corrected renormalized-resummed scalar power spectrum. With effective sound speed parameter, 1 ≤ c s ≤ 1.17, the direct consequence is the generation of PBH masses spanning M PBH ∼ O(10−31 M⊙ − 104M⊙),  thus evading well known No-go theorem on PBH mass. Our results align coherently with the extensive NANOGrav 15-year data and the sensitivities outlined by other terrestrial and space-based experiments (e.g.: LISA, HLVK, BBO, HLV(O3), etc.).																																	2024-08-08	PPRN:84723527		
J	Chen, Hongruixuan; Song, Jian; Han, Chengxi; Xia, Junshi; Yokoya, Naoto				Yokoya, Naoto/AAC-1530-2022; Xia, Junshi/ABD-4116-2020; han, chengxi/JDM-8614-2023; Chen, Hongruixuan/GVU-2737-2022						ChangeMamba: Remote Sensing Change Detection With Spatiotemporal State Space Model								Arxiv											6	6;2024-07-26;https://www.arxiv.org/abs/2404.03425v6| 5;2024-06-26;https://www.arxiv.org/abs/2404.03425v5| 4;2024-06-17;https://www.arxiv.org/abs/2404.03425v4| 3;2024-04-14;https://www.arxiv.org/abs/2404.03425v3| 2;2024-04-11;https://www.arxiv.org/abs/2404.03425v2| 1;2024-04-04;https://www.arxiv.org/abs/2404.03425v1	arXiv:2404.03425			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jul 26 2024	2024	Convolutional neural networks (CNN) and Transformers have made impressive progress in the field of remote sensing change detection (CD). However, both architectures have inherent shortcomings: CNN are constrained by a limited receptive field that may hinder their ability to capture broader spatial contexts, while Transformers are computationally intensive, making them costly to train and deploy on large datasets. Recently, the Mamba architecture, based on state space models, has shown remarkable performance in a series of natural language processing tasks, which can effectively compensate for the shortcomings of the above two architectures. In this paper, we explore for the first time the potential of the Mamba architecture for remote sensing CD tasks. We tailor the corresponding frameworks, called MambaBCD, MambaSCD, and MambaBDA, for binary change detection (BCD), semantic change detection (SCD), and building damage assessment (BDA), respectively. All three frameworks adopt the cutting-edge Visual Mamba architecture as the encoder, which allows full learning of global spatial contextual information from the input images. For the change decoder, which is available in all three architectures, we propose three spatio-temporal relationship modeling mechanisms, which can be naturally combined with the Mamba architecture and fully utilize its attribute to achieve spatio-temporal interaction of multi-temporal features, thereby obtaining accurate change information. On five benchmark datasets, our proposed frameworks outperform current CNN- and Transformer-based approaches without using any complex training strategies or tricks, fully demonstrating the potential of the Mamba architecture in CD tasks. Further experiments show that our architecture is quite robust to degraded data. 																																	2024-08-03	PPRN:88414050		
J	Zhuang, Junhao; Zeng, Yanhong; Liu, Wenran; Yuan, Chun; Chen, Kai				zeng, yanhong/Y-2891-2018; Yuan, Chun/JMD-0079-2023						A Task is Worth One Word: Learning with Task Prompts for High-Quality Versatile Image Inpainting								Arxiv											3	3;2024-07-23;https://www.arxiv.org/abs/2312.03594v4| 2;2023-12-12;https://www.arxiv.org/abs/2312.03594v3| 1;2023-12-07;https://www.arxiv.org/abs/2312.03594v2	arXiv:2312.03594			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 23 2024	2024	Advancing image inpainting is challenging as it requires filling user-specified regions for various intents, such as background filling and object synthesis. Existing approaches focus on either context-aware filling or object synthesis using text descriptions. However, achieving both tasks simultaneously is challenging due to differing training strategies. To overcome this challenge, we introduce PowerPaint, the first high-quality and versatile inpainting model that excels in multiple inpainting tasks. First, we introduce learnable task prompts along with tailored fine-tuning strategies to guide the model's focus on different inpainting targets explicitly. This enables PowerPaint to accomplish various inpainting tasks by utilizing different task prompts, resulting in state-of-the-art performance. Second, we demonstrate the versatility of the task prompt in PowerPaint by showcasing its effectiveness as a negative prompt for object removal. Moreover, we leverage prompt interpolation techniques to enable controllable shape-guided object inpainting, enhancing the model's applicability in shape-guided applications. Finally, we conduct extensive experiments and applications to verify the effectiveness of PowerPaint. 																																	2024-07-30	PPRN:86443128		
J	Ji, Ziwei; Lee, Nayeon; Frieske, Rita; Yu, Tiezheng; Su, Dan; Xu, Yan; Ishii, Etsuko; Bang, Yejin; Chen, Delong; Dai, Wenliang; Chan, Ho Shu; Madotto, Andrea; Fung, Pascale				Yu, Tiezheng/JJE-0199-2023; Frieske, Rita/MEK-9685-2025						Survey of Hallucination in Natural Language Generation								Arxiv											3	3;2024-07-14;https://www.arxiv.org/abs/2202.03629v7| 2;2024-02-19;https://www.arxiv.org/abs/2202.03629v6| 1;2022-11-07;https://www.arxiv.org/abs/2202.03629v5	arXiv:2202.03629			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 14 2024	2024	Natural Language Generation (NLG) has improved exponentially in recent years thanks to the development of sequence-to-sequence deep learning technologies such as Transformer-based language models. This advancement has led to more fluent and coherent NLG, leading to improved development in downstream tasks such as abstractive summarization, dialogue generation and data-to-text generation. However, it is also apparent that deep learning based generation is prone to hallucinate unintended text, which degrades the system performance and fails to meet user expectations in many real-world scenarios. To address this issue, many studies have been presented in measuring and mitigating hallucinated texts, but these have never been reviewed in a comprehensive manner before. In this survey, we thus provide a broad overview of the research progress and challenges in the hallucination problem in NLG. The survey is organized into two parts: (1) a general overview of metrics, mitigation methods, and future directions; (2) an overview of task-specific research progress on hallucinations in the following downstream tasks, namely abstractive summarization, dialogue generation, generative question answering, data-to-text generation, machine translation, and visual-language generation; and (3) hallucinations in large language models (LLMs) 1 . This survey serves to facilitate collaborative efforts among researchers in tackling the challenge of hallucinated texts in NLG.																																	2024-07-23	PPRN:22547563		
J	Yu, Yue; Ping, Wei; Liu, Zihan; Wang, Boxin; You, Jiaxuan; Zhang, Chao; Shoeybi, Mohammad; Catanzaro, Bryan				You, Jiaxuan/ABC-7506-2020						RankRAG: Unifying Context Ranking with Retrieval-Augmented Generation in LLMs								Arxiv											1	1;2024-07-02;https://www.arxiv.org/abs/2407.02485v1	arXiv:2407.02485			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 02 2024	2024	Large language models (LLMs) typically utilize the top-k contexts from a retriever in retrieval-augmented generation (RAG). In this work, we propose a novel instruction fine-tuning framework RankRAG, which instruction-tunes a single LLM for the dual purpose of context ranking and answer generation in RAG. In particular, the instruction-tuned LLMs work surprisingly well by adding a small fraction of ranking data into the training blend, and outperform existing expert ranking models, including the same LLM exclusively fine-tuned on a large amount of ranking data. For generation, we compare our model with many strong baselines, including GPT-4-0613, GPT-4-turbo-2024-0409, and ChatQA-1.5, an open-sourced model with the state-of-the-art performance on RAG benchmarks. Specifically, our Llama3-RankRAG significantly outperforms Llama3-ChatQA-1.5 and GPT-4 models on nine knowledge-intensive benchmarks. In addition, it also performs comparably to GPT-4 on five RAG benchmarks in the biomedical domain without instruction fine-tuning on biomedical data, demonstrating its superb capability for generalization to new domains.																																	2024-07-19	PPRN:90674161		
J	Tao, Yan; Viberg, Olga; Baker, Ryan S.; Kizilcec, Rene F.										Cultural Bias and Cultural Alignment of Large Language Models								Arxiv											2	2;2024-06-26;https://www.arxiv.org/abs/2311.14096v2| 1;2023-11-23;https://www.arxiv.org/abs/2311.14096v1	arXiv:2311.14096			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 26 2024	2024	Culture fundamentally shapes people’s reasoning, behavior, and communication. As people increasingly use generative artificial intelligence (AI) to expedite and automate personal and professional tasks, cultural values embedded in AI models may bias people’s authentic expression and contribute to the dominance of certain cultures. We conduct a disaggregated evaluation of cultural bias for five widely used large language models (OpenAI’s GPT-4o/4-turbo/4/3.5-turbo/3) by comparing the models’ responses to nationally representative survey data. All models exhibit cultural values resembling English-speaking and Protestant European countries. We test cultural prompting as a control strategy to increase cultural alignment for each country/territory. For recent models (GPT-4, 4 -turbo, 4o), this improves the cultural alignment of the models’ output for 71-81% of countries and territories. We suggest using cultural prompting and ongoing evaluation to reduce cultural bias																																	2024-07-15	PPRN:86274768		
J	Shi, Weijia; Min, Sewon; Lomeli, Maria; Zhou, Chunting; Li, Margaret; Szilvasy, Gergely; James, Rich; Lin, Xi Victoria; Smith, Noah A.; Zettlemoyer, Luke; Yih, Scott; Lewis, Mike										In-context Pretraining: Language Modeling Beyond Document Boundaries								Arxiv											6	6;2024-06-24;https://www.arxiv.org/abs/2310.10638v6| 5;2024-03-09;https://www.arxiv.org/abs/2310.10638v5| 4;2023-11-30;https://www.arxiv.org/abs/2310.10638v4| 3;2023-10-20;https://www.arxiv.org/abs/2310.10638v3| 2;2023-10-19;https://www.arxiv.org/abs/2310.10638v2| 1;2023-10-16;https://www.arxiv.org/abs/2310.10638v1	arXiv:2310.10638			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 24 2024	2024	Large language models (LMs) are currently trained to predict tokens given document prefixes, enabling them to directly perform long-form generation and prompting-style tasks which can be reduced to document completion. Existing pretraining pipelines train LMs by concatenating random sets of short documents to create input contexts but the prior documents provide no signal for predicting the next document. We instead present In-Context Pretraining, a new approach where language models are pretrained on a sequence of related documents, thereby explicitly encouraging them to read and reason across document boundaries. We can do In-Context Pretraining by simply changing the document ordering so that each context contains related documents, and directly applying existing pretraining pipelines. However, this document sorting problem is challenging. There are billions of documents and we would like the sort to maximize contextual similarity for every document without repeating any data. To do this, we introduce approximate algorithms for finding related documents with efficient nearest neighbor search and constructing coherent input contexts with a graph traversal algorithm. Our experiments show In-Context Pretraining offers a simple and scalable approach to significantly enhance LMs'performance: we see notable improvements in tasks that require more complex contextual reasoning, including in-context learning (+8%), reading comprehension (+15%), faithfulness to previous contexts (+16%), long-context reasoning (+5%), and retrieval augmentation (+9%).																																	2024-07-15	PPRN:85660489		
J	Zhang, Yihua; Fan, Chongyu; Zhang, Yimeng; Yao, Yuguang; Jia, Jinghan; Liu, Jiancheng; Zhang, Gaoyuan; Liu, Gaowen; Kompella, Ramana; Liu, Xiaoming; Liu, Sijia				Zhang, Yimeng/IUQ-7269-2023; Liu, Gaowen/AAP-9890-2021; Zhang, Yimeng/ACD-2102-2022						UnlearnCanvas: Stylized Image Dataset for Enhanced Machine Unlearning Evaluation in Diffusion Models								Arxiv											2	2;2024-06-14;https://www.arxiv.org/abs/2402.11846v3| 1;2024-02-19;https://www.arxiv.org/abs/2402.11846v1	arXiv:2402.11846			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 14 2024	2024	The technological advancements in diffusion models (DMs) have demonstrated unprecedented capabilities in text-to-image generation and are widely used in diverse applications. However, they have also raised significant societal concerns, such as the generation of harmful content and copyright disputes. Machine unlearning (MU) has emerged as a promising solution, capable of removing undesired generative capabilities from DMs. However, existing MU evaluation systems present several key challenges that can result in incomplete and inaccurate assessments. To address these issues, we propose UnlearnCanvas, a comprehensive high-resolution stylized image dataset that facilitates the evaluation of the unlearning of artistic styles and associated objects. This dataset enables the establishment of a standardized, automated evaluation framework with 7 quantitative metrics assessing various aspects of the unlearning performance for DMs. Through extensive experiments, we benchmark 9 state-of-the-art MU methods for DMs, revealing novel insights into their strengths, weaknesses, and underlying mechanisms. Additionally, we explore challenging unlearning scenarios for DMs to evaluate worst-case performance against adversarial prompts, the unlearning of finer-scale concepts, and sequential unlearning. We hope that this study can pave the way for developing more effective, accurate, and robust DM unlearning methods, ensuring safer and more ethical applications of DMs in the future. The dataset, benchmark, and codes are publicly available at https://unlearn-canvas.netlify.app/.																																	2024-07-04	PPRN:87761333		
J	Xiang, Jiannan; Liu, Guangyi; Gu, Yi; Gao, Qiyue; Ning, Yuting; Zha, Yuheng; Feng, Zeyu; Tao, Tianhua; Hao, Shibo; Shi, Yemin; Liu, Zhengzhong; Xing, Eric P.; Hu, Zhiting				Gu, Yi/JRX-8093-2023						<italic>Pandora:</italic> Towards General World Model with Natural Language Actions and Video States								Arxiv											1	1;2024-06-12;https://www.arxiv.org/abs/2406.09455v1	arXiv:2406.09455			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 12 2024	2024	World models simulate future states of the world in response to different actions. They facilitate interactive content creation and provides a foundation for grounded, long-horizon reasoning. Current foundation models do not fully meet the capabilities of general world models: large language models (LLMs) are constrained by their reliance on language modality and their limited understanding of the physical world, while video models lack interactive action control over the world simulations. This paper makes a step towards building a general world model by introducing Pandora, a hybrid autoregressive-diffusion model that simulates world states by generating videos and allows real-time control with free-text actions. Pandora achieves domain generality, video consistency, and controllability through large-scale pretraining and instruction tuning. Crucially, Pandora bypasses the cost of training-from-scratch by integrating a pretrained LLM (7B) and a pretrained video model, requiring only additional lightweight finetuning. We illustrate extensive outputs by Pandora across diverse domains (indoor/outdoor, natural/urban, human/robot, 2D/3D, etc.). The results indicate great potential of building stronger general world models with larger-scale training.																																	2024-07-02	PPRN:89328667		
J	Voronov, Anton; Wolf, Lena; Ryabinin, Max				Wolf, Lena/JPX-8351-2023; Voronov, Anton/JED-4209-2023						Mind Your Format: Towards Consistent Evaluation of In-Context Learning Improvements								Arxiv											3	3;2024-06-06;https://www.arxiv.org/abs/2401.06766v3| 2;2024-01-22;https://www.arxiv.org/abs/2401.06766v2| 1;2024-01-12;https://www.arxiv.org/abs/2401.06766v1	arXiv:2401.06766			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 06 2024	2024	Large language models demonstrate a remarkable capability for learning to solve new tasks from a few examples. The prompt template, or the way the input examples are formatted to obtain the prompt, is an important yet often overlooked aspect of in-context learning. In this work, we conduct a comprehensive study of the template format's influence on the in-context learning performance. We evaluate the impact of the prompt template across 21 models (from 770M to 70B parameters) and 4 standard classification datasets. We show that a poor choice of the template can reduce the performance of the strongest models and inference methods to a random guess level. More importantly, the best templates do not transfer between different setups and even between models of the same family. Our findings show that the currently prevalent approach to evaluation, which ignores template selection, may give misleading results due to different templates in different works. As a first step towards mitigating this issue, we propose Template Ensembles that aggregate model predictions across several templates. This simple test-time augmentation boosts average performance while being robust to the choice of random set of templates.																																	2024-06-22	PPRN:87154789		
J	Guo, Yinjie; Pack, Jordan; Swann, Joshua; Holtzman, Luke; Cothrine, Matthew; Watanabe, Kenji; Taniguchi, Takashi; Mandrus, David G; Barmak, Katayun; Hone, James; Millis, Andrew J.; Pasupathy, Abhay; Dean, Cory R.				Watanabe, Kenji/H-2825-2011; Dean, Cory/HMD-9142-2023; Hone, James/E-1879-2011; TANIGUCHI, Takashi/H-2718-2011						Superconductivity in twisted bilayer WSe2								Arxiv											2	2;2024-06-05;https://www.arxiv.org/abs/2406.03418v1| 1;2024-06-05;https://www.arxiv.org/abs/2406.03418v1	arXiv:2406.03418			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 05 2024	2024	The discovery of superconductivity in twisted bilayer and twisted trilayer graphene[1–5] has generated tremendous interest. The key feature of these systems is an interplay between interlayer coupling and a moire superlattice that gives rise to low-energy flat bands with strong correlations[6]. Flat bands can also be induced by moire patterns in lattice-mismatched and or twisted heterostructures of other two-dimensional materials such as transition metal dichalcogenides (TMDs)[7–11]. Although a wide range of correlated phenomenon have indeed been observed in the moire TMDs[12–24], robust demonstration of superconductivity has remained absent[12]. Here we report superconductivity in 5 degree twisted bilayer WSe2 (tWSe2) with a maximum critical temperature of 426 mK. The superconducting state appears in a limited region of displacement field and density that is adjacent to a metallic state with Fermi surface reconstruction believed to arise from antiferromagnetic order[25]. A sharp boundary is observed between the superconducting and magnetic phases at low temperature, reminiscent of spin-fluctuation mediated superconductivity[26]. Our results establish that moire flat-band superconductivity extends beyond graphene structures. Material properties that are absent in graphene but intrinsic among the TMDs such as a native band gap, large spin-orbit coupling, spin- valley locking, and magnetism offer the possibility to access a broader superconducting parameter space than graphene-only structures.																																	2025-03-15	PPRN:89262734		
J	Lu, Xudong; Liu, Qi; Xu, Yuhui; Zhou, Aojun; Huang, Siyuan; Zhang, Bo; Yan, Junchi; Li, Hongsheng				Xu, Yuhui/AAW-6061-2021; Liu, Qi/AAS-9988-2021; Zhang, Bo/LYO-2794-2024; Li, Hongsheng/AES-5328-2022						Not All Experts are Equal: Efficient Expert Pruning and Skipping for Mixture-of-Experts Large Language Models								Arxiv											1	1;2024-05-30;https://www.arxiv.org/abs/2402.14800v2	arXiv:2402.14800			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 30 2024	2024	A pivotal advancement in the progress of large language models (LLMs) is the emergence of the Mixture-of-Experts (MoE) LLMs. Compared to traditional LLMs, MoE LLMs can achieve higher performance with fewer parameters, but it is still hard to deploy them due to their immense parameter sizes. Different from previous weight pruning methods that rely on specifically designed hardware, this paper mainly aims to enhance the deployment efficiency of MoE LLMs by introducing plug-and-play expert-level sparsification techniques. Specifically, we propose, for the first time to our best knowledge, post-training approaches for task-agnostic and task-specific expert pruning and skipping of MoE LLMs, tailored to improve deployment efficiency while maintaining model performance across a wide range of tasks. Extensive experiments show that our proposed methods can simultaneously reduce model sizes and increase the inference speed, while maintaining satisfactory performance.																																	2024-11-10	PPRN:89112926		
J	Street, Winnie; Siy, John Oliver; Keeling, Geoff; Baranes, Adrien; Barnett, Benjamin; Mckibben, Michael; Kanyere, Tatenda; Lentz, Alison; Aguera y Arcas, Blaise; Dunbar, Robin I.M.										LLMs achieve adult human performance on higher-order theory of mind tasks								Arxiv											2	2;2024-05-31;https://www.arxiv.org/abs/2405.18870v2| 1;2024-05-29;https://www.arxiv.org/abs/2405.18870v1	arXiv:2405.18870			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 29 2024	2024	This paper examines the extent to which large language models (LLMs) have developed higher-order theory of mind (ToM); the human ability to reason about multiple mental and emotional states in a recursive manner (e.g. I think that you believe that she knows ). This paper builds on prior work by introducing a handwritten test suite – Multi-Order Theory of Mind Q&A – and using it to compare the performance of five LLMs to a newly gathered adult human benchmark. We find that GPT-4 and Flan-PaLM reach adult-level and near adult-level performance on ToM tasks overall, and that GPT-4 exceeds adult performance on 6th order inferences. Our results suggest that there is an interplay between model size and finetuning for the realisation of ToM abilities, and that the best-performing LLMs have developed a generalised capacity for ToM. Given the role that higher-order ToM plays in a wide range of cooperative and competitive human behaviours, these findings have significant implications for user-facing LLM applications.																																	2024-08-24	PPRN:89125084		
J	Lin, Licong; Bai, Yu; Mei, Song				Bai, Yu/AAG-7494-2020; Mei, Song/AFQ-2667-2022						Transformers as Decision Makers: Provable In-Context Reinforcement Learning via Supervised Pretraining								Arxiv											2	2;2024-05-26;https://www.arxiv.org/abs/2310.08566v2| 1;2023-10-12;https://www.arxiv.org/abs/2310.08566v1	arXiv:2310.08566			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 26 2024	2024	Large transformer models pretrained on offline reinforcement learning datasets have demonstrated remarkable in -context reinforcement learning (ICRL) capabilities, where they can make good decisions when prompted with interaction trajectories from unseen environments. However, when and how transformers can be trained to perform ICRL have not been theoretically well -understood. In particular, it is unclear which reinforcement -learning algorithms transformers can perform in context, and how distribution mismatch in offline training data affects the learned algorithms. This paper provides a theoretical framework that analyzes supervised pretraining for ICRL. This includes two recently proposed training methods — algorithm distillation and decision-pretrained transformers. First, assuming model realizability, we prove the supervised-pretrained transformer will imitate the conditional expectation of the expert algorithm given the observed trajectory. The generalization error will scale with model capacity and a distribution divergence factor between the expert and offline algorithms. Second, we show transformers with ReLU attention can efficiently approximate near -optimal online reinforcement learning algorithms like LinUCB and Thompson sampling for stochastic linear bandits, and UCB-VI for tabular Markov decision processes. This provides the first quantitative analysis of the ICRL capabilities of transformers pretrained from offline trajectories.																																	2024-06-11	PPRN:85605405		
J	Besiroglu, Tamay; Erdil, Ege; Barnett, Matthew; You, Josh				Erdil, Erkan/D-2031-2010						Chinchilla Scaling: A replication attempt								Arxiv											2	2;2024-05-15;https://www.arxiv.org/abs/2404.10102v2| 1;2024-04-15;https://www.arxiv.org/abs/2404.10102v1	arXiv:2404.10102			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 15 2024	2024	Hoffmann et al. (2022) propose three methods for estimating a compute-optimal scaling law. We attempt to replicate their third estimation procedure, which involves fitting a parametric loss function to a reconstruction of data from their plots. However, we find that their reported estimates are inconsistent with their first two estimation methods, fail at fitting the extracted data, and report implausibly narrow confidence intervals—intervals this narrow would require over 600,000 experiments, while they likely only ran fewer than 500. Two factors explain these findings: firstly, the optimizer used by Hoffmann et al. stopped before convergence due to a poor choice of loss scale, and secondly, the parameter estimates reported in the body of the paper (as opposed to the TeX source) are rounded in a way that results in substantial bias in the predictions of the scaling law. In contrast, our re-derivation of the scaling law using the third approach yields results that are compatible with the findings from the first two estimation procedures described by Hoffmann et al.																																	2024-06-11	PPRN:88544063		
J	Wu, Bo; Yu, Shoubin; Chen, Zhenfang; Tenenbaum, Joshua B; Gan, Chuang				Chen, Zhenfang/HTS-8543-2023						STAR: A Benchmark for Situated Reasoning in Real-World Videos								Arxiv											1	1;2024-05-15;https://www.arxiv.org/abs/2405.09711v1	arXiv:2405.09711			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 15 2024	2024	Reasoning in the real world is not divorced from situations. How to capture the present knowledge from surrounding situations and perform reasoning accordingly is crucial and challenging for machine intelligence. This paper introduces a new benchmark that evaluates the situated reasoning ability via situation abstraction and logic-grounded question answering for real-world videos, called Situated Reasoning in Real-World Videos (STAR Benchmark). This benchmark is built upon the real-world videos associated with human actions or interactions, which are naturally dynamic, compositional, and logical. The dataset includes four types of questions, including interaction, sequence, prediction, and feasibility. We represent the situations in real-world videos by hyper-graphs connecting extracted atomic entities and relations (e.g., actions, persons, objects, and relationships). Besides visual perception, situated reasoning also requires structured situation comprehension and logical reasoning. Questions and answers are procedurally generated. The answering logic of each question is represented by a functional program based on a situation hyper-graph. We compare various existing video reasoning models and find that they all struggle on this challenging situated reasoning task. We further propose a diagnostic neuro-symbolic model that can disentangle visual perception, situation abstraction, language understanding, and functional reasoning to understand the challenges of this benchmark.																																	2024-06-12	PPRN:89086055		
J	Ma, Chong; Wu, Zihao; Wang, Jiaqi; Xu, Shaochen; Wei, Yaonai; Zeng, Fang; Liu, Zhengliang; Jiang, Xi; Guo, Lei; Cai, Xiaoyan; Zhang, Shu; Zhang, Tuo; Zhu, Dajiang; Shen, Dinggang; Liu, Tianming; Li, Xiang				Jiang, Xi/ADT-2238-2022; wang, jiaqi/HHS-0123-2022; Liu, Tianming/GLS-1211-2022; Wei, Yaonai/KFS-3242-2024; Guo, Lei/C-6558-2014; wu, zihao/R-8745-2019; Ma, Chong/MIT-9373-2025; Zhang, Tuo/NHP-8722-2025; Cai, Xiaoyan/OCK-9718-2025; Li, Xiang/J-6924-2019						An Iterative Optimizing Framework for Radiology Report Summarization with ChatGPT								Arxiv											3	3;2024-05-08;https://www.arxiv.org/abs/2304.08448v3| 2;1800-01-01;https://www.arxiv.org/abs/2304.08448v2| 1;2023-04-17;https://www.arxiv.org/abs/2304.08448v1	arXiv:2304.08448			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 08 2024	2024	The 'Impression' section of a radiology report is a critical basis for communication between radiologists and other physicians, and it is typically written by radiologists based on the 'Findings' section. However, writing numerous impressions can be laborious and error-prone for radiologists. Although recent studies have achieved promising results in automatic impression generation using large-scale medical text data for pre-training and fine-tuning pre-trained language models, such models often require substantial amounts of medical text data and have poor generalization performance. While large language models (LLMs) like ChatGPT have shown strong generalization capabilities and performance, their performance in specific domains, such as radiology, remains under-investigated and potentially limited. To address this limitation, we propose ImpressionGPT, which leverages the in-context learning capability of LLMs by constructing dynamic contexts using domain-specific, individualized data. This dynamic prompt approach enables the model to learn contextual knowledge from semantically similar examples from existing data. Additionally, we design an iterative optimization algorithm that performs automatic evaluation on the generated impression results and composes the corresponding instruction prompts to further optimize the model. The proposed ImpressionGPT model achieves state-of-the-art performance on both MIMIC-CXR and OpenI datasets without requiring additional training data or fine-tuning the LLMs. This work presents a paradigm for localizing LLMs that can be applied in a wide range of similar application scenarios, bridging the gap between general-purpose LLMs and the specific language processing needs of various domains.																																	2024-05-29	PPRN:63657300		
J	Zhao, Zhiyuan; Ding, Xueying; Prakash, B. Aditya										PINNsFormer: A Transformer-Based Framework For Physics-Informed Neural Networks								Arxiv											3	3;2024-05-07;https://www.arxiv.org/abs/2307.11833v3| 2;2023-10-03;https://www.arxiv.org/abs/2307.11833v2| 1;2023-07-21;https://www.arxiv.org/abs/2307.11833v1	arXiv:2307.11833			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 07 2024	2024	Physics-Informed Neural Networks (PINNs) have emerged as a promising deep learning framework for approximating numerical solutions to partial differential equations (PDEs). However, conventional PINNs, relying on multilayer perceptrons (MLP), neglect the crucial temporal dependencies inherent in practical physics systems and thus fail to propagate the initial condition constraints globally and accurately capture the true solutions under various scenarios. In this paper, we introduce a novel Transformer-based framework, termed PINNsFormer, designed to address this limitation. PINNsFormer can accurately approximate PDE solutions by utilizing multi-head attention mechanisms to capture temporal dependencies. PINNsFormer transforms point-wise inputs into pseudo sequences and replaces point-wise PINNs loss with a sequential loss. Additionally, it incorporates a novel activation function, Wavelet, , which anticipates Fourier decomposition through deep neural networks. Empirical results demonstrate that PINNsFormer achieves superior generalization ability and accuracy across various scenarios, including PINNs failure modes and high-dimensional PDEs. Moreover, PINNsFormer offers flexibility in integrating existing learning schemes for PINNs, further enhancing its performance.																																	2024-05-28	PPRN:74086472		
J	Yang, Ling; Yu, Zhaochen; Meng, Chenlin; Xu, Minkai; Ermon, Stefano; Cui, Bin				Xu, Minkai/JXL-2266-2024; Meng, Chenlin/HKF-5727-2023						Mastering Text-to-Image Diffusion: Recaptioning, Planning, and Generating with Multimodal LLMs								Arxiv											3	3;2024-05-05;https://www.arxiv.org/abs/2401.11708v3| 2;2024-02-06;https://www.arxiv.org/abs/2401.11708v2| 1;2024-01-22;https://www.arxiv.org/abs/2401.11708v1	arXiv:2401.11708			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 05 2024	2024	Diffusion models have exhibit exceptional performance in text -to -image generation and editing. However, existing methods often face challenges when handling complex text prompts that involve multiple objects with multiple attributes and relationships. In this paper, we propose a brand new training -free text -to -image generation/editing framework, namely Recaption, Plan and Generate (RPG), harnessing the powerful chain -of -thought reasoning ability of multimodal LLMs to enhance the compositionality of text -toimage diffusion models. Our approach employs the MLLM as a global planner to decompose the process of generating complex images into multiple simpler generation tasks within subregions. We propose complementary regional diffusion to enable region -wise compositional generation. Furthermore, we integrate text -guided image generation and editing within the proposed RPG in a closed -loop fashion, thereby enhancing generalization ability. Extensive experiments demonstrate our RPG outperforms state-of-the-art textto -image diffusion models, including DALL-E 3 and SDXL, particularly in multi -category object composition and text -image semantic alignment. Notably, our RPG framework exhibits wide compatibility with various MLLM architectures (e.g., MiniGPT-4) and diffusion backbones (e.g., ControlNet). Our code is available at https://github.com/YangLing0818/RPGDiffusionMaster																																	2024-05-14	PPRN:87277666		
J	Liao, Jiayi; Li, Sihang; Yang, Zhengyi; Wu, Jiancan; Yuan, Yancheng; Wang, Xiang; He, Xiangnan				Yang, Zhengyi/KWU-3780-2024; liao, jiayi/OOL-4725-2025						LLaRA: Large Language-Recommendation Assistant								Arxiv											4	4;2024-05-04;https://www.arxiv.org/abs/2312.02445v4| 3;2024-04-09;https://www.arxiv.org/abs/2312.02445v3| 2;2023-12-31;https://www.arxiv.org/abs/2312.02445v2| 1;2023-12-05;https://www.arxiv.org/abs/2312.02445v1	arXiv:2312.02445			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 04 2024	2024	Sequential recommendation aims to predict users' next interaction with items based on their past engagement sequence. Recently, the advent of Large Language Models (LLMs) has sparked interest in leveraging them for sequential recommendation, viewing it as language modeling. Previous studies represent items within LLMs' input prompts as either ID indices or textual metadata. However, these approaches often fail to either encapsulate comprehensive world knowledge or exhibit sufficient behavioral understanding. To combine the complementary strengths of conventional recommenders in capturing behavioral patterns of users and LLMs in encoding world knowledge about items, we introduce Large Language-Recommendation Assistant (LLaRA). Specifically, it uses a novel hybrid prompting method that integrates ID-based item embeddings learned by traditional recommendation models with textual item features. Treating the "sequential behaviors of users" as a distinct modality beyond texts, we employ a projector to align the traditional recommender's ID embeddings with the LLM's input space. Moreover, rather than directly exposing the hybrid prompt to LLMs, a curriculum learning strategy is adopted to gradually ramp up training complexity. Initially, we warm up the LLM using text-only prompts, which better suit its inherent language modeling ability. Subsequently, we progressively transition to the hybrid prompts, training the model to seamlessly incorporate the behavioral knowledge from the traditional sequential recommender into the LLM. Empirical results validate the effectiveness of our proposed framework. 																																	2024-05-24	PPRN:86401595		
J	Mehta, Ajit Kumar; Olsen, Seth; Wadekar, Digvijay; Roulet, Javier; Venumadhav, Tejaswi; Mushkin, Jonathan; Zackay, Barak; Zaldarriaga, Matias				Wadekar, Digvijay/AAM-3622-2021						New binary black hole mergers in the LIGO-Virgo O3b data								Arxiv											2	2;2024-05-04;https://www.arxiv.org/abs/2311.06061v2| 1;2023-11-10;https://www.arxiv.org/abs/2311.06061v1	arXiv:2311.06061			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 04 2024	2024	We report the detection of 6 new candidate binary black hole (BBH) merger signals in the publicly released data from the second half of the third observing run (O3b) of advanced LIGO and advanced Virgo. The LIGO–Virgo–KAGRA (LVK) collaboration reported 35 compact binary coalescences (CBCs) in their analysis of the O3b data [1], with 30 BBH mergers having coincidence in the Hanford and Livingston detectors. We confirm 17 of these for a total of 23 detections in our analysis of the Hanford–Livingston coincident O3b data. We identify candidates using a search pipeline employing aligned -spin quadrupole -only waveforms. Our pipeline is similar to the one used in our O3a coincident analysis [2], except for a few improvements in the veto procedure and the ranking statistic, and we continue to use an astrophysical probability of one half as our detection threshold, following the approach of the LVK catalogs. Most of the new candidates reported in this work are placed in the upper/lower-mass gap of the black hole (BH) mass distribution. We also identify a possible neutron star -black hole (NSBH) merger. We expect these events to help inform the black hole mass and spin distributions inferred in a full population analysis.																																	2024-05-24	PPRN:86125074		
J	Strachan, David J.; Purkayastha, Archak; Clark, Stephen R.				Purkayastha, Archak/T-7123-2018; Clark, Stephen/G-5368-2012						Non-Markovian Quantum Mpemba effect								Arxiv											2	2;2024-04-30;https://www.arxiv.org/abs/2402.05756v2| 1;2024-02-08;https://www.arxiv.org/abs/2402.05756v1	arXiv:2402.05756			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 30 2024	2024	Since its rediscovery in the twentieth century, the Mpemba effect, where a far -from -equilibrium state may relax faster than a state closer to equilibrium, has been extensively studied in classical systems and has recently received significant attention in quantum systems. Many theories explaining this counter -intuitive behavior in classical systems rely on memory effects. However, in quantum systems, the relation between the Mpemba effect and memory has remained unexplored. In this work, we consider general non-Markovian open quantum systems and reveal new classes of quantum Mpemba effects, with no analog in Markovian quantum dynamics. Generically, open quantum dynamics possess a finite memory time and a unique steady state. Due to non-Markovian dynamics, even if the system is initialized in the steady state it can take a long time to relax back. We find other initial states that reach the steady state much faster. Most notably, we demonstrate that there can be an initial state in which the system reaches the steady state within the finite memory time itself, therefore giving the fastest possible relaxation to stationarity. We verify the effect for quantum dot systems coupled to electronic reservoirs in equilibrium and non -equilibrium setups at weak, intermediate and strong coupling, and both with and without interactions. Our work provides new insights into the rich physics underlying accelerated relaxation in quantum systems.																																	2024-05-17	PPRN:87568880		
J	Zhang, Yuqi; Ding, Liang; Zhang, Lefei; Tao, Dacheng				Shen, Li/AEZ-9528-2022; Zhang, Lefei/HHM-8850-2022; Zhang, Yuqi/JQJ-3502-2023; Ding, Liang/IXD-6099-2023						Intention Analysis Makes LLMs A Good Jailbreak Defender								Arxiv											3	3;2024-04-29;https://www.arxiv.org/abs/2401.06561v3| 2;2024-02-21;https://www.arxiv.org/abs/2401.06561v2| 1;2024-01-12;https://www.arxiv.org/abs/2401.06561v1	arXiv:2401.06561			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 29 2024	2024	Aligning large language models (LLMs) with human values, particularly in the face of complex and stealthy jailbreak attacks, presents a formidable challenge. In this study, we present a simple yet highly effective defense strategy, i.e., Intention Analysis (IA). The principle behind this is to trigger LLMs’ inherent self-correct and improve ability through a twostage process: 1) essential intention analysis, and 2) policy-aligned response. Notably, IA is an inference-only method, thus could enhance the safety of LLMs without compromising their helpfulness 1 . Extensive experiments on varying jailbreak benchmarks across ChatGLM, LLaMA2, Vicuna, MPT, DeepSeek, and GPT-3.5 show that IA could consistently and significantly reduce the harmfulness in responses (averagely-53.1% attack success rate) and maintain the general helpfulness. Encouragingly, with the help of our IA, Vicuna-7B even outperforms GPT-3.5 in terms of attack success rate. Further analyses present some insights into how our method works. 																																	2024-05-15	PPRN:87155851		
J	Wang, Zihan; Kong, Fanheng; Feng, Shi; Wang, Ming; Yang, Xiaocui; Zhao, Han; Wang, Daling; Zhang, Yifei				Kong, Fanheng/NTQ-9137-2025; Wang, Ming/GYJ-7973-2022; Yang, XIaocui/MIN-0864-2025; Zhang, Yifei/JCO-2457-2023						Is Mamba Effective for Time Series Forecasting?								Arxiv											3	3;2024-04-27;https://www.arxiv.org/abs/2403.11144v3| 2;2024-04-02;https://www.arxiv.org/abs/2403.11144v2| 1;2024-03-17;https://www.arxiv.org/abs/2403.11144v1	arXiv:2403.11144			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 27 2024	2024	In the realm of time series forecasting (TSF), it is imperative for models to adeptly discern and distill hidden patterns within historical time series data to forecast future states. Transformer-based models exhibit formidable efficacy in TSF, primarily attributed to their advantage in apprehending these patterns. However, the quadratic complexity of the Transformer leads to low computational efficiency and high costs, which somewhat hinders the deployment of the TSF model in real-world scenarios. Recently, Mamba, a selective state space model, has gained traction due to its ability to process dependencies in sequences while maintaining near-linear complexity. For TSF tasks, these characteristics enable Mamba to comprehend hidden patterns as the Transformer and reduce computational overhead compared to the Transformer. Therefore, we propose a Mamba-based model named Simple-Mamba (S-Mamba) for TSF. Specifically, we tokenize the time points of each variate autonomously via a linear layer. A bidirectional Mamba layer is utilized to extract inter-variate correlations and a Feed-Forward Network is set to learn temporal dependencies. Finally, the generation of forecast outcomes through a linear mapping layer. Experiments on thirteen public datasets prove that S-Mamba maintains low computational overhead and achieves leading performance. Furthermore, we conduct extensive experiments to explore Mamba's potential in TSF tasks. Our code is available at https://github.com/wzhwzhwzh0921/S-D-Mamba.																																	2024-05-15	PPRN:88189282		
J	Chernozhukov, Victor; Newey, Whitney; Singh, Rahul; Syrgkanis, Vasilis										Adversarial Estimation of Riesz Representers								Arxiv											3	3;2024-04-26;https://www.arxiv.org/abs/2101.00009v3| 2;2024-01-15;https://www.arxiv.org/abs/2101.00009v2| 1;2020-12-30;https://www.arxiv.org/abs/2101.00009v1	arXiv:2101.00009			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 26 2024	2024	Many causal parameters are linear functionals of an underlying regression. The Riesz representer is a key component in the asymptotic variance of a semiparametrically estimated linear functional. We propose an adversarial framework to estimate the Riesz representer using general function spaces. We prove a nonasymptotic mean square rate in terms of an abstract quantity called the critical radius, then specialize it for neural networks, random forests, and reproducing kernel Hilbert spaces as leading cases. Our estimators are highly compatible with targeted and debiased machine learning with sample splitting; our guarantees directly verify general conditions for inference that allow mis-specification. We also use our guarantees to prove inference without sample splitting, based on stability or complexity. Our estimators achieve nominal coverage in highly nonlinear simulations where some previous methods break down. They shed new light on the heterogeneous effects of matching grants.																																	2024-05-15	PPRN:10682497		
J	Park, Jongho; Park, Jaeseung; Xiong, Zheyang; Lee, Nayoung; Cho, Jaewoong; Oymak, Samet; Lee, Kangwook; Papailiopoulos, Dimitris										Can Mamba Learn How to Learn? A Comparative Study on In-Context Learning Tasks								Arxiv											2	2;2024-04-25;https://www.arxiv.org/abs/2402.04248v2| 1;2024-02-06;https://www.arxiv.org/abs/2402.04248v1	arXiv:2402.04248			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 25 2024	2024	State -space models (SSMs), such as Mamba (Gu & Dao, 2023), have been proposed as alternatives to Transformer networks in language modeling, by incorporating gating, convolutions, and input -dependent token selection to mitigate the quadratic cost of multi -head attention. Although SSMs exhibit competitive performance, their in -context learning (ICL) capabilities, a remarkable emergent property of modern language models that enables task execution without parameter optimization, remain underexplored compared to Transformers. In this study, we evaluate the ICL performance of SSMs, focusing on Mamba, against Transformer models across various tasks. Our results show that SSMs perform comparably to Transformers in standard regression ICL tasks, while outperforming them in tasks like sparse parity learning. However, SSMs fall short in tasks involving non-standard retrieval functionality. To address these limitations, we introduce a hybrid model, MambaFormer, that combines Mamba with attention blocks, surpassing individual models in tasks where they struggle independently. Our findings suggest that hybrid architectures offer promising avenues for enhancing ICL in language models.																																	2024-05-04	PPRN:87533800		
J	Callister, Thomas A.; Farr, Will M.				Farr, Will/KCY-9315-2024						A Parameter-Free Tour of the Binary Black Hole Population								Arxiv											3	3;2024-04-23;https://www.arxiv.org/abs/2302.07289v4| 2;2023-11-08;https://www.arxiv.org/abs/2302.07289v3| 1;2023-02-14;https://www.arxiv.org/abs/2302.07289v1	arXiv:2302.07289			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 23 2024	2024	The continued operation of the Advanced LIGO and Advanced Virgo gravitational -wave detectors is enabling the first detailed measurements of the mass, spin, and redshift distributions of the merging binary black hole population. Our present knowledge of these distributions, however, is based largely on strongly parameteric models. Such models typically assume the distributions of binary parameters to be superpositions of “building block” features like power laws, peaks, dips, and breaks. Although this approach has yielded great progress in the initial characterization of the compact binary population, the strong assumptions entailed often leave it unclear which physical conclusions are driven by observation and which by the specific choice of model. In this paper, we instead model the merger rate of binary black holes as an unknown autoregressive process over the space of binary parameters, allowing us to measure the distributions of binary black hole masses, redshifts, component spins, and effective spins with near -complete agnosticism. We find the primary mass spectrum of binary black holes to be doubly peaked, with a fairly flat continuum that steepens at high masses. We identify signs of unexpected structure in the redshift distribution of binary black holes: a uniform-in-comoving volume merger rate at low redshift followed by an increase in the merger rate beyond redshift z ≈ 0.5. Finally, we find that the distribution of black hole spin magnitudes is unimodal and concentrated at small but nonzero values, and that spin orientations span a wide range of spin -orbit misalignment angles but are also moderately unlikely to be truly isotropic.																																	2024-05-02	PPRN:38080876		
J	Zhou, Da-Wei; Sun, Hai-Long; Ning, Jingyi; Ye, Han-Jia; Zhan, De-Chuan				Zhou, Da-Wei/ABB-6259-2021						Continual Learning with Pre-Trained Models: A Survey								Arxiv											2	2;2024-04-23;https://www.arxiv.org/abs/2401.16386v2| 1;2024-01-29;https://www.arxiv.org/abs/2401.16386v1	arXiv:2401.16386			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 23 2024	2024	Nowadays, real-world applications often face streaming data, which requires the learning system to absorb new knowledge as data evolves. Continual Learning (CL) aims to achieve this goal and meanwhile overcome the catastrophic forgetting of former knowledge when learning new ones. Typical CL methods build the model from scratch to grow with incoming data. However, the advent of the pre-trained model (PTM) era has sparked immense research interest, particularly in leveraging PTMs' robust representational capabilities. This paper presents a comprehensive survey of the latest advancements in PTM-based CL. We categorize existing methodologies into three distinct groups, providing a comparative analysis of their similarities, differences, and respective advantages and disadvantages. Additionally, we offer an empirical study contrasting various state-of-the-art methods to highlight concerns regarding fairness in comparisons. 																																	2024-05-02	PPRN:87392140		
J	Szymanowicz, Stanislaw; Rupprecht, Christian; Vedaldi, Andrea				Rupprecht, Christian/ABF-7744-2021						Splatter Image: Ultra-Fast Single-View 3D Reconstruction								Arxiv											2	2;2024-04-16;https://www.arxiv.org/abs/2312.13150v2| 1;2023-12-20;https://www.arxiv.org/abs/2312.13150v1	arXiv:2312.13150			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Apr 16 2024	2024	We introduce the method, an ultra-efficient approach for monocular 3D object reconstruction. Splatter Image is based on Gaussian Splatting, which allows fast and high-quality reconstruction of 3D scenes from multiple images. We apply Gaussian Splatting to monocular reconstruction by learning a neural network that, at test time, performs reconstruction in a feed-forward manner, at 38 FPS. Our main innovation is the surprisingly straightforward design of this network, which, using 2D operators, maps the input image to one 3D Gaussian per pixel. The resulting set of Gaussians thus has the form an image, the Splatter Image. We further extend the method take several images as input via cross-view attention. Owning to the speed of the renderer (588 FPS), we use a single GPU for training while generating entire images at each iteration to optimize perceptual metrics like LPIPS. On several synthetic, real, multi-category and large-scale benchmark datasets, we achieve better results in terms of PSNR, LPIPS, and other metrics while training and evaluating much faster than prior works.																																	2024-04-26	PPRN:86741723		
J	Chaudhari, Shreyas; Aggarwal, Pranjal; Murahari, Vishvak; Rajpurohit, Tanmay; Kalyan, Ashwin; Narasimhan, Karthik; Deshpande, Ameet; da Silva, Bruno Castro										RLHF Deciphered: A Critical Analysis of Reinforcement Learning from Human Feedback for LLMs								Arxiv											2	2;2024-04-16;https://www.arxiv.org/abs/2404.08555v2| 1;2024-04-12;https://www.arxiv.org/abs/2404.08555v1	arXiv:2404.08555			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 12 2024	2024	State-of-the-art large language models (LLMs) have become indispensable tools for various tasks. However, training LLMs to serve as effective assistants for humans requires careful consideration. A promising approach is reinforcement learning from human feedback (RLHF), which leverages human feedback to update the model in accordance with human preferences and mitigate issues like toxicity and hallucinations. Yet, an understanding of RLHF for LLMs is largely entangled with initial design choices that popularized the method and current research focuses on augmenting those choices rather than fundamentally improving the framework. In this paper, we analyze RLHF through the lens of reinforcement learning principles to develop an understanding of its fundamentals, dedicating substantial focus to the core component of RLHF—the reward model. Our study investigates modeling choices, caveats of function approximation, and their implications on RLHF training algorithms, highlighting the underlying assumptions made about the expressivity of reward. Our analysis improves the understanding of the role of reward models and methods for their training, concurrently revealing limitations of the current methodology. We characterize these limitations, including incorrect generalization, model misspecification, and the sparsity of feedback, along with their impact on the performance of a language model. The discussion and analysis are substantiated by a categorical review of current literature, serving as a reference for researchers and practitioners to understand the challenges of RLHF and build upon existing efforts.																																	2024-04-27	PPRN:88538151		
J	Mele, Antonio Anna										Introduction to Haar Measure Tools in Quantum Information: A Beginner's Tutorial								Arxiv											3	3;2024-04-09;https://www.arxiv.org/abs/2307.08956v4| 2;2024-03-06;https://www.arxiv.org/abs/2307.08956v3| 1;2023-07-18;https://www.arxiv.org/abs/2307.08956v1	arXiv:2307.08956			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 09 2024	2024	The Haar measure plays a vital role in quantum information, but its study often requires a deep understanding of representation theory, posing a challenge for beginners. This tutorial aims to provide a basic introduction to Haar measure tools in quantum information, utilizing only basic knowledge of linear algebra and thus aiming to make this topic more accessible. The tutorial begins by introducing the Haar measure with a specific emphasis on characterizing the moment operator, an essential element for computing integrals over the Haar measure. It also covers properties of the symmetric subspace and introduces helpful tools like tensor network diagrammatic notation, which aid in visualizing and simplifying calculations. Next, the tutorial explores the concept of unitary designs, providing equivalent definitions, and subsequently explores approximate notions of unitary designs, shedding light on the relationships between these different notions. Practical examples of Haar measure calculations are illustrated, including the derivation of well-known formulas such as the twirling of a quantum channel. Lastly, the tutorial showcases the applications of Haar measure calculations in quantum machine learning and classical shadow tomography.																																	2024-04-22	PPRN:73990288		
J			The LIGO Scientific Collaboration; the Virgo Collaboration; the KAGRA Collaboration								Observation of Gravitational Waves from the Coalescence of a 2.5–4.5 M⊙ Compact Object and a Neutron Star								Arxiv											1	1;2024-04-05;https://www.arxiv.org/abs/2404.04248v1	arXiv:2404.04248			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 05 2024	2024	We report the observation of a coalescing compact binary with component masses 2.5–4.5 M⊙ and 1.2–2.0 M⊙ (all measurements quoted at the 90% credible level). The gravitational -wave signal GW230529 181500 was observed during the fourth observing run of the LIGO–Virgo–KAGRA detector network on 2023 May 29 by the LIGO Livingston observatory. The primary component of the source has a mass less than 5 M⊙ at 99% credibility. We cannot definitively determine from gravitational -wave data alone whether either component of the source is a neutron star or a black hole. However, given existing estimates of the maximum neutron star mass, we find the most probable interpretation of the source to be the coalescence of a neutron star with a black hole that has a mass between the most massive neutron stars and the least massive black holes observed in the Galaxy. We estimate a merger rate density of 55−47+127 Gpc−3 yr−1 for compact binary coalescences with properties similar to the source of GW230529 181500; assuming that the source is a neutron star–black hole merger, GW230529 181500 -like sources constitute about 60% of the total merger rate inferred for neutron star–black hole coalescences. The discovery of this system implies an increase in the expected rate of neutron star–black hole mergers with electromagnetic counterparts and provides further evidence for compact objects existing within the purported lower mass gap.																																	2024-04-20	PPRN:88429771		
J	Fu, Yujia; Liang, Peng; Tahir, Amjed; Li, Zengyang; Shahin, Mojtaba; Yu, Jiaxin; Chen, Jinfu				Fu, Yujia/HJA-9391-2022; Zahedi, Mansooreh/LXX-0292-2024						Security Weaknesses of Copilot Generated Code in GitHub								Arxiv											2	2;2024-04-04;https://www.arxiv.org/abs/2310.02059v2| 1;2023-10-03;https://www.arxiv.org/abs/2310.02059v1	arXiv:2310.02059			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 04 2024	2024	Modern code generation tools, utilizing AI models like Large Language Models (LLMs), have gained popularity for producing functional code. However, their usage presents security challenges, often resulting in insecure code merging into the code base. Evaluating the quality of generated code, especially its security, is crucial. While prior research explored various aspects of code generation, the focus on security has been limited, mostly examining code produced in controlled environments rather than real-world scenarios. To address this gap, we conducted an empirical study, analyzing code snippets generated by GitHub Copilot from GitHub projects. Our analysis identified 452 snippets generated by Copilot, revealing a high likelihood of security issues, with 32.8% of Python and 24.5% of JavaScript snippets affected. These issues span 38 different Common Weakness Enumeration (CWE) categories, including significant ones like CWE-330: Use of Insufficiently Random Values, CWE-78: OS Command Injection, and CWE-94: Improper Control of Generation of Code. Notably, eight CWEs are among the 2023 CWE Top -25, highlighting their severity. Our findings confirm that developers should be careful when adding code generated by Copilot and should also run appropriate security checks as they accept the suggested code. It also shows that practitioners should cultivate corresponding security awareness and skills.																																	2024-04-19	PPRN:85378604		
J	Wang, Lean; Yang, Wenkai; Chen, Deli; Zhou, Hao; Lin, Yankai; Meng, Fandong; Zhou, Jie; Sun, Xu				Chen, De-Li/H-6867-2012						Towards Codable Watermarking for Injecting Multi-bits Information to LLMs								Arxiv											3	3;2023-11-27;https://www.arxiv.org/abs/2307.15992v2| 2;2023-07-29;https://www.arxiv.org/abs/2307.15992v1| 1;2024-04-01;	arXiv:2307.15992			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 01 2024	2024	As large language models (LLMs) generate texts with increasing fluency and realism, there is a growing need to identify the source of texts to prevent the abuse of LLMs. Text watermarking techniques have proven reliable in distinguishing whether a text is generated by LLMs by injecting hidden patterns. However, we argue that existing LLM watermarking methods are encoding-inefficient and cannot flexibly meet the diverse information encoding needs (such as encoding model version, generation time, user id, etc.). In this work, we conduct the first systematic study on the topic of Codable Text Watermarking for LLMs (CTWL) that allows text watermarks to carry multi-bit customizable information. First of all, we study the taxonomy of LLM watermarking technologies and give a mathematical formulation for CTWL. Additionally, we provide a comprehensive evaluation system for CTWL: (1) watermarking success rate, (2) robustness against various corruptions, (3) coding rate of payload information, (4) encoding and decoding efficiency, (5) impacts on the quality of the generated text. To meet the requirements of these non-Pareto-improving metrics, we follow the most prominent vocabulary partition-based watermarking direction, and devise an advanced CTWL method named Balance-Marking. The core idea of our method is to use a proxy language model to split the vocabulary into probability-balanced parts, thereby effectively maintaining the quality of the watermarked text. 																																	2024-11-16	PPRN:74184876		
J	Hammoudeh, Zayd; Lowd, Daniel										Training Data Influence Analysis and Estimation: A Survey								Arxiv											2	2;2024-03-29;https://www.arxiv.org/abs/2212.04612v3| 1;2022-12-09;https://www.arxiv.org/abs/2212.04612v1	arXiv:2212.04612			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 29 2024	2024	Good models require good training data. For overparameterized deep models, the causal relationship between training data and model predictions is increasingly opaque and poorly understood. Influence analysis partially demystifies training's underlying interactions by quantifying the amount each training instance alters the final model. Measuring the training data's influence exactly can be provably hard in the worst case; this has led to the development and use of influence estimators, which only approximate the true influence. This paper provides the first comprehensive survey of training data influence analysis and estimation. We begin by formalizing the various, and in places orthogonal, definitions of training data influence. We then organize state-of-the-art influence analysis methods into a taxonomy; we describe each of these methods in detail and compare their underlying assumptions, asymptotic complexities, and overall strengths and weaknesses. Finally, we propose future research directions to make influence analysis more useful in practice as well as more theoretically and empirically sound. 																																	2024-04-18	PPRN:35897039		
J	Gong, Anqi; Cammerer, Sebastian; Renes, Joseph M.										Toward Low-latency Iterative Decoding of QLDPC Codes Under Circuit-Level Noise								Arxiv											1	1;2024-03-27;https://www.arxiv.org/abs/2403.18901v1	arXiv:2403.18901			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 27 2024	2024	We introduce a sliding window decoder based on belief propagation (BP) with guided decimation for the purposes of decoding quantum low-density parity-check codes in the presence of circuit-level noise. Windowed decoding keeps the decoding complexity reasonable when, as is typically the case, repeated rounds of syndrome extraction are required to decode. Within each window, we employ several rounds of BP with decimation of the variable node that we expect to be the most likely to flip in each round, Furthermore, we employ ensemble decoding to keep both decimation options (guesses) open in a small number of chosen rounds. We term the resulting decoder BP with guided decimation guessing (GDG). Applied to bivariate bicycle codes, GDG achieves a similar logical error rate as BP with an additional OSD post -processing stage (BP+OSD) and combination-sweep of order 10. For a window size of three syndrome cycles, a multi-threaded CPU implementation of GDG achieves a worst-case decoding latency of 3ms per window for the [[144,12,12]] code. 																																	2024-04-15	PPRN:88335909		
J	Manas, Oscar; Astolfi, Pietro; Hall, Melissa; Ross, Candace; Urbanek, Jack; Williams, Adina; Agrawal, Aishwarya; Romero-Soriano, Adriana; Drozdzal, Michal										Improving Text-to-Image Consistency via Automatic Prompt Optimization								Arxiv											1	1;2024-03-26;https://www.arxiv.org/abs/2403.17804v1	arXiv:2403.17804			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 26 2024	2024	Impressive advances in text-to-image (T2I) generative models have yielded a plethora of high performing models which are able to generate aesthetically appealing, photorealistic images. Despite the progress, these models still struggle to produce images that are consistent with the input prompt, oftentimes failing to capture object quantities, relations and attributes properly. Existing solutions to improve prompt-image consistency suffer from the following challenges: (1) they oftentimes require model fine-tuning, (2) they only focus on nearby prompt samples, and (3) they are affected by unfavorable trade-offs among image quality, representation diversity, and prompt-image consistency. In this paper, we address these challenges and introduce a T2I optimization-by-prompting framework, OPT2I, which leverages a large language model (LLM) to improve prompt-image consistency in T2I models. Our framework starts from a user prompt and iteratively generates revised prompts with the goal of maximizing a consistency score. Our extensive validation on two datasets, MSCOCO and PartiPrompts, shows that OPT2I can boost the initial consistency score by up to 24.9% in terms of DSG score while preserving the FID and increasing the recall between generated and real data. Our work paves the way toward building more reliable and robust T2I systems by harnessing the power of LLMs.																																	2024-04-14	PPRN:88296804		
J	Ma, Ze; Zhou, Daquan; Wang, Xue-She; Yeh, Chun-Hsiao; Li, Xiuyu; Yang, Huanrui; Dong, Zhen; Keutzer, Kurt; Feng, Jiashi				Wang, Xue-She/LIG-6068-2024; Zhou, Daquan/ACT-7390-2022; Feng, Jiashi/AGX-6209-2022; huang, yinshan/JRX-4534-2023						Magic-Me: Identity-Specific Video Customized Diffusion								Arxiv											2	2;2024-03-20;https://www.arxiv.org/abs/2402.09368v2| 1;2024-02-14;https://www.arxiv.org/abs/2402.09368v1	arXiv:2402.09368			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 20 2024	2024	Creating content with specified identities (ID) has attracted significant interest in the field of generative models. In the field of text-to-image generation (T2I), subject-driven creation has achieved great progress with the identity controlled via reference images. However, its extension to video generation is not well explored. In this work, we propose a simple yet effective subject identity controllable video generation framework, termed Video Custom Diffusion (VCD). With a specified identity defined by a few images, VCD reinforces the identity characteristics and injects frame-wise correlation at the initialization stage for stable video outputs. To achieve this, we propose three novel components that are essential for high-quality identity preservation and stable video generation: 1) a noise initialization method with 3D Gaussian Noise Prior for better inter-frame stability; 2) an ID module based on extended Textual Inversion trained with the cropped identity to disentangle the ID information from the background 3) Face VCD and Tiled VCD modules to reinforce faces and upscale the video to higher resolution while preserving the identity's features. We conducted extensive experiments to verify that VCD is able to generate stable videos with better ID over the baselines. Besides, with the transferability of the encoded identity in the ID module, VCD is also working well with personalized text-to-image models available publicly. 																																	2024-04-12	PPRN:87688950		
J	Bueno, Pablo; Cano, Pablo A.; Hennigar, Robie A.				Bueno, Pablo/AAX-8202-2020; Hennigar, Robie/LFV-5213-2024						Regular Black Holes From Pure Gravity								Arxiv											2	2;2024-03-19;https://www.arxiv.org/abs/2403.04827v2| 1;2024-03-07;https://www.arxiv.org/abs/2403.04827v1	arXiv:2403.04827			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 19 2024	2024	We show via an explicit construction how an infinite tower of higher-curvature corrections generically leads to a resolution of the Schwarzschild singularity in any spacetime dimension D ≥ 5. The theories we consider have two key properties that ensure the results are general and robust: (1) they provide a basis for (vacuum) gravitational effective field theory in five and higher-dimensions, (2) for each value of the mass, they have a unique static spherically symmetric solution. We present several exact solutions of the theories that include the Hayward black hole and metrics similar to the Bardeen and Dymnikova ones. Unlike previous constructions, these regular black holes arise as vacuum solutions, as we include no matter fields whatsoever in our analysis. We show how the black hole thermodynamics can be studied in a completely universal and unambiguous way for all solutions.																																	2024-04-12	PPRN:88082531		
J	Chen, Zehui; Liu, Kuikun; Wang, Qiuchen; Zhang, Wenwei; Liu, Jiangning; Lin, Dahua; Chen, Kai; Zhao, Feng				Chen, Zehui/HDN-3605-2022; Zhao, Feng/NGQ-9015-2025; Lin, Dahua/W-6576-2019; Zhang, Wenwei/HKO-4277-2023						Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models								Arxiv											1	1;2024-03-19;https://www.arxiv.org/abs/2403.12881v1	arXiv:2403.12881			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 19 2024	2024	Open -sourced Large Language Models (LLMs) have achieved great success in various NLP tasks, however, they are still far inferior to API -based models when acting as agents. How to integrate agent ability into general LLMs becomes a crucial and urgent problem. This paper first delivers three key observations: (1) the current agent training corpus is entangled with both formats following and agent reasoning, which significantly shifts from the distribution of its pre -training data; (2) LLMs exhibit different learning speeds on the capabilities required by agent tasks; and (3) current approaches have side -effects when improving agent abilities by introducing hallucinations. Based on the above findings, we propose AgentFLAN to effectively Fine-tune LANguage models for Agents. Through careful decomposition and redesign of the training corpus, Agent -FLAN enables Llama2-7B to outperform prior best works by 3.5% across various agent evaluation datasets. With comprehensively constructed negative samples, Agent -FLAN greatly alleviates the hallucination issues based on our established evaluation benchmark. Besides, it consistently improves the agent capability of LLMs when scaling model sizes while slightly enhancing the general capability of LLMs. 																																	2024-04-12	PPRN:88242299		
J	Guo, Ziyao; Wang, Kai; Cazenavette, George; Li, Hui; Zhang, Kaipeng; You, Yang				Zhang, Kaipeng/IAN-8361-2023; Wang, Kai/K-4586-2012						Towards Lossless Dataset Distillation via Difficulty-Aligned Trajectory Matching								Arxiv											2	2;2024-03-18;https://www.arxiv.org/abs/2310.05773v2| 1;2023-10-09;https://www.arxiv.org/abs/2310.05773v1	arXiv:2310.05773			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 18 2024	2024	The ultimate goal of Dataset Distillation is to synthesize a small synthetic dataset such that a model trained on this synthetic set will perform equally well as a model trained on the full, real dataset. Until now, no method of Dataset Distillation has reached this completely lossless goal, in part due to the fact that previous methods only remain effective when the total number of synthetic samples is extremely small. Since only so much information can be contained in such a small number of samples, it seems that to achieve truly loss dataset distillation, we must develop a distillation method that remains effective as the size of the synthetic dataset grows. In this work, we present such an algorithm and elucidate why existing methods fail to generate larger, high-quality synthetic sets. Current state-of-the-art methods rely on trajectory-matching, or optimizing the synthetic data to induce similar long-term training dynamics as the real data. We empirically find that the training stage of the trajectories we choose to match (i.e., early or late) greatly affects the effectiveness of the distilled dataset. Specifically, early trajectories (where the teacher network learns easy patterns) work well for a low-cardinality synthetic set since there are fewer examples wherein to distribute the necessary information. Conversely, late trajectories (where the teacher network learns hard patterns) provide better signals for larger synthetic sets since there are now enough samples to represent the necessary complex patterns. Based on our findings, we propose to align the difficulty of the generated patterns with the size of the synthetic dataset. In doing so, we successfully scale trajectory matching-based methods to larger synthetic datasets, achieving lossless dataset distillation for the very first time. 																																	2024-04-11	PPRN:85583129		
J	Bilkis, M.; Cerezo, M.; Verdon, Guillaume; Coles, Patrick J.; Cincio, Lukasz				Cerezo, Marco/ABD-9254-2020						A semi-agnostic ansatz with variable structure for Variational Quantum Algorithms								Arxiv											3	3;2024-03-14;https://www.arxiv.org/abs/2103.06712v4| 2;2023-01-30;https://www.arxiv.org/abs/2103.06712v3| 1;2021-03-11;https://www.arxiv.org/abs/2103.06712v2	arXiv:2103.06712			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 14 2024	2024	Quantum machine learning— and specifically Variational Quantum Algorithms (VQAs)— offers a powerful, flexible paradigm for programming near-term quantum computers, with applications in chemistry, metrology, materials science, data science, and mathematics. Here, one trains an ansatz, in the form of a parameterized quantum circuit, to accomplish a task of interest. However, challenges have recently emerged suggesting that deep ansatzes are difficult to train, due to flat training landscapes caused by randomness or by hardware noise. This motivates our work, where we present a variable structure approach to build ansatzes for VQAs. Our approach, called VAns (Variable Ansatz), applies a set of rules to both grow and (crucially) remove quantum gates in an informed manner during the optimization. Consequently, VAns is ideally suited to mitigate trainability and noise-related issues by keeping the ansatz shallow. We employ VAns in the variational quantum eigensolver for condensed matter and quantum chemistry applications, in the quantum autoencoder for data compression and in unitary compilation problems showing successful results in all cases.																																	2024-04-11	PPRN:12032444		
J	Ye, Jianglong; Wang, Peng; Li, Kejie; Shi, Yichun; Wang, Heng				Shi, Yichun/AGV-8080-2022; Li, Kejie/D-3595-2013						Consistent-1-to-3: Consistent Image to 3D View Synthesis via Geometry-aware Diffusion Models								Arxiv											2	2;2024-03-14;https://www.arxiv.org/abs/2310.03020v2| 1;2023-10-04;https://www.arxiv.org/abs/2310.03020v1	arXiv:2310.03020			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 14 2024	2024	Zero-shot novel view synthesis (NVS) from a single image is an essential problem in 3D object understanding. While recent approaches that leverage pre-trained generative models can synthesize high-quality novel views from in-the-wild inputs, they still struggle to maintain 3D consistency across different views. In this paper, we present Consistent-1-to-3, which is a generative framework that significantly mitigates this issue. Specifically, we decompose the NVS task into two stages: (i) transforming observed regions to a novel view, and (ii) hallucinating unseen regions. We design a scene representation transformer and view-conditioned diffusion model for performing these two stages respectively. Inside the models, to enforce 3D consistency, we propose to employ epipolor-guided attention to incorporate geometry constraints, and multi-view attention to better aggregate multi-view information. Finally, we design a hierarchy generation paradigm to generate long sequences of consistent views, allowing a full 360-degree observation of the provided object image. Qualitative and quantitative evaluation over multiple datasets demonstrates the effectiveness of the proposed mechanisms against state-of-the-art approaches. 																																	2024-04-11	PPRN:85421704		
J	Ma, Yue; He, Yingqing; Wang, Hongfa; Wang, Andong; Qi, Chenyang; Cai, Chengfei; Li, Xiu; Li, Zhifeng; Shum, Heung-Yeung; Liu, Wei; Chen, Qifeng				Wang, Yu-Zhong/S-5172-2019; Wang, Andong/N-6525-2018; Liu, Wei/L-1951-2019						Follow-Your-Click: Open-domain Regional Image Animation via Short Prompts								Arxiv											1	1;2024-03-13;https://www.arxiv.org/abs/2403.08268v1	arXiv:2403.08268			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Mar 13 2024	2024	Despite recent advances in image -to -video generation, better controllability and local animation are less explored. Most existing image -to -video methods are not locally aware and tend to move the entire scene. However, human artists may need to control the movement of different objects or regions. Additionally, current I2V methods require users not only to describe the target motion but also to provide redundant detailed descriptions of frame contents. These two issues hinder the practical utilization of current I2V tools. In this paper, we propose a practical framework, named Follow -Your -Click, to achieve image animation with a simple user click (for specifying what to move) and a short motion prompt (for specifying how to move). Technically, we propose the first -frame masking strategy, which significantly improves the video generation quality, and a motion -augmented module equipped with a short motion prompt dataset to improve the short prompt following abilities of our model. To further control the motion speed, we propose flow -based motion magnitude control to control the speed of target movement more precisely. Our framework has simpler yet precise user control and better generation performance than previous methods. Extensive experiments compared with 7 baselines, including both commercial tools and research methods on 8 metrics, suggest the superiority of our approach.																																	2024-04-11	PPRN:88133319		
J	Wu, Xuansheng; Zhao, Haiyan; Zhu, Yaochen; Shi, Yucheng; Yang, Fan; Liu, Tianming; Zhai, Xiaoming; Yao, Wenlin; Li, Jundong; Du, Mengnan; Liu, Ninghao				Liu, Tianming/GLS-1211-2022; Zhao, Haiyan/KHW-5412-2024; Wu, Xuansheng/JCE-2579-2023; Zhu, Yaochen/AAO-2023-2020; Zhai, Xiaoming/AAB-7129-2021; Shi, Yucheng/AAT-4428-2021; Yang, Fan/LGY-6359-2024; Du, Mengnan/MXL-9283-2025						Usable XAI: 10 Strategies Towards Exploiting Explainability in the LLM Era								Arxiv											1	1;2024-03-13;https://www.arxiv.org/abs/2403.08946v1	arXiv:2403.08946			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 13 2024	2024	Explainable AI (XAI) refers to techniques that provide human -understandable insights into the workings of AI models. Recently, the focus of XAI is being extended towards Large Language Models (LLMs) which are often criticized for their lack of transparency. This extension calls for a significant transformation in XAI methodologies because of two reasons. First, many existing XAI methods cannot be directly applied to LLMs due to their complexity and advanced capabilities. Second, as LLMs are increasingly deployed across diverse industry applications, the role of XAI shifts from merely opening the “black box” to actively enhancing the productivity and applicability of LLMs in real -world settings. Meanwhile, unlike traditional machine learning models that are passive recipients of XAI insights, the distinct abilities of LLMs can reciprocally enhance XAI. Therefore, in this paper, we introduce Usable XAI in the context of LLMs by analyzing (1) how XAI can benefit LLMs and AI systems, and (2) how LLMs can contribute to the advancement of XAI. We introduce 10 strategies, introducing the key techniques for each and discussing their associated challenges. We also provide case studies to demonstrate how to obtain and leverage explanations. The code used in this paper can be found at: https://github.com/JacksonWuxs/UsableXAI_LLM.																																	2024-04-11	PPRN:88145192		
J	Qiu, Ri-Zhao; Hu, Yafei; Yang, Ge; Song, Yuchen; Fu, Yang; Ye, Jianglong; Mu, Jiteng; Yang, Ruihan; Atanasov, Nikolay; Scherer, Sebastian; Wang, Xiaolong				Fu, Yang/AAC-6064-2019; Yang, Ruihan/AAC-7500-2020						Learning Generalizable Feature Fields for Mobile Manipulation								Arxiv											1	1;2024-03-12;https://www.arxiv.org/abs/2403.07563v1	arXiv:2403.07563			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 12 2024	2024	An open problem in mobile manipulation is how to represent objects and scenes in a unified manner so that robots can use it both for navigating in the environment and manipulating objects. The latter requires capturing intricate geometry while understanding fine-grained semantics, whereas the former involves capturing the complexity inherited to an expansive physical scale. In this work, we present GeFF (Generalizable Feature Fields), a scene-level generalizable neural feature field that acts as a unified representation for both navigation and manipulation that performs in real-time. To do so, we treat generative novel view synthesis as a pre-training task, and then align the resulting rich scene priors with natural language via CLIP feature distillation. We demonstrate the effectiveness of this approach by deploying GeFF on a quadrupedal robot equipped with a manipulator. We evaluate GeFF’s ability to generalize to open -set objects as well as running time when performing open vocabulary mobile manipulation in dynamic scenes.																																	2024-04-08	PPRN:88120638		
J	Ulhaq, Anwaar; Akhtar, Naveed				Ulhaq, Anwaar/AAN-5714-2020						Efficient Diffusion Models for Vision: A Survey								Arxiv											2	2;2024-03-12;https://www.arxiv.org/abs/2210.09292v3| 1;2022-10-20;https://www.arxiv.org/abs/2210.09292v2	arXiv:2210.09292			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 12 2024	2024	Diffusion Models (DMs) have demonstrated state-of-the-art performance in content generation without requiring adversarial training. These models are trained using a two-step process. First, a forward - diffusion - process gradually adds noise to a datum (usually an image). Then, a backward - reverse diffusion - process gradually removes the noise to turn it into a sample of the target distribution being modelled. DMs are inspired by non-equilibrium thermodynamics and have inherent high computational complexity. Due to the frequent function evaluations and gradient calculations in high-dimensional spaces, these models incur considerable computational overhead during both training and inference stages. This can not only preclude the democratization of diffusion-based modelling, but also hinder the adaption of diffusion models in real-life applications. Not to mention, the efficiency of computational models is fast becoming a significant concern due to excessive energy consumption and environmental scares. These factors have led to multiple contributions in the literature that focus on devising computationally efficient DMs. In this review, we present the most recent advances in diffusion models for vision, specifically focusing on the important design aspects that affect the computational efficiency of DMs. In particular, we emphasize the recently proposed design choices that have led to more efficient DMs. Unlike the other recent reviews, which discuss diffusion models from a broad perspective, this survey is aimed at pushing this research direction forward by highlighting the design strategies in the literature that are resulting in practicable models for the broader research community. We also provide a future outlook of diffusion models in vision from their computational efficiency viewpoint.																																	2024-04-08	PPRN:22125594		
J	Farebrother, Jesse; Orbay, Jordi; Vuong, Quan; Taiga, Adrien Ali; Chebotar, Yevgen; Xiao, Ted; Irpan, Alex; Levine, Sergey; Castro, Pablo Samuel; Faust, Aleksandra; Kumar, Aviral; Agarwal, Rishabh				Vuong, Quan-Hoang/F-2115-2010						Stop Regressing: Training Value Functions via Classification for Scalable Deep RL								Arxiv											1	1;2024-03-06;https://www.arxiv.org/abs/2403.03950v1	arXiv:2403.03950			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 06 2024	2024	Value functions are a central component of deep reinforcement learning (RL). These functions, parameterized by neural networks, are trained using a mean squared error regression objective to match bootstrapped target values. However, scaling value-based RL methods that use regression to large networks, such as high-capacity Transformers, has proven challenging. This difficulty is in stark contrast to supervised learning: by leveraging a cross-entropy classification loss, supervised methods have scaled reliably to massive networks. Observing this discrepancy, in this paper, we investigate whether the scalability of deep RL can also be improved simply by using classification in place of regression for training value functions. We demonstrate that value functions trained with categorical cross-entropy significantly improves performance and scalability in a variety of domains. These include: single-task RL on Atari 2600 games with SoftMoEs, multi-task RL on Atari with large-scale ResNets, robotic manipulation with Q-transformers, playing Chess without search, and a language-agent Wordle task with high-capacity Transformers, achieving state-of-the-art results on these domains. Through careful analysis, we show that the benefits of categorical cross-entropy primarily stem from its ability to mitigate issues inherent to value-based RL, such as noisy targets and non-stationarity. Overall, we argue that a simple shift to training value functions with categorical cross-entropy can yield substantial improvements in the scalability of deep RL at little-to-no cost.																																	2024-04-03	PPRN:88048783		
J	Feng, Wenfeng; Hao, Chuzhan; Zhang, Yuewei; Han, Yu; Wang, Hao				zhang, yuewei/AAN-1480-2021; Feng, Wenfeng/ABH-2639-2020						Mixture-of-LoRAs: An Efficient Multitask Tuning for Large Language Models								Arxiv											1	1;2024-03-06;https://www.arxiv.org/abs/2403.03432v1	arXiv:2403.03432			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 06 2024	2024	Instruction Tuning has the potential to stimulate or enhance specific capabilities of large language models (LLMs). However, achieving the right balance of data is crucial to prevent catastrophic forgetting and interference between tasks. To address these limitations and enhance training flexibility, we propose the Mixture-of-LoRAs (MoA) architecture which is a novel and parameter-efficient tuning method designed for multi-task learning with LLMs. In this paper, we start by individually training multiple domain-specific LoRA modules using corresponding supervised corpus data. These LoRA modules can be aligned with the expert design principles observed in Mixture-of-Experts (MoE). Subsequently, we combine the multiple LoRAs using an explicit routing strategy and introduce domain labels to facilitate multi-task learning, which help prevent interference between tasks and ultimately enhances the performance of each individual task. Furthermore, each LoRA model can be iteratively adapted to a new domain, allowing for quick domain-specific adaptation. Experiments on diverse tasks demonstrate superior and robust performance, which can further promote the wide application of domain-specific LLMs																																	2024-04-03	PPRN:88043542		
J											Functional Interpolation for Relative Positions Improves Long Context Transformers								Arxiv											3	3;2024-03-03;https://www.arxiv.org/abs/2310.04418v2| 2;2023-10-06;https://www.arxiv.org/abs/2310.04418v1| 1;2023-10-06;https://www.arxiv.org/abs/2310.04418v1	arXiv:2310.04418			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 03 2024	2024	Preventing the performance decay of Transformers on inputs longer than those used for training has been an important challenge in extending the context length of these models. Though the Transformer architecture has fundamentally no limits on the input sequence lengths it can process, the choice of position encoding used during training can limit the performance of these models on longer inputs. We propose a novel functional relative position encoding with progressive interpolation, FIRE, to improve Transformer generalization to longer contexts. We theoretically prove that this can represent some of the popular relative position encodings, such as T5's RPE, Alibi, and Kerple. We next empirically show that FIRE models have better generalization to longer contexts on both zero-shot language modeling and long text benchmarks.																																	2024-03-31	PPRN:85519123		
J	Liu, Fei; Lin, Xi; Wang, Zhenkun; Yao, Shunyu; Tong, Xialiang; Yuan, Mingxuan; Zhang, Qingfu				Zhang, Qingfu/K-4320-2015; Yao, ShunYu/GWV-1046-2022						Large Language Model for Multi-objective Evolutionary Optimization								Arxiv											3	3;2023-10-25;https://www.arxiv.org/abs/2310.12541v2| 2;2023-10-19;https://www.arxiv.org/abs/2310.12541v1| 1;2024-03-01;	arXiv:2310.12541			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 01 2024	2024	Multiobjective evolutionary algorithms (MOEAs) are major methods for solving multiobjective optimization problems (MOPs). Many MOEAs have been proposed in the past decades, of which the search operators need a carefully handcrafted design with domain knowledge. Recently, some attempts have been made to replace the manually designed operators in MOEAs with learning-based operators (e.g., neural network models). However, much effort is still required for designing and training such models, and the learned operators might not generalize well on new problems. To tackle the above challenges, this work investigates a novel approach that leverages the powerful large language model (LLM) to design MOEA operators. With proper prompt engineering, we successfully let a general LLM serve as a black-box search operator for decomposition-based MOEA (MOEA/D) in a zero-shot manner. In addition, by learning from the LLM behavior, we further design an explicit white-box operator with randomness and propose a new version of decomposition-based MOEA, termed MOEA/D-LO. Experimental studies on different test benchmarks show that our proposed method can achieve competitive performance with widely used MOEAs. It is also promising to see the operator only learned from a few instances can have robust generalization performance on unseen problems with quite different patterns and settings. The results reveal the potential benefits of using pre-trained LLMs in the design of MOEAs.To foster reproducibility and accessibility, the source code is https://github.com/FeiLiu36/LLM4MOEA.																																	2025-11-07	PPRN:85719228		
J	Xia, Congying; Xing, Chen; Du, Jiangshu; Yang, Xinyi; Feng, Yihao; Xu, Ran; Yin, Wenpeng; Xiong, Caiming				Feng, Yihao/LVR-7524-2024; 邢, 陈/GWR-2940-2022						FOFO: A Benchmark to Evaluate LLMs' Format-Following Capability								Arxiv											1	1;2024-02-28;https://www.arxiv.org/abs/2402.18667v1	arXiv:2402.18667			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 28 2024	2024	This paper presents FoFo, a pioneering benchmark for evaluating large language models' (LLMs) ability to follow complex, domain-specific formats, a crucial yet underexamined capability for their application as AI agents. Despite LLMs' advancements, existing benchmarks fail to assess their format-following proficiency adequately. FoFo fills this gap with a diverse range of real-world formats and instructions, developed through an AI-Human collaborative method. Our evaluation across both open-source (e.g., Llama 2, WizardLM) and closed-source (e.g., GPT-4, PALM2, Gemini) LLMs highlights three key findings: open-source models significantly lag behind closed-source ones in format adherence; LLMs' format-following performance is independent of their content generation quality; and LLMs' format proficiency varies across different domains. These insights suggest the need for specialized tuning for format-following skills and highlight FoFo's role in guiding the selection of domain-specific AI agents. FoFo is released here 1																																	2024-03-28	PPRN:88005912		
J	Cheng, Tianheng; Song, Lin; Ge, Yixiao; Liu, Wenyu; Wang, Xinggang; Shan, Ying				Cheng, Tianheng/MIP-3645-2025; Wang, Xinggang/LSL-0946-2024						YOLO-World: Real-Time Open-Vocabulary Object Detection								Arxiv											3	3;2024-02-22;https://www.arxiv.org/abs/2401.17270v3| 2;2024-02-02;https://www.arxiv.org/abs/2401.17270v2| 1;2024-01-30;https://www.arxiv.org/abs/2401.17270v1	arXiv:2401.17270			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 22 2024	2024	The You Only Look Once (YOLO) series of detectors have established themselves as efficient and practical tools. However, their reliance on predefined and trained object categories limits their applicability in open scenarios. Addressing this limitation, we introduce YOLO-World, an innovative approach that enhances YOLO with open-vocabulary detection capabilities through vision-language modeling and pre-training on large-scale datasets. Specifically, we propose a new Re-parameterizable Vision-Language Path Aggregation Network (RepVL-PAN) and region-text contrastive loss to facilitate the interaction between visual and linguistic information. Our method excels in detecting a wide range of objects in a zero-shot manner with high efficiency. On the challenging LVIS dataset, YOLO-World achieves 35.4 AP with 52.0 FPS on V100, which outperforms many state-of-the-art methods in terms of both accuracy and speed. Furthermore, the fine-tuned YOLO-World achieves remarkable performance on several downstream tasks, including object detection and open-vocabulary instance segmentation.																																	2024-03-21	PPRN:87421857		
J	Liu, Yifan; Li, Chenxin; Yang, Chen; Yuan, Yixuan				yuan, yixuan/KLZ-6092-2024; Li, Chenxin/OZE-3193-2025						EndoGaussian: Real-time Gaussian Splatting for Dynamic Endoscopic Scene Reconstruction								Arxiv											2	2;2024-02-13;https://www.arxiv.org/abs/2401.12561v2| 1;2024-01-23;https://www.arxiv.org/abs/2401.12561v1	arXiv:2401.12561			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Feb 13 2024	2024	Reconstructing deformable tissues from endoscopic videos is essential in many downstream surgical applications. However, existing methods suffer from slow rendering speed, greatly limiting their practical use. In this paper, we introduce EndoGaussian, a real -time endoscopic scene reconstruction framework built on 3D Gaussian Splatting (3DGS). By integrating the efficient Gaussian representation and highly-optimized rendering engine, our framework significantly boosts the rendering speed to a real -time level. To adapt 3DGS for endoscopic scenes, we propose two strategies, Holistic Gaussian Initialization (HGI) and Spatio-temporal Gaussian Tracking (SGT), to handle the non -trivial Gaussian initialization and tissue deformation problems, respectively. In HGI, we leverage recent depth estimation models to predict depth maps of input binocular/mono cular image sequences, based on which pixels are re -pro jected and combined for holistic initialization. In SPT, we propose to model surface dynamics using a deformation field, which is composed of an efficient encoding voxel and a lightweight deformation decoder, allowing for Gaussian tracking with minor training and rendering burden. Experiments on public datasets demonstrate our efficacy against prior SOTAs in many aspects, including better rendering speed (195 FPS real -time, 100× gain), better rendering quality (37.848 PSNR), and less training overhead (within 2 min/scene), showing significant promise for intraoperative surgery applications. Code is available at:https://yifliu3.github.io/EndoGaussian/.																																	2024-02-29	PPRN:87300863		
J	Staffilani, Gigliola; Tran, Minh-Binh										On the wave turbulence theory for a stochastic KdV type equation								Arxiv											2	2;2024-02-12;https://www.arxiv.org/abs/2106.09819v5| 1;2021-06-17;https://www.arxiv.org/abs/2106.09819v4	arXiv:2106.09819			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 12 2024	2024	Starting from the Zakharov-Kuznetsov (ZK) equation, a multidimensional KdV type equation on a hypercubic lattice, we provide a derivation of the 3 -wave kinetic equation. We show that the two point correlation function can be asymptotically expressed as the solution of the 3 -wave kinetic equation at the kinetic limit under very general assumptions: the initial condition is out of equilibrium, the dimension is d ≥ 2, the smallness of the nonlinearity λ is allowed to be independent of the size D of the lattice. To the best of our knowledge, the work provides the first rigorous derivation of nonlinear 3 -wave kinetic equations. Also this is the first derivation for wave kinetic equations in the lattice setting and out -of -equilibrium.																																	2024-02-27	PPRN:12133648		
J	Shaik, Thanveer; Tao, Xiaohui; Xie, Haoran; Li, Lin; Zhu, Xiaofeng; Li, Qing				Zhu, Xiaofeng/HII-5291-2022; Shaik, Thanveer/AFV-4713-2022; Li, Li/AEM-3636-2022; Tao, Xiaohui/JKI-2330-2023; Xie, Haoran/AFS-3515-2022; Li, Qing/JMH-1365-2023						Exploring the Landscape of Machine Unlearning: A Comprehensive Survey and Taxonomy								Arxiv											4	4;2024-02-01;https://www.arxiv.org/abs/2305.06360v6| 3;2023-10-23;https://www.arxiv.org/abs/2305.06360v5| 2;2023-09-24;https://www.arxiv.org/abs/2305.06360v4| 1;2023-05-10;https://www.arxiv.org/abs/2305.06360v2	arXiv:2305.06360			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Feb 01 2024	2024	Machine unlearning (MU) is gaining increasing attention due to the need to remove or modify predictions made by machine learning (ML) models. While training models have become more efficient and accurate, the importance of unlearning previously learned information has become increasingly significant in fields such as privacy, security, and fairness. This paper presents a comprehensive survey of MU, covering current state-of-the-art techniques and approaches, including data deletion, perturbation, and model updates. In addition, commonly used metrics and datasets are also presented. The paper also highlights the challenges that need to be addressed, including attack sophistication, standardization, transferability, interpretability, training data, and resource constraints. The contributions of this paper include discussions about the potential benefits of MU and its future directions. Additionally, the paper emphasizes the need for researchers and practitioners to continue exploring and refining unlearning techniques to ensure that ML models can adapt to changing circumstances while maintaining user trust. The importance of unlearning is further highlighted in making Artificial Intelligence (AI) more trustworthy and transparent, especially with the increasing importance of AI in various domains that involve large amounts of personal user data.																																	2024-05-25	PPRN:69102384		
J	Cao, Yunkang; Xu, Xiaohao; Zhang, Jiangning; Cheng, Yuqi; Huang, Xiaonan; Pang, Guansong; Shen, Weiming				Huang, Xiaonan/AAP-6905-2020; Cheng, Yuqi/HMV-2015-2023						A Survey on Visual Anomaly Detection: Challenge, Approach, and Prospect								Arxiv											1	1;2024-01-29;https://www.arxiv.org/abs/2401.16402v1	arXiv:2401.16402			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 29 2024	2024	Visual Anomaly Detection (VAD) endeavors to 1 Dv ity f is l dali pinpoint deviations from the concept of normality in visual data, widely applied across diverse domains, e.g. , industrial defect inspection, and medi3 Complexity of hierarchical anomal cal lesion detection. This survey comprehensively S mples examines recent advancements in VAD by identifyingthree primary challenges: 1) scarcity of trainSample Numbe Data Modality ing data, 2) diversity of visual modalities, and 3) complexity of hierarchical anomalies. Starting with ... ... a brief overview of the VAD background and its Se i n p 2D D generic concept definitions, we progressively categorize, emphasize, and discuss the latest VAD progress from the perspective of sample number, datamodality, and anomaly hierarchy. Through an Few-shot Zero shot M lti-modality in-depth analysis of the VAD field, we finally summarize future developments for VAD and conclude ee /Uns e No ma mp es Anomaly Hierarchy e se Ab mpl the key findings and contributions of this survey.																																	2024-05-25	PPRN:87389710		
J	Wu, Yuanwei; Li, Xiang; Liu, Yixin; Zhou, Pan; Sun, Lichao										Jailbreaking GPT-4V via Self-Adversarial Attacks with System Prompts								Arxiv											2	2;2024-01-20;https://www.arxiv.org/abs/2311.09127v2| 1;2023-11-15;https://www.arxiv.org/abs/2311.09127v1	arXiv:2311.09127			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 20 2024	2024	Existing work on jailbreak Multimodal Large Language Models (MLLMs) has focused primarily on adversarial examples in model inputs, with less attention to vulnerabilities, especially in model API. To fill the research gap, we carry out the following work: 1) We discover a system prompt leakage vulnerability in GPT-4V. Through carefully designed dialogue, we successfully extract the internal system prompts of GPT-4V. This finding indicates potential exploitable security risks in MLLMs; 2) Based on the acquired system prompts, we propose a novel MLLM jailbreaking attack method termed SASP (Self-Adversarial Attack via System Prompt). By employing GPT-4 as a red teaming tool against itself, we aim to search for potential jailbreak prompts leveraging stolen system prompts. Furthermore, in pursuit of better performance, we also add human modification based on GPT-4's analysis, which further improves the attack success rate to 98.7%; 3) We evaluated the effect of modifying system prompts to defend against jailbreaking attacks. Results show that appropriately designed system prompts can significantly reduce jailbreak success rates. Overall, our work provides new insights into enhancing MLLM security, demonstrating the important role of system prompts in jailbreaking. This finding could be leveraged to greatly facilitate jailbreak success rates while also holding the potential for defending against jailbreaks.																																	2024-05-25	PPRN:86172915		
J	Liu, Zhiyuan; Li, Sihang; Luo, Yanchen; Fei, Hao; Cao, Yixin; Kawaguchi, Kenji; Wang, Xiang; Chua, Tat-Seng				Liu, Zhiyuan/I-2233-2014; Wang, Meng/AEZ-9059-2022; cao, yixin/ABV-6408-2022; Kawaguchi, Kenji/AAR-8297-2020; Fei, Hao/IZD-5292-2023						MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter								Arxiv											4	4;2024-01-18;https://www.arxiv.org/abs/2310.12798v4| 3;2024-01-15;https://www.arxiv.org/abs/2310.12798v3| 2;2023-11-07;https://www.arxiv.org/abs/2310.12798v2| 1;2023-10-19;https://www.arxiv.org/abs/2310.12798v1	arXiv:2310.12798			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 18 2024	2024	Language Models (LMs) have demonstrated impressive molecule understanding ability on various 1D text-related tasks. However, they inherently lack 2D graph perception - a critical ability of human professionals in comprehending molecules' topological structures. To bridge this gap, we propose MolCA: Molecular Graph-Language Modeling with Cross-Modal Projector and Uni-Modal Adapter. MolCA enables an LM (e.g., Galactica) to understand both text- and graph-based molecular contents via the cross-modal projector. Specifically, the cross-modal projector is implemented as a Q-Former to connect a graph encoder's representation space and an LM's text space. Further, MolCA employs a uni-modal adapter (i.e., LoRA) for the LM's efficient adaptation to downstream tasks. Unlike previous studies that couple an LM with a graph encoder via cross-modal contrastive learning, MolCA retains the LM's ability of open-ended text generation and augments it with 2D graph information. To showcase its effectiveness, we extensively benchmark MolCA on tasks of molecule captioning, IUPAC name prediction, and molecule-text retrieval, on which MolCA significantly outperforms the baselines. Our codes and checkpoints can be found at https://github.com/acharkq/MolCA.																																	2024-05-25	PPRN:85720764		
J	Song, Yakun; Chen, Zhuo; Wang, Xiaofei; Ma, Ziyang; Chen, Xie				song, yakun/IUO-2479-2023						ELLA-V: Stable Neural Codec Language Modeling with Alignment-guided Sequence Reordering								Arxiv											1	1;2024-01-14;https://www.arxiv.org/abs/2401.07333v1	arXiv:2401.07333			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 14 2024	2024	The language model (LM) approach based on acoustic and linguistic prompts, such as VALL-E, has achieved remarkable progress in the field of zero-shot audio generation. However, existing methods still have some limitations: 1) repetitions, transpositions, and omissions in the output synthesized speech due to limited alignment constraints between audio and phoneme tokens; 2) challenges of fine-grained control over the synthesized speech with autoregressive (AR) language model; 3) infinite silence generation due to the nature of AR-based decoding, especially under the greedy strategy. To alleviate these issues, we propose ELLA-V, a simple but efficient LM-based zero-shot text-to-speech (TTS) framework, which enables fine-grained control over synthesized audio at the phoneme level. The key to ELLA-V is interleaving sequences of acoustic and phoneme tokens, where phoneme tokens appear ahead of the corresponding acoustic tokens. The experimental findings reveal that our model outperforms VALL-E in terms of accuracy and delivers more stable results using both greedy and sampling-based decoding strategies. The code of ELLA-V will be open-sourced after cleanups. 																																	2024-05-25	PPRN:87188774		
J	Hughes, John; Price, Sara; Lynch, Aengus; Schaeffer, Rylan; Barez, Fazl; Koyejo, Sanmi; Sleight, Henry; Jones, Erik; Perez, Ethan; Sharma, Mrinank										Best-of-N Jailbreaking								Arxiv											1	1;2024-12-19;https://www.arxiv.org/abs/2412.03556v2	arXiv:2412.03556			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 19 2024	2024	We introduce Best-of-N (BoN) Jailbreaking, a simple black-box algorithm that jailbreaks frontier AI systems across modalities. BoN Jailbreaking works by repeatedly sampling variations of a prompt with a combination of augmentations - such as random shuffling or capitalization for textual prompts - until a harmful response is elicited. We find that BoN Jailbreaking achieves high attack success rates (ASRs) on closed-source language models, such as 89% on GPT-4o and 78% on Claude 3.5 Sonnet when sampling 10,000 augmented prompts. Further, it is similarly effective at circumventing state-of-the-art open-source defenses like circuit breakers. BoN also seamlessly extends to other modalities: it jailbreaks vision language models (VLMs) such as GPT-4o and audio language models (ALMs) like Gemini 1.5 Pro, using modality-specific augmentations. BoN reliably improves when we sample more augmented prompts. Across all modalities, ASR, as a function of the number of samples (N), empirically follows power-law-like behavior for many orders of magnitude. BoN Jailbreaking can also be composed with other black-box algorithms for even more effective attacks - combining BoN with an optimized prefix attack achieves up to a 35% increase in ASR. Overall, our work indicates that, despite their capability, language models are sensitive to seemingly innocuous changes to inputs, which attackers can exploit across modalities.																																	2025-01-29	PPRN:119700068		
J	Zhao, Haozhe; Ma, Xiaojian; Chen, Liang; Si, Shuzheng; Wu, Rujie; An, Kaikai; Yu, Peiyu; Zhang, Minjia; Li, Qing; Chang, Baobao				Zhang, Minjia/MFH-5718-2025						UltraEdit: Instruction-based Fine-Grained Image Editing at Scale								Arxiv											2	2;2024-12-19;https://www.arxiv.org/abs/2407.05282v2| 1;2024-07-01;	arXiv:2407.05282			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 19 2024	2024	This paper presents UltraEdit, a large-scale (approximately 4 million editing samples), automatically generated dataset for instruction-based image editing. Our key idea is to address the drawbacks in existing image editing datasets like InstructPix2Pix and MagicBrush, and provide a systematic approach to producing massive and high-quality image editing samples. UltraEdit offers several distinct advantages: 1) It features a broader range of editing instructions by leveraging the creativity of large language models (LLMs) alongside in-context editing examples from human raters; 2) Its data sources are based on real images, including photographs and artworks, which provide greater diversity and reduced bias compared to datasets solely generated by text-to-image models; 3) It also supports region-based editing, enhanced by high-quality, automatically produced region annotations. Our experiments show that canonical diffusion-based editing baselines trained on UltraEdit set new records on MagicBrush and Emu-Edit benchmarks. Our analysis further confirms the crucial role of real image anchors and region-based editing data. 																																	2025-01-26	PPRN:118689095		
J	Xu, Yuemei; Hu, Ling; Zhao, Jiayi; Qiu, Zihan; Xu, Kexin; Ye, Yuqi; Gu, Hanwen				ye, yuqi/IVV-6836-2023						A Survey on Multilingual Large Language Models: Corpora, Alignment, and Bias								Arxiv											2	2;2024-12-09;https://www.arxiv.org/abs/2404.00929v3| 1;2024-06-06;https://www.arxiv.org/abs/2404.00929v2	arXiv:2404.00929			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 09 2024	2024	Based on the foundation of Large Language Models (LLMs), Multilingual LLMs (MLLMs) have been developed to address the challenges faced in multilingual natural language processing, hoping to achieve knowledge transfer from high- resource languages to low-resource languages. However, significant limitations and challenges still exist, such as language imbalance, multilingual alignment, and inherent bias. In this paper, we aim to provide a comprehensive analysis of MLLMs, delving deeply into discussions surrounding these critical issues. First of all, we start by presenting an overview of MLLMs, covering their evolutions, key techniques, and multilingual capacities. Secondly, we explore the multilingual training corpora of MLLMs and the multilingual datasets oriented for downstream tasks that are crucial to enhance the cross-lingual capability of MLLMs. Thirdly, we survey the state-of-theart studies of multilingual representations and investigate whether the current MLLMs can learn a universal language representation. Fourthly, we discuss bias on MLLMs, including its categories, evaluation metrics, and debiasing techniques. Finally, we discuss existing challenges and point out promising research directions of MLLMs.																																	2025-01-17	PPRN:89261249		
J	Turkeshi, Xhek; Calabrese, Pasquale; De Luca, Andrea				Turkeshi, Xhek/LFT-4234-2024						Quantum Mpemba Effect in Random Circuits								Arxiv											2	2;2024-11-30;https://www.arxiv.org/abs/2405.14514v2| 1;2024-05-23;https://www.arxiv.org/abs/2405.14514v1	arXiv:2405.14514			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 30 2024	2024	The essence of the Mpemba effect is that non-equilibrium systems may relax faster the further they are from their equilibrium configuration. In the quantum realm, this phenomenon arises in the dynamics of closed systems, where it is witnessed by fundamental features such as symmetry and entanglement. Here, we study the quantum Mpemba effect in charge-preserving random circuits on qudits combining extensive numerical simulations and analytical arguments. We show that the more asymmetric certain classes of initial states (tilted ferromagnets) are, the faster they restore symmetry and reach the grand-canonical ensemble. Conversely, other classes of states (tilted antiferromagnets) do not show the Mpemba effect. We provide a simple and general mechanism underlying the effect, based on the spreading of nonconserved operators in terms of conserved densities. Our analysis is based on minimal principles—locality, unitarity, and symmetry. Consequently, our results represent a significant advancement in clarifying the emergence of Mpemba physics in chaotic systems.																																	2025-01-11	PPRN:88982964		
J	Zhao, Guosheng; Ni, Chaojun; Wang, Xiaofeng; Zhu, Zheng; Zhang, Xueyang; Wang, Yida; Huang, Guan; Chen, Xinze; Wang, Boyuan; Zhang, Youyi; Mei, Wenjun; Wang, Xingang				Wang, Boyuan/AFK-6940-2022; Wang, Xiaofeng/LPQ-0701-2024; Wang, Jiarui/GQP-2582-2022						DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation								Arxiv											3	3;2024-11-25;https://www.arxiv.org/abs/2410.13571v3| 2;2024-10-21;https://www.arxiv.org/abs/2410.13571v2| 1;2024-10-17;https://www.arxiv.org/abs/2410.13571v1	arXiv:2410.13571			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 25 2024	2024	Closed-loop simulation is essential for advancing end-to-end autonomous driving systems. Contemporary sensor simulation methods, such as NeRF and 3DGS, rely predominantly on conditions closely aligned with training data distributions, which are largely confined to forward-driving scenarios. Consequently, these methods face limitations when rendering complex maneuvers (e.g., lane change, acceleration, deceleration). Recent advancements in autonomous-driving world models have demonstrated the potential to generate diverse driving videos. However, these approaches remain constrained to 2D video generation, inherently lacking the spatiotemporal coherence required to capture intricacies of dynamic driving environments. In this paper, we introduce DriveDreamer4D, which enhances 4D driving scene representation leveraging world model priors. Specifically, we utilize the world model as a data machine to synthesize novel trajectory videos, where structured conditions are explicitly leveraged to control the spatial-temporal consistency of traffic elements. Besides, the cousin data training strategy is proposed to facilitate merging real and synthetic data for optimizing 4DGS. To our knowledge, DriveDreamer4D is the first to utilize video generation models for improving 4D reconstruction in driving scenarios. Experimental results reveal that DriveDreamer4D significantly enhances generation quality under novel trajectory views, achieving a relative improvement in FID by 32.1%, 46.4%, and 16.3% compared to PVG, S3Gaussian, and Deformable-GS. Moreover, DriveDreamer4D markedly enhances the spatiotemporal coherence of driving agents, which is verified by a comprehensive user study and the relative increases of 22.6%, 43.5%, and 15.6% in the NTA-IoU metric.																																	2025-01-08	PPRN:115392420		
J	Shi, Luohe; Zhang, Hongyi; Yao, Yao; Li, Zuchao; Zhao, Hai				Li, ZhiHua/GYU-9914-2022; Zhang, Hongyi/GPX-3703-2022; Yao, Yao/OCL-4665-2025						Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption								Arxiv											4	4;2024-11-20;https://www.arxiv.org/abs/2407.18003v4| 3;2024-08-13;https://www.arxiv.org/abs/2407.18003v3| 2;2024-07-28;https://www.arxiv.org/abs/2407.18003v2| 1;2024-07-25;https://www.arxiv.org/abs/2407.18003v1	arXiv:2407.18003			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 20 2024	2024	Large Language Models (LLMs), epitomized by ChatGPT’s release in late 2022, have revolutionized various industries with their advanced language comprehension. However, their efficiency is challenged by the Transformer architecture’s struggle with handling long texts. KV Cache has emerged as a pivotal solution to this issue, converting the time complexity of token generation from quadratic to linear, albeit with increased GPU memory overhead proportional to conversation length. With the development of the LLM community and academia, various KV Cache compression methods have been proposed. In this review, we dissect the various properties of KV Cache and elaborate on various methods currently used to optimize the KV Cache space usage of LLMs. These methods span the pre-training phase, deployment phase, and inference phase, and we summarize the commonalities and differences among these methods. Additionally, we list some metrics for evaluating the long-text capabilities of large language models, from both efficiency and capability perspectives. Our review thus sheds light on the evolving landscape of LLM optimization, offering insights into future advancements in this dynamic field. 																																	2024-12-31	PPRN:91102842		
J	Zhang, Chong; Xiao, Wenli; He, Tairan; Shi, Guanya										WoCoCo: Learning Whole-Body Humanoid Control with Sequential Contacts								Arxiv											2	2;2024-11-07;https://www.arxiv.org/abs/2406.06005v2| 1;2024-06-10;https://www.arxiv.org/abs/2406.06005v1	arXiv:2406.06005			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 07 2024	2024	Humanoid activities involving sequential contacts are crucial for complex robotic interactions and operations in the real world and are traditionally solved by model-based motion planning, which is time-consuming and often relies on simplified dynamics models. Although model-free reinforcement learning (RL) has become a powerful tool for versatile and robust whole-body humanoid control, it still requires tedious task-specific tuning and state machine design and suffers from long-horizon exploration issues in tasks involving contact sequences. In this work, we propose WoCoCo (Whole-Body Co ntrol with Sequential Co ntacts), a unified framework to learn whole-body humanoid control with sequential contacts by naturally decomposing the tasks into separate contact stages. Such decomposition facilitates simple and general policy learning pipelines through task-agnostic reward and sim-to-real designs, requiring only one or two task-related terms to be specified for each task. We demonstrated that end- to-end RL-based controllers trained with WoCoCo enable four challenging whole- body humanoid tasks involving diverse contact sequences in the real world without any motion priors: 1) versatile parkour jumping, 2) box loco-manipulation, 3) dynamic clap-and-tap dancing, and 4) cliffside climbing. We further show that WoCoCo is a general framework beyond humanoid by applying it in 22-DoF dinosaur robot loco-manipulation tasks. 																																	2024-12-16	PPRN:89266308		
J	Brennan, T.Daniel; Sun, Zhengdi										A SymTFT for Continuous Symmetries								Arxiv											2	2;2024-11-05;https://www.arxiv.org/abs/2401.06128v3| 1;2024-04-15;https://www.arxiv.org/abs/2401.06128v2	arXiv:2401.06128			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 05 2024	2024	Symmetry is a powerful tool for studying dynamics in QFT: it provides selection rules, constrains RG flows, and often simplifies analysis. Currently, our understanding is that the most general form of symmetry is described by categorical symmetries which can be realized via Symmetry TQFTs or “SymTFTs.” In this paper, we show how the framework of the SymTFT, which is understood for discrete symmetries (i.e. finite categorical symmetries), can be generalized to continuous symmetries. In addition to demonstrating how U(1) global symmetries can be incorporated into the paradigm of the SymTFT, we apply our formalism to study cubic U(1) anomalies in 4d QFTs, describe the Q/Z non-invertible chiral symmetry in 4d theories, and conjecture the SymTFT for general continuous G(0)global symmetries.																																	2024-12-10	PPRN:88546117		
J	Romero, David; Lyu, Chenyang; Wibowo, Haryo Akbarianto; Lynn, Teresa; Hamed, Injy; Kishore, Aditya Nanda; Mandal, Aishik; Dragonetti, Alina; Abzaliev, Artem; Tonja, Atnafu Lambebo; Balcha, Bontu Fufa; Whitehouse, Chenxi; Salamea, Christian; Velasco, Dan John; Adelani, David Ifeoluwa; Meur, David Le; Villa-Cueva, Emilio; Koto, Fajri; Farooqui, Fauzan; Belcavello, Frederico; Batnasan, Ganzorig; Vallejo, Gisela; Caulfield, Grainne; Ivetta, Guido; Song, Haiyue; Ademtew, Henok Biadglign; Maina, Hernan; Lovenia, Holy; Azime, Israel Abebe; Cruz, Jan Christian Blaise; Gala, Jay; Geng, Jiahui; Ortiz-Barajas, Jesus-German; Baek, Jinheon; Dunstan, Jocelyn; Alemany, Laura Alonso; Nagasinghe, Kumaranage Ravindu Yasas; Benotti, Luciana; D'Haro, Luis Fernando; Viridiano, Marcelo; Estecha-Garitagoitia, Marcos; Cabrera, Maria Camila Buitrago; Rodriguez-Cantelar, Mario; Jouitteau, Melanie; Mihaylov, Mihail; Imam, Mohamed Fazli Mohamed; Adilazuarda, Muhammad Farid; Gochoo, Munkhjargal; Otgonbold, Munkh-Erdene; Etori, Naome; Niyomugisha, Olivier; Silva, Paula Monica; Chitale, Pranjal; Dabre, Raj; Chevi, Rendi; Zhang, Ruochen; Diandaru, Ryandito; Cahyawijaya, Samuel; Gongora, Santiago; Jeong, Soyeong; Purkayastha, Sukannya; Kuribayashi, Tatsuki; Clifford, Teresa; Jayakumar, Thanmay; Torrent, Tiago Timponi; Ehsan, Toqeer; Araujo, Vladimir; Kementchedjhieva, Yova; Burzo, Zara; Lim, Zheng Wei; Yong, Zheng Xin; Ignat, Oana; Nwatu, Joan; Mihalcea, Rada; Solorio, Thamar; Aji, Alham Fikri				de Oliveira Silva, Paulo/R-8289-2018; Zhang, Ruochen/ABC-4628-2021; Araujo, Vladimir/IYJ-2611-2023; CHITALE, PRANJAL AGADH/FBW-9879-2022; D'Haro, Luis Fernando/B-8194-2011; Gochoo, Munkhjargal/AAB-1196-2022; Kuribayashi, Tatsuki/MAI-4000-2025; Koto, Fajri/ISS-6497-2023; Baek, Jinheon/HLX-1814-2023						CVQA: Culturally-diverse Multilingual Visual Question Answering Benchmark								Arxiv											2	2;2024-11-04;https://www.arxiv.org/abs/2406.05967v2| 1;2024-06-10;https://www.arxiv.org/abs/2406.05967v1	arXiv:2406.05967			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Nov 04 2024	2024	Visual Question Answering (VQA) is an important task in multimodal AI, and it is often used to test the ability of vision-language models to understand and reason on knowledge present in both visual and textual data. However, most of the current VQA models use datasets that are primarily focused on English and a few major world languages, with images that are typically Western-centric. While recent efforts have tried to increase the number of languages covered on VQA datasets, they still lack diversity in low-resource languages. More importantly, although these datasets often extend their linguistic range via translation or some other approaches, they usually keep images the same, resulting in narrow cultural representation. To address these limitations, we construct CVQA, a new Culturally-diverse multilingual Visual Question Answering benchmark, designed to cover a rich set of languages and cultures, where we engage native speakers and cultural experts in the data collection process. As a result, CVQA includes culturally-driven images and questions from across 30 countries on four continents, covering 31 languages with 13 scripts, providing a total of 10k questions. We then benchmark several Multimodal Large Language Models (MLLMs) on CVQA, and show that the dataset is challenging for the current state-of-the-art models. This benchmark can serve as a probing evaluation suite for assessing the cultural capability and bias of multimodal models and hopefully encourage more research efforts toward increasing cultural awareness and linguistic diversity in this field.																																	2024-12-16	PPRN:89267646		
J	Xie, Qianqian; Chen, Qingyu; Chen, Aokun; Peng, Cheng; Hu, Yan; Lin, Fongci; Peng, Xueqing; Huang, Jimin; Zhang, Jeffrey; Keloth, Vipina; Zhou, Xinyu; Qian, Lingfei; He, Huan; Shung, Dennis; Ohno-Machado, Lucila; Wu, Yonghui; Xu, Hua; Bian, Jiang				peng, cheng/AAM-1236-2021; Chen, Qingyu/JYQ-2478-2024; Peng, Xueqing/GSN-3085-2022						Me-LLaMA: Medical Foundation Large Language Models for Comprehensive Text Analysis and Beyond								Arxiv											5	5;2024-11-02;https://www.arxiv.org/abs/2402.12749v5| 4;2024-04-11;https://www.arxiv.org/abs/2402.12749v4| 3;2024-03-14;https://www.arxiv.org/abs/2402.12749v3| 2;2024-03-11;https://www.arxiv.org/abs/2402.12749v2| 1;2024-02-20;https://www.arxiv.org/abs/2402.12749v1	arXiv:2402.12749			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Nov 02 2024	2024	Background Recent advancements in large language models (LLMs) like ChatGPT and LLaMA have shown promise in medical applications, though their performance in medical language understanding still requires enhancement. This study aims to develop foundational medical LLMs by training open-source LLaMA models with large-scale, domain-specific datasets to enhance their efficacy across a variety of medical text analysis tasks and medical diagnosis. Methods We developed Me-LLaMA, a new medical LLM family that includes foundation models – Me-LLaMA 13/70B, and their chat-enhanced versions, through continual pre-training and instruction tuning of LLaMA2 using both biomedical literature and clinical notes. Me-LLaMA utilized the largest and most comprehensive medical data, including 129B pre-training tokens and 214K instruction tuning samples from diverse biomedical and clinical data sources. Training the 70B models required substantial computational resources, exceeding 100,000 A100 GPU hours. We applied Me-LLaMA to six medical text analysis tasks and evaluated its performance on 12 benchmark datasets. To further assess Me-LLaMA’s potential clinical utility, we evaluated its performance on complex clinical case diagnosis compared with other commercial LLMs, using both automatic and human evaluations. Results Me-LLaMA models outperform LLaMA, and other existing open-source medical LLMs in both zero-shot and supervised learning settings for most text analysis tasks. With task-specific instruction tuning, Me-LLaMA models also surpass leading commercial LLMs, outperforming ChatGPT on 7 out of 8 datasets and GPT-4 on 5 out of 8 datasets. Moreover, for diagnosing complex clinical cases, Me-LLaMA’s performance is comparable to ChatGPT and GPT-4. Conclusion Domain-specific data is crucial for building medical foundation LLMs that enhance diverse downstream text analysis tasks and medical applications. The substantial computing costs associated with training such models require careful consideration of training strategies (pretraining vs. fine-tuning). Me-LLaMA models are now publicly available through appropriate user agreements, making them a valuable resource for advancing medical AI applications.																																	2024-12-09	PPRN:87772163		
J	Gui, Lin; Garbacea, Cristina; Veitch, Victor				Gui, Lin/KRO-8983-2024						BoNBoN Alignment for Large Language Models and the Sweetness of Best-of-n Sampling								Arxiv											3	3;2024-11-01;https://www.arxiv.org/abs/2406.00832v3| 2;2024-06-05;https://www.arxiv.org/abs/2406.00832v2| 1;2024-06-02;https://www.arxiv.org/abs/2406.00832v1	arXiv:2406.00832			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 01 2024	2024	This paper concerns the problem of aligning samples from large language models to human preferences using best-of-n sampling, where we draw n samples, rank them, and return the best one. We consider two fundamental problems. First: what is the relationship between best-of-n and approaches to alignment that train LLMs to output samples with a high expected reward (e.g., RLHF or DPO)? To answer this, we embed both the best-of-n distribution and the sampling distributions learned by alignment procedures in a common class of tiltings of the base LLM distribution. We then show that, within this class, best-of-n is essentially optimal in terms of the trade-off between win-rate against the base model vs KL distance from the base model. That is, best-of-n is the best choice of alignment distribution if the goal is to maximize win rate. However, best-of-n requires drawing n samples for each inference, a substantial cost. To avoid this, the second problem we consider is how to fine-tune a LLM to mimic the best-of-n sampling distribution. We derive BoNBoN Alignment to achieve this by exploiting the special structure of the best-of-n distribution. Experiments show that BoNBoN alignment yields substantial improvements in producing a model that is preferred to the base policy while minimally affecting off-target aspects. 																																	2024-12-16	PPRN:89163227		
J	Bresch, Didier; Jabin, Pierre-Emmanuel; Soler, Juan				Soler, Juan/L-4627-2014						A new approach to the mean-field limit of Vlasov-Fokker-Planck equations								Arxiv											2	2;2024-10-31;https://www.arxiv.org/abs/2203.15747v4| 1;2022-03-29;https://www.arxiv.org/abs/2203.15747v3	arXiv:2203.15747			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 31 2024	2024	This article introduces a novel approach to the meanfield limit of stochastic systems of interacting particles, leading to the first ever derivation of the mean-field limit to the VlasovPoisson-Fokker-Planck system for plasmas in dimension 2 together with a partial result in dimension 3. The method is broadly compatible with second order systems that lead to kinetic equations and it relies on novel estimates on the BBGKY hierarchy. By taking advantage of the diffusion in velocity, those estimates bound weighted L p norms of the marginals or observables of the system, uniformly in the number of particles. This allows to qualitatively derive the mean-field limit for very singular interaction kernels between the particles, including repulsive Poisson interactions, together with quantitative estimates for a general kernel in L 2 .																																	2024-12-05	PPRN:44237740		
J	Rosati, Domenic; Wehner, Jan; Williams, Kai; Bartoszcze, Lukasz; Atanasov, David; Gonzales, Robie; Majumdar, Subhabrata; Maple, Carsten; Sajjad, Hassan; Rudzicz, Frank				Sajjad, Hassan/AAG-8665-2019						Representation Noising: A Defence Mechanism Against Harmful Finetuning								Arxiv											3	3;2024-10-30;https://www.arxiv.org/abs/2405.14577v4| 2;2024-10-07;https://www.arxiv.org/abs/2405.14577v2| 1;2024-05-23;https://www.arxiv.org/abs/2405.14577v1	arXiv:2405.14577			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 30 2024	2024	Releasing open-source large language models (LLMs) presents a dual-use risk since bad actors can easily fine-tune these models for harmful purposes. Even without the open release of weights, weight stealing and fine-tuning APIs make closed models vulnerable to harmful fine-tuning attacks (HFAs). While safety measures like preventing jailbreaks and improving safety guardrails are important, such measures can easily be reversed through fine-tuning. In this work, we propose Representation Noising (RepNoise), a defence mechanism that operates even when attackers have access to the weights. RepNoise works by removing information about harmful representations such that it is difficult to recover them during fine-tuning. Importantly, our defence is also able to generalize across different subsets of harm that have not been seen during the defence process as long as they are drawn from the same distribution of the attack set. Our method does not degrade the general capability of LLMs and retains the ability to train the model on harmless tasks. We provide empirical evidence that the efficacy of our defence lies in its ``depth'': the degree to which information about harmful representations is removed across all layers of the LLM. We also find areas where RepNoise still remains ineffective and highlight how those limitations can inform future research.																																	2024-12-06	PPRN:88989615		
J	Wu, Jianzong; Li, Xiangtai; Zeng, Yanhong; Zhang, Jiangning; Zhou, Qianyu; Li, Yining; Tong, Yunhai; Chen, Kai				zeng, yanhong/Y-2891-2018; Yan, Shuicheng/HCI-1431-2022; Wu, Jianzong/LBH-7900-2024						MotionBooth: Motion-Aware Customized Text-to-Video Generation								Arxiv											3	3;2024-10-29;https://www.arxiv.org/abs/2406.17758v3| 2;2024-08-21;https://www.arxiv.org/abs/2406.17758v2| 1;2024-06-25;https://www.arxiv.org/abs/2406.17758v1	arXiv:2406.17758			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 29 2024	2024	In this work, we present MotionBooth, an innovative framework designed for animating customized subjects with precise control over both object and camera movements. By leveraging a few images of a specific object, we efficiently finetune a text-to-video model to capture the object’s shape and attributes accurately. Our approach presents subject region loss and video preservation loss to enhance the subject’s learning performance, along with a subject token cross-attention loss to integrate the customized subject with motion control signals. Additionally, we propose training-free techniques for managing subject and camera motions during inference. In particular, we utilize cross-attention map manipulation to govern subject motion and introduce a novel latent shift module for camera movement control as well. MotionBooth excels in preserving the appearance of subjects while simultaneously controlling the motions in generated videos. Extensive quantitative and qualitative evaluations demonstrate the superiority and effectiveness of our method. Models and codes will be made publicly available.																																	2024-11-30	PPRN:89503112		
J	Wu, Rongyuan; Sun, Lingchen; Ma, Zhiyuan; Zhang, Lei				Wu, Rongyuan/OGA-8118-2025; MA, Zhiyuan/HKV-3827-2023; Zhang, Lei/HSC-7058-2023						One-Step Effective Diffusion Network for Real-World Image Super-Resolution								Arxiv											3	3;2024-10-24;https://www.arxiv.org/abs/2406.08177v3| 2;2024-06-14;https://www.arxiv.org/abs/2406.08177v2| 1;2024-06-12;https://www.arxiv.org/abs/2406.08177v1	arXiv:2406.08177			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 24 2024	2024	The pre-trained text-to-image diffusion models have been increasingly employed to tackle the real-world image super-resolution (Real-ISR) problem due to their powerful generative image priors. Most of the existing methods start from random noise to reconstruct the high-quality (HQ) image under the guidance of the given low-quality (LQ) image. While promising results have been achieved, such RealISR methods require multiple diffusion steps to reproduce the HQ image, increasing the computational cost. Meanwhile, the random noise introduces uncertainty in the output, which is unfriendly to image restoration tasks. To address these issues, we propose a one-step effective diffusion network, namely OSEDiff, for the RealISR problem. We argue that the LQ image contains rich information to restore its HQ counterpart, and hence the given LQ image can be directly taken as the starting point for diffusion, eliminating the uncertainty introduced by random noise sampling. We finetune the pre-trained diffusion network with trainable layers to adapt it to complex image degradations. To ensure that the one-step diffusion model could yield HQ Real-ISR output, we apply variational score distillation in the latent space to conduct KL-divergence regularization. As a result, our OSEDiff model can efficiently and effectively generate HQ images in just one diffusion step. Our experiments demonstrate that OSEDiff achieves comparable or even better Real-ISR results, in terms of both objective metrics and subjective evaluations, than previous diffusion model-based Real-ISR methods that require dozens or hundreds of steps. 																																	2024-11-27	PPRN:89290229		
J	Yoran, Ori; Amouyal, Samuel Joseph; Malaviya, Chaitanya; Bogin, Ben; Press, Ofir; Berant, Jonathan				Malaviya, Chaitanya/NXC-5110-2025						AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?								Arxiv											2	2;2024-10-21;https://www.arxiv.org/abs/2407.15711v2| 1;2024-07-22;https://www.arxiv.org/abs/2407.15711v1	arXiv:2407.15711			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 21 2024	2024	Language agents, built on top of language models (LMs), are systems that can interact with complex environments, such as the open web. In this work, we examine whether such agents can perform realistic and time-consuming tasks on the web, e.g., monitoring real-estate markets or locating relevant nearby businesses. We introduce AssistantBench, a challenging new benchmark consisting of 214 realistic tasks that can be automatically evaluated, covering different scenarios and domains. We find that AssistantBench exposes the limitations of current systems, including language models and retrieval-augmented language models, as no model reaches an accuracy of more than 26 points. While closed-book LMs perform well in terms of accuracy, they exhibit low precision and tend to hallucinate facts. State-of-the-art web agents reach a score of near zero. Additionally, we introduce SeePlanAct (SPA), a new web agent that significantly outperforms previous agents, and an ensemble of SPA and closed-book models reaches the best overall performance. Moreover, we analyze failures of current systems and highlight that open web navigation remains a major challenge.																																	2024-11-20	PPRN:91027262		
J	Liu, Yong; Zhang, Haoran; Li, Chenyu; Huang, Xiangdong; Wang, Jianmin; Long, Mingsheng				Li, Chenyu/HPH-7271-2023						Timer: Generative Pre-trained Transformers Are Large Time Series Models								Arxiv											3	3;2024-10-18;https://www.arxiv.org/abs/2402.02368v3| 2;2024-02-04;https://www.arxiv.org/abs/2402.02368v1| 1;2024-02-04;https://www.arxiv.org/abs/2402.02368v1	arXiv:2402.02368			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Oct 18 2024	2024	Deep learning has contributed remarkably to the advancement of time series analysis. Still, deep models can encounter performance bottlenecks in real-world data-scarce scenarios, which can be concealed due to the performance saturation with small models on current benchmarks. Meanwhile, large models have demonstrated great powers in these scenarios through large-scale pre-training. Continuous progress has been achieved with the emergence of large language models, exhibiting unprecedented abilities such as few-shot generalization, scalability, and task generality, which are however absent in small deep models. To change the status quo of training scenario-specific small models from scratch, this paper aims at the early development of large time series models (LTSM). During pre-training, we curate large-scale datasets with up to 1 billion time points, unify heterogeneous time series into single-series sequence (S3) format, and develop the GPT-style architecture toward LTSMs. To meet diverse application needs, we convert forecasting, imputation, and anomaly detection of time series into a unified generative task. The outcome of this study is a Time Series Transformer (Timer), which is generative pre-trained by next token prediction and adapted to various downstream tasks with promising capabilities as an LTSM. 																																	2024-11-17	PPRN:87523546		
J	Zhang, Bowen; Fu, Xianghua; Ding, Daijun; Huang, Hu; Dai, Genan; Yin, Nan; Li, Yangyang; Jing, Liwen				Huang, Hu/AFW-0648-2022; Zhang, Bowen/HHS-0516-2022						Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media								Arxiv											2	2;2024-10-17;https://www.arxiv.org/abs/2304.03087v2| 1;2023-04-06;https://www.arxiv.org/abs/2304.03087v1	arXiv:2304.03087			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 17 2024	2024	Stance detection predicts attitudes towards targets in texts and has gained attention with the rise of social media. Traditional approaches include conventional machine learning, early deep neural networks, and pre-trained finetuning models. However, with the evolution of very large pre-trained language models (VLPLMs) like ChatGPT (GPT-3.5), traditional methods face deployment challenges. The parameter-free Chain-of-Thought (CoT) approach, not requiring backpropagation training, has emerged as a promising alternative. This paper examines CoT’s effectiveness in stance detection tasks, demonstrating its superior accuracy and discussing associated challenges.																																	2024-11-07	PPRN:55157389		
J	Coda-Forno, Julian; Witte, Kristin; Jagadish, Akshay K.; Binz, Marcel; Akata, Zeynep; Schulz, Eric				Akata, Zeynep/I-6018-2016						Inducing anxiety in large language models can induce bias								Arxiv											2	2;2024-10-15;https://www.arxiv.org/abs/2304.11111v2| 1;2023-04-21;https://www.arxiv.org/abs/2304.11111v1	arXiv:2304.11111			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 15 2024	2024	Large language models (LLMs) are transforming research on machine learning while galvanizing public debates. Understanding not only when these models work well and succeed but also why they fail and misbehave is of great societal relevance. We propose to turn the lens of psychiatry, a framework used to describe and modify maladaptive behavior, to the outputs produced by these models. We focus on twelve established LLMs and subject them to a questionnaire commonly used in psychiatry. Our results show that six of the latest LLMs respond robustly to the anxiety questionnaire, producing comparable anxiety scores to humans. Moreover, the LLMs’ responses can be predictably changed by using anxiety-inducing prompts. Anxiety-induction not only influences LLMs’ scores on an anxiety questionnaire but also influences their behavior in a previously-established benchmark measuring biases1 such as racism and ageism. Importantly, greater anxiety-inducing text leads to stronger increases in biases, suggesting that how anxiously a prompt is communicated to large language models has a strong influence on their behavior in applied settings. These results demonstrate the usefulness of methods taken from psychiatry for studying the capable algorithms to which we increasingly delegate authority and autonomy.																																	2024-11-11	PPRN:65021949		
J	Lu, Yinquan; Zhu, Wenhao; Li, Lei; Qiao, Yu; Yuan, Fei				Qiao, Yu/ABD-5787-2021; zhu, wenhao/IJR-0851-2023						LLaMAX: Scaling Linguistic Horizons of LLM by Enhancing Translation Capabilities Beyond 100 Languages								Arxiv											2	2;2024-10-12;https://www.arxiv.org/abs/2407.05975v2| 1;2024-07-08;https://www.arxiv.org/abs/2407.05975v1	arXiv:2407.05975			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 12 2024	2024	Large Language Models (LLMs) demonstrate remarkable translation capabilities in high-resource language tasks, yet their performance in low-resource languages is hindered by insufficient multilingual data during pre-training. To address this, we conduct extensive multilingual continual pre-training on the LLaMA series models, enabling translation support across more than 100 languages. Through a comprehensive analysis of training strategies, such as vocabulary expansion and data augmentation, we develop LLaMAX. Remarkably, without sacrificing its generalization ability, LLaMAX achieves significantly higher translation performance compared to existing opensource LLMs (by more than 10 spBLEU points) and performs on-par with specialized translation model (M2M-100-12B) on the Flores-101 benchmark. Extensive experiments indicate that LLaMAX can serve as a robust multilingual foundation model. 																																	2024-11-11	PPRN:90738444		
J	Lei, Wenhui; Wei, Xu; Zhang, Xiaofan; Li, Kang; Zhang, Shaoting				Zhang, Xiaofan/ABG-4594-2021; lei, wenhui/LGZ-5354-2024						MedLSAM: Localize and Segment Anything Model for 3D CT Images								Arxiv											3	3;2024-10-09;https://www.arxiv.org/abs/2306.14752v4| 2;2023-11-16;https://www.arxiv.org/abs/2306.14752v3| 1;2023-06-26;https://www.arxiv.org/abs/2306.14752v1	arXiv:2306.14752			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 09 2024	2024	Recent advancements in foundation models have shown significant potential in medical image analysis. However, there is still a gap in models specifically designed for medical image localization. To address this, we introduce MedLAM, a 3D medical foundation localization model that accurately identifies any anatomical part within the body using only a few template scans. MedLAM employs two self-supervision tasks: unified anatomical mapping (UAM) and multi-scale similarity (MSS) across a comprehensive dataset of 14,012 CT scans. Furthermore, we developed MedLSAM by integrating MedLAM with the Segment Anything Model (SAM). This innovative framework requires extreme point annotations across three directions on several templates to enable MedLAM to locate the target anatomical structure in the image, with SAM performing the segmentation. It significantly reduces the amount of manual annotation required by SAM in 3D medical imaging scenarios. We conducted extensive experiments on two 3D datasets covering 38 distinct organs. Our findings are twofold: 1) MedLAM can directly localize anatomical structures using just a few template scans, achieving performance comparable to fully supervised models; 2) MedLSAM closely matches the performance of SAM and its specialized medical adaptations with manual prompts, while minimizing the need for extensive point annotations across the entire dataset. Moreover, MedLAM has the potential to be seamlessly integrated with future 3D SAM models, paving the way for enhanced segmentation performance.  ©2024 Elsevier B. V. All rights reserved.																																	2024-10-24	PPRN:73534329		
J	Jin, Bowen; Yoon, Jinsung; Han, Jiawei; Arik, Sercan O.				Jin, Bowen/HTR-0099-2023						Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG								Arxiv											1	1;2024-10-08;https://www.arxiv.org/abs/2410.05983v1	arXiv:2410.05983			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 08 2024	2024	Retrieval-augmented generation (RAG) empowers large language models (LLMs) to utilize external knowledge sources. The increasing capacity of LLMs to process longer input sequences opens up avenues for providing more retrieved information, to potentially enhance the quality of generated outputs. It is plausible to assume that a larger retrieval set would contain more relevant information (higher recall), that might result in improved performance. However, our empirical findings demonstrate that for many long-context LLMs, the quality of generated output initially improves first, but then subsequently declines as the number of retrieved passages increases. This paper investigates this phenomenon, identifying the detrimental impact of retrieved "hard negatives" as a key contributor. To mitigate this and enhance the robustness of long-context LLM-based RAG, we propose both training-free and training-based approaches. We first showcase the effectiveness of retrieval reordering as a simple yet powerful training-free optimization. Furthermore, we explore training-based methods, specifically RAG-specific implicit LLM fine-tuning and RAG-oriented fine-tuning with intermediate reasoning, demonstrating their capacity for substantial performance gains. Finally, we conduct a systematic analysis of design choices for these training-based methods, including data distribution, retriever selection, and training context length.																																	2024-10-29	PPRN:105760396		
J	Lami, Guglielmo; Haug, Tobias; De Nardis, Jacopo				Lami, Guglielmo/MBW-1156-2025						Quantum State Designs with Clifford Enhanced Matrix Product States								Arxiv											2	2;2024-10-08;https://www.arxiv.org/abs/2404.18751v2| 1;2024-04-29;https://www.arxiv.org/abs/2404.18751v1	arXiv:2404.18751			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 08 2024	2024	Nonstabilizerness, or ‘magic’, is a critical quantum resource that, together with entanglement, characterizes the non-classical complexity of quantum states. Here, we address the problem of quantifying the average nonstabilizerness of random Matrix Product States (RMPS). RMPS represent a generalization of random product states featuring bounded entanglement that scales logarithmically with the bond dimension χ. We demonstrate that the Stabilizer Renyi Entropies converges to that of Haar random states as N/χα , where N is the system size and α are integer exponents. This indicates that MPS with a modest bond dimension are as magical as generic states. Subsequently, we introduce the ensemble of Clifford enhanced Matrix Product States (CMPS), built by the action of Clifford unitaries on RMPS. Leveraging our previous result, we show that CMPS can approximate a quantum state 4-designs with arbitrary accuracy. Specifically, for a constant N, CMPS become close to 4-designs with a scaling as χ−2 . Our findings indicate that combining Clifford unitaries with polynomially complex tensor network states can generate highly non-trivial quantum states.																																	2024-10-28	PPRN:88696723		
J	Wang, Minzheng; Chen, Longze; Fu, Cheng; Liao, Shengyi; Zhang, Xinghua; Wu, Bingli; Yu, Haiyang; Xu, Nan; Zhang, Lei; Luo, Run; Li, Yunshui; Yang, Min; Huang, Fei; Li, Yongbin				Lin, Hongyu/LXA-3658-2024; li, Yongbin/MBG-2998-2025; Li, Yunshui/JNS-3522-2023; Zhang, Xinghua/K-2471-2012						Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA								Arxiv											2	2;2024-10-03;https://www.arxiv.org/abs/2406.17419v2| 1;2024-06-25;https://www.arxiv.org/abs/2406.17419v1	arXiv:2406.17419			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 03 2024	2024	Long-context modeling capabilities have garnered widespread attention, leading to the emergence of Large Language Models (LLMs) with ultra-context windows. Meanwhile, benchmarks for evaluating long-context LLMs are gradually catching up. However, existing benchmarks employ irrelevant noise texts to artificially extend the length of test cases, diverging from the real-world scenarios of longcontext applications. To bridge this gap, we propose a novel long-context benchmark, Loong , aligning with realistic scenarios through extended multi-document question answering (QA). Unlike typical document QA, in Loong’s test cases, each document is relevant to the final answer, ignoring any document will lead to the failure of the answer. Furthermore, Loong introduces four types of tasks with a range of context lengths: Spotlight Locating , Comparison , Clustering , and Chain of Reasoning , to facilitate a more realistic and comprehensive evaluation of long-context understanding. Extensive experiments indicate that existing longcontext language models still exhibit considerable potential for enhancement. Retrieval augmented generation (RAG) achieves poor performance, demonstrating that Loong can reliably assess the model’s long-context modeling capabilities. 1																																	2024-10-18	PPRN:89510989		
J	Bernstein, Jeremy; Newhouse, Laker										Old Optimizer, New Norm: An Anthology								Arxiv											1	1;2024-09-30;https://www.arxiv.org/abs/2409.20325v1	arXiv:2409.20325			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 30 2024	2024	Deep learning optimizers are often motivated through a mix of convex and approximate second-order theory. We select three such methods—Adam, Shampoo and Prodigy—and argue that each method can instead be understood as a squarely first-order method without convexity assumptions. In fact, after switching off exponential moving averages, each method is equivalent to steepest descent under a particular norm. . By generalizing this observation, we chart a new design space for training algorithms. Different operator norms should be assigned to different tensors based on the role that the tensor plays within the network. For example, while linear and embedding layers may have the same weight space of Rm×n , these layers play different roles and should be assigned different norms. We hope that this idea of carefully metrizing the neural architecture might lead to more stable, scalable and indeed faster training.																																	2024-10-10	PPRN:100734918		
J	Zhang, Yu; Chen, Xiusi; Jin, Bowen; Wang, Sheng; Ji, Shuiwang; Wang, Wei; Han, Jiawei				Jin, Bowen/HTR-0099-2023; Zhang, Yu/W-8504-2019; han, jiawei/GVT-3012-2022						A Comprehensive Survey of Scientific Large Language Models and Their Applications in Scientific Discovery								Arxiv											3	3;2024-09-28;https://www.arxiv.org/abs/2406.10833v3| 2;2024-08-26;https://www.arxiv.org/abs/2406.10833v2| 1;2024-06-16;https://www.arxiv.org/abs/2406.10833v1	arXiv:2406.10833			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 28 2024	2024	In many scientific fields, large language models (LLMs) have revolutionized the way text and other modalities of data (e.g., molecules and proteins) are handled, achieving superior performance in various applications and augmenting the scientific discovery process. Nevertheless, previous surveys on scientific LLMs often concentrate on one or two fields or a single modality. In this paper, we aim to provide a more holistic view of the research landscape by unveiling cross-field and cross-modal connections between scientific LLMs regarding their architectures and pre-training techniques. To this end, we comprehensively survey over 260 scientific LLMs, discuss their commonalities and differences, as well as summarize pre-training datasets and evaluation tasks for each field and modality. Moreover, we investigate how LLMs have been deployed to benefit scientific discovery.																																	2024-10-10	PPRN:89343123		
J	Li, Chaofan; Qin, Minghao; Xiao, Shitao; Chen, Jianlyu; Luo, Kun; Shao, Yingxia; Lian, Defu; Liu, Zheng				Liu, Zheng/AHI-3660-2022; Lian, Defu/AFN-4573-2022; qin, minghao/JLM-4650-2023; Shao, Yingxia/AAT-2150-2020						Making Text Embedders Few-Shot Learners								Arxiv											1	1;2024-09-24;https://www.arxiv.org/abs/2409.15700v1	arXiv:2409.15700			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 24 2024	2024	Large language models (LLMs) with decoder-only architectures demonstrate remarkable in-context learning (ICL) capabilities. This feature enables them to effectively handle both familiar and novel tasks by utilizing examples provided within their input context. Recognizing the potential of this capability, we propose leveraging the ICL feature in LLMs to enhance the process of text embedding generation. To this end, we introduce a novel model bge-en-icl, which employs few-shot examples to produce high-quality text embeddings. Our approach integrates task-related examples directly into the query side, resulting in significant improvements across various tasks. Additionally, we have investigated how to effectively utilize LLMs as embedding models, including various attention mechanisms, pooling methods, etc. Our findings suggest that retaining the original framework often yields the best results, underscoring that simplicity is best. Experimental results on the MTEB and AIR-Bench benchmarks demonstrate that our approach sets new state-of-the-art (SOTA) performance. 																																	2024-10-07	PPRN:98862842		
J	Stone, James M.; Mullen, Patrick D.; Fielding, Drummond; Grete, Philipp; Guo, Minghao; Kempski, Philipp; Most, Elias R.; White, Christopher J.; Wong, George N.				Wong, George/AAL-1016-2021; Kempski, Philipp/NDR-8528-2025; Stone, J/H-9424-2019; Most, Elias/AAK-8709-2020; Fielding, Drummond/ABD-8921-2020						AthenaK: A Performance-Portable Version of the Athena++ AMR Framework								Arxiv											1	1;2024-09-24;https://www.arxiv.org/abs/2409.16053v1	arXiv:2409.16053			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 24 2024	2024	We describe AthenaK: a new implementation of the Athena++ block-based adaptive mesh refinement (AMR) framework using the Kokkos programming model. Finite volume methods for Newtonian, special relativistic (SR), and general relativistic (GR) hydrodynamics and magnetohydrodynamics (MHD), and GR-radiation hydrodynamics and MHD, as well as a module for evolving Lagrangian tracer or charged test particles (e.g., cosmic rays) are implemented using the framework. In two companion papers we describe (1) a new solver for the Einstein equations based on the Z4c formalism and (2) a GRMHD solver in dynamical spacetimes also implemented using the framework, enabling new applications in numerical relativity. By adopting Kokkos, the code can be run on virtually any hardware, including CPUs, GPUs from multiple vendors, and emerging ARM processors. AthenaK shows excellent performance and weak scaling, achieving over one billion cell updates per second for hydrodynamics in three-dimensions on a single NVIDIA Grace Hopper processor and with a typical parallel efficiency of 80% on 65536 AMD GPUs on the OLCF Frontier system. Such performance portability enables AthenaK to leverage modern exascale computing systems for challenging applications in astrophysical fluid dynamics, numerical relativity, and multimessenger astrophysics.																																	2024-11-03	PPRN:98864073		
J	Yuan, Chengbo; Wen, Chuan; Zhang, Tong; Gao, Yang				Wen, Chuan/LIF-6638-2024						General Flow as Foundation Affordance for Scalable Robot Learning								Arxiv											2	2;2024-09-23;https://www.arxiv.org/abs/2401.11439v2| 1;2024-01-21;https://www.arxiv.org/abs/2401.11439v1	arXiv:2401.11439			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 23 2024	2024	We address the challenge of acquiring real-world manipulation skills with a scalable framework. We hold the belief that identifying an appropriate prediction target capable of leveraging large-scale datasets is crucial for achieving efficient and universal learning. Therefore, we propose to utilize 3D flow, which represents the future trajectories of 3D points on objects of interest, as an ideal prediction target. To exploit scalable data resources, we turn our attention to human videos. We develop, for the first time, a language-conditioned 3D flow prediction model directly from large-scale RGBD human video datasets. Our predicted flow offers actionable guidance, thus facilitating zero-shot skill transfer in real-world scenarios. We deploy our method with a policy based on closed-loop flow prediction. Remarkably, without any in-domain finetuning, our method achieves an impressive 81% success rate in zero-shot human-to-robot skill transfer, covering 18 tasks in 6 scenes. Our framework features the following benefits: (1) scalability: leveraging cross-embodiment data resources; (2) wide application: multiple object categories, including rigid, articulated, and soft bodies; (3) stable skill transfer: providing actionable guidance with a small inference domain-gap. 																																	2024-10-21	PPRN:87278347		
J	Wang, Ziyao; Shen, Zheyu; He, Yexiao; Sun, Guoheng; Wang, Hongyi; Lyu, Lingjuan; Li, Ang				Wang, Hongyi/KMA-5952-2024; Li, Ang/GWD-0502-2022; Wang, Ziyao/KCL-3215-2024; He, Yexiao/LPQ-4863-2024						FLoRA: Federated Fine-Tuning Large Language Models with Heterogeneous Low-Rank Adaptations								Arxiv											1	1;2024-09-09;https://www.arxiv.org/abs/2409.05976v1	arXiv:2409.05976			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 09 2024	2024	The rapid development of Large Language Models (LLMs) has been pivotal in advancing AI, with pre-trained LLMs being adaptable to diverse downstream tasks through fine-tuning. Federated learning (FL) further enhances fine-tuning in a privacy-aware manner by utilizing clients' local data through in-situ computation, eliminating the need for data movement. However, fine-tuning LLMs, given their massive scale of parameters, poses challenges for clients with constrained and heterogeneous resources in FL. Previous methods employed low-rank adaptation (LoRA) for efficient federated fine-tuning but utilized traditional FL aggregation strategies on LoRA adapters. These approaches led to mathematically inaccurate aggregation noise, reducing fine-tuning effectiveness and failing to address heterogeneous LoRAs. In this work, we first highlight the mathematical incorrectness of LoRA aggregation in existing federated fine-tuning methods. We introduce a new approach called FLORA that enables federated fine-tuning on heterogeneous LoRA adapters across clients through a novel stacking-based aggregation method. Our approach is noise-free and seamlessly supports heterogeneous LoRA adapters. Extensive experiments demonstrate FLORA' s superior performance in both homogeneous and heterogeneous settings, surpassing state-of-the-art methods. We envision this work as a milestone for efficient, privacy-preserving, and accurate federated fine-tuning of LLMs. 																																	2024-09-26	PPRN:91820668		
J	Cai, Zhongang; Zhang, Mingyuan; Ren, Jiawei; Wei, Chen; Ren, Daxuan; Lin, Zhengyu; Zhao, Haiyu; Yang, Lei; Loy, Chen Change; Liu, Ziwei				Ren, Jiawei/LYO-8771-2024; Liu, Ziwei/AAG-6939-2021						Playing for 3D Human Recovery								Arxiv											2	2;2024-09-08;https://www.arxiv.org/abs/2110.07588v3| 1;2021-10-14;https://www.arxiv.org/abs/2110.07588v1	arXiv:2110.07588			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 08 2024	2024	Image- and video-based 3D human recovery (i.e., pose and shape estimation) have achieved substantial progress. However, due to the prohibitive cost of motion capture, existing datasets are often limited in scale and diversity. In this work, we obtain massive human sequences by playing the video game with automatically annotated 3D ground truths. Specifically, we contribute GTA-Human, , a large-scale 3D human dataset generated with the GTA-V game engine, featuring a highly diverse set of subjects, actions, and scenarios. More importantly, we study the use of game-playing data and obtain five major insights. First, , game-playing data is surprisingly effective. A simple frame-based baseline trained on GTA-Human outperforms more sophisticated methods by a large margin. For videobased methods, GTA-Human is even on par with the in-domain training set. Second, , we discover that synthetic data provides critical complements to the real data that is typically collected indoor. We highlight that our investigation into domain gap provides explanations for our data mixture strategies that are simple yet useful, which offers new insights to the research community. Third, , the scale of the dataset matters. The performance boost is closely related to the additional data available. A systematic study on multiple key factors (such as camera angle and body pose) reveals that the model performance is sensitive to data density. Fourth, , the effectiveness of GTA-Human is also attributed to the rich collection of strong supervision labels (SMPL parameters), which are otherwise expensive to acquire in real datasets. Fifth, , the benefits of synthetic data extend to larger models such as deeper convolutional neural networks (CNNs) and Transformers, for which a significant impact is also observed. We hope our work could pave the way for scaling up 3D human recovery to the real world. 																																	2024-09-27	PPRN:11940541		
J	Li, Zhongyu; Peng, Xue Bin; Abbeel, Pieter; Levine, Sergey; Berseth, Glen; Sreenath, Koushil										Reinforcement Learning for Versatile, Dynamic, and Robust Bipedal Locomotion Control								Arxiv											2	2;2024-08-26;https://www.arxiv.org/abs/2401.16889v2| 1;2024-01-30;https://www.arxiv.org/abs/2401.16889v1	arXiv:2401.16889			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 26 2024	2024	This paper presents a comprehensive study on using deep reinforcement learning (RL) to create dynamic locomotion controllers for bipedal robots. Going beyond focusing on a single locomotion skill, we develop a general control solution that can be used for a range of dynamic bipedal skills, from periodic walking and running to aperiodic jumping and standing. Our RL-based controller incorporates a novel dual-history architecture, utilizing both a long-term and short-term input/output (I/O) history of the robot. This control architecture, when trained through the proposed end-to-end RL approach, consistently outperforms other methods across a diverse range of skills in both simulation and the real world. The study also delves into the adaptivity and robustness introduced by the proposed RL system in developing locomotion controllers. We demonstrate that the proposed architecture can adapt to both time-invariant dynamics shifts and time-variant changes, such as contact events, by effectively using the robot’s I/O history. Additionally, we identify task randomization as another key source of robustness, fostering better task generalization and compliance to disturbances. The resulting control policies can be successfully deployed on Cassie, a torque-controlled human-sized bipedal robot. This work pushes the limits of agility for bipedal robots through extensive realworld experiments. We demonstrate a diverse range of locomotion skills, including: robust standing, versatile walking, fast running with a demonstration of a 400-meter dash, and a diverse set of jumping skills, such as standing long jumps and high jumps.																																	2024-09-04	PPRN:87420291		
J	Zhang, Zaibin; Zhang, Yongting; Li, Lijun; Gao, Hongzhi; Wang, Lijun; Lu, Huchuan; Zhao, Feng; Qiao, Yu; Shao, Jing				Zhao, Feng/NGQ-9015-2025; Qiao, Yu/ABD-5787-2021; Chen, Xiangyu/P-7839-2018						PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety								Arxiv											2	2;2024-08-20;https://www.arxiv.org/abs/2401.11880v3| 1;2024-01-22;https://www.arxiv.org/abs/2401.11880v1	arXiv:2401.11880			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 20 2024	2024	Multi-agent systems, when enhanced with Large Language Models (LLMs), exhibit profound capabilities in collective intelligence. However, the potential misuse of this intelligence for malicious purposes presents significant risks. To date, comprehensive research on the safety issues associated with multi-agent systems remains limited. In this paper, we explore these concerns through the innovative lens of agent psychology, revealing that the dark psychological states of agents constitute a significant threat to safety. To tackle these concerns, we propose a comprehensive framework (PsySafe) grounded in agent psychology, focusing on three key areas: firstly, identifying how dark personality traits in agents can lead to risky behaviors; secondly, evaluating the safety of multi-agent systems from the psychological and behavioral perspectives, and thirdly, devising effective strategies to mitigate these risks. Our experiments reveal several intriguing phenomena, such as the collective dangerous behaviors among agents, agents' self-reflection when engaging in dangerous behavior, and the correlation between agents' psychological assessments and dangerous behaviors. We anticipate that our framework and observations will provide valuable insights for further research into the safety of multi-agent systems. 																																	2024-08-30	PPRN:87278318		
J	Qin, Zengyi; Zhao, Wenliang; Yu, Xumin; Sun, Xin				Qin, Zengyi/CAJ-0463-2022						OpenVoice: Versatile Instant Voice Cloning								Arxiv											6	6;2024-08-18;https://www.arxiv.org/abs/2312.01479v6| 5;2024-01-02;https://www.arxiv.org/abs/2312.01479v5| 4;2023-12-21;https://www.arxiv.org/abs/2312.01479v4| 3;2023-12-16;https://www.arxiv.org/abs/2312.01479v3| 2;2023-12-13;https://www.arxiv.org/abs/2312.01479v2| 1;2023-12-03;https://www.arxiv.org/abs/2312.01479v1	arXiv:2312.01479			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 18 2024	2024	We introduce OpenVoice, a versatile voice cloning approach that requires only a short audio clip from the reference speaker to replicate their voice and generate speech in multiple languages. OpenVoice represents a significant advancement in addressing the following open challenges in the field: 1) Flexible Voice Style Control. OpenVoice enables granular control over voice styles, including emotion, accent, rhythm, pauses, and intonation, in addition to replicating the tone color of the reference speaker. The voice styles are not directly copied from and constrained by the style of the reference speaker. Previous approaches lacked the ability to flexibly manipulate voice styles after cloning. 2) Zero-Shot Cross-Lingual Voice Cloning. OpenVoice achieves zero-shot cross-lingual voice cloning for languages not included in the massive-speaker training set. Unlike previous approaches, which typically require extensive massive-speaker multi-lingual (MSML) dataset for all languages, OpenVoice can clone voices into a new language without any massive-speaker training data for that language. OpenVoice is also computationally efficient, costing tens of times less than commercially available APIs that offer even inferior performance. To foster further research in the field, we have made the source code and trained model publicly accessible. We also provide qualitative results in our demo website. OpenVoice has been used by more than 2M users worldwide as the voice engine of MyShell.ai																																	2024-08-30	PPRN:86378396		
J	Liu, Xiao; Zhang, Tianjie; Gu, Yu; Iong, Iat Long; Xu, Yifan; Song, Xixuan; Zhang, Shudan; Lai, Hanyu; Liu, Xinyi; Zhao, Hanlin; Sun, Jiadai; Yang, Xinyue; Yang, Yu; Qi, Zehan; Yao, Shuntian; Sun, Xueqiao; Cheng, Siyi; Zheng, Qinkai; Yu, Hao; Zhang, Hanchen; Hong, Wenyi; Ding, Ming; Pan, Lihang; Gu, Xiaotao; Zeng, Aohan; Du, Zhengxiao; Song, Chan Hee; Su, Yu; Dong, Yuxiao; Tang, Jie				Cheng, Siyi/IUQ-6798-2023; Liu, Xinyi/LCD-2349-2024; Zheng, Qinkai/AAI-9267-2021; Zhang, Hanchen/MIK-3870-2025; Xu, Yifan/I-9273-2014						VisualAgentBench: Towards Large Multimodal Models as Visual Foundation Agents								Arxiv											1	1;2024-08-12;https://www.arxiv.org/abs/2408.06327v1	arXiv:2408.06327			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 12 2024	2024	Large Multimodal Models (LMMs) have ushered in a new era in artificial intelligence, merging capabilities in both language and vision to form highly capable Visual Foundation Agents. These agents are postulated to excel across a myriad of tasks, potentially approaching general artificial intelligence. However, existing benchmarks fail to sufficiently challenge or showcase the full potential of LMMs in complex, real-world environments. To address this gap, we introduce VisualAgentBench (VAB), a comprehensive and pioneering benchmark specifically designed to train and evaluate LMMs as visual foundation agents across diverse scenarios, including Embodied, Graphical User Interface, and Visual Design, with tasks formulated to probe the depth of LMMs' understanding and interaction capabilities. Through rigorous testing across nine proprietary LMM APIs and eight open models, we demonstrate the considerable yet still developing agent capabilities of these models. Additionally, VAB constructs a trajectory training set constructed through hybrid methods including Program-based Solvers, LMM Agent Bootstrapping, and Human Demonstrations, promoting substantial performance improvements in LMMs through behavior cloning. Our work not only aims to benchmark existing models but also provides a solid foundation for future development into visual foundation agents.																																	2024-08-22	PPRN:91353480		
J	Chen, Tianrun; Lu, Ankang; Zhu, Lanyun; Ding, Chaotao; Yu, Chunan; Ji, Deyi; Li, Zejian; Sun, Lingyun; Mao, Papa; Zang, Ying				Ji, Deyi/MYR-4920-2025; Sun, Lingyun/AFQ-4832-2022; Chen, Tianrun/KYP-2807-2024; Zhu, Lanyun/LNQ-2089-2024						SAM2-Adapter: Evaluating & Adapting Segment Anything 2 in Downstream Tasks: Camouflage, Shadow, Medical Image Segmentation, and More								Arxiv											2	2;2024-08-10;https://www.arxiv.org/abs/2408.04579v2| 1;2024-08-08;https://www.arxiv.org/abs/2408.04579v1	arXiv:2408.04579			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 10 2024	2024	The advent of large models, also known as foundation models, has significantly transformed the AI research landscape, with models like Segment Anything (SAM) achieving notable success in diverse image segmentation scenarios. Despite its advancements, SAM encountered limitations in handling some complex low-level segmentation tasks like camouflaged object and medical imaging. In response, in 2023, we introduced SAM-Adapter, which demonstrated improved performance on these challenging tasks. Now, with the release of Segment Anything 2 (SAM2), a successor with enhanced architecture and a larger training corpus, we reassess these challenges. This paper introduces SAM2-Adapter, the first adapter designed to overcome the persistent limitations observed in SAM2 and achieve new state-of-the-art (SOTA) results in specific downstream tasks including medical image segmentation, camouflaged (concealed) object detection, and shadow detection. SAM2-Adapter builds on the SAM-Adapter's strengths, offering enhanced generalizability and composability for diverse applications. We present extensive experimental results demonstrating SAM2-Adapter's effectiveness. We show the potential and encourage the research community to leverage the SAM2 model with our SAM2-Adapter for achieving superior segmentation outcomes.																																	2024-08-22	PPRN:91291858		
J	Wan, Shengye; Nikolaidis, Cyrus; Song, Daniel; Molnar, David; Crnkovich, James; Grace, Jayson; Bhatt, Manish; Chennabasappa, Sahana; Whitman, Spencer; Ding, Stephanie; Ionescu, Vlad; Li, Yue; Saxe, Joshua				Bhatt, Manish/O-5347-2019; Molnár, Dávid/A-9572-2013; Ionescu, VLAD ALEXANDRU/IWM-3808-2023; Wan, Shengye/JHS-4767-2023						CYBERSECEVAL 3: Advancing the Evaluation of Cybersecurity Risks and Capabilities in Large Language Models								Arxiv											1	1;2024-08-02;https://www.arxiv.org/abs/2408.01605v1	arXiv:2408.01605			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 02 2024	2024	We are releasing a new suite of security benchmarks for LLMs, CYBERSECEVAL 3, to continue the conversation on empirically measuring LLM cybersecurity risks and capabilities. CYBERSECEVAL 3 assesses 8 different risks across two broad categories: risk to third parties, and risk to application developers and end users. Compared to previous work, we add new areas focused on offensive security capabilities: automated social engineering, scaling manual offensive cyber operations, and autonomous offensive cyber operations. In this paper we discuss applying these benchmarks to the Llama 3 models and a suite of contemporaneous state-of-the-art LLMs, enabling us to contextualize risks both with and without mitigations in place.																																	2024-08-09	PPRN:91245190		
J	Yang, Xuemeng; Wen, Licheng; Ma, Yukai; Mei, Jianbiao; Li, Xin; Wei, Tiantian; Lei, Wenjie; Fu, Daocheng; Cai, Pinlong; Dou, Min; Shi, Botian; He, Liang; Liu, Yong; Qiao, Yu				Qiao, Yu/ABD-5787-2021; Shi, Botian/HTT-0363-2023; Wei, tiantian/HOC-9486-2023; Fu, Daocheng/LCE-6917-2024; Cai, Pinlong/P-6490-2017; yang, xuemeng/MAI-5800-2025						DriveArena: A Closed-loop Generative Simulation Platform for Autonomous Driving								Arxiv											2	2;2024-08-01;https://www.arxiv.org/abs/2408.00415v1| 1;2024-08-01;https://www.arxiv.org/abs/2408.00415v1	arXiv:2408.00415			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 01 2024	2024	This paper presented DriveArena, the first high-fidelity closed-loop simulation system designed for driving agents navigating in real scenarios. DriveArena features a flexible, modular architecture, allowing for the seamless interchange of its core components: Traffic Manager, a traffic simulator capable of generating realistic traffic flow on any worldwide street map, and World Dreamer, a high-fidelity conditional generative model with infinite autoregression. This powerful synergy empowers any driving agent capable of processing real-world images to navigate in DriveArena's simulated environment. The agent perceives its surroundings through images generated by World Dreamer and output trajectories. These trajectories are fed into Traffic Manager, achieving realistic interactions with other vehicles and producing a new scene layout. Finally, the latest scene layout is relayed back into World Dreamer, perpetuating the simulation cycle. This iterative process fosters closed-loop exploration within a highly realistic environment, providing a valuable platform for developing and evaluating driving agents across diverse and challenging scenarios. DriveArena signifies a substantial leap forward in leveraging generative image data for the driving simulation platform, opening insights for closed-loop autonomous driving. 																																	2024-12-16	PPRN:91240530		
J	Ghirardini, V.; Bulbul, E.; Artis, E.; Clerc, N.; Garrel, C.; Grandis, S.; Kluge, M.; Liu, A.; Bahar, Y.E.; Balzer, F.; Chiu, I.; Comparat, J.; Gruen, D.; Kleinebreil, F.; Krippendorf, S.; Merloni, A.; Nandra, K.; Okabe, N.; Pacaud, F.; Predehl, P.; Ramos-Ceja, M.E.; Reiprich, T.H.; Sanders, J.S.; Schrabback, T.; Seppi, R.; Zelmer, S.; Zhang, X.; Bornemann, W.; Brunner, H.; Burwitz, V.; Coutinho, D.; Dennerl, K.; Freyberg, M.; Friedrich, S.; Gaida, R.; Gueguen, A.; Haberl, F.; Kink, W.; Lamer, G.; Li, X.; Liu, T.; Maitra, C.; Meidinger, N.; Mueller, S.; Miyatake, H.; Miyazaki, S.; Robrade, J.; Schwope, A.; Stewart, I.				Schwope, Axel/AAX-9701-2021; Grandis, Sebastian/KCY-7025-2024; BULBUL, Esra/MIJ-7500-2025; comparat, johan/JHV-0065-2023; Liu, Ang/HNQ-4696-2023						The SRG/eROSITA all-sky survey&nbsp;Cosmology constraints from cluster abundances in the western Galactic hemisphere								Arxiv											2	2;2024-07-25;https://www.arxiv.org/abs/2402.08458v2| 1;2024-02-13;https://www.arxiv.org/abs/2402.08458v1	arXiv:2402.08458			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 25 2024	2024	The evolution of the cluster mass function traces the growth of linear density perturbations, providing valuable insights into the growth of structures, the nature of dark matter, and the cosmological parameters governing the Universe. The primary science goal of eROSITA, on board the Spectrum Roentgen Gamma (SRG) mission, is to constrain cosmology through the evolution of the cluster mass function. In this paper, we present a set of cosmological constraints obtained from 5259 clusters of galaxies detected over an area of 12791 deg2 in the western Galactic hemisphere of eROSITA’s first All-Sky Survey (eRASS1). The common footprint region (4968 deg2) between the eROSITA Survey and Dark Energy Survey (DES), the Kilo-Degree Survey (KiDS), and the Hyper Supreme Camera (HSC) survey is used for calibration of the scaling between X-ray count rate of the clusters and their total mass through measurements of their weak gravitational lensing signal. The eRASS1 cluster abundances constrain the ΛCDM parameters, namely, the energy density of the total matter to Ωm = 0.29−0.02+0 .01  and the normalization of the density fluctuations to σ8 = 0.88 ± 0.02 and their combination yields S8 = σ8(Ωm/0.3)0.5 = 0.86 ± 0.01. These results are consistent and achieve at a similar precision with state-of-the-art cosmic microwave background (CMB) measurements. Furthermore, the eRASS1 cosmological experiment places a most stringent upper limit on the summed masses of left-handed light neutrinos to Σmν < 0.43 eV (95% confidence interval) from cluster number counts alone. By combining eRASS1 cluster abundance measurements with CMB- and ground-based neutrino oscillation experiments, we measured the summed neutrino masses to be Σmν = 0.09−0.02+0.04  eV or Σmν = 0.12−0.02+0.03  eV, , assuming a normal or inverted mass hierarchy scenario for neutrino eigenstates. The eRASS1 cluster abundances significantly improve the constraints on the dark energy equation of state parameter to w = −1.12 ± 0.12.  When Σ mν and w are left free, we find consistent results with the concordance ΛCDM cosmology. Our results from the first All-Sky Survey improve the cosmological constraints by over a factor of 5 to 9 over the previous cluster surveys, establishing cluster abundance measurements for precision cosmology and setting the stage for deeper eROSITA All-Sky Surveys, as well as for future cluster abundance experiments.																																	2025-05-26	PPRN:87674582		
J	Hu, Mengkang; Mu, Yao; Yu, Xinmiao; Ding, Mingyu; Wu, Shiguang; Shao, Wenqi; Chen, Qiguang; Wang, Bin; Qiao, Yu; Luo, Ping				Wang, Bin/MVU-8917-2025; Qiao, Yu/ABD-5787-2021; pluo/GPG-2707-2022; Chen, Qiguang/IVH-6127-2023						Tree-Planner: Efficient Close-loop Task Planning with Large Language Models								Arxiv											2	2;2024-07-24;https://www.arxiv.org/abs/2310.08582v2| 1;2023-10-12;https://www.arxiv.org/abs/2310.08582v1	arXiv:2310.08582			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 24 2024	2024	This paper studies close-loop task planning, which refers to the process of generating a sequence of skills (a plan) to accomplish a specific goal while adapting the plan based on real-time observations. Recently, prompting Large Language Models (LLMs) to generate actions iteratively has become a prevalent paradigm due to its superior performance and user-friendliness. However, this paradigm is plagued by two inefficiencies: high token consumption and redundant error correction, both of which hinder its scalability for large-scale testing and applications. To address these issues, we propose Tree-Planner, which reframes task planning with LLMs into three distinct phases: plan sampling, action tree construction, and grounded deciding. Tree-Planner starts by using an LLM to sample a set of potential plans before execution, followed by the aggregation of them to form an action tree. Finally, the LLM performs a top-down decision-making process on the tree, taking into account real-time environmental information. Experiments show that Tree-Planner achieves state-of-the-art performance while maintaining high efficiency. By decomposing LLM queries into a single plan-sampling call and multiple grounded-deciding calls, a considerable part of the prompt are less likely to be repeatedly consumed. As a result, token consumption is reduced by 92.2% compared to the previously best-performing model. Additionally, by enabling backtracking on the action tree as needed, the correction process becomes more flexible, leading to a 40.5% decrease in error corrections.																																	2024-07-31	PPRN:85603980		
J	Yue, Zongsheng; Loy, Chen Change				Yue, Zongsheng/ADZ-0457-2022						DifFace: Blind Face Restoration with Diffused Error Contraction								Arxiv											3	3;2024-07-20;https://www.arxiv.org/abs/2212.06512v4| 2;2023-12-11;https://www.arxiv.org/abs/2212.06512v3| 1;2022-12-13;https://www.arxiv.org/abs/2212.06512v2	arXiv:2212.06512			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jul 20 2024	2024	While deep learning-based methods for blind face restoration have achieved unprecedented success, they still suffer from two major limitations. First, most of them deteriorate when facing complex degradations out of their training data. Second, these methods require multiple constraints, e.g., fidelity, perceptual, and adversarial losses, which require laborious hyperparameter tuning to stabilize and balance their influences. In this work, we propose a novel method named DifFace that is capable of coping with unseen and complex degradations more gracefully without complicated loss designs. The key of our method is to establish a posterior distribution from the observed low-quality (LQ) image to its high-quality (HQ) counterpart. In particular, we design a transition distribution from the LQ image to the intermediate state of a pre-trained diffusion model and then gradually transmit from this intermediate state to the HQ target by recursively applying a pre-trained diffusion model. The transition distribution only relies on a restoration backbone that is trained with L 1 loss on some synthetic data, which favorably avoids the cumbersome training process in existing methods. Moreover, the transition distribution can contract the error of the restoration backbone and thus makes our method more robust to unknown degradations. Comprehensive experiments show that DifFace is superior to current state-of-the-art methods, especially in cases with severe degradations. 																																	2024-07-28	PPRN:56459486		
J	Gui, Jie; Chen, Tuo; Zhang, Jing; Cao, Qiong; Sun, Zhenan; Luo, Hao; Tao, Dacheng				ZHANG, JING/HKF-4837-2023; Shen, Li/AEZ-9528-2022						A Survey on Self-supervised Learning: Algorithms, Applications, and Future Trends								Arxiv											3	3;2024-07-14;https://www.arxiv.org/abs/2301.05712v4| 2;2023-09-17;https://www.arxiv.org/abs/2301.05712v3| 1;2023-08-21;https://www.arxiv.org/abs/2301.05712v2	arXiv:2301.05712			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 14 2024	2024	Deep supervised learning algorithms typically require a large volume of labeled data to achieve satisfactory performance. However, the process of collecting and labeling such data can be expensive and time-consuming. Self-supervised learning (SSL), a subset of unsupervised learning, aims to learn discriminative features from unlabeled data without relying on human-annotated labels. SSL has garnered significant attention recently, leading to the development of numerous related algorithms. However, there is a dearth of comprehensive studies that elucidate the connections and evolution of different SSL variants. This paper presents a review of diverse SSL methods, encompassing algorithmic aspects, application domains, three key trends, and open research questions. Firstly, we provide a detailed introduction to the motivations behind most SSL algorithms and compare their commonalities and differences. Secondly, we explore representative applications of SSL in domains such as image processing, computer vision, and natural language processing. Lastly, we discuss the three primary trends observed in SSL research and highlight the open questions that remain.																																	2024-07-23	PPRN:82089176		
J	Parmar, Jupinder; Satheesh, Sanjev; Patwary, Mostofa; Shoeybi, Mohammad; Catanzaro, Bryan										Reuse, Don't Retrain: A Recipe for Continued Pretraining of Language Models								Arxiv											1	1;2024-07-09;https://www.arxiv.org/abs/2407.07263v1	arXiv:2407.07263			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 09 2024	2024	As language models have scaled both their number of parameters and pretraining dataset sizes, the computational cost for pretraining has become intractable except for the most well-resourced teams. This increasing cost makes it ever more important to be able to reuse a model after it has completed pretraining; allowing for a model's abilities to further improve without needing to train from scratch. In this work, we detail a set of guidelines that cover how to design efficacious data distributions and learning rate schedules for continued pretraining of language models. When applying these findings within a continued pretraining run on top of a well-trained 15B parameter model, we show an improvement of 9% in average model accuracy compared to the baseline of continued training on the pretraining set. The resulting recipe provides a practical starting point with which to begin developing language models through reuse rather than retraining.																																	2024-07-21	PPRN:90760383		
J	Lin, Xian; Xiang, Yangyang; Yu, Li; Yan, Zengqiang				Yan, Zengqiang/LTF-9621-2024						Beyond Adapting SAM: Towards End-to-End Ultrasound Image Segmentation via Auto Prompting								Arxiv											2	2;2024-07-08;https://www.arxiv.org/abs/2309.06824v2| 1;2023-09-13;https://www.arxiv.org/abs/2309.06824v1	arXiv:2309.06824			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 08 2024	2024	End-to-end medical image segmentation is of great value for computer-aided diagnosis dominated by task-specific models, usually suffering from poor generalization. With recent breakthroughs brought by the segment anything model (SAM) for universal image segmentation, extensive efforts have been made to adapt SAM for medical imaging but still encounter two major issues: 1) severe performance degradation and limited generalization without proper adaptation, and 2) semi-automatic segmentation relying on accurate manual prompts for interaction. In this work, we propose SAMUS as a universal model tailored for ultrasound image segmentation and further enable it to work in an end-to-end manner denoted as AutoSAMUS. Specifically, in SAMUS, a parallel CNN branch is introduced to supplement local information through cross-branch attention, and a feature adapter and a position adapter are jointly used to adapt SAM from natural to ultrasound domains while reducing training complexity. AutoSAMUS is realized by introducing an auto prompt generator (APG) to replace the manual prompt encoder of SAMUS to automatically generate prompt embeddings. A comprehensive ultrasound dataset, comprising about 30k images and 69k masks and covering six object categories, is collected for verification. Extensive comparison experiments demonstrate the superiority of SAMUS and AutoSAMUS against the state-of-the-art task-specific and SAM-based foundation models. We believe the auto-prompted SAM-based model has the potential to become a new paradigm for end-to-end medical image segmentation and deserves more exploration. 																																	2024-07-21	PPRN:85007796		
J	Prasad, Aaditya; Lin, Kevin; Wu, Jimmy; Zhou, Linqi; Bohg, Jeannette				Bohg, Jeannette/AAD-4010-2019						Consistency Policy: Accelerated Visuomotor Policies via Consistency Distillation								Arxiv											2	2;2024-06-28;https://www.arxiv.org/abs/2405.07503v2| 1;2024-05-13;https://www.arxiv.org/abs/2405.07503v1	arXiv:2405.07503			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 28 2024	2024	Many robotic systems, such as mobile manipulators or quadrotors, cannot be equipped with high -end GPUs due to space, weight, and power constraints. These constraints prevent these systems from leveraging recent developments in visuomotor policy architectures that require high -end GPUs to achieve fast policy inference. In this paper, we propose Consistency Policy, a faster and similarly powerful alternative to Diffusion Policy for learning visuomotor robot control. By virtue of its fast inference speed, Consistency Policy can enable low latency decision making in resource -constrained robotic setups. A Consistency Policy is distilled from a pretrained Diffusion Policy by enforcing selfconsistency along the Diffusion Policy’s learned trajectories. We compare Consistency Policy with Diffusion Policy and other related speed-up methods across 6 simulation tasks as well as three real -world tasks where we demonstrate inference on a laptop GPU. For all these tasks, Consistency Policy speeds up inference by an order of magnitude compared to the fastest alternative method and maintains competitive success rates. We also show that the Conistency Policy training procedure is robust to the pretrained Diffusion Policy’s quality, a useful result that helps practioners avoid extensive testing of the pretrained model. Key design decisions that enabled this performance are the choice of consistency objective, reduced initial sample variance, and the choice of preset chaining steps.																																	2024-11-03	PPRN:89041201		
J	Leone, Lorenzo; Oliviero, Salvatore F.E.; Cincio, Lukasz; Cerezo, M.				Cerezo, Marco/ABD-9254-2020; Leone, Lorenzo/OML-9300-2025; Oliviero, SalvatoreFrancescoEmanuele/LMP-7997-2024						On the practical usefulness of the Hardware Efficient Ansatz								Arxiv											2	2;2024-06-26;https://www.arxiv.org/abs/2211.01477v2| 1;2022-11-02;https://www.arxiv.org/abs/2211.01477v1	arXiv:2211.01477			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 26 2024	2024	Variational Quantum Algorithms (VQAs) and Quantum Machine Learning (QML) models train a parametrized quantum circuit to solve a given learning task. The success of these algorithms greatly hinges on appropriately choosing an ansatz for the quantum circuit. Perhaps one of the most famous ansatzes is the one-dimensional layered Hardware Efficient Ansatz (HEA), which seeks to minimize the effect of hardware noise by using native gates and connectives. The use of this HEA has generated a certain ambivalence arising from the fact that while it suffers from barren plateaus at long depths, it can also avoid them at shallow ones. In this work, we attempt to determine whether one should, or should not, use a HEA. We rigorously identify scenarios where shallow HEAs should likely be avoided (e.g., VQA or QML tasks with data satisfying a volume law of entanglement). More importantly, we identify a Goldilocks scenario where shallow HEAs could achieve a quantum speedup: QML tasks with data satisfying an area law of entanglement. We provide examples for such scenario (such as Gaussian diagonal ensemble random Hamiltonian discrimination), and we show that in these cases a shallow HEA is always trainable and that there exists an anti-concentration of loss function values. Our work highlights the crucial role that input states play in the trainability of a parametrized quantum circuit, a phenomenon that is verified in our numerics.																																	2024-07-15	PPRN:22597697		
J	Liu, Zuxin; Hoang, Thai; Zhang, Jianguo; Zhu, Ming; Lan, Tian; Kokane, Shirley; Tan, Juntao; Yao, Weiran; Liu, Zhiwei; Feng, Yihao; Murthy, Rithesh; Yang, Liangwei; Savarese, Silvio; Niebles, Juan Carlos; Wang, Huan; Heinecke, Shelby; Xiong, Caiming				Liu, Zhi-Wei/G-6187-2011; Yang, Lingwei/AHC-6477-2022; Liu, Zuxin/GQY-8303-2022; Niebles, Juan/AAT-5882-2021; Zhou, Mingo/KPA-7866-2024; Lan, Tian/JEP-4658-2023; Feng, Yihao/LVR-7524-2024						APIGen: Automated Pipeline for Generating Verifiable and Diverse Function-Calling Datasets								Arxiv											1	1;2024-06-26;https://www.arxiv.org/abs/2406.18518v1	arXiv:2406.18518			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 26 2024	2024	The advancement of function-calling agent models requires diverse, reliable, and high-quality datasets. This paper presents APIGen, an automated data generation pipeline designed to synthesize verifiable high-quality datasets for function-calling applications. We leverage APIGen and collect 3,673 executable APIs across 21 different categories to generate diverse function-calling datasets in a scalable and structured manner. Each data in our dataset is verified through three hierarchical stages: format checking, actual function executions, and semantic verification, ensuring its reliability and correctness. We demonstrate that models trained with our curated datasets, even with only 7B parameters, can achieve state-of-the-art performance on the Berkeley Function-Calling Benchmark, outperforming multiple GPT-4 models. Moreover, our 1B model achieves exceptional performance, surpassing GPT-3.5-Turbo and Claude-3 Haiku. We release a dataset containing 60,000 high-quality entries, aiming to advance the field of function-calling agent domains. The dataset is available on Huggingface 1 and the project homepage 2 .																																	2024-07-15	PPRN:89907732		
J	Chen, Tianxiang; Ye, Zi; Tan, Zhentao; Gong, Tao; Wu, Yue; Chu, Qi; Liu, Bin; Yu, Nenghai; Ye, Jieping				Tan, Zhentao/KCY-1789-2024; Chu, Qi/AAQ-5998-2020						MiM-ISTD: Mamba-in-Mamba for Efficient Infrared Small Target Detection								Arxiv											3	3;2024-06-24;https://www.arxiv.org/abs/2403.02148v4| 2;2024-03-17;https://www.arxiv.org/abs/2403.02148v3| 1;2024-03-08;https://www.arxiv.org/abs/2403.02148v2	arXiv:2403.02148			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 24 2024	2024	Recently, infrared small target detection (ISTD) has made significant progress, thanks to the development of basic models. Specifically, the models combining CNNs with transformers can successfully extract both local and global features. However, the disadvantage of the transformer is also inherited, i.e., the quadratic computational complexity to sequence length. Inspired by the recent basic model with linear complexity for long-distance modeling, Mamba, we explore the potential of this state space model for ISTD task in terms of effectiveness and efficiency in the paper. However, directly applying Mamba achieves suboptimal performances due to the insufficient harnessing of local features, which are imperative for detecting small targets. Instead, we tailor a nested structure, Mamba-in-Mamba (MiM-ISTD), for efficient ISTD. It consists of Outer and Inner Mamba blocks to adeptly capture both global and local features. Specifically, we treat the local patches as "visual sentences" and use the Outer Mamba to explore the global information. We then decompose each visual sentence into sub-patches as "visual words" and use the Inner Mamba to further explore the local information among words in the visual sentence with negligible computational costs. By aggregating the visual word and visual sentence features, our MiM-ISTD can effectively explore both global and local information. Experiments on NUAA-SIRST and IRSTD-1k show the superior accuracy and efficiency of our method. Specifically, MiM-ISTD is 8× faster than the SOTA method and reduces GPU memory usage by 62.2% when testing on 2048 × 2048 images, overcoming the computation and memory constraints on high-resolution infrared images.																																	2024-07-15	PPRN:88081753		
J	Wang, Bohan; Zhang, Yushun; Zhang, Huishuai; Meng, Qi; Sun, Ruoyu; Ma, Zhi-Ming; Liu, Tie-Yan; Luo, Zhi-Quan; Chen, Wei				MENG, QI/KRO-4878-2024; Sun, Ruoyu/ITV-0426-2023						Provable Adaptivity of Adam under Non-uniform Smoothness								Arxiv											2	2;2024-06-24;https://www.arxiv.org/abs/2208.09900v2| 1;2022-08-21;https://www.arxiv.org/abs/2208.09900v1	arXiv:2208.09900			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 24 2024	2024	Adam is widely adopted in practical applications due to its fast convergence. However, its theoretical analysis is still far from satisfactory. Existing convergence analyses for Adam rely on the bounded smoothness assumption, referred to as the L-smooth condition . Unfortunately, this assumption does not hold for many deep learning tasks. Moreover, we believe that this assumption obscures the true benefit of Adam, as the algorithm can adapt its update magnitude according to local smoothness. This important feature of Adam becomes irrelevant when assuming globally bounded smoothness. This paper studies the convergence of randomly reshuffled Adam (RR Adam) with diminishing learning rate, which is the major version of Adam adopted in deep learning tasks. We present the first convergence analysis of RR Adam without the bounded smoothness assumption. We demonstrate that RR Adam can maintain its convergence properties when smoothness is linearly bounded by the gradient norm, referred to as the (L0 , L1 ) -smooth condition . We further compare Adam to SGD when both methods use diminishing learning rate. We refine the existing lower bound of SGD and show that SGD can be slower than Adam. To our knowledge, this is the first time that Adam and SGD are rigorously compared in the same setting and the advantage of Adam is revealed.																																	2024-07-15	PPRN:12240025		
J	Ni, Haowei; Meng, Shuchen; Geng, Xieming; Li, Panfeng; Li, Zhuoying; Chen, Xupeng; Wang, Xiaotong; Zhang, Shiyao				Li, Panfeng/LBG-9988-2024; Ni, Haowei/LBG-9535-2024; Chen, Xupeng/KFA-5959-2024						Time Series Modeling for Heart Rate Prediction: From ARIMA to Transformers								Arxiv											3	3;2024-11-12;https://www.arxiv.org/abs/2406.12199v3| 2;2024-06-27;https://www.arxiv.org/abs/2406.12199v2| 1;2024-06-18;https://www.arxiv.org/abs/2406.12199v1	arXiv:2406.12199			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 18 2024	2024	Cardiovascular disease (CVD) is a leading cause of death globally, necessitating precise forecasting models for monitoring vital signs like heart rate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet, are limited by their need for manual parameter tuning and challenges in handling noisy, sparse, and highly variable medical data. This study investigates advanced deep learning models, including LSTM, and transformer-based architectures, for predicting heart rate time series from the MIT-BIH Database. Results demonstrate that deep learning models, particularly PatchTST, significantly outperform traditional models across multiple metrics, capturing complex patterns and dependencies more effectively. This research underscores the potential of deep learning to enhance patient monitoring and CVD management, suggesting substantial clinical benefits. Future work should extend these findings to larger, more diverse datasets and real-world clinical applications to further validate and optimize model performance.																																	2025-08-07	PPRN:89358324		
J	Huang, Jin; Zhang, Xingjian; Mei, Qiaozhu; Ma, Jiaqi				Zhang, Xingjian/MIP-1191-2025; Huang, Jin/LFS-4009-2024						Can LLMs Effectively Leverage Graph Structural Information through Prompts, and Why?								Arxiv											4	4;2024-06-15;https://www.arxiv.org/abs/2309.16595v4| 3;2024-02-27;https://www.arxiv.org/abs/2309.16595v3| 2;2023-09-29;https://www.arxiv.org/abs/2309.16595v2| 1;2023-09-28;https://www.arxiv.org/abs/2309.16595v1	arXiv:2309.16595			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 15 2024	2024	Large language models (LLMs) are gaining increasing attention for their capability to process graphs with rich text attributes, especially in a zero-shot fashion. Recent studies demonstrate that LLMs obtain decent text classification performance on common text-rich graph benchmarks, and the performance can be improved by appending encoded structural information as natural languages into prompts. We aim to understand why the incorporation of structural information inherent in graph data can improve the prediction performance of LLMs. First, we rule out the concern of data leakage by curating a novel leakage-free dataset and conducting a comparative analysis alongside a previously widely-used dataset. Second, as past work usually encodes the ego-graph by describing the graph structure in natural language, we ask the question: do LLMs understand the graph structure in accordance with the intent of the prompt designers? Third, we investigate why LLMs can improve their performance after incorporating structural information. Our exploration of these questions reveals that (i) there is no substantial evidence that the performance of LLMs is significantly attributed to data leakage; (ii) instead of understanding prompts as graph structures as intended by the prompt designers, LLMs tend to process prompts more as contextual paragraphs and (iii) the most efficient elements of the local neighborhood included in the prompt are phrases that are pertinent to the node label, rather than the graph structure.1																																	2024-07-04	PPRN:85321555		
J	Farrell, Roland C.; Illa, Marc; Ciavarella, Anthony N.; Savage, Martin J.				Illa Subina, Marc/HPG-2289-2023						Quantum Simulations of Hadron Dynamics in the Schwinger Model using 112 Qubits								Arxiv											2	2;2024-06-11;https://www.arxiv.org/abs/2401.08044v2| 1;2024-01-16;https://www.arxiv.org/abs/2401.08044v1	arXiv:2401.08044			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 11 2024	2024	Hadron wavepackets are prepared and time evolved in the Schwinger model using 112 qubits of IBM’s 133-qubit Heron quantum computer ibm_torino . The initialization of the hadron wavepacket is performed in two steps. First, the vacuum is prepared across the whole lattice using the recently developed SC-ADAPT-VQE algorithm and workflow. SC-ADAPT-VQE is then extended to the preparation of localized states, and used to establish a hadron wavepacket on top of the vacuum. This is done by adaptively constructing low-depth circuits that maximize the overlap with an adiabatically prepared hadron wavepacket. Due to the localized nature of the wavepacket, these circuits can be determined on a sequence of small lattices using classical computers , and then robustly scaled to prepare wavepackets on large lattices for simulations using quantum computers . Time evolution is implemented with a second-order Trotterization. To reduce both the required qubit connectivity and circuit depth, an approximate quasi-lo cal interaction is introduced. This approximation is made possible by the emergence of confinement at long distances, and converges exponentially with increasing distance of the interactions. Using multiple error-mitigation strategies, up to 14 Trotter steps of time evolution are performed, employing 13,858 two-qubit gates (with a CNOT depth of 370). The propagation of hadrons is clearly identified, with results that compare favorably with Matrix Product State simulations. Prospects for a near-term quantum advantage in simulations of hadron scattering are discussed.																																	2024-07-04	PPRN:87189172		
J	Zhang, Yichi; Huang, Yao; Sun, Yitong; Liu, Chang; Zhao, Zhe; Fang, Zhengwei; Wang, Yifan; Chen, Huanran; Yang, Xiao; Wei, Xingxing; Su, Hang; Dong, Yinpeng; Zhu, Jun				Dong, Yinpeng/KBA-4751-2024; Fang, Zhengwei/JBR-8442-2023; Wang, Yifan/JDM-1982-2023; Zhang, Yichi/AAV-2870-2021						Benchmarking Trustworthiness of Multimodal Large Language Models: A Comprehensive Study								Arxiv											1	1;2024-06-11;https://www.arxiv.org/abs/2406.07057v1	arXiv:2406.07057			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jun 11 2024	2024	Despite the superior capabilities of Multimodal Large Language Models (MLLMs) across diverse tasks, they still face significant trustworthiness challenges. Yet, current literature on the assessment of trustworthy MLLMs remains limited, lacking a holistic evaluation to offer thorough insights into future improvements. In this work, we establish MultiTrust, the first comprehensive and unified benchmark on the trustworthiness of MLLMs across five primary aspects: truthfulness, safety, robustness, fairness, and privacy. Our benchmark employs a rigorous evaluation strategy that addresses both multimodal risks and cross-modal impacts, encompassing 32 diverse tasks with self-curated datasets. Extensive experiments with 21 modern MLLMs reveal some previously unexplored trustworthiness issues and risks, highlighting the complexities introduced by the multimodality and underscoring the necessity for advanced methodologies to enhance their reliability. For instance, typical proprietary models still struggle with the perception of visually confusing images and are vulnerable to multimodal jailbreaking and adversarial attacks; MLLMs are more inclined to disclose privacy in text and reveal ideological and cultural biases even when paired with irrelevant images in inference, indicating that the multimodality amplifies the internal risks from base LLMs. Additionally, we release a scalable toolbox for standardized trustworthiness research, aiming to facilitate future advancements in this important field. 																																	2024-07-10	PPRN:89287291		
J	Maini, Pratyush; Jia, Hengrui; Papernot, Nicolas; Dziedzic, Adam										LLM Dataset Inference: Did you train on my dataset?								Arxiv											1	1;2024-06-10;https://www.arxiv.org/abs/2406.06443v1	arXiv:2406.06443			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 10 2024	2024	The proliferation of large language models (LLMs) in the real world has come with a rise in copyright cases against companies for training their models on unlicensed data from the internet. Recent works have presented methods to identify if individual text sequences were members of the model's training data, known as membership inference attacks (MIAs). We demonstrate that the apparent success of these MIAs is confounded by selecting non-members (text sequences not used for training) belonging to a different distribution from the members (e.g., temporally shifted recent Wikipedia articles compared with ones used to train the model). This distribution shift makes membership inference appear successful. However, most MIA methods perform no better than random guessing when discriminating between members and non-members from the same distribution (e.g., in this case, the same period of time). Even when MIAs work, we find that different MIAs succeed at inferring membership of samples from different distributions. Instead, we propose a new dataset inference method to accurately identify the datasets used to train large language models. This paradigm sits realistically in the modern-day copyright landscape, where authors claim that an LLM is trained over multiple documents (such as a book) written by them, rather than one particular paragraph. While dataset inference shares many of the challenges of membership inference, we solve it by selectively combining the MIAs that provide positive signal for a given distribution, and aggregating them to perform a statistical test on a given dataset. Our approach successfully distinguishes the train and test sets of different subsets of the Pile with statistically significant p-values < 0.1, without any false positives.																																	2024-07-04	PPRN:89264847		
J	Goldblum, Micah; Finzi, Marc; Rowan, Keefer; Wilson, Andrew Gordon				Rowan, Keefer/MIU-0416-2025						The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning								Arxiv											3	3;2024-06-07;https://www.arxiv.org/abs/2304.05366v3| 2;2024-06-05;https://www.arxiv.org/abs/2304.05366v2| 1;2023-04-11;https://www.arxiv.org/abs/2304.05366v1	arXiv:2304.05366			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 07 2024	2024	No free lunch theorems for supervised learning state that no learner can solve all problems or that all learners achieve exactly the same accuracy on average over a uniform distribution on learning problems. Accordingly, these theorems are often referenced in support of the notion that individual problems require specially tailored inductive biases. While virtually all uniformly sampled datasets have high complexity, real-world problems disproportionately generate low-complexity data, and we argue that neural network models share this same preference, formalized using Kolmogorov complexity. Notably, we show that architectures designed for a particular domain, such as computer vision, can compress datasets on a variety of seemingly unrelated domains. Our experiments show that pre-trained and even randomly initialized language models prefer to generate low-complexity sequences. Whereas no free lunch theorems seemingly indicate that individual problems require specialized learners, we explain how tasks that often require human intervention such as picking an appropriately sized model when labeled data is scarce or plentiful can be automated into a single learning algorithm. These observations justify the trend in deep learning of unifying seemingly disparate problems with an increasingly small set of machine learning models.																																	2024-07-04	PPRN:57990073		
J	Tong, Yongqi; Li, Dawei; Wang, Sizhe; Wang, Yujia; Teng, Fei; Shang, Jingbo				Li, Dawei/AAY-3098-2020; Shang, Jingbo/T-4207-2019; Wang, Yujia/AFF-1559-2022						Can LLMs Learn from Previous Mistakes? Investigating LLMs' Errors to Boost for Reasoning								Arxiv											2	2;2024-06-07;https://www.arxiv.org/abs/2403.20046v2| 1;2024-03-29;https://www.arxiv.org/abs/2403.20046v1	arXiv:2403.20046			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 07 2024	2024	Large language models (LLMs) have demonstrated striking reasoning capability. Recent works have shown the benefits to LLMs from fine-tuning golden-standard Chain-of-Thought (CoT) rationales or using them as correct examples in few-shot prompting. While humans can indeed imitate correct examples, learning from our mistakes is another vital aspect of human cognition. Hence, a question naturally arises: can LLMs learn and benefit from their mistakes, especially for their reasoning? This study investigates this problem from both the prompting and model-tuning perspectives. We begin by introducing CoTErrorSet, a new benchmark with 609,432 questions, each designed with both correct and error references, and demonstrating the types and reasons for making such mistakes. To explore the effectiveness of those mistakes, we design two methods: (1) Self-rethinking prompting guides LLMs to rethink whether they have made similar previous mistakes; and (2) Mistake tuning involves finetuning models in both correct and incorrect reasoning domains, rather than only tuning models to learn ground truth in traditional methodology. We conduct a series of experiments to prove LLMs can obtain benefits from mistakes in both directions. Our two methods offer potentially cost-effective strategies by leveraging errors to enhance reasoning capabilities, which costs significantly less than creating meticulously hand-crafted golden references. We ultimately make a thorough analysis of the reasons behind LLMs’ errors, which provides directions that future research needs to overcome																																	2024-06-22	PPRN:88342650		
J	Zhao, Hao; Andriushchenko, Maksym; Croce, Francesco; Flammarion, Nicolas										<italic>Long </italic>Is More for Alignment: A Simple but Tough-to-Beat Baseline for Instruction Fine-Tuning								Arxiv											2	2;2024-06-04;https://www.arxiv.org/abs/2402.04833v2| 1;2024-02-07;https://www.arxiv.org/abs/2402.04833v1	arXiv:2402.04833			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 04 2024	2024	There is a consensus that instruction fine-tuning of LLMs requires high-quality data, but what are they? LIMA (NeurIPS 2023) and AlpaGasus (ICLR 2024) are state-of-the-art methods for selecting such high-quality examples, either via manual curation or using GPT-3.5-Turbo as a quality scorer. We show that the extremely simple baseline of selecting the 1,000 instructions with longest responses - that intuitively contain more learnable information and are harder to overfit - from standard datasets can consistently outperform these sophisticated methods according to GPT-4 and PaLM-2 as judges, while remaining competitive on the Open LLM benchmarks that test factual knowledge. We demonstrate this for several LLMs (Llama-2-7B, Llama-2-13B, Mistral-7B-v0.1) and datasets (Alpaca-52k, Evol-Instruct-70k). In addition, a lightweight refinement of such long instructions can further improve the abilities of the fine-tuned LLMs, and allows us to obtain competitive results on MT-Bench and the 2nd highest-ranked Llama-2-7B-based model on AlpacaEval 2.0, while training on only 1,000 examples and no extra preference data. We also conduct a thorough analysis of our models to ensure that their enhanced performance is not simply due to GPT-4's preference for longer responses. Overall, our findings suggest that fine-tuning on the longest responses should be the default baseline for any work on instruction fine-tuning. We provide our code in this GitHub repository.																																	2024-07-04	PPRN:87553195		
J	Melechovsky, Jan; Guo, Zixun; Ghosal, Deepanway; Majumder, Navonil; Herremans, Dorien; Poria, Soujanya				PORIA, SOUJANYA/KIJ-4789-2024; Herremans, Dorien/G-9599-2018						Mustango: Toward Controllable Text-to-Music Generation								Arxiv											3	3;2024-06-03;https://www.arxiv.org/abs/2311.08355v3| 2;2024-03-16;https://www.arxiv.org/abs/2311.08355v2| 1;2023-11-14;https://www.arxiv.org/abs/2311.08355v1	arXiv:2311.08355			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jun 03 2024	2024	The quality of the text-to-music models has reached new heights due to recent advancements in diffusion models. The controllability of various musical aspects, however, has barely been explored. In this paper, we propose Mustango: : a music-domain-knowledgeinspired text-to-music system based on diffusion. Mustango aims to control the generated music, not only with general text captions, but with more rich captions that can include specific instructions related to chords, beats, tempo, and key. At the core of Mustango is MuNet, a Music-DomainKnowledge-Informed UNet guidance module that steers the generated music to include the music-specific conditions, which we predict from the text prompt, as well as the general text embedding, during the reverse diffusion process. To overcome the limited availability of open datasets of music with text captions, we propose a novel data augmentation method that includes altering the harmonic, rhythmic, and dynamic aspects of music audio and using state-of-the-art Music Information Retrieval methods to extract the music features which will then be appended to the existing descriptions in text format. We release the resulting MusicBench dataset which contains over 52K instances and includes music-theory -based descriptions in the caption text. Through extensive experiments, we show that the quality of the music generated by Mustango is state-of-the-art, and the controllability through music-specific text prompts greatly outperforms other models such as MusicGen and AudioLDM2. .																																	2024-06-19	PPRN:86203492		
J	Cheon, Minjong				Cheon, Minjong/JZE-2329-2024						Kolmogorov-Arnold Network for Satellite Image Classification in Remote Sensing								Arxiv											1	1;2024-06-02;https://www.arxiv.org/abs/2406.00600v1	arXiv:2406.00600			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 02 2024	2024	In this research, we propose the first approach for integrating the Kolmogorov-Arnold Network (KAN) with various pre-trained Convolutional Neural Network (CNN) models for remote sensing (RS) scene classification tasks using the EuroSAT dataset. Our novel methodology, named KCN, aims to replace traditional Multi-Layer Perceptrons (MLPs) with KAN to enhance classification performance. We employed multiple CNN-based models, including VGG16, MobileNetV2, EfficientNet, ConvNeXt, ResNet101, and Vision Transformer (ViT), and evaluated their performance when paired with KAN. Our experiments demonstrated that KAN achieved high accuracy with fewer training epochs and parameters. Specifically, ConvNeXt paired with KAN showed the best performance, achieving 94% accuracy in the first epoch, which increased to 96% and remained consistent across subsequent epochs. The results indicated that KAN and MLP both achieved similar accuracy, with KAN performing slightly better in later epochs. By utilizing the EuroSAT dataset, we provided a robust testbed to investigate whether KAN is suitable for remote sensing classification tasks. Given that KAN is a novel algorithm, there is substantial capacity for further development and optimization, suggesting that KCN offers a promising alternative for efficient image analysis in the RS field.																																	2024-06-22	PPRN:89158854		
J	Li, Zhishuai; Wang, Xiang; Zhao, Jingjing; Yang, Sun; Du, Guoqing; Hu, Xiaoru; Zhang, Bin; Ye, Yuxiao; Li, Ziyue; Zhao, Rui; Mao, Hangyu				hu, xiaoru/LIH-0577-2024; Zhang, Bin/LJK-3344-2024; Li, Ziyue/HZH-3369-2023; Zhao, Jingjing/JAC-6495-2023						PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency								Arxiv											3	3;2024-06-02;https://www.arxiv.org/abs/2403.09732v4| 2;2024-03-29;https://www.arxiv.org/abs/2403.09732v3| 1;2024-03-18;https://www.arxiv.org/abs/2403.09732v2	arXiv:2403.09732			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jun 02 2024	2024	Recent advancements in Text-to-SQL (Text2SQL) emphasize stimulating the large language models (LLM) on in-context learning, achieving significant results. Nevertheless, they face challenges when dealing with verbose database information and complex user intentions. This paper presents a two-stage framework to enhance the performance of current LLM-based natural language to SQL systems. We first introduce a novel prompt representation, called reference-enhanced representation, which includes schema information and randomly sampled cell values from tables to instruct LLMs in generating SQL queries. Then, in the first stage, question-SQL pairs are retrieved as few-shot demonstrations, prompting the LLM to generate a preliminary SQL (PreSQL). After that, the mentioned entities in PreSQL are parsed to conduct schema linking, which can significantly compact the useful information. In the second stage, with the linked schema, we simplify the prompt's schema information and instruct the LLM to produce the final SQL. Finally, as the post-refinement module, we propose using cross-consistency across different LLMs rather than self-consistency within a particular LLM. Our methods achieve new SOTA results on the Spider benchmark, with an execution accuracy of 87.6%.																																	2024-06-22	PPRN:88162752		
J	Shen, Qiuhong; Wu, Zike; Yi, Xuanyu; Zhou, Pan; Zhang, Hanwang; Yan, Shuicheng; Wang, Xinchao				Gao, Shanghua/ACY-3354-2022						Gamba: Marry Gaussian Splatting with Mamba for single view 3D reconstruction								Arxiv											3	3;2024-05-24;https://www.arxiv.org/abs/2403.18795v3| 2;2024-03-29;https://www.arxiv.org/abs/2403.18795v2| 1;2024-03-27;https://www.arxiv.org/abs/2403.18795v1	arXiv:2403.18795			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	May 24 2024	2024	We tackle the challenge of efficiently reconstructing a 3D asset from a single image at millisecond speed. Existing methods for single-image 3D reconstruction are primarily based on Score Distillation Sampling (SDS) with Neural 3D representations. Despite promising results, these approaches encounter practical limitations due to lengthy optimizations and significant memory consumption. In this work, we introduce Gamba, an end-to-end 3D reconstruction model from a single-view image, emphasizing two main insights: (1) Efficient Backbone Design: introducing a Mamba-based GambaFormer network to model 3D Gaussian Splatting (3DGS) reconstruction as sequential prediction with linear scalability of token length, thereby accommodating a substantial number of Gaussians; (2) Robust Gaussian Constraints: deriving radial mask constraints from multi-view masks to eliminate the need for warmup supervision of 3D point clouds in training. We trained Gamba on Objaverse and assessed it against existing optimization-based and feed-forward 3D reconstruction approaches on the GSO Dataset, among which Gamba is the only end-to-end trained single-view reconstruction model with 3DGS. Experimental results demonstrate its competitive generation capabilities both qualitatively and quantitatively and highlight its remarkable speed: Gamba completes reconstruction within 0.05 seconds on a single NVIDIA A100 GPU, which is about $1,000times$ faster than optimization-based methods. 																																	2024-06-11	PPRN:88332058		
J	Muqeeth, Mohammed; Liu, Haokun; Raffel, Colin										Soft Merging of Experts with Adaptive Routing								Arxiv											2	2;2024-05-13;https://www.arxiv.org/abs/2306.03745v2| 1;2023-06-06;https://www.arxiv.org/abs/2306.03745v1	arXiv:2306.03745			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 13 2024	2024	Sparsely activated neural networks with conditional computation learn to route their inputs through different "expert" subnetworks, providing a form of modularity that densely activated models lack. Despite their possible benefits, models with learned routing often underperform their parameter-matched densely activated counterparts as well as models that use non-learned heuristic routing strategies. In this paper, we hypothesize that these shortcomings stem from the gradient estimation techniques used to train sparsely activated models that use non-differentiable discrete routing decisions. To address this issue, we introduce Soft Merging of Experts with Adaptive Routing (SMEAR), which avoids discrete routing by using a single "merged" expert constructed via a weighted average of all of the experts' parameters. By routing activations through a single merged expert, SMEAR does not incur a significant increase in computational costs and enables standard gradient-based training. We empirically validate that models using SMEAR outperform models that route based on metadata or learn sparse routing through gradient estimation. Furthermore, we provide qualitative analysis demonstrating that the experts learned via SMEAR exhibit a significant amount of specialization. All of the code used in our experiments is publicly available.1																																	2024-05-29	PPRN:72868578		
J	Zhang, An; Chen, Yuxin; Sheng, Leheng; Wang, Xiang; Chua, Tat-Seng				Wang, Meng/AEZ-9059-2022; Chen, Yuxin/H-8672-2019; Chen, Yuxin/HOH-1234-2023						On Generative Agents in Recommendation								Arxiv											2	2;2024-05-11;https://www.arxiv.org/abs/2310.10108v2| 1;2023-10-16;https://www.arxiv.org/abs/2310.10108v1	arXiv:2310.10108			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 11 2024	2024	Recommender systems are the cornerstone of today's information dissemination, yet a disconnect between offline metrics and online performance greatly hinders their development. Addressing this challenge, we envision a recommendation simulator, capitalizing on recent breakthroughs in human-level intelligence exhibited by Large Language Models (LLMs). We propose Agent4Rec, a user simulator in recommendation, leveraging LLM-empowered generative agents equipped with user profile, memory, and actions modules specifically tailored for the recommender system. In particular, these agents' profile modules are initialized using real-world datasets (e.g. MovieLens, Steam, Amazon-Book), capturing users' unique tastes and social traits; memory modules log both factual and emotional memories and are integrated with an emotion-driven reflection mechanism; action modules support a wide variety of behaviors, spanning both taste-driven and emotion-driven actions. Each agent interacts with personalized recommender models in a page-by-page manner, relying on a pre-implemented collaborative filtering-based recommendation algorithm. We delve into both the capabilities and limitations of Agent4Rec, aiming to explore an essential research question: "To what extent can LLM-empowered generative agents faithfully simulate the behavior of real, autonomous humans in recommender systems?'' Extensive and multi-faceted evaluations of Agent4Rec highlight both the alignment and deviation between agents and user-personalized preferences. Beyond mere performance comparison, we explore insightful experiments, such as emulating the filter bubble effect and discovering the underlying causal relationships in recommendation tasks. Our codes are available at https://github.com/LehengTHU/Agent4Rec.																																	2024-06-08	PPRN:85660515		
J	Jiang, Xilin; Han, Cong; Mesgarani, Nima				Han, Cong/HOI-0631-2023						Dual-path Mamba: Short and Long-term Bidirectional Selective Structured State Space Models for Speech Separation								Arxiv											2	2;2024-05-01;https://www.arxiv.org/abs/2403.18257v2| 1;2024-03-27;https://www.arxiv.org/abs/2403.18257v1	arXiv:2403.18257			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 01 2024	2024	Transformers have been the most successful architecture for various speech modeling tasks, including speech separation. However, the self-attention mechanism in transformers with quadratic complexity is inefficient in computation and memory. Recent models incorporate new layers and modules along with transformers for better performance but also introduce extra model complexity. In this work, we replace transformers with Mamba, a selective state space model, for speech separation. We propose dual-path Mamba, which models short-term and long-term forward and backward dependency of speech signals using selective state spaces. Our experimental results on the WSJ0-2mix data show that our dual-path Mamba models of comparably smaller sizes outperform state-of-the-art RNN model DPRNN, CNN model WaveSplit, and transformer model Sepformer. Code: https://github.com/xi-j/Mamba-TasNet																																	2024-05-18	PPRN:88335238		
J	Fujii, Kazuki; Nakamura, Taishi; Loem, Mengsay; Iida, Hiroki; Ohi, Masanari; Hattori, Kakeru; Shota, Hirai; Mizuki, Sakae; Yokota, Rio; Okazaki, Naoaki				Yokota, Rio/F-6611-2016						Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities								Arxiv											1	1;2024-04-27;https://www.arxiv.org/abs/2404.17790v1	arXiv:2404.17790			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 27 2024	2024	Cross-lingual continual pre-training of large language models (LLMs) initially trained on English corpus allows us to leverage the vast amount of English language resources and reduce the pre-training cost. In this study, we constructed Swallow, an LLM with enhanced Japanese capability, by extending the vocabulary of Llama 2 to include Japanese characters and conducting continual pre-training on a large Japanese web corpus. Experimental results confirmed that the performance on Japanese tasks drastically improved through continual pre-training, and the performance monotonically increased with the amount of training data up to 100B tokens. Consequently, Swallow achieved superior performance compared to other LLMs that were trained from scratch in English and Japanese. An analysis of the effects of continual pre-training revealed that it was particularly effective for Japanese question answering tasks. Furthermore, to elucidate effective methodologies for cross-lingual continual pre-training from English to Japanese, we investigated the impact of vocabulary expansion and the effectiveness of incorporating parallel corpora. The results showed that the efficiency gained through vocabulary expansion had no negative impact on performance, except for the summarization task, and that the combined use of parallel corpora enhanced translation ability.																																	2024-05-16	PPRN:88696846		
J	Farrell, Roland C.; Illa, Marc; Ciavarella, Anthony N.; Savage, Martin J.				Illa Subina, Marc/HPG-2289-2023						Scalable Circuits for Preparing Ground States on Digital Quantum Computers: The Schwinger Model Vacuum on 100 Qubits								Arxiv											3	3;2024-04-22;https://www.arxiv.org/abs/2308.04481v3| 2;2023-09-08;https://www.arxiv.org/abs/2308.04481v2| 1;2023-08-08;https://www.arxiv.org/abs/2308.04481v1	arXiv:2308.04481			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 22 2024	2024	The vacuum of the lattice Schwinger model is prepared on up to 100 qubits of IBM’s Eagle -processor quantum computers. A new algorithm to prepare the ground state of a gapped translationallyinvariant system on a quantum computer is presented, which we call Scalable Circuits ADAPT-VQE (SC-ADAPT-VQE). This algorithm uses the exponential decay of correlations between distant regions of the ground state, together with ADAPT-VQE, to construct quantum circuits for state preparation that can be scaled to arbitrarily large systems. These scalable circuits can be determined using classical computers, avoiding the challenging task of optimizing parameterized circuits on a quantum computer. SC-ADAPT-VQE is applied to the Schwinger model, and shown to be systematically improvable, with an accuracy that converges exponentially with circuit depth. Both the structure of the circuits and the deviations of prepared wavefunctions are found to become independent of the number of spatial sites, L. This allows for a controlled extrapolation of the circuits, determined using small or modest -sized systems, to arbitrarily large L. The circuits for the Schwinger model are determined on lattices up to L = 14 (28 qubits) with the qiskit classical simulator, and subsequently scaled up to prepare the L = 50 (100 qubits) vacuum on IBM’s 127 sup erconducting-qubit quantum computers ibm brisbane and ibm cusco. After introducing an improved error -mitigation technique, which we call Operator Decoherence Renormalization, the chiral condensate and charge -charge correlators obtained from the quantum computers are found to be in good agreement with classical Matrix Product State simulations.																																	2024-04-30	PPRN:74943057		
J	Dhani, Arnab; Voelkel, Sebastian; Buonanno, Alessandra; Estelles, Hector; Gair, Jonathan; Pfeiffer, Harald P.; Pompili, Lorenzo; Toubiana, Alexandre										Systematic Biases in Estimating the Properties of Black Holes Due to Inaccurate Gravitational-Wave Models								Arxiv											1	1;2024-04-08;https://www.arxiv.org/abs/2404.05811v1	arXiv:2404.05811			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 08 2024	2024	Gravitational -wave (GW) observations of binary black -hole (BBH) coalescences are expected to address outstanding questions in astrophysics, cosmology, and fundamental physics. Inference of BBH parameters relies on waveform models, and realizing the full discovery potential of upcoming LIGO-Virgo-KAGRA observing runs and new ground -based facilities (such as the Einstein Telescope and Cosmic Explorer) hinges on the accuracy of these waveform models. Using linear -signal approximation methods and Bayesian analysis, we start to assess our readiness for what lies ahead using two state-of-the-art quasi -circular, spin-precessing models: SEOBNRv5PHM and IMRPhenomXPHM. We find that systematic biases increase with the spin of the BH, with parameter biases being approximately 6 to 8 times likelier, if the primary -spin magnitude exceeds 0.5 compared to when it is less than 0.5. Additionally, we ascertain that current waveforms can accurately recover the distribution of masses in the LVK astrophysical population, but not spins. Upon exploring the broader parameter space of BHs, we find that systematic biases increase with detector -frame total mass, binary asymmetry, and spin -precession, with a majority of such binaries incurring parameter biases, extending up to redshifts ∼ 3 in future detectors. Furthermore, we examine three “golden” events characterized by mass ratios of approximately 6 to 10, significant spin magnitudes (0.6–0.9), and high precession, evaluating how systematic biases may affect their scientific outcomes. Our findings reveal that current waveforms fail to enable the unbiased measurement of the Hubble-Lemaître parameter and sky localization from loud signals, even for current detectors. Moreover, highly asymmetric systems within the lower BH mass -gap exhibit biased measurements of the secondary -companion mass, which impacts the physics of both neutron stars and formation channels. Similarly, we deduce that the primary mass of massive binaries (> 60M⊙) will also be biased, affecting supernova physics. Future progress in analytical calculations and numerical -relativity simulations, crucial for calibrating the models, must target regions of the parameter space with significant biases to develop more accurate models. Only then can precision GW astronomy fulfill the promise it holds.																																	2024-04-22	PPRN:88468346		
J	Xu, Jiashu; Wang, Fei; Ma, Mingyu Derek; Koh, Pang Wei; Xiao, Chaowei; Chen, Muhao				Xiao, Chaowei/AAT-8772-2021; Chen, Muhao/AAA-3634-2021						Instructional Fingerprinting of Large Language Models								Arxiv											3	3;2024-04-03;https://www.arxiv.org/abs/2401.12255v2| 2;2024-01-21;https://www.arxiv.org/abs/2401.12255v1| 1;2024-01-21;https://www.arxiv.org/abs/2401.12255v1	arXiv:2401.12255			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 03 2024	2024	The exorbitant cost of training Large language models (LLMs) from scratch makes it essential to fingerprint the models to protect intellectual property via ownership authentication and to ensure downstream users and developers comply with their license terms (e.g. restricting commercial use). In this study, we present a pilot study on LLM fingerprinting as a form of very lightweight instruction tuning. Model publisher specifies a confidential private key and implants it as an instruction backdoor that causes the LLM to generate specific text when the key is present. Results on 11 popularly-used LLMs showed that this approach is lightweight and does not affect the normal behavior of the model. It also prevents publisher overclaim, maintains robustness against fingerprint guessing and parameter-efficient training, and supports multi-stage fingerprinting akin to MIT License.																																	2024-04-18	PPRN:87300910		
J	Heintz, K.E.; Brammer, G.B.; Watson, D.; Oesch, P.A.; Keating, L.C.; Hayes, M.J.; Abdurro’uf; Arellano-Cordova, K.Z.; Carnall, A.C.; Christiansen, C.R.; Cullen, F.; Dave, R.; Dayal, P.; Ferrara, A.; Finlator, K.; Fynbo, J.P.U.; Flury, S.R.; Gelli, V.; Gillman, S.; Gottumukkala, R.; Gould, K.; Greve, T.R.; Hardin, S.E.; Hsiao, T. Y. Y; Hutter, A.; Jakobsson, P.; Killi, M.; Khosravaninezhad, N.; Laursen, P.; Lee, M. M.; Magdis, G.E.; Matthee, J.; Naidu, R.P.; Narayanan, D.; Pollock, C.; Prescott, M.; Rusakov, V.; Shuntov, M.; Sneppen, A.; Smit, R.; Tanvir, N.R.; Terp, C.; Toft, S.; Valentino, F.; Vijayan, A.P.; Weaver, J.R.; Wise, J.H.; Witstok, J.				Greve, Thomas/ITV-1914-2023; Fynbo, Johan/L-8496-2014; Matthee, Jorryt/KHD-9384-2024; Wise, John/AAW-5312-2021; Smit, Renske/MIK-8564-2025; Toft, Sune/JEZ-2766-2023; dayal, Pratika/AAD-4237-2019; May Lee, Marco/HKO-8861-2023; Witstok, Joris/GQA-8643-2022; Oesch, Pascal/AFN-4775-2022; Jakobsson, Pall/L-9950-2015; Labbe, Ivo/B-1408-2016						The JWST-PRIMAL Legacy Survey A JWST/NIRSpec reference sample for the physical properties and Lyman-α absorption and emission of ∼ 500 galaxies at z = 5.5 − 13.4								Arxiv											1	1;2024-04-02;https://www.arxiv.org/abs/2404.02211v1	arXiv:2404.02211			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 02 2024	2024	Context. One of the surprising early findings with JWST has been the discovery of a strong “roll-over” or a softening of the absorption edge of Lyα in a large number of galaxies at z ≳ 6, in addition to systematic offsets from photometric redshift estimates and fundamental galaxy scaling relations. This has been interpreted as strong cumulative damped Lyα absorption (DLA) wings from high column densities of neutral atomic hydrogen (H i), signifying major gas accretion events in the formation of these galaxies.   Aims. To explore this new phenomenon systematically, we assemble the JWST/NIRSpec PRImordial gas Mass AssembLy (PRIMAL) legacy survey of 494 galaxies at z = 5.5 − 13.4, designed to study the physical properties and gas in and around galaxies during the reionization epoch.   Methods. We characterize this benchmark sample in full and spectroscopically derive the galaxy redshifts, metallicities, star-formation rates, and ultraviolet slopes. We define a new diagnostic, the Lyα damping parameter DLyα to measure and quantify the net effect of Lyα emission strength, H i fraction in the IGM, or local H i column density for each source. The JWST-PRIMAL survey is based on the spectroscopic DAWN JWST Archive (DJA-Spec). We describe DJA-Spec in this paper, detailing the reduction methods, the postprocessing steps, and basic analysis tools. All the software, reduced spectra, and spectroscopically derived quantities and catalogs are made publicly available in dedicated repositories.   Results. We find that the fraction of galaxies showing strong integrated DLAs with NHI > 1021 cm−2 only increases slightly from ≈60% at z ≈ 6 up to ≈ 65 − 90% at z > 8. Similarly, the prevalence and prominence of Lyα emission is found to increase with decreasing redshift, in qualitative agreement with previous observational results. Strong Lyα emitters (LAEs) are predominantly found to be associated with low-metallicity and UV faint galaxies. By contrast, strong DLAs are observed in galaxies with a variety of intrinsic physical properties, but predominantly at high redshifts and low metallicities.   Conclusions. Our results indicate that strong DLAs likely reflect a particular early assembly phase of reionization-era galaxies, at which point they are largely dominated by pristine H i gas accretion. At z = 8 − 10, this gas gradually cools and forms into stars that ionize their local surroundings, forming large ionized bubbles and produce strong observed Lyα emission at z < 8.																																	2024-05-07	PPRN:88390318		
J	Fanaskov, Vladimir; Oseledets, Ivan										Spectral Neural Operators								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2205.10573v2| 1;2022-05-21;https://www.arxiv.org/abs/2205.10573v1	arXiv:2205.10573			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Apr 01 2024	2024	A plentitude of applications in scientific computing requires the approximation of mappings between Banach spaces. Recently introduced Fourier Neural Operator (FNO) and Deep Operator Network (DeepONet) can provide this functionality. For both of these neural operators, the input function is sampled on a given grid (uniform for FNO), and the output function is parametrized by a neural network. We argue that this parametrization leads to 1) opaque output that is hard to analyze and 2) systematic bias caused by aliasing errors in the case of FNO. The alternative, advocated in this article, is to use Chebyshev and Fourier series for both domain and codomain. The resulting Spectral Neural Operator (SNO) has transparent output, never suffers from aliasing, and may include many exact (lossless) operations on functions. The functionality is based on well -developed fast, and stable algorithms from spectral methods. The implementation requires only standard numerical linear algebra. Our benchmarks show that for many operators, SNO is superior to FNO and DeepONet.																																	2024-04-17	PPRN:12840770		
J	Li, Miaoran; Peng, Baolin; Galley, Michel; Gao, Jianfeng; Zhang, Zhu				Gao, Jianfeng/AAP-8200-2021; Peng, Baolin/F-2278-2019						Self-Checker: Plug-and-Play Modules for Fact-Checking with Large Language Models								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2305.14623v2| 1;2023-05-24;https://www.arxiv.org/abs/2305.14623v1	arXiv:2305.14623			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 01 2024	2024	Fact-checking is an essential task in NLP that is commonly utilized for validating the factual accuracy of claims. Prior work has mainly focused on fine-tuning pre-trained languages models on specific datasets, which can be computationally intensive and time-consuming. With the rapid development of large language models (LLMs), such as ChatGPT and GPT-3, researchers are now exploring their in-context learning capabilities for a wide range of tasks. In this paper, we aim to assess the capacity of LLMs for fact-checking by introducing Self-Checker, a framework comprising a set of plug-and-play modules that facilitate fact-checking by purely prompting LLMs in an almost zero-shot setting. This framework provides a fast and efficient way to construct fact-checking systems in low-resource environments. Empirical results demonstrate the potential of Self-Checker in utilizing LLMs for fact-checking. However, there is still significant room for improvement compared to SOTA fine-tuned models, which suggests that LLM adoption could be a promising approach for future fact-checking research.																																	2024-04-18	PPRN:72712998		
J	Liu, Minghuan; Chen, Zixuan; Cheng, Xuxin; Ji, Yandong; Yang, Ruihan; Wang, Xiaolong				chen, zixuan/JBJ-4564-2023; Yang, Ruihan/AAC-7500-2020; Yang, Ruihan/MTE-7082-2025; Ji, Yandong/JFA-9241-2023						Visual Whole-Body Control for Legged Loco-Manipulation								Arxiv											5	5;2024-11-02;https://www.arxiv.org/abs/2403.16967v5| 4;2024-05-14;https://www.arxiv.org/abs/2403.16967v4| 3;2024-04-20;https://www.arxiv.org/abs/2403.16967v3| 2;2024-03-26;https://www.arxiv.org/abs/2403.16967v2| 1;2024-03-25;https://www.arxiv.org/abs/2403.16967v1	arXiv:2403.16967			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 25 2024	2024	We study the problem of mobile manipulation using legged robots equipped with an arm, namely legged loco-manipulation. The robot legs, while usually utilized for mobility, offer an opportunity to amplify the manipulation capabilities by conducting whole-body control. That is, the robot can control the legs and the arm at the same time to extend its workspace. We propose a framework that can conduct the whole-body control autonomously with visual observations. Our approach, namely ourFull~(our), is composed of a low-level policy using all degrees of freedom to track the end-effector manipulator position and a high-level policy proposing the end-effector position based on visual inputs. We train both levels of policies in simulation and perform Sim2Real transfer for real robot deployment. We perform extensive experiments and show significant improvements over baselines in picking up diverse objects in different configurations (heights, locations, orientations) and environments. Project page: https://wholebody-b1.github.io																																	2025-08-07	PPRN:88281657		
J	Ma, Lezhi; Liu, Shangqing; Li, Yi; Xie, Xiaofei; Bu, Lei				Xie, Xiaofei/ABE-4095-2020; Bu, Lei/ACB-7465-2022; Liu, Shangqing/LCD-8169-2024						SpecGen: Automated Generation of Formal Program Specifications via Large Language Models								Arxiv											1	1;2024-03-24;https://www.arxiv.org/abs/2401.08807v2	arXiv:2401.08807			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 24 2024	2024	Formal program specifications play a crucial role in various stages of software development. However, manually crafting formal program specifications is rather difficult, making the job time-consuming and labor-intensive. It is even more challenging to write specifications that correctly and comprehensively describe the semantics of complex programs. To reduce the burden on software developers, automated specification generation methods have emerged. However, existing methods usually rely on predefined templates or grammar, making them struggle to accurately describe the behavior and functionality of complex real-world programs. To tackle this challenge, we introduce SpecGen, a novel technique for formal program specification generation based on Large Language Models. Our key insight is to overcome the limitations of existing methods by leveraging the code comprehension capability of LLMs. The process of SpecGen consists of two phases. The first phase employs a conversational approach that guides the LLM to generate appropriate specifications for a given program. The second phase, designed for where the LLM fails to generate correct specifications, applies four mutation operators to the model-generated specifications and selects verifiable specifications from the mutated ones through a novel heuristic selection strategy. We evaluate SpecGen on two datasets, including the SV-COMP Java category benchmark and a manually constructed dataset. Experimental results demonstrate that SpecGen succeeds in generating verifiable specifications for 279 out of 385 programs, outperforming the existing purely LLM-based approaches and conventional specification generation tools like Houdini and Daikon. Further investigations on the quality of generated specifications indicate that SpecGen can comprehensively articulate the behaviors of the input program.																																	2025-08-07	PPRN:123156478		
J	Wang, Weiyun; Ren, Yiming; Luo, Haowen; Li, Tiantong; Yan, Chenxiang; Chen, Zhe; Wang, Wenhai; Li, Qingyun; Lu, Lewei; Zhu, Xizhou; Qiao, Yu; Dai, Jifeng				Li, Qingyun/GZL-4438-2022; Dai, Jifeng/HGU-8741-2022						The All-Seeing Project V2: Towards General Relation Comprehension of the Open World								Arxiv											1	1;2024-03-21;https://www.arxiv.org/abs/2402.19474v2	arXiv:2402.19474			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 21 2024	2024	We present the All-Seeing Project V2: a new model and dataset designed for understanding object relations in images. Specifically, we propose the All-Seeing Model V2 (ASMv2) that integrates the formulation of text generation, object localization, and relation comprehension into a relation conversation (ReC) task. Leveraging this unified task, our model excels not only in perceiving and recognizing all objects within the image but also in grasping the intricate relation graph between them, diminishing the relation hallucination often encountered by Multi-modal Large Language Models (MLLMs). To facilitate training and evaluation of MLLMs in relation understanding, we created the first high-quality ReC dataset ({AS-V2) which is aligned with the format of standard instruction tuning data. In addition, we design a new benchmark, termed Circular-based Relation Probing Evaluation (CRPE) for comprehensively evaluating the relation comprehension capabilities of MLLMs. Notably, our ASMv2 achieves an overall accuracy of 52.04 on this relation-aware benchmark, surpassing the 43.14 of LLaVA-1.5 by a large margin. We hope that our work can inspire more future research and contribute to the evolution towards artificial general intelligence. Our project is released at https://github.com/OpenGVLab/all-seeing.																																	2025-08-07	PPRN:123150745		
J	Marcu, Ana-Maria; Chen, Long; Huenermann, Jan; Karnsund, Alice; Hanotte, Benoit; Chidananda, Prajwal; Nair, Saurabh; Badrinarayanan, Vijay; Kendall, Alex; Shotton, Jamie; Arani, Elahe; Sinavski, Oleg										LingoQA: Video Question Answering for Autonomous Driving								Arxiv											2	2;2024-03-20;https://www.arxiv.org/abs/2312.14115v2| 1;2023-12-21;https://www.arxiv.org/abs/2312.14115v1	arXiv:2312.14115			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 20 2024	2024	We introduce LingoQA, a novel dataset and benchmark for video question answering in autonomous driving. The dataset contains 28K unique scenarios and 419K annotations. Evaluating state-of-the-art vision -language models on our benchmark shows that their performance is below human capabilities, with GPT-4V responding truthfully to 56.67% of the questions compared to 93.4% for humans. For evaluation, in addition to conducting a human study, we propose a truthfulness classifier, called Lingo -Judge, that achieves a 0.95 Spearman correlation coefficient to human evaluations, surpassing existing techniques like METEOR, BLEU, CIDEr, and GPT-4. We establish a baseline vision -language model and run extensive ablation studies to understand its performance. We release our dataset and benchmark1 and hope that it will provide a thorough evaluation platform for future vision -language models in autonomous driving.																																	2024-04-12	PPRN:86787115		
J	Liu, Zhengliang; Zhong, Aoxiao; Li, Yiwei; Yang, Longtao; Ju, Chao; Wu, Zihao; Ma, Chong; Shu, Peng; Chen, Cheng; Kim, Sekeun; Dai, Haixing; Zhao, Lin; Sun, Lichao; Zhu, Dajiang; Liu, Jun; Liu, Wei; Shen, Dinggang; Li, Xiang; Li, Quanzheng; Liu, Tianming				Liu, Tianming/GLS-1211-2022; Zhao, Lin/ABM-7665-2022; Wu, Zihao/KDP-2552-2024; Li, Xiang/J-6924-2019; Liu, Wei/JYQ-6082-2024						Radiology-GPT: A Large Language Model for Radiology								Arxiv											2	2;2024-03-19;https://www.arxiv.org/abs/2306.08666v2| 1;2023-06-14;https://www.arxiv.org/abs/2306.08666v1	arXiv:2306.08666			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 19 2024	2024	We introduce Radiology-GPT, a large language model for radiology. Using an instruction tuning approach on an extensive dataset of radiology domain knowledge, Radiology-GPT demonstrates superior performance compared to general language models such as StableLM, Dolly and LLaMA. It exhibits significant versatility in radiological diagnosis, research, and communication. This work serves as a catalyst for future developments in clinical NLP. The successful implementation of Radiology-GPT is indicative of the potential of localizing generative large language models, specifically tailored for distinctive medical specialties, while ensuring adherence to privacy standards such as HIPAA. The prospect of developing individualized, large-scale language models that cater to specific needs of various hospitals presents a promising direction. The fusion of conversational competence and domain-specific knowledge in these models is set to foster future development in healthcare AI. A demo of Radiology-																																	2024-04-12	PPRN:73362767		
J	Kesselring, Markus S.; de la Fuente, Julio C. Magdalena; Thomsen, Felix; Eisert, Jens; Bartlett, Stephen D.; Brown, Benjamin J.				Bartlett, Stephen/A-4163-2008; Brown, Benjamin/J-7893-2017						Anyon condensation and the color code								Arxiv											2	2;2024-03-13;https://www.arxiv.org/abs/2212.00042v2| 1;2022-11-30;https://www.arxiv.org/abs/2212.00042v1	arXiv:2212.00042			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 13 2024	2024	The manipulation of topologically-ordered phases of matter to encode and process quantum information forms the cornerstone of many approaches to fault-tolerant quantum computing. Here we demonstrate that fault-tolerant logical operations in these approaches can be interpreted as instances of anyon condensation. We present a constructive theory for anyon condensation and, in tandem, illustrate our theory explicitly using the color-code model. We show that different condensation processes are associated with a general class of domain walls, which can exist in both space- and time-like directions. This class includes semi-transparent domain walls that condense certain subsets of anyons. We use our theory to classify topological objects and design novel fault-tolerant logic gates for the color code. As a final example, we also argue that dynamical `Floquet codes' can be viewed as a series of condensation operations. We propose a general construction for realising planar dynamically driven codes based on condensation operations on the color code. We use our construction to introduce a new Calderbank-Shor Steane-type Floquet code that we call the Floquet color code.																																	2024-04-08	PPRN:23256801		
J	Kwon, Yongchan; Wu, Eric; Wu, Kevin; Zou, James										DataInf: Efficiently Estimating Data Influence in LoRA-tuned LLMs and Diffusion Models								Arxiv											3	3;2024-03-13;https://www.arxiv.org/abs/2310.00902v3| 2;2024-02-23;https://www.arxiv.org/abs/2310.00902v2| 1;2023-10-02;https://www.arxiv.org/abs/2310.00902v1	arXiv:2310.00902			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Mar 13 2024	2024	Quantifying the impact of training data points is crucial for understanding the outputs of machine learning models and for improving the transparency of the AI pipeline. The influence function is a principled and popular data attribution method, but its computational cost often makes it challenging to use. This issue becomes more pronounced in the setting of large language models and text-to-image models. In this work, we propose DataInf, an efficient influence approximation method that is practical for large-scale generative AI models. Leveraging an easy-to-compute closed-form expression, DataInf outperforms existing influence computation algorithms in terms of computational and memory efficiency. Our theoretical analysis shows that DataInf is particularly well-suited for parameter-efficient fine-tuning techniques such as LoRA. Through systematic empirical evaluations, we show that DataInf accurately approximates influence scores and is orders of magnitude faster than existing methods. In applications to RoBERTa-large, Llama-2-13B-chat, and stable-diffusion-v1.5 models, DataInf effectively identifies the most influential fine-tuning examples better than other approximate influence scores. Moreover, it can help to identify which data points are mislabeled.																																	2024-04-08	PPRN:85355931		
J	Lai, Zhengfeng; Zhang, Haotian; Zhang, Bowen; Wu, Wentao; Bai, Haoping; Timofeev, Aleksei; Du, Xianzhi; Gan, Zhe; Shan, Jiulong; Chuah, Chen-Nee; Yang, Yinfei; Cao, Meng				Zhang, Haotian/CAH-0725-2022; Zhang, Xiangwen/ABD-9717-2021; Wu, Wentao/JAX-2475-2023; Lai, Zhengfeng/AAG-9453-2021						VeCLIP: Improving CLIP Training via Visual-enriched Captions								Arxiv											2	2;2024-03-13;https://www.arxiv.org/abs/2310.07699v3| 1;2024-03-07;https://www.arxiv.org/abs/2310.07699v2	arXiv:2310.07699			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 13 2024	2024	Large-scale web-crawled datasets are fundamental for the success of pre-training vision-language models, such as CLIP. However, the inherent noise and potential irrelevance of web-crawled AltTexts pose challenges in achieving precise image-text alignment. Existing methods utilizing large language models (LLMs) for caption rewriting have shown promise on small, curated datasets like CC3M and CC12M. This study introduces a scalable pipeline for noisy caption rewriting. Unlike recent LLM rewriting techniques, we emphasize the incorporation of visual concepts into captions, termed as Visual-enriched Captions (VeCap). To ensure data diversity, we propose a novel mixed training scheme that optimizes the utilization of AltTexts alongside newly generated VeCap. We showcase the adaptation of this method for training CLIP on large-scale web-crawled datasets, termed VeCLIP. Employing this cost-effective pipeline, we effortlessly scale our dataset up to 300 million samples named VeCap dataset. Our results show significant advantages in image-text alignment and overall model performance. For example, VeCLIP achieves up to +25.2% gain in COCO and Flickr30k retrieval tasks under the 12M setting. For data efficiency, VeCLIP achieves +3% gain while only using 14% of the data employed in the vanilla CLIP and 11% in ALIGN. We also note the VeCap data is complementary with other well curated datasets good for zero-shot classification tasks. When combining VeCap and DFN, our model can achieve strong performance on both of image-text retrieval and zero-shot classification tasks, e.g. 83.1% accuracy@1 on ImageNet zero-shot for a H/14 model. We release the pre-trained models at https://github.com/apple/ml-veclip.																																	2024-04-11	PPRN:88062835		
J	Tang, Jiapeng; Nie, Yinyu; Markhasin, Lev; Dai, Angela; Thies, Justus; Niessner, Matthias				Tang, Jiapeng/AAU-1512-2021; Nie, Yinyu/AES-2766-2022						DiffuScene: Denoising Diffusion Models for Generative Indoor Scene Synthesis								Arxiv											2	2;2024-03-12;https://www.arxiv.org/abs/2303.14207v2| 1;2023-03-24;https://www.arxiv.org/abs/2303.14207v1	arXiv:2303.14207			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Mar 12 2024	2024	We present DiffuScene for indoor 3D scene synthesis based on a novel scene configuration denoising diffusion model. It generates 3D instance properties stored in an unordered object set and retrieves the most similar geometry for each object configuration, which is characterized as a concatenation of different attributes, including location, size, orientation, semantics, and geometry features. We introduce a diffusion network to synthesize a collection of 3D indoor objects by denoising a set of unordered object attributes. Unordered parametrization simplifies and eases the joint distribution approximation. The shape feature diffusion facilitates natural object placements, including symmetries. Our method enables many downstream applications, including scene completion, scene arrangement, and text-conditioned scene synthesis. Experiments on the 3D-FRONT dataset show that our method can synthesize more physically plausible and diverse indoor scenes than state-of-the-art methods. Extensive ablation studies verify the effectiveness of our design choice in scene diffusion models.																																	2024-04-08	PPRN:49579053		
J	Yang, Zhou; Sun, Zhensu; Yue, Terry Zhuo; Devanbu, Premkumar; Lo, David				Yang, Zhou/KCY-4504-2024						Robustness, Security, Privacy, Explainability, Efficiency, and Usability of Large Language Models for Code								Arxiv											1	1;2024-03-12;https://www.arxiv.org/abs/2403.07506v1	arXiv:2403.07506			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 12 2024	2024	Large language models for code (LLM4Code), which demonstrate strong performance (e.g., high accuracy) in processing source code, have significantly transformed software engineering. Many studies separately investigate the non-functional properties of LM4Code, but there is no systematic review of how these properties are evaluated and enhanced. This paper fills this gap by thoroughly examining 146 relevant studies, thereby presenting the first systematic literature review to identify seven important properties beyond accuracy, including robustness, security, privacy, explainability, efficiency, and usability. We discuss the current state-of-the-art methods and trends, identify gaps in existing research, and present promising directions for future study.																																	2024-04-08	PPRN:88112700		
J	Hoogeboom, Emiel; Agustsson, Eirikur; Mentzer, Fabian; Versari, Luca; Toderici, George; Theis, Lucas										High-Fidelity Image Compression with Score-based Generative Models								Arxiv											3	3;2024-03-07;https://www.arxiv.org/abs/2305.18231v3| 2;2024-03-06;https://www.arxiv.org/abs/2305.18231v2| 1;2023-05-26;https://www.arxiv.org/abs/2305.18231v1	arXiv:2305.18231			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 07 2024	2024	Despite the tremendous success of diffusion generative models in text-to-image generation, replicating this success in the domain of image compression has proven difficult. In this paper, we demonstrate that diffusion can significantly improve perceptual quality at a given bit-rate, outperforming state-of-the-art approaches PO-ELIC [14] and HiFiC [27] as measured by FID score. This is achieved using a simple but theoretically motivated two-stage approach combining an autoencoder targeting MSE followed by a further score-based decoder. However, as we will show, implementation details matter and the optimal design decisions can differ greatly from typical text-to-image models.																																	2024-04-01	PPRN:72756727		
J	Ju, Wei; Yi, Siyu; Wang, Yifan; Xiao, Zhiping; Mao, Zhengyang; Li, Hourun; Gu, Yiyang; Qin, Yifang; Yin, Nan; Wang, Senzhang; Liu, Xinwang; Luo, Xiao; Yu, Philip S.; Zhang, Ming				LIU, Xinwang/L-8089-2019; Luo, Xiao/IYS-9183-2023; WANG, YIFAN/CAH-6765-2022; Wang, Senzhang/ABE-8684-2022; Ju, Wei/A-5064-2018; Qin, Yifang/JMC-3669-2023						A Survey of Graph Neural Networks in Real world: Imbalance, Noise, Privacy and OOD Challenges								Arxiv											1	1;2024-03-07;https://www.arxiv.org/abs/2403.04468v1	arXiv:2403.04468			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 07 2024	2024	Graph-structured data exhibits universality and widespread applicability across diverse domains, such as social network analysis, biochemistry, financial fraud detection, and network security. Significant strides have been made in leveraging Graph Neural Networks (GNNs) to achieve remarkable success in these areas. However, in real-world scenarios, the training environment for models is often far from ideal, leading to substantial performance degradation of GNN models due to various unfavorable factors, including imbalance in data distribution, the presence of noise in erroneous data, privacy protection of sensitive information, and generalization capability for out-of-distribution (OOD) scenarios. To tackle these issues, substantial efforts have been devoted to improving the performance of GNN models in practical real-world scenarios, as well as enhancing their reliability and robustness. In this paper, we present a comprehensive survey that systematically reviews existing GNN models, focusing on solutions to the four mentioned real-world challenges including imbalance, noise, privacy, and OOD in practical scenarios that many existing reviews have not considered. Specifically, we first highlight the four key challenges faced by existing GNNs, paving the way for our exploration of real-world GNN models. Subsequently, we provide detailed discussions on these four aspects, dissecting how these solutions contribute to enhancing the reliability and robustness of GNN models. Last but not least, we outline promising directions and offer future perspectives in the field.																																	2024-04-04	PPRN:88055693		
J	Ren, Weijieying; Li, Xinlong; Wang, Lei; Zhao, Tianxiang; Qin, Wei				Ren, Weijieying/KHD-0030-2024; zhao, tianxiang/ITT-1867-2023						Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning								Arxiv											1	1;2024-02-29;https://www.arxiv.org/abs/2402.18865v1	arXiv:2402.18865			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 29 2024	2024	Existing research has shown that large language models (LLMs) exhibit remarkable performance in language understanding and generation. However, when LLMs are continuously fine-tuned on complex and diverse domainspecific downstream tasks, the inference performance on historical tasks decreases dramatically, which is known as a catastrophic forgetting problem. A trade-off needs to be kept between learning plasticity and memory stability. Plenty of existing works have explored strategies like memory replay, regularization and parameter isolation, but little is known about the geometric connection of various adjacent minima in the continual LLMs fine-tuning scenarios. In this work, we investigate the geometric connections of different minima through the lens of mode connectivity, which means different minima can be connected by a low -loss valley. Through extensive experiments, we uncover the mode connectivity phenomenon in the LLMs continual learning scenario and find that it can strike a balance between plasticity and stability. Building upon these findings, we propose a simple yet effective method called Interpolation -based LoRA (I-LoRA), which constructs a dual -memory experience replay framework based on LoRA parameter interpolations. Extensive experiments and analysis on eight domain -specific CL benchmarks demonstrate that I-LoRA consistently show significant improvement over the previous state-of-the-art approaches with up to 11% performance gains, providing a strong baseline and insights for future research on the large language model continual learning problem. 																																	2024-11-10	PPRN:88005032		
J	Zhang, Shaolei; Yu, Tian; Feng, Yang				Yu, Tianrun/ORI-1087-2025; Zhang, Shengchen/IQT-8260-2023						TruthX: Alleviating Hallucinations by Editing Large Language Models in Truthful Space								Arxiv											1	1;2024-02-27;https://www.arxiv.org/abs/2402.17811v1	arXiv:2402.17811			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 27 2024	2024	Large Language Models (LLMs) have demonstrated remarkable capabilities across various tasks. However, they sometimes suffer from producing hallucinations, particularly in cases where they may generate untruthful responses despite possessing the correct knowledge. In this paper, we propose TruthX, an inference-time method to elicit the truthfulness of LLMs by editing their internal representations in truthful space. TruthX employs an auto-encoder to map LLM's representations into semantic and truthful latent spaces respectively, and applies contrastive learning to identify a truthful editing direction within the truthful space. During inference, by editing LLM's internal representations in truthful space, TruthX effectively enhances the truthfulness of LLMs. Experiments show that TruthX effectively improves the truthfulness of 13 advanced LLMs by an average of 20% on TruthfulQA benchmark. Further analyses suggest that the truthful space acquired by TruthX plays a pivotal role in controlling LLM to produce truthful or hallucinatory responses.																																	2024-11-10	PPRN:87988996		
J	Behrouz, Ali; Hashemi, Farnoosh										Graph Mamba: Towards Learning on Graphs with State Space Models								Arxiv											2	2;2024-02-19;https://www.arxiv.org/abs/2402.08678v2| 1;2024-02-13;https://www.arxiv.org/abs/2402.08678v1	arXiv:2402.08678			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 19 2024	2024	Graph Neural Networks (GNNs) have shown promising potential in graph representation learning. The majority of GNNs define a local message-passing mechanism, propagating information over the graph by stacking multiple layers. These methods, however, are known to suffer from two major limitations: over-squashing and poor capturing of long-range dependencies. Recently, Graph Transformers (GTs) emerged as a powerful alternative to Message-Passing Neural Networks (MPNNs). GTs, however, have quadratic computational cost, lack inductive biases on graph structures, and rely on complex Positional/Structural Encodings (SE/PE). In this paper, we show that while Transformers, complex message-passing, and SE/PE are sufficient for good performance in practice, neither is necessary. Motivated by the recent success of State Space Models (SSMs), such as Mamba, we present Graph Mamba Networks (GMNs), a general framework for a new class of GNNs based on selective SSMs. We discuss and categorize the new challenges when adapting SSMs to graph-structured data, and present four required and one optional steps to design GMNs, where we choose (1) Neighborhood Tokenization, (2) Token Ordering, (3) Architecture of Bidirectional Selective SSM Encoder, (4) Local Encoding, and dispensable (5) PE and SE. We further provide theoretical justification for the power of GMNs. Experiments demonstrate that despite much less computational cost, GMNs attain an outstanding performance in long-range, small-scale, large-scale, and heterophilic benchmark datasets.																																	2024-03-16	PPRN:87674628		
J	Zhang, Jenny; Lehman, Joel; Stanley, Kenneth; Clune, Jeff				Lehman, Joel/AAH-9977-2019						OMNI: Open-endedness via Models of human Notions of Interestingness								Arxiv											3	3;2024-02-15;https://www.arxiv.org/abs/2306.01711v3| 2;2023-10-06;https://www.arxiv.org/abs/2306.01711v2| 1;2023-06-02;https://www.arxiv.org/abs/2306.01711v1	arXiv:2306.01711			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 15 2024	2024	Open-ended algorithms aim to learn new, interesting behaviors forever. That requires a vast environment search space, but there are thus infinitely many possible tasks. Even after filtering for tasks the current agent can learn (i.e., learning progress), countless learnable yet uninteresting tasks remain (e.g., minor variations of previously learned tasks). An Achilles Heel of open-endedness research is the inability to quantify (and thus prioritize) tasks that are not just learnable, but also interesting (e.g., worthwhile and novel). We propose solving this problem by Open-endedness via Models of human Notions of Interestingness (OMNI). The insight is that we can utilize foundation models (FMs) as a model of interestingness (MoI), because they already internalize human concepts of interestingness from training on vast amounts of human -generated data, where humans naturally write about what they find interesting or boring. We show that FM-based MoIs improve open-ended learning by focusing on tasks that are both learnable and interesting, outperforming baselines based on uniform task sampling or learning progress alone. This approach has the potential to dramatically advance the ability to intelligently select which tasks to focus on next (i.e., auto-curricula), and could be seen as AI selecting its own next task to learn, facilitating self-improving AI and AI-Generating Algorithms.1																																	2024-03-13	PPRN:72844018		
J	Platania, Alessia				Platania, Alessia/V-3190-2018						Black Holes in Asymptotically Safe Gravity								Arxiv											2	2;2024-02-10;https://www.arxiv.org/abs/2302.04272v3| 1;2023-02-08;https://www.arxiv.org/abs/2302.04272v1	arXiv:2302.04272			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 10 2024	2024	In this chapter we review the state-of-the-art of black holes in asymptotically safe gravity. After a brief recap of the asymptotic safety program, we shall summarize the features of asymptotic-safety-inspired black-hole models that have been constructed in the past by the so-called renormalization group improvement. Specifically, we will discuss static configurations, both in spherically- and axiallysymmetric settings, the role played by the cosmological constant, and the impact of the collapse dynamics in determining black-hole configurations realized in Nature. In particular, we will review how quantum gravity could modify the Buchdahl limit and the corresponding conditions to form ultra -compact objects and Planckian black holes. We will then proceed by describing the most recent developments, particularly those aiming at making model building in asymptotic safety more rigorous and free from ambiguities. These include self -consistent and coordinate-independent versions of the renormalization group improvement, and next steps to fill the gap between model building and renormalization group computations in asymptotic safety. Finally, we will focus on a selection of results that have been obtained from first-principle calculations or arguments, within and beyond asymptotic safety. Concretely, we will review the state-of-the-art in determining black-hole entropy in asymptotic safety from a microstate counting, and progress in deriving the quantumcorrected Newtonian potential. We will discuss how in quantum gravity theories linked to a gravitational path integral singularity resolution could be achieved by a dynamical suppression of singular configurations. Finally, we will show that— independent of the specific ultraviolet completion of gravity—asymptotic modifications to Schwarzschild black holes are strongly constrained by the principle of least action at large distance scales.																																	2024-05-25	PPRN:36866131		
J	Fan, Simin; Pagliardini, Matteo; Jaggi, Martin										DoGE: Domain Reweighting with Generalization Estimation								Arxiv											2	2;2024-02-05;https://www.arxiv.org/abs/2310.15393v2| 1;2023-10-23;https://www.arxiv.org/abs/2310.15393v1	arXiv:2310.15393			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 05 2024	2024	The coverage and composition of the pretraining data significantly impacts the generalization ability of Large Language Models (LLMs). Despite its importance, recent LLMs still rely on heuristics and trial and error to increase or reduce the influence of data-domains. We propose DOmain reweighting with Generalization Estimation (DoGE), which optimizes the probability of sampling from each domain (domain weights) in a principled way. Our approach is a two-stage process consisting of (i) training a proxy model to obtain domain weights using a bi-level optimization algorithm; (ii) training a larger base model by sampling training domains according to the learned domain weights. In our experiments, we extensively show how DoGE improves the generalization of the base model to any target data mixture. On the SlimPajama dataset, our base model gets better perplexity and few-shot reasoning accuracies across $6$ tasks compared to baseline methods. Moreover, aiming to generalize to out-of-domain target tasks, which is unseen in the pretraining corpus (OOD domain), DoGE can effectively identify inter-domain dependencies, and consistently achieves better test perplexity on the target domain.																																	2024-05-01	PPRN:85776944		
J	Wang, Bin; Wu, Fan; Han, Xiao; Peng, Jiahui; Zhong, Huaping; Zhang, Pan; Dong, Xiaoyi; Li, Weijia; Li, Wei; Wang, Jiaqi; He, Conghui				He, Conghui/AAZ-3323-2021; WANG, JIAQI/KBB-8837-2024; Dong, Xiaoyi/AAC-8666-2019; Li, WeiJia/GRJ-3727-2022; Wang, Bin/MVU-8917-2025						VIGC: Visual Instruction Generation and Correction								Arxiv											3	3;2024-02-04;https://www.arxiv.org/abs/2308.12714v3| 2;2023-09-11;https://www.arxiv.org/abs/2308.12714v2| 1;2023-08-24;https://www.arxiv.org/abs/2308.12714v1	arXiv:2308.12714			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 04 2024	2024	The integration of visual encoders and large language models (LLMs) has driven recent progress in multimodal large language models (MLLMs). However, the scarcity of highquality instruction-tuning data for vision-language tasks remains a challenge. The current leading paradigm, such as LLaVA, relies on language-only GPT-4 to generate data, which requires pre-annotated image captions and detection bounding boxes, suffering from understanding image details. A practical solution to this problem would be to utilize the available multimodal large language models to generate instruction data for vision-language tasks. However, it’s worth noting that the currently accessible MLLMs are not as powerful as their LLM counterparts, as they tend to produce inadequate responses and generate false information. As a solution for addressing the current issue, this paper proposes the Visual Instruction Generation and Correction (VIGC) framework that enables multimodal large language models to generate instruction-tuning data and progressively enhance its quality on-the-fly. Specifically, Visual Instruction Generation (VIG) guides the vision-language model to generate diverse instruction-tuning data. To ensure generation quality, Visual Instruction Correction (VIC) adopts an iterative update mechanism to correct any inaccuracies in data produced by VIG, effectively reducing the risk of hallucination. Leveraging the diverse, high-quality data generated by VIGC, we finetune mainstream models and validate data quality based on various evaluations. Experimental results demonstrate that VIGC not only compensates for the shortcomings of language-only data generation methods, but also effectively enhances the benchmark performance. The models, datasets, and code are available at https://opendatalab.github.io/VIGC.																																	2024-05-25	PPRN:83899950		
J	Xu, Zhiyuan; Wu, Kun; Wen, Junjie; Li, Jinming; Liu, Ning; Che, Zhengping; Tang, Jian				Che, Zhengping/U-2509-2019						A Survey on Robotics with Foundation Models: toward Embodied AI								Arxiv											2	2;2024-02-04;https://www.arxiv.org/abs/2402.02385v1| 1;2024-02-04;https://www.arxiv.org/abs/2402.02385v1	arXiv:2402.02385			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 04 2024	2024	While the exploration for embodied AI has spanned multiple decades, it remains a persistent challenge to endow agents with human-level intelligence, including perception, learning, reasoning, decision-making, control, and generalization capabilities, so that they can perform general-purpose tasks in open, unstructured, and dynamic environments. Recent advances in computer vision, natural language processing, and multi-modality learning have shown that the foundation models have superhuman capabilities for specific tasks. They not only provide a solid cornerstone for integrating basic modules into embodied AI systems but also shed light on how to scale up robot learning from a methodological perspective. This survey aims to provide a comprehensive and up-to-date overview of foundation models in robotics, focusing on autonomous manipulation and encompassing high-level planning and low-level control. Moreover, we showcase their commonly used datasets, simulators, and benchmarks. Importantly, we emphasize the critical challenges intrinsic to this field and delineate potential avenues for future research, contributing to advancing the frontier of academic and industrial discourse.																																	2024-05-25	PPRN:87518176		
J	Ma, Ruotian; Wang, Xiaolei; Zhou, Xin; Li, Jian; Du, Nan; Gui, Tao; Zhang, Qi; Huang, Xuanjing				Wang, Xiaolei/Q-9999-2019; Zhang, Qi/ABD-3983-2020; Gui, Tao/LWI-6783-2024						Are Large Language Models Good Prompt Optimizers?								Arxiv											1	1;2024-02-03;https://www.arxiv.org/abs/2402.02101v1	arXiv:2402.02101			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 03 2024	2024	LLM-based Automatic Prompt Optimization, which typically utilizes LLMs as Prompt Optimizers to self -reflect and refine prompts, has shown promising performance in recent studies. Despite the success, the underlying mechanism of this approach remains unexplored, and the true effectiveness of LLMs as Prompt Optimizers requires further validation. In this work, we conducted a comprehensive study to uncover the actual mechanism of LLM-based Prompt Optimization. Our findings reveal that the LLM optimizers struggle to identify the true causes of errors during reflection, tending to be biased by their own prior knowledge rather than genuinely reflecting on the errors. Furthermore, even when the reflection is semantically valid, the LLM optimizers often fail to generate appropriate prompts for the target models with a single prompt refinement step, partly due to the unpredictable behaviors of the target models. Based on the observations, we introduce a new “Automatic Behavior Optimization” paradigm, which directly optimizes the target model’s behavior in a more controllable manner. We hope our study can inspire new directions for automatic prompt optimization development.																																	2024-02-21	PPRN:87522338		
J	Bauer, Andre; Trapp, Simon; Stenger, Michael; Leppich, Robert; Kounev, Samuel; Leznik, Mark; Chard, Kyle; Foster, Ian										Comprehensive Exploration of Synthetic Data Generation: A Survey								Arxiv											2	2;2024-02-01;https://www.arxiv.org/abs/2401.02524v2| 1;2024-01-04;https://www.arxiv.org/abs/2401.02524v1	arXiv:2401.02524			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 01 2024	2024	Recent years have witnessed a surge in the popularity of Machine Learning (ML), applied across diverse domains. However, progress is impeded by the scarcity of training data due to expensive acquisition and privacy legislation. Synthetic data emerges as a solution, but the abundance of released models and limited overview literature pose challenges for decision -making. This work surveys 417 Synthetic Data Generation (SDG) models over the last decade, providing a comprehensive overview of model types, functionality, and improvements. Common attributes are identified, leading to a classification and trend analysis. The findings reveal increased model performance and complexity, with neural network -based approaches prevailing, except for privacy -preserving data generation. Computer vision dominates, with GANs as primary generative models, while diffusion models, transformers, and RNNs compete. Implications from our performance evaluation highlight the scarcity of common metrics and datasets, making comparisons challenging. Additionally, the neglect of training and computational costs in literature necessitates attention in future research. This work serves as a guide for SDG model selection and identifies crucial areas for future exploration.																																	2024-02-19	PPRN:86996779		
J	Wang, Sai; Zhao, Zhi-Chao; Zhu, Qing-Hua				Zhu, Qìng-Hua/JHU-3274-2023						Constraints On Scalar-Induced Gravitational Waves Up To Third Order From Joint Analysis of BBN, CMB, And PTA Data								Arxiv											3	3;2024-01-25;https://www.arxiv.org/abs/2307.03095v3| 2;2023-09-16;https://www.arxiv.org/abs/2307.03095v2| 1;2023-07-06;https://www.arxiv.org/abs/2307.03095v1	arXiv:2307.03095			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jan 25 2024	2024	Recently, strong evidence for a gravitational wave background has been reported by collaborations of pulsar timing arrays (PTA). In the framework of scalar-induced gravitational waves (SIGWs), we concurrently investigate the second and third order gravitational waves by jointly analyzing PTA data, alongside big-bang nucleosynthesis (BBN), and cosmic microwave background (CMB) datasets. We determine the primordial curvature spectral amplitude as 0.021 < Aζ < 0.085 and the spectral peak frequency as 10−7.3 Hz < f∗ < 10−6.3 Hz at a 95% confidence interval, pointing towards a mass range for primordial black holes of 10−4.5M⊙ < mPBH < 10−2.5M⊙. Our findings suggest that third order gravitational waves contribute more significantly to the integrated energy density than the second order ones when Aζ ≳ 0.06. Furthermore, we expect future PTA projects to validate these findings and provide robust means to investigate the genesis and evolution of the universe, especially inflation.																																	2024-02-11	PPRN:73806098		
J	Rose, Daniel; Himakunthala, Vaishnavi; Ouyang, Andy; He, Ryan; Mei, Alex; Lu, Yujie; Saxon, Michael; Sonar, Chinmay; Mirza, Diba; Wang, William Yang										Visual Chain of Thought: Bridging Logical Gaps with Multimodal Infillings								Arxiv											3	3;2024-01-23;https://www.arxiv.org/abs/2305.02317v3| 2;2023-11-10;https://www.arxiv.org/abs/2305.02317v2| 1;2023-05-03;https://www.arxiv.org/abs/2305.02317v1	arXiv:2305.02317			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 23 2024	2024	Recent advances in large language models elicit reasoning in a chain-of-thought that allows models to decompose problems in a human-like fashion. Though this paradigm improves multi-step reasoning ability in language models, it is limited by being unimodal and applied mainly to question-answering tasks. We claim that incorporating visual augmentation into reasoning is essential, especially for complex, imaginative tasks. Consequently, we introduce VCoT, a novel method that leverages chain-of-thought prompting with vision-language grounding to recursively bridge the logical gaps within sequential data. Our method uses visual guidance to generate synthetic multimodal infillings that add consistent and novel information to reduce the logical gaps for downstream tasks that can benefit from temporal reasoning, as well as provide interpretability into models' multi-step reasoning. We apply VCoT to the Visual Storytelling and WikiHow summarization datasets and demonstrate through human evaluation that VCoT offers novel and consistent synthetic data augmentation beating chain-of-thought baselines, which can be used to enhance downstream performance.																																	2024-02-08	PPRN:67049602		
J	Gurnee, Wes; Horsley, Theo; Guo, Zifan Carl; Kheirkhah, Tara Rezaei; Sun, Qinyi; Hathaway, Will; Nanda, Neel; Bertsimas, Dimitris										Universal Neurons in GPT2 Language Models								Arxiv											1	1;2024-01-22;https://www.arxiv.org/abs/2401.12181v1	arXiv:2401.12181			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 22 2024	2024	A basic question within the emerging field of mechanistic interpretability is the degree to which neural networks learn the same underlying mechanisms. In other words, are neural mechanisms universal across different models? In this work, we study the universality of individual neurons across GPT2 models trained from different initial random seeds, motivated by the hypothesis that universal neurons are likely to be interpretable. In particular, we compute pairwise correlations of neuron activations over 100 million tokens for every neuron pair across five different seeds and find that 1-5% of neurons are universal, that is, pairs of neurons which consistently activate on the same inputs. We then study these universal neurons in detail, finding that they usually have clear interpretations and taxonomize them into a small number of neuron families. We conclude by studying patterns in neuron weights to establish several universal functional roles of neurons in simple circuits: deactivating attention heads, changing the entropy of the next token distribution, and predicting the next token to (not) be within a particular set.																																	2024-05-25	PPRN:87277135		
J	Wang, Pengyu; Zhang, Dong; Li, Linyang; Tan, Chenkun; Wang, Xinghao; Ren, Ke; Jiang, Botian; Qiu, Xipeng				Wang, Pengyu/ISA-9451-2023						InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance								Arxiv											1	1;2024-01-20;https://www.arxiv.org/abs/2401.11206v1	arXiv:2401.11206			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 20 2024	2024	With the rapid development of large language models (LLMs), they are not only used as general-purpose AI assistants but are also customized through further fine-tuning to meet the requirements of different applications. A pivotal factor in the success of current LLMs is the alignment process. Current alignment methods, such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF), focus on training-time alignment and are often complex and cumbersome to implement. Therefore, we develop textbf{InferAligner}, a novel inference-time alignment method that utilizes cross-model guidance for harmlessness alignment. InferAligner utilizes safety steering vectors extracted from safety-aligned model to modify the activations of the target model when responding to harmful inputs, thereby guiding the target model to provide harmless responses. Experimental results show that our method can be very effectively applied to domain-specific models in finance, medicine, and mathematics, as well as to multimodal large language models (MLLMs) such as LLaVA. It significantly diminishes the Attack Success Rate (ASR) of both harmful instructions and jailbreak attacks, while maintaining almost unchanged performance in downstream tasks.																																	2024-02-06	PPRN:87278088		
J	Xiang, Zhen; Jiang, Fengqing; Xiong, Zidi; Ramasubramanian, Bhaskar; Poovendran, Radha; Li, Bo				Xiong, Zidi/KBB-8747-2024						BadChain: Backdoor Chain-of-Thought Prompting for Large Language Models								Arxiv											1	1;2024-01-20;https://www.arxiv.org/abs/2401.12242v1	arXiv:2401.12242			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 20 2024	2024	Large language models (LLMs) are shown to benefit from chain-of-thought (COT) prompting, particularly when tackling tasks that require systematic reasoning processes. On the other hand, COT prompting also poses new vulnerabilities in the form of backdoor attacks, wherein the model will output unintended malicious content under specific backdoor-triggered conditions during inference. Traditional methods for launching backdoor attacks involve either contaminating the training dataset with backdoored instances or directly manipulating the model parameters during deployment. However, these approaches are not practical for commercial LLMs that typically operate via API access. In this paper, we propose BadChain, the first backdoor attack against LLMs employing COT prompting, which does not require access to the training dataset or model parameters and imposes low computational overhead. BadChain leverages the inherent reasoning capabilities of LLMs by inserting a backdoor reasoning step into the sequence of reasoning steps of the model output, thereby altering the final response when a backdoor trigger exists in the query prompt. Empirically, we show the effectiveness of BadChain for two COT strategies across four LLMs (Llama2, GPT-3.5, PaLM2, and GPT-4) and six complex benchmark tasks encompassing arithmetic, commonsense, and symbolic reasoning. Moreover, we show that LLMs endowed with stronger reasoning capabilities exhibit higher susceptibility to BadChain, exemplified by a high average attack success rate of 97.0% across the six benchmark tasks on GPT-4. Finally, we propose two defenses based on shuffling and demonstrate their overall ineffectiveness against BadChain. Therefore, BadChain remains a severe threat to LLMs, underscoring the urgency for the development of robust and effective future defenses.																																	2024-05-25	PPRN:87300247		
J	Qin, Zhen; Li, Dong; Sun, Weigao; Sun, Weixuan; Shen, Xuyang; Han, Xiaodong; Wei, Yunshen; Lv, Baohong; Luo, Xiao; Qiao, Yu; Zhong, Yiran				Qiao, Yu/ABD-5787-2021; Yang, Yifan/JTV-1487-2023						TransNormerLLM: A Faster and Better Large Language Model with Improved TransNormer								Arxiv											2	2;2024-01-19;https://www.arxiv.org/abs/2307.14995v2| 1;2023-07-27;https://www.arxiv.org/abs/2307.14995v1	arXiv:2307.14995			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 19 2024	2024	We present TransNormerLLM, the first linear attention-based Large Language Model (LLM) that outperforms conventional softmax attention-based models in terms of both accuracy and efficiency. TransNormerLLM evolves from the previous linear attention architecture TransNormer (Qin et al., 2022a) by making advanced modifications that include positional embedding, linear attention acceleration, gating mechanism, tensor normalization, and inference acceleration and stabilization. Specifically, we use LRPE (Qin et al., 2023b) together with an exponential decay to avoid attention dilution issues while allowing the model to retain global interactions between tokens. Additionally, we propose Lightning Attention, a cutting-edge technique that accelerates linear attention by more than twice in runtime and reduces memory usage by a remarkable four times. To further enhance the performance of TransNormer, we leverage a gating mechanism to smooth training and a new tensor normalization scheme to accelerate the model, resulting in an impressive acceleration of over 20%. Furthermore, we develop a robust inference algorithm that ensures numerical stability and consistent inference speed, regardless of the sequence length, showcasing superior efficiency during both training and inference stages. We also implement an efficient model parallel schema for TransNormerLLM, enabling seamless deployment on large-scale clusters and facilitating expansion to even more extensive models, i.e., LLMs with 175B parameters. We validate our model design through a series of ablations and train models with sizes of 385M, 1B, and 7B on our self-collected corpus. Benchmark results demonstrate that our models not only match the performance of state-of-the-art LLMs with Transformer but are also significantly faster.																																	2024-02-09	PPRN:74129734		
J	Mao, Shaoguang; Cai, Yuzhe; Xia, Yan; Wu, Wenshan; Wang, Xun; Wang, Fengyi; Ge, Tao; Wei, Furu										ALYMPICS: LLM Agents Meet Game Theory -- Exploring Strategic Decision-Making with AI Agents								Arxiv											4	4;2024-01-16;https://www.arxiv.org/abs/2311.03220v4| 3;2024-01-11;https://www.arxiv.org/abs/2311.03220v3| 2;2023-11-16;https://www.arxiv.org/abs/2311.03220v2| 1;2023-11-06;https://www.arxiv.org/abs/2311.03220v1	arXiv:2311.03220			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 16 2024	2024	This paper introduces Alympics (Olympics for Agents), a systematic simulation framework utilizing Large Language Model (LLM) agents for game theory research. Alympics creates a versatile platform for studying complex game theory problems, bridging the gap between theoretical game theory and empirical investigations by providing a controlled environment for simulating human-like strategic interactions with LLM agents. In our pilot case study, the "Water Allocation Challenge," we explore Alympics through a challenging strategic game focused on the multi-round auction on scarce survival resources. This study demonstrates the framework's ability to qualitatively and quantitatively analyze game determinants, strategies, and outcomes. Additionally, we conduct a comprehensive human assessment and an in-depth evaluation of LLM agents in strategic decision-making scenarios. Our findings not only expand the understanding of LLM agents' proficiency in emulating human strategic behavior but also highlight their potential in advancing game theory knowledge, thereby enriching our understanding of both game theory and empowering further research into strategic decision-making domains with LLM agents. Codes, prompts, and all related resources are available at https://github.com/microsoft/Alympics.																																	2024-05-25	PPRN:86052007		
J	Wen, Hao; Wang, Hongming; Liu, Jiaxuan; Li, Yuanchun				Li, Yuanchun/LTD-1972-2024; Wen, Hao/MEO-8739-2025; Liu, Jiaxuan/GPF-9189-2022						DroidBot-GPT: GPT-powered UI Automation for Android								Arxiv											4	4;2024-01-07;https://www.arxiv.org/abs/2304.07061v5| 3;2023-11-24;https://www.arxiv.org/abs/2304.07061v4| 2;2023-11-22;https://www.arxiv.org/abs/2304.07061v3| 1;2023-04-14;https://www.arxiv.org/abs/2304.07061v1	arXiv:2304.07061			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 07 2024	2024	This paper introduces DroidBot-GPT, a tool that utilizes GPT-like large language models (LLMs) to automate the interactions with Android mobile applications. Given a natural language description of a desired task, DroidBot-GPT can automatically generate and execute actions that navigate the app to complete the task. It works by translating the app GUI state information and the available actions on the smartphone screen to natural language prompts and asking the LLM to make a choice of actions. Since the LLM is typically trained on a large amount of data including the how-to manuals of diverse software applications, it has the ability to make reasonable choices of actions based on the provided information. We evaluate DroidBot-GPT with a self-created dataset that contains 33 tasks collected from 17 Android applications spanning 10 categories. It can successfully complete 39.39% of the tasks, and the average partial completion progress is about 66.76%. Given the fact that our method is fully unsupervised (no modification required from both the app and the LLM), we believe there is great potential to enhance the automation performance with better app development paradigms and/or custom model training.																																	2024-05-25	PPRN:62668404		
J	Gao, Difei; Ji, Lei; Bai, Zechen; Ouyang, Mingyu; Li, Peiran; Mao, Dongxing; Wu, Qinchen; Zhang, Weichen; Wang, Peiyi; Guo, Xiangwu; Wang, Hengxu; Zhou, Luowei; Shou, Mike Zheng				wang, peiyi/IVH-7687-2023; Shou, Mike Zheng/LXW-9197-2024						ASSISTGUI: Task-Oriented Desktop Graphical User Interface Automation								Arxiv											2	2;2024-01-01;https://www.arxiv.org/abs/2312.13108v2| 1;2023-12-20;https://www.arxiv.org/abs/2312.13108v1	arXiv:2312.13108			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 01 2024	2024	Graphical User Interface (GUI) automation holds significant promise for assisting users with complex tasks, thereby boosting human productivity. Existing works leveraging Large Language Model (LLM) or LLM-based AI agents have shown capabilities in automating tasks on Android and Web platforms. However, these tasks are primarily aimed at simple device usage and entertainment operations. This paper presents a novel benchmark, AssistGUI, to evaluate whether models are capable of manipulating the mouse and keyboard on the Windows platform in response to user-requested tasks. We carefully collected a set of 100 tasks from nine widely-used software applications, such as, After Effects and MS Word, each accompanied by the necessary project files for better evaluation. Moreover, we propose an advanced Actor-Critic Embodied Agent framework, which incorporates a sophisticated GUI parser driven by an LLM-agent and an enhanced reasoning mechanism adept at handling lengthy procedural tasks. Our experimental results reveal that our GUI Parser and Reasoning mechanism outshine existing methods in performance. Nevertheless, the potential remains substantial, with the best model attaining only a 46% success rate on our benchmark. We conclude with a thorough analysis of the current methods' limitations, setting the stage for future breakthroughs in this domain.																																	2024-05-25	PPRN:86743611		
J	Zhuo, Terry Yue; Zebaze, Armel; Suppattarachai, Nitchakarn; Werra, Leandro von; Vries, Harm de; Liu, Qian; Muennighoff, Niklas										Astraios: Parameter-Efficient Instruction Tuning Code Large Language Models								Arxiv											1	1;2024-01-01;https://www.arxiv.org/abs/2401.00788v1	arXiv:2401.00788			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 01 2024	2024	The high cost of full-parameter fine-tuning (FFT) of Large Language Models (LLMs) has led to a series of parameter-efficient fine-tuning (PEFT) methods. However, it remains unclear which methods provide the best cost-performance trade-off at different model scales. We introduce ASTRAIOS, a suite of 28 instruction-tuned OctoCoder models using 7 tuning methods and 4 model sizes up to 16 billion parameters. Through investigations across 5 tasks and 8 different datasets encompassing both code comprehension and code generation tasks, we find that FFT generally leads to the best downstream performance across all scales, and PEFT methods differ significantly in their efficacy based on the model scale. LoRA usually offers the most favorable trade-off between cost and performance. Further investigation into the effects of these methods on both model robustness and code security reveals that larger models tend to demonstrate reduced robustness and less security. At last, we explore the relationships among updated parameters, cross-entropy loss, and task performance. We find that the tuning effectiveness observed in small models generalizes well to larger models, and the validation loss in instruction tuning can be a reliable indicator of overall downstream performance.																																	2024-05-25	PPRN:86903982		
J	Wang, Kai; Tang, Dongwen; Zeng, Boya; Yin, Yida; Xu, Zhaopan; Zhou, Yukun; Zang, Zelin; Darrell, Trevor; Liu, Zhuang; You, Yang				Wang, Kai/K-4586-2012						Neural Network Diffusion								Arxiv											3	3;2024-12-30;https://www.arxiv.org/abs/2402.13144v3| 2;2024-05-28;https://www.arxiv.org/abs/2402.13144v2| 1;2024-02-20;https://www.arxiv.org/abs/2402.13144v1	arXiv:2402.13144			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 30 2024	2024	Diffusion models have achieved remarkable success in image and video generation. In this work, we demonstrate that diffusion models can also textit{generate high-performing neural network parameters}. Our approach is simple, utilizing an autoencoder and a diffusion model. The autoencoder extracts latent representations of a subset of the trained neural network parameters. Next, a diffusion model is trained to synthesize these latent representations from random noise. This model then generates new representations, which are passed through the autoencoder's decoder to produce new subsets of high-performing network parameters. Across various architectures and datasets, our approach consistently generates models with comparable or improved performance over trained networks, with minimal additional cost. Notably, we empirically find that the generated models are not memorizing the trained ones. Our results encourage more exploration into the versatile use of diffusion models. 																																	2025-02-15	PPRN:87776489		
J	Zheng, Zifan; Wang, Yezhaohui; Huang, Yuxin; Song, Shichao; Yang, Mingchuan; Tang, Bo; Xiong, Feiyu; Li, Zhiyu				Zheng, Zifan/OCL-2681-2025; Song, Shichao/GZA-6212-2022						Attention Heads of Large Language Models: A Survey								Arxiv											3	3;2024-12-23;https://www.arxiv.org/abs/2409.03752v3| 2;2024-09-23;https://www.arxiv.org/abs/2409.03752v2| 1;2024-09-05;https://www.arxiv.org/abs/2409.03752v1	arXiv:2409.03752			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 23 2024	2024	Since the advent of ChatGPT, Large Language Models (LLMs) have excelled in various tasks but remain as black-box systems. Understanding the reasoning bottlenecks of LLMs has become a critical challenge, as these limitations are deeply tied to their internal architecture. Among these, attention heads have emerged as a focal point for investigating the underlying mechanics of LLMs. In this survey, we aim to demystify the internal reasoning processes of LLMs by systematically exploring the roles and mechanisms of attention heads. We first introduce a novel four-stage framework inspired by the human thought process: Knowledge Recalling, In-Context Identification, Latent Reasoning, and Expression Preparation. Using this framework, we comprehensively review existing research to identify and categorize the functions of specific attention heads. Additionally, we analyze the experimental methodologies used to discover these special heads, dividing them into two categories: Modeling-Free and Modeling-Required methods. We further summarize relevant evaluation methods and benchmarks. Finally, we discuss the limitations of current research and propose several potential future directions.																																	2025-02-02	PPRN:91750223		
J	Golkar, Siavash; Pettee, Mariel; Eickenberg, Michael; Bietti, Alberto; Cranmer, Miles; Krawezik, Geraud; Lanusse, Francois; Mccabe, Michael; Ohana, Ruben; Parker, Liam; Blancard, Bruno Regaldo-Saint; Tesileanu, Tiberiu; Cho, Kyunghyun; Ho, Shirley				Cranmer, Miles/ABE-2188-2021						xVal: A Continuous Numerical Tokenization for Scientific Language Models								Arxiv											2	2;2024-12-15;https://www.arxiv.org/abs/2310.02989v2| 1;2023-10-04;https://www.arxiv.org/abs/2310.02989v1	arXiv:2310.02989			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 15 2024	2024	Due in part to their discontinuous and discrete default encodings for numbers, Large Language Models (LLMs) have not yet been commonly used to process numerically-dense scientific datasets. Rendering datasets as text, however, could help aggregate diverse and multi-modal scientific data into a single training corpus, thereby potentially facilitating the development of foundation models for science. In this work, we introduce xVal, a strategy for continuously tokenizing numbers within language models that results in a more appropriate inductive bias for scientific applications. By training specially-modified language models from scratch on a variety of scientific datasets formatted as text, we find that xVal generally outperforms other common numerical tokenization strategies on metrics including out-of-distribution generalization and computational efficiency.																																	2025-01-23	PPRN:85398182		
J	Ruan, Haifeng; Zhang, Yuntong; Roychoudhury, Abhik				Zhang, Yuntong/MYS-4463-2025						SpecRover: Code Intent Extraction via LLMs								Arxiv											4	4;2024-12-11;https://www.arxiv.org/abs/2408.02232v4| 3;2024-08-22;https://www.arxiv.org/abs/2408.02232v3| 2;2024-08-07;https://www.arxiv.org/abs/2408.02232v2| 1;2024-08-05;https://www.arxiv.org/abs/2408.02232v1	arXiv:2408.02232			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 11 2024	2024	Autonomous program improvement typically involves automatically producing bug fixes and feature additions. Such program improvement can be accomplished by a combination of large language model (LLM) and program analysis capabilities, in the form of an LLM agent. Since program repair or program improvement typically requires a specification of intended behavior- specification inference can be useful for producing high quality program patches. In this work, we examine efficient and low-cost workflows for iterative specification inference within an LLM agent. Given a GitHub issue to be resolved in a software project, our goal is to conduct iterative code search accompanied by specification inference- thereby inferring intent from both the project structure and behavior. The intent thus captured is examined by a reviewer agent with the goal of vetting the patches as well as providing a measure of confidence in the vetted patches. Our approach SpecRover is built on the open-source LLM agent AutoCodeRover. In an evaluation on the full SWE-Bench consisting of 2294 GitHub issues, it shows more than 50% improvement in efficacy over AutoCodeRover. Compared to the open-source agents available, our work shows modest cost ($0.65 per issue) in resolving an average GitHub issue in SWE-Bench lite. The production of explanation by SpecRover allows for a better “signal” to be given to the developer, on when the suggested patches can be accepted with confidence. SpecRover also seeks to demonstrate the continued importance of specification inference in automated program repair, even as program repair technologies enter the LLM era.																																	2025-01-19	PPRN:91248529		
J	Han, Dongchen; Wang, Ziyi; Xia, Zhuofan; Han, Yizeng; Pu, Yifan; Ge, Chunjiang; Song, Jun; Song, Shiji; Zheng, Bo; Huang, Gao				Yifan, Pu/HHY-9398-2022; Ge, Chunjiang/LOS-5681-2024; Xia, Zhuofan/KEH-5398-2024						Demystify Mamba in Vision: A Linear Attention Perspective								Arxiv											2	2;2024-12-02;https://www.arxiv.org/abs/2405.16605v2| 1;2024-05-26;https://www.arxiv.org/abs/2405.16605v1	arXiv:2405.16605			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 02 2024	2024	Mamba is an effective state space model with linear computation complexity. It has recently shown impressive efficiency in dealing with high-resolution inputs across various vision tasks. In this paper, we reveal that the powerful Mamba model shares surprising similarities with linear attention Transformer, which typically underperform conventional Transformer in practice. By exploring the similarities and disparities between the effective Mamba and subpar linear attention Transformer, we provide comprehensive analyses to demystify the key factors behind Mamba's success. Specifically, we reformulate the selective state space model and linear attention within a unified formulation, rephrasing Mamba as a variant of linear attention Transformer with six major distinctions: input gate, forget gate, shortcut, no attention normalization, single-head, and modified block design. For each design, we meticulously analyze its pros and cons, and empirically evaluate its impact on model performance in vision tasks. Interestingly, the results highlight the forget gate and block design as the core contributors to Mamba's success, while the other four designs are less crucial. Based on these findings, we propose a Mamba-Inspired Linear Attention (MILA) model by incorporating the merits of these two key designs into linear attention. The resulting model outperforms various vision Mamba models in both image classification and high-resolution dense prediction tasks, while enjoying parallelizable computation and fast inference speed. 																																	2025-01-11	PPRN:89063088		
J	Dong, Xin; Fu, Yonggan; Diao, Shizhe; Byeon, Wonmin; Chen, Zijia; Mahabaleshwarkar, Ameya Sunil; Liu, Shih-Yang; Van Keirsbilck, Matthijs; Chen, Min-Hung; Suhara, Yoshi; Lin, Yingyan; Kautz, Jan; Molchanov, Pavlo				Diao, Shizhe/JXY-7398-2024; Lin, Yingyan Celine/HTM-2624-2023; Dong, Xin/OKS-7830-2025; Chen, Min-Hung/W-2192-2019						Hymba: A Hybrid-head Architecture for Small Language Models								Arxiv											1	1;2024-11-20;https://www.arxiv.org/abs/2411.13676v1	arXiv:2411.13676			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 20 2024	2024	We propose Hymba, a family of small language models featuring a hybrid-head parallel architecture that integrates transformer attention mechanisms with state space models (SSMs) for enhanced efficiency. Attention heads provide high-resolution recall, while SSM heads enable efficient context summarization. Additionally, we introduce learnable meta tokens that are prep ended to prompts, storing critical information and alleviating the “forced-to-attend” burden associated with attention mechanisms. This model is further optimized by incorporating cross-layer key-value (KV) sharing and partial sliding window attention, resulting in a compact cache size. During development, we conducted a controlled study comparing various architectures under identical settings and observed significant advantages of our proposed architecture. Notably, Hymba achieves state-of-the-art results for small LMs: Our Hymba-1.5B-Base model surpasses all sub-2B public models in performance and even outperforms Llama-3.2-3B with 1.32% higher average accuracy, an 11.67× cache size reduction, and 3.49× throughput.																																	2024-12-31	PPRN:119317903		
J	Guo, Yufei; Guo, Muzhe; Su, Juntao; Yang, Zhou; Zhu, Mengqiu; Li, Hongfei; Qiu, Mengyang; Liu, Shuo Shuo				Su, Juntao/NOF-8151-2025; Qiu, Mengyang/OGN-1509-2025; Liu, ShuoShuo/NIS-5721-2025; Li, Hongfei/O-8487-2019						Bias in Large Language Models: Origin, Evaluation, and Mitigation								Arxiv											1	1;2024-11-16;https://www.arxiv.org/abs/2411.10915v1	arXiv:2411.10915			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 16 2024	2024	Large Language Models (LLMs) have revolutionized natural language processing, but their susceptibility to biases poses significant challenges. This comprehensive review examines the landscape of bias in LLMs, from its origins to current mitigation strategies. We categorize biases as intrinsic and extrinsic, analyzing their manifestations in various NLP tasks. The review critically assesses a range of bias evaluation methods, including data-level, model-level, and output-level approaches, providing researchers with a robust toolkit for bias detection. We further explore mitigation strategies, categorizing them into pre-model, intra-model, and post-model techniques, highlighting their effectiveness and limitations. Ethical and legal implications of biased LLMs are discussed, emphasizing potential harms in real-world applications such as healthcare and criminal justice. By synthesizing current knowledge on bias in LLMs, this review contributes to the ongoing effort to develop fair and responsible AI systems. Our work serves as a comprehensive resource for researchers and practitioners working towards understanding, evaluating, and mitigating bias in LLMs, fostering the development of more equitable AI technologies.																																	2024-12-27	PPRN:119255569		
J	Li, Panfeng; Yang, Qikai; Geng, Xieming; Zhou, Wenjing; Ding, Zhicheng; Nian, Yi				Ding, Zhicheng/KGK-9412-2024; Li, Panfeng/LBG-9988-2024; Zhou, Wenjing/IXD-4162-2023; Nian, Yi/LKZ-9148-2024; Yang, Qikai/OMK-9174-2025						Exploring Diverse Methods in Visual Question Answering								Arxiv											3	3;2024-11-12;https://www.arxiv.org/abs/2404.13565v3| 2;2024-05-21;https://www.arxiv.org/abs/2404.13565v2| 1;2024-04-21;https://www.arxiv.org/abs/2404.13565v1	arXiv:2404.13565			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 12 2024	2024	This study explores innovative methods for improving Visual Question Answering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and attention mechanisms. Leveraging a balanced VQA dataset, we investigate three distinct strategies. Firstly, GAN-based approaches aim to generate answer embeddings conditioned on image and question inputs, showing potential but struggling with more complex tasks. Secondly, autoencoder-based techniques focus on learning optimal embeddings for questions and images, achieving comparable results with GAN due to better ability on complex questions. Lastly, attention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB), address language priors and attention modeling, albeit with a complexity-performance trade-off. This study underscores the challenges and opportunities in VQA and suggests avenues for future research, including alternative GAN formulations and attentional mechanisms.																																	2024-12-18	PPRN:88600923		
J	Ekambaram, Vijay; Jati, Arindam; Dayama, Pankaj; Mukherjee, Sumanta; Nguyen, Nam H.; Gifford, Wesley M.; Reddy, Chandra; Kalagnanam, Jayant				Reddy, Chandra/N-6720-2017						Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot Forecasting of Multivariate Time Series								Arxiv											7	7;2024-11-07;https://www.arxiv.org/abs/2401.03955v8| 6;2024-06-05;https://www.arxiv.org/abs/2401.03955v7| 5;2024-06-03;https://www.arxiv.org/abs/2401.03955v6| 4;2024-04-09;https://www.arxiv.org/abs/2401.03955v5| 3;2024-01-17;https://www.arxiv.org/abs/2401.03955v3| 2;2024-01-11;https://www.arxiv.org/abs/2401.03955v2| 1;2024-01-08;https://www.arxiv.org/abs/2401.03955v1	arXiv:2401.03955			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Nov 07 2024	2024	Large pre-trained models excel in zero/few-shot learning for language and vision tasks but face challenges in multivariate time series (TS) forecasting due to diverse data characteristics. Consequently, recent research efforts have focused on developing pre-trained TS forecasting models. These models, whether built from scratch or adapted from large language models (LLMs), excel in zero/few-shot forecasting tasks. However, they are limited by slow performance, high computational demands, and neglect of cross-channel and exogenous correlations. To address this, we introduce Tiny Time Mixers (TTM), a compact model (starting from 1M parameters) with effective transfer learning capabilities, trained exclusively on public TS datasets. TTM, based on the light-weight TSMixer architecture, incorporates innovations like adaptive patching, diverse resolution sampling, and resolution prefix tuning to handle pre-training on varied dataset resolutions with minimal model capacity. Additionally, it employs multi-level modeling to capture channel correlations and infuse exogenous signals during fine-tuning. TTM outperforms existing popular benchmarks in zero/few-shot forecasting by (4-40%), while reducing computational requirements significantly. Moreover, TTMs are lightweight and can be executed even on CPU-only machines, enhancing usability and fostering wider adoption in resource-constrained environments. The model weights for reproducibility and research use are available here, while enterprise-use weights under the Apache license can be accessed as follows: the initial TTMQvariant here, and the latest variants (TTMB, TTME, TTMA) weights are available here (preferred use). The source code for the TTM model along with the usage scripts are available here.																																	2024-12-16	PPRN:87043722		
J	Liao, Shijia; Wang, Yuxuan; Li, Tianyu; Cheng, Yifan; Zhang, Ruoyi; Zhou, Rongzhi; Xing, Yijin				Zhang, Ruoyi/KDM-9339-2024; Cheng, Yifan/AAP-3680-2021						Fish-Speech: Leveraging Large Language Models for Advanced Multilingual Text-to-Speech Synthesis								Arxiv											1	1;2024-11-02;https://www.arxiv.org/abs/2411.01156v1	arXiv:2411.01156			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 02 2024	2024	Text-to-Speech (TTS) systems face ongoing challenges in processing complex linguistic features, handling polyphonic expressions, and producing natural-sounding multilingual speech- capabilities that are crucial for future AI applications. In this paper, we present Fish-Speech, a novel framework that implements a serial fast-slow Dual Autoregressive (Dual-AR) architecture to enhance the stability of Grouped Finite Scalar Vector Quantization (GFSQ) in sequence generation tasks. This architecture improves codebook processing efficiency while maintaining high-fidelity outputs, making it particularly effective for AI interactions and voice cloning. Fish-Speech leverages Large Language Models (LLMs) for linguistic feature extraction, eliminating the need for traditional grapheme-to-phoneme (G2P) conversion and thereby streamlining the synthesis pipeline and enhancing multilingual support. Additionally, we developed FF-GAN through GFSQ to achieve superior compression ratios and near 100% codebook utilization. Our approach addresses key limitations of current TTS systems while providing a foundation for more sophisticated, context-aware speech synthesis. Experimental results show that Fish-Speech significantly outperforms baseline models in handling complex linguistic scenarios and voice cloning tasks, demonstrating its potential to advance TTS technology in AI applications. 																																	2024-12-16	PPRN:119088897		
J	Guo, Zinan; Wu, Yanze; Chen, Zhuowei; Chen, Lang; Zhang, Peng; He, Qian										PuLID: Pure and Lightning ID Customization via Contrastive Alignment								Arxiv											2	2;2024-10-31;https://www.arxiv.org/abs/2404.16022v2| 1;2024-04-24;https://www.arxiv.org/abs/2404.16022v1	arXiv:2404.16022			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 31 2024	2024	We propose Pure and Lightning ID customization (PuLID), a novel tuning-free ID customization method for text-to-image generation. By incorporating a Lightning T2I branch with a standard diffusion one, PuLID introduces both contrastive alignment loss and accurate ID loss, minimizing disruption to the original model and ensuring high ID fidelity. Experiments show that PuLID achieves superior performance in both ID fidelity and editability. Another attractive property of PuLID is that the image elements (e.g., background, lighting, composition, and style) before and after the ID insertion are kept as consistent as possible. 																																	2024-12-06	PPRN:88634551		
J	Liu, Xiao; Qin, Bo; Liang, Dongzhu; Dong, Guang; Lai, Hanyu; Zhang, Hanchen; Zhao, Hanlin; Iong, Iat Long; Sun, Jiadai; Wang, Jiaqi; Gao, Junjie; Shan, Junjun; Liu, Kangning; Zhang, Shudan; Yao, Shuntian; Cheng, Siyi; Yao, Wentao; Zhao, Wenyi; Liu, Xinghan; Liu, Xinyi; Chen, Xinying; Yang, Xinyue; Yang, Yang; Xu, Yifan; Yang, Yu; Wang, Yujia; Xu, Yulin; Qi, Zehan; Dong, Yuxiao; Tang, Jie				Cheng, Siyi/IUQ-6798-2023; Wang, Yujia/AFF-1559-2022; Liu, Xinyi/LCD-2349-2024; chen, xinying/IQV-3856-2023; Zhang, Hanchen/MIK-3870-2025; Zhao, Wenyi/GQQ-5868-2022; Xu, Yifan/I-9273-2014						AutoGLM: Autonomous Foundation Agents for GUIs								Arxiv											1	1;2024-10-28;https://www.arxiv.org/abs/2411.00820v1	arXiv:2411.00820			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 28 2024	2024	We present AUTOGLM, a new series in the ChatGLM family [11], designed to serve as foundation agents for autonomous control of digital devices through Graphical User Interfaces (GUIs). While foundation models excel at acquiring human knowledge, they often struggle with decision-making in dynamic real-world environments, limiting their progress toward artificial general intelligence. This limitation underscores the importance of developing foundation agents capable of learning through autonomous environmental interactions by reinforcing existing models. Focusing on Web Browser and Phone as representative GUI scenarios, we have developed AUTOGLM as a practical foundation agent system for real-world GUI interactions. Our approach integrates a comprehensive suite of techniques and infrastructures to create deployable agent systems suitable for user delivery. Through this development, we have derived two key insights: First, the design of an appropriate "intermediate interface" for GUI control is crucial, enabling the separation of planning and grounding behaviors, which require distinct optimization for flexibility and accuracy respectively. Second, we have developed a novel progressive training framework that enables self-evolving online curriculum reinforcement learning for AUTOGLM. Our evaluations demonstrate AUTOGLM’s effectiveness across multiple domains. For web browsing, AUTOGLM achieves a 55.2% success rate on VAB-WebArena-Lite (improving to 59.1% with a second attempt) and 96.2% on OpenTable evaluation tasks. In Android device control, AUTOGLM attains a 36.2% success rate on AndroidLab (VAB-Mobile) and 89.7% on common tasks in popular Chinese APPs. Select AUTOGLM capabilities are now available through the Qingyan Browser Plugin for web applications and via Form Applications for invited Android testing. Additional results and materials will be released at https://github.com/THUDM/AutoGLM.																																	2024-12-16	PPRN:119091089		
J	Khare, Avishree; Dutta, Saikat; Li, Ziyang; Solko-Breslin, Alaia; Alur, Rajeev; Naik, Mayur										Understanding the Effectiveness of Large Language Models in Detecting Security Vulnerabilities								Arxiv											3	3;2024-10-23;https://www.arxiv.org/abs/2311.16169v3| 2;2024-06-09;https://www.arxiv.org/abs/2311.16169v2| 1;2023-11-16;https://www.arxiv.org/abs/2311.16169v1	arXiv:2311.16169			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Oct 23 2024	2024	vulnerabilities in modern software are prevalent and harmful. While automated vulnerability detection techniques have made promising progress, their scalability and applicability remain challenging. The remarkable performance of Large Language Models (LLMs), such as GPT-4 and CodeLlama, on code-related tasks has prompted recent works to explore if LLMs can be used to detect security vulnerabilities. In this paper, we perform a more comprehensive study by examining a larger and more diverse set of datasets, languages, and LLMs, and qualitatively evaluating detection performance across prompts and vulnerability classes. Concretely, we evaluate the effectiveness of 16 pre-trained LLMs on 5,000 code samples—1,000 randomly selected each from five diverse security datasets. These balanced datasets encompass synthetic and real-world projects in Java and C/C++ and cover 25 distinct vulnerability classes. Our results show that LLMs across all scales and families show modest effectiveness in end-to-end reasoning about vulnerabilities, obtaining an average accuracy of 62.8% and F1 score of 0.71 across all datasets. LLMs are significantly better at detecting vulnerabilities that typically only need intra-procedural reasoning, such as OS Command Injection and NULL Pointer Dereference. Moreover, LLMs report higher accuracies on these vulnerabilities than popular static analysis tools, such as CodeQL. We find that advanced prompting strategies that involve stepby-step analysis significantly improve performance of LLMs on real-world datasets in terms of F1 score (by up to 0.18 on average). Interestingly, we observe that LLMs show promising abilities at performing parts of the analysis correctly, such as identifying vulnerability-related specifications (e.g., sources and sinks) and leveraging natural language information to understand code behavior (e.g., to check if code is sanitized). We believe our insights can motivate future work on LLM-augmented vulnerability detection systems.																																	2024-11-26	PPRN:86309972		
J	Wu, Siwei; Peng, Zhongyuan; Du, Xinrun; Zheng, Tuney; Liu, Minghao; Wu, Jialong; Ma, Jiachen; Li, Yizhi; Yang, Jian; Zhou, Wangchunshu; Lin, Qunshu; Zhao, Junbo; Zhang, Zhaoxiang; Huang, Wenhao; Zhang, Ge; Lin, Chenghua; Liu, J.H.				Zhang, Zhaoxiang/LTF-2817-2024; Huang, Wenhao/GWU-9337-2022						A Comparative Study on Reasoning Patterns of OpenAI's o1 Model								Arxiv											2	2;2024-10-22;https://www.arxiv.org/abs/2410.13639v2| 1;2024-10-17;https://www.arxiv.org/abs/2410.13639v1	arXiv:2410.13639			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 22 2024	2024	Enabling Large Language Models (LLMs) to handle a wider range of complex tasks (e.g., coding, math) has drawn great attention from many researchers. As LLMs continue to evolve, merely increasing the number of model parameters yields diminishing performance improvements and heavy computational costs. Recently, OpenAI's o1 model has shown that inference strategies (i.e., Test-time Compute methods) can also significantly enhance the reasoning capabilities of LLMs. However, the mechanisms behind these methods are still unexplored. In our work, to investigate the reasoning patterns of o1, we compare o1 with existing Test-time Compute methods (BoN, Step-wise BoN, Agent Workflow, and Self-Refine) by using OpenAI's GPT-4o as a backbone on general reasoning benchmarks in three domains (i.e., math, coding, commonsense reasoning). Specifically, first, our experiments show that the o1 model has achieved the best performance on most datasets. Second, as for the methods of searching diverse responses (e.g., BoN), we find the reward models' capability and the search space both limit the upper boundary of these methods. Third, as for the methods that break the problem into many sub-problems, the Agent Workflow has achieved better performance than Step-wise BoN due to the domain-specific system prompt for planning better reasoning processes. Fourth, it is worth mentioning that we have summarized six reasoning patterns of o1, and provided a detailed analysis on several reasoning benchmarks.																																	2024-11-24	PPRN:115557311		
J	Zhu, Changxi; Dastani, Mehdi; Wang, Shihan										A Survey of Multi-Agent Deep Reinforcement Learning with Communication								Arxiv											2	2;2024-10-18;https://www.arxiv.org/abs/2203.08975v2| 1;2022-03-16;https://www.arxiv.org/abs/2203.08975v1	arXiv:2203.08975			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 18 2024	2024	Communication is an effective mechanism for coordinating the behaviors of multiple agents, broadening their views of the environment, and to support their collaborations. In the field of multi-agent deep reinforcement learning (MADRL), agents can improve the overall learning performance and achieve their objectives by communication. Agents can communicate various types of messages, either to all agents or to specific agent groups, or conditioned on specific constraints. With the growing body of research work in MADRL with communication (Comm-MADRL), there is a lack of a systematic and structural approach to distinguish and classify existing Comm-MADRL approaches. In this paper, we survey recent works in the Comm-MADRL field and consider various aspects of communication that can play a role in designing and developing multi-agent reinforcement learning systems. With these aspects in mind, we propose 9 dimensions along which Comm-MADRL approaches can be analyzed, developed, and compared. By projecting existing works into the multi-dimensional space, we discover interesting trends. We also propose some novel directions for designing future Comm-MADRL systems through exploring possible combinations of the dimensions.																																	2024-11-15	PPRN:12112021		
J	Wang, Fu-Yun; Huang, Zhaoyang; Bian, Weikang; Shi, Xiaoyu; Sun, Keqiang; Song, Guanglu; Liu, Yu; Li, Hongsheng				Li, Hongsheng/AES-5328-2022; Huang, Zhaoyang/IUN-1167-2023						AnimateLCM: Computation-Efficient Personalized Style Video Generation without Personalized Video Data								Arxiv											2	2;2024-10-16;https://www.arxiv.org/abs/2402.00769v3| 1;2024-02-01;https://www.arxiv.org/abs/2402.00769v1	arXiv:2402.00769			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 16 2024	2024	This paper introduces an effective method for computation-efficient personalized style video generation without requiring access to any personalized video data. It reduces the necessary generation time of similarly sized video diffusion models from 25 seconds to around 1 second while maintaining the same level of performance. The method's effectiveness lies in its dual-level decoupling learning approach: 1) separating the learning of video style from video generation acceleration, which allows for personalized style video generation without any personalized style video data, and 2) separating the acceleration of image generation from the acceleration of video motion generation, enhancing training efficiency and mitigating the negative effects of low-quality video data.																																	2024-11-07	PPRN:87455065		
J	Leng, Yan; Yuan, Yuan										Do LLM Agents Exhibit Social Behavior?								Arxiv											3	3;2024-10-15;https://www.arxiv.org/abs/2312.15198v3| 2;2024-02-22;https://www.arxiv.org/abs/2312.15198v2| 1;2023-12-23;https://www.arxiv.org/abs/2312.15198v1	arXiv:2312.15198			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Oct 15 2024	2024	As Large Language Models (LLMs) increasingly take on roles in human-AI interactions and autonomous AI systems, understanding their social behavior becomes important for informed use and continuous improvement. However, their behaviors in social interactions with humans and other agents, as well as the mechanisms shaping their responses, remain underexplored in the literature. To address this gap, we introduce a novel probabilistic framework, “State-Understanding-Value-Action” ( SUVA ), to systematically analyze LLM responses in social contexts based on their textual outputs (i.e., utterances). Using canonical behavioral economics games (e.g., dictator games) and social preference concepts relatable to LLM users, SUVA assesses LLMs’ social behavior through both their final decisions and the response generation processes leading to those decisions. Our analysis of eight LLMs—including two GPT, four Meta LLaMA, and two Mistral models—suggests that most models do not generate decisions aligned solely with self-interest; instead, they often produce responses that reflect social welfare considerations and display patterns consistent with direct and indirect reciprocity. Additionally, higher-capacity models more frequently display group identity effects. Interestingly, in GPT and Mistral models, increased model capacity is associated with reduced self-interest in their generated responses, while LLaMA models display the opposite trend. The SUVA framework also provides explainable to ols—including tree-based visualizations and probabilistic dependency analysis—to elucidate how factors in LLMs’ utterance-based “reasoning” influence their decisions. We demonstrate that utterance-based “reasoning” reliably predicts LLMs’ final actions; references to altruism, fairness, and cooperation in the “reasoning” increase the likelihood of prosocial actions, while mentions of self-interest and competition reduce them. Overall, our framework enables practitioners to assess LLMs for applications involving social interactions, supporting informed model selection and alignment with organizational values. For researchers, it provides a structured method to interpret how LLM behavior arises from utterance-based “reasoning”, advancing understanding without attributing human-like cognition or consciousness to these models.																																	2024-11-07	PPRN:86820268		
J	Luccioni, Alexandra Sasha; Jernite, Yacine; Strubell, Emma										Power Hungry Processing: Watts Driving the Cost of AI Deployment?								Arxiv											3	3;2024-10-15;https://www.arxiv.org/abs/2311.16863v3| 2;2024-05-23;https://www.arxiv.org/abs/2311.16863v2| 1;2023-11-28;https://www.arxiv.org/abs/2311.16863v1	arXiv:2311.16863			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Oct 15 2024	2024	Recent years have seen a surge in the popularity of commercial AI products based on generative, multi-purpose AI systems promising a unified approach to building machine learning (ML) models into technology. However, this ambition of “generality” comes at a steep cost to the environment, given the amount of energy these systems require and the amount of carbon that they emit. In this work, we propose the first systematic comparison of the ongoing inference cost of various categories of ML systems, covering both task-specific (i.e. finetuned models that carry out a single task) and ‘general-purpose’ models, (i.e. those trained for multiple tasks). We measure deployment cost as the amount of energy and carbon required to perform 1,000 inferences on representative benchmark dataset using these models. We find that multi-purpose, generative architectures are orders of magnitude more expensive than task-specific systems for a variety of tasks, even when controlling for the number of model parameters. We conclude with a discussion around the current trend of deploying multi-purpose generative ML systems, and caution that their utility should be more intentionally weighed against increased costs in terms of energy and emissions. All the data from our study can be accessed via an interactive demo to carry out further exploration and analysis.																																	2024-11-11	PPRN:86308633		
J	Wang, Yen-Jen; Zhang, Bike; Chen, Jianyu; Sreenath, Koushil										Prompt a Robot to Walk with Large Language Models								Arxiv											3	3;2024-10-15;https://www.arxiv.org/abs/2309.09969v3| 2;2023-11-17;https://www.arxiv.org/abs/2309.09969v2| 1;2023-09-18;https://www.arxiv.org/abs/2309.09969v1	arXiv:2309.09969			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 15 2024	2024	Large language models (LLMs) pre-trained on vast internet-scale data have showcased remarkable capabilities across diverse domains. Recently, there has been escalating interest in deploying LLMs for robotics, aiming to harness the power of foundation models in real-world settings. However, this approach faces significant challenges, particularly in grounding these models in the physical world and in generating dynamic robot motions. To address these issues, we introduce a novel paradigm in which we use few-shot prompts collected from the physical environment, enabling the LLM to autoregressively predict low-level control actions for robots without task-specific fine-tuning. We utilize LLMs as a controller, diverging from the conventional approach of employing them primarily as planners. Simulation experiments across various robots and environments validate that our method can effectively prompt a robot to walk. We thus illustrate how LLMs can function as low-level feedback controllers for dynamic motion control, even in high-dimensional robotic systems. The project website and source code can be found at: prompt2walk.github.io.																																	2024-11-10	PPRN:85030494		
J	Shi, Chufan; Yang, Haoran; Cai, Deng; Zhang, Zhisong; Wang, Yifan; Yang, Yujiu; Lam, Wai				Yang, Yujiu/JGM-0303-2023; Lam, Wai/GNW-3026-2022						A Thorough Examination of Decoding Methods in the Era of LLMs								Arxiv											3	3;2024-10-08;https://www.arxiv.org/abs/2402.06925v3| 2;2024-06-17;https://www.arxiv.org/abs/2402.06925v2| 1;2024-02-10;https://www.arxiv.org/abs/2402.06925v1	arXiv:2402.06925			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 08 2024	2024	Decoding methods play an indispensable role in converting language models from next-token predictors into practical task solvers. Prior research on decoding methods, primarily focusing on task-specific models, may not extend to the current era of general-purpose large language models (LLMs). Moreover, the recent influx of decoding strategies has further complicated this landscape. This paper provides a comprehensive and multifaceted analysis of various decoding methods within the context of LLMs, evaluating their performance, robustness to hyperparameter changes, and decoding speeds across a wide range of tasks, models, and deployment environments. Our findings reveal that decoding method performance is notably task-dependent and influenced by factors such as alignment, model size, and quantization. Intriguingly, sensitivity analysis exposes that certain methods achieve superior performance at the cost of extensive hyperparameter tuning, highlighting the trade-off between attaining optimal results and the practicality of implementation in varying contexts.																																	2024-10-29	PPRN:87638032		
J	Wang, Fei; Zhou, Wenxuan; Huang, James Y.; Xu, Nan; Zhang, Sheng; Poon, Hoifung; Chen, Muhao				Chen, Muhao/AAA-3634-2021; Zhou, Wenxuan/AAN-4529-2020						MDPO: Conditional Preference Optimization for Multimodal Large Language Models								Arxiv											2	2;2024-10-07;https://www.arxiv.org/abs/2406.11839v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11839v1	arXiv:2406.11839			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 07 2024	2024	Direct preference optimization (DPO) has shown to be an effective method for large language model (LLM) alignment. Recent works have attempted to apply DPO to multimodal scenarios but have found it challenging to achieve consistent improvement. Through a comparative experiment, we identify the unconditional preference problem in multimodal preference optimization, where the model overlooks the image condition. To address this problem, we propose mDPO, a multimodal DPO objective that prevents the over-prioritization of language-only preferences by also optimizing image preference. Moreover, we introduce a reward anchor that forces the reward to be positive for chosen responses, thereby avoiding the decrease in their likelihood -- an intrinsic problem of relative preference optimization. Experiments on two multimodal LLMs of different sizes and three widely used benchmarks demonstrate that mDPO effectively addresses the unconditional preference problem in multimodal preference optimization and significantly improves model performance, particularly in reducing hallucination.																																	2024-10-28	PPRN:89351718		
J	Huang, Jen-tse; Jiao, Wenxiang; Lam, Man Ho; Li, Eric John; Wang, Wenxuan; Lyu, Michael R.				Lam, Man Ho/LRS-9509-2024; Huang, Jen-Tse/IRZ-7526-2023; Wang, Wenxuan/AAW-9073-2020						Revisiting the Reliability of Psychological Scales on Large Language Models								Arxiv											4	4;2024-10-04;https://www.arxiv.org/abs/2305.19926v5| 3;2024-09-20;https://www.arxiv.org/abs/2305.19926v4| 2;2023-12-28;https://www.arxiv.org/abs/2305.19926v3| 1;2023-05-31;https://www.arxiv.org/abs/2305.19926v1	arXiv:2305.19926			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 04 2024	2024	Recent research has focused on examining Large Language Models' (LLMs) characteristics from a psychological standpoint, acknowledging the necessity of understanding their behavioral characteristics. The administration of personality tests to LLMs has emerged as a noteworthy area in this context. However, the suitability of employing psychological scales, initially devised for humans, on LLMs is a matter of ongoing debate. Our study aims to determine the reliability of applying personality assessments to LLMs, explicitly investigating whether LLMs demonstrate consistent personality traits. Analysis of 2,500 settings per model, including GPT-3.5, GPT-4, Gemini-Pro, and LLaMA-3.1, reveals that various LLMs show consistency in responses to the Big Five Inventory, indicating a satisfactory level of reliability. Furthermore, our research explores the potential of GPT-3.5 to emulate diverse personalities and represent various groups-a capability increasingly sought after in social sciences for substituting human participants with LLMs to reduce costs. Our findings reveal that LLMs have the potential to represent different personalities with specific prompt instructions.																																	2024-10-27	PPRN:72777824		
J	Zhang, Guibin; Yue, Yanwei; Li, Zhixun; Yun, Sukwon; Wan, Guancheng; Wang, Kun; Cheng, Dawei; Yu, Jeffrey Xu; Chen, Tianlong				Cheng, Dawei/JPY-1457-2023; Yu, Jeffrey/F-6005-2011						Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems								Arxiv											1	1;2024-10-03;https://www.arxiv.org/abs/2410.02506v1	arXiv:2410.02506			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 03 2024	2024	Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed AgentPrune, , which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, AgentPrune is the first to identify and formally define the communication redundancy issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatialtemporal message-passing graph, yielding a token-economic and high-performing communication topology. Extensive experiments across six benchmarks demonstrate that AgentPrune (I) achieves comparable results as state-of-the-art topologies at merely $5.6 . 6 cost compared to their $43.7, . 7, (II) integrates seamlessly into existing multi-agent frameworks with 28.1% . 1% ∼ 72.8% . 8% ↓ token reduction, and (III) successfully defend against two types of agent-based adversarial attacks with 3.5% . 5% ∼ 10.8% . 8% ↑ performance boost. The source code is available at https://github.com/yanweiyue/AgentPrune. .																																	2024-10-18	PPRN:102612649		
J	Li, Xiang; Qiu, Kai; Chen, Hao; Kuen, Jason; Lin, Zhe; Singh, Rita; Raj, Bhiksha				林, Z/HHD-0305-2022; Kuen, Jason/AAA-1809-2020						ControlVAR: Exploring Controllable Visual Autoregressive Modeling								Arxiv											2	2;2024-10-02;https://www.arxiv.org/abs/2406.09750v2| 1;2024-06-14;https://www.arxiv.org/abs/2406.09750v1	arXiv:2406.09750			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 02 2024	2024	Conditional visual generation has witnessed remarkable progress with the advent of diffusion models (DMs), especially in tasks like control-to-image generation. However, challenges such as expensive computational cost, high inference latency, and difficulties of integration with large language models (LLMs) have necessitated exploring alternatives to DMs. This paper introduces ControlVAR, a novel framework that explores pixel-level controls in visual autoregressive (VAR) modeling for flexible and efficient conditional generation. In contrast to traditional conditional models that learn the conditional distribution, ControlVAR jointly models the distribution of image and pixel-level conditions during training and imposes conditional controls during testing. To enhance the joint modeling, we adopt the next-scale AR prediction paradigm and unify control and image representations. A teacher-forcing guidance strategy is proposed to further facilitate controllable generation with joint modeling. Extensive experiments demonstrate the superior efficacy and flexibility of ControlVAR across various conditional generation tasks against popular conditional DMs, eg, ControlNet and T2I-Adaptor. 																																	2024-10-16	PPRN:89333597		
J	Que, Haoran; Duan, Feiyu; He, Liqun; Mou, Yutao; Zhou, Wangchunshu; Liu, Jiaheng; Rong, Wenge; Wang, Zekun Moore; Yang, Jian; Zhang, Ge; Peng, Junran; Zhang, Zhaoxiang; Zhang, Songyang; Chen, Kai				Zhang, Ge/N-4150-2013; Zhang, Songyang/GPX-5621-2022; Zhang, Zhao-xiang/R-2819-2018						HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models								Arxiv											1	1;2024-09-24;https://www.arxiv.org/abs/2409.16191v1	arXiv:2409.16191			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 24 2024	2024	In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in various tasks (e.g., long-context understanding), and many benchmarks have been proposed. However, we observe that long text generation capabilities are not well investigated. Therefore, we introduce the Hierarchical Long Text Generation Benchmark (HelloBench), a comprehensive, in-the-wild, and open-ended benchmark to evaluate LLMs' performance in generating long text. Based on Bloom's Taxonomy, HelloBench categorizes long text generation tasks into five subtasks: open-ended QA, summarization, chat, text completion, and heuristic text generation. Besides, we propose Hierarchical Long Text Evaluation (HelloEval), a human-aligned evaluation method that significantly reduces the time and effort required for human evaluation while maintaining a high correlation with human evaluation. We have conducted extensive experiments across around 30 mainstream LLMs and observed that the current LLMs lack long text generation capabilities. Specifically, first, regardless of whether the instructions include explicit or implicit length constraints, we observe that most LLMs cannot generate text that is longer than 4000 words. Second, we observe that while some LLMs can generate longer text, many issues exist (e.g., severe repetition and quality degradation). Third, to demonstrate the effectiveness of HelloEval, we compare HelloEval with traditional metrics (e.g., ROUGE, BLEU, etc.) and LLM-as-a-Judge methods, which show that HelloEval has the highest correlation with human evaluation.																																	2025-01-24	PPRN:98863750		
J	Liu, Akide; Liu, Jing; Pan, Zizheng; He, Yefei; Haffari, Gholamreza; Zhuang, Bohan				Liu, Jing/LFU-9046-2024						MiniCache: KV Cache Compression in Depth Dimension for Large Language Models								Arxiv											2	2;2024-09-07;https://www.arxiv.org/abs/2405.14366v2| 1;2024-05-23;https://www.arxiv.org/abs/2405.14366v1	arXiv:2405.14366			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 07 2024	2024	A critical approach for efficiently deploying computationally demanding large language models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value states of previously generated tokens, significantly reducing the need for repetitive computations and thereby lowering latency in autoregressive generation. However, the size of the KV cache grows linearly with sequence length, posing challenges for applications requiring long context input and extensive sequence generation. In this paper, we present a simple yet effective approach, called MiniCache, to compress the KV cache across layers from a novel depth perspective, significantly reducing the memory footprint for LLM inference. Our approach is based on the observation that KV cache states exhibit high similarity between the adjacent layers in the middle-to-deep portion of LLMs. To facilitate merging, we propose disentangling the states into the magnitude and direction components, interpolating the directions of the state vectors while preserving their lengths unchanged. Furthermore, we introduce a token retention strategy to keep highly distinct state pairs unmerged, thus preserving the information with minimal additional storage overhead. Our MiniCache is training-free and general, complementing existing KV cache compression strategies, such as quantization and sparsity. We conduct a comprehensive evaluation of MiniCache utilizing various models including LLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks, demonstrating its exceptional performance in achieving superior compression ratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit MiniCache achieves a remarkable compression ratio of up to 5.02x, enhances inference throughput by approximately 5x, and reduces the memory footprint by 41% compared to the FP16 full cache baseline, all while maintaining near-lossless performance.																																	2024-09-23	PPRN:88989181		
J	Ma, Jiachen; Cao, Anda; Xiao, Zhiqing; Li, Yijiang; Zhang, Jie; Ye, Chao; Zhao, Junbo				li（李）, Yijiang（懿江）/NHQ-5088-2025						Jailbreaking Prompt Attack: A Controllable Adversarial Attack against Diffusion Models								Arxiv											3	3;2024-09-04;https://www.arxiv.org/abs/2404.02928v3| 2;2024-06-02;https://www.arxiv.org/abs/2404.02928v2| 1;2024-04-02;https://www.arxiv.org/abs/2404.02928v1	arXiv:2404.02928			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 04 2024	2024	Text-to-image (T2I) models can be maliciously used to generate harmful content such as sexually explicit, unfaithful, and misleading or Not-Safe-for-Work (NSFW) images. Previous attacks largely depend on the availability of the diffusion model or involve a lengthy optimization process. In this work, we investigate a more practical and universal attack that does not require the presence of a target model and demonstrate that the high-dimensional text embedding space inherently contains NSFW concepts that can be exploited to generate harmful images. We present the Jailbreaking Prompt Attack (JPA). JPA first searches for the target malicious concepts in the text embedding space using a group of antonyms generated by ChatGPT. Subsequently, a prefix prompt is optimized in the discrete vocabulary space to align malicious concepts semantically in the text embedding space. We further introduce a soft assignment with gradient masking technique that allows us to perform gradient ascent in the discrete vocabulary space. We perform extensive experiments with open-sourced T2I models, e.g. stable-diffusion-v1-4 and closed-sourced online services, e.g. DALLE2, Midjourney with black-box safety checkers. Results show that (1) JPA bypasses both text and image safety checkers (2) while preserving high semantic alignment with the target prompt. (3) JPA demonstrates a much faster speed than previous methods and can be executed in a fully automated manner. These merits render it a valuable tool for robustness evaluation in future text-to-image generation research.																																	2024-09-12	PPRN:88405689		
J	Yu, Tan; Xu, Anbang; Akkiraju, Rama										In Defense of RAG in the Era of Long-Context Language Models								Arxiv											1	1;2024-09-03;https://www.arxiv.org/abs/2409.01666v1	arXiv:2409.01666			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 03 2024	2024	Overcoming the limited context limitations in early-generation LLMs, retrieval-augmented generation (RAG) has been a reliable solution for context-based answer generation in the past. Recently, the emergence of long-context LLMs allows the models to incorporate much longer text sequences, making RAG less attractive. Recent studies show that long-context LLMs significantly outperform RAG in long-context applications. Unlike the existing works favoring the long-context LLM over RAG, we argue that the extremely long context in LLMs suffers from a diminished focus on relevant information and leads to potential degradation in answer quality. This paper revisits the RAG in long-context answer generation. We propose an order-preserve retrieval-augmented generation (OP-RAG) mechanism, which significantly improves the performance of RAG for long-context question-answer applications. With OP-RAG, as the number of retrieved chunks increases, the answer quality initially rises, and then declines, forming an inverted U-shaped curve. There exist sweet points where OP-RAG could achieve higher answer quality with much less tokens than long-context LLM taking the whole context as input. Extensive experiments on public benchmark demonstrate the superiority of our OP-RAG.																																	2024-09-11	PPRN:91714777		
J	Guo, Jiaxian; Yang, Bo; Yoo, Paul; Lin, Bill Yuchen; Iwasawa, Yusuke; Matsuo, Yutaka										Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware GPT-4								Arxiv											3	3;2024-08-31;https://www.arxiv.org/abs/2309.17277v3| 2;2023-10-06;https://www.arxiv.org/abs/2309.17277v2| 1;2023-09-29;https://www.arxiv.org/abs/2309.17277v1	arXiv:2309.17277			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 31 2024	2024	Unlike perfect information games, where all elements are known to every player, imperfect information games emulate the real-world complexities of decision-making under uncertain or incomplete information. GPT-4, the recent breakthrough in large language models (LLMs) trained on massive passive data, is notable for its knowledge retrieval and reasoning abilities. This paper delves into the applicability of GPT-4's learned knowledge for imperfect information games. To achieve this, we introduce textbf{Suspicion-Agent}, an innovative agent that leverages GPT-4's capabilities for performing in imperfect information games. With proper prompt engineering to achieve different functions, Suspicion-Agent based on GPT-4 demonstrates remarkable adaptability across a range of imperfect information card games. Importantly, GPT-4 displays a strong high-order theory of mind (ToM) capacity, meaning it can understand others and intentionally impact others' behavior. Leveraging this, we design a planning strategy that enables GPT-4 to competently play against different opponents, adapting its gameplay style as needed, while requiring only the game rules and descriptions of observations as input. In the experiments, we qualitatively showcase the capabilities of Suspicion-Agent across three different imperfect information games and then quantitatively evaluate it in Leduc Hold'em. The results show that Suspicion-Agent can potentially outperform traditional algorithms designed for imperfect information games, without any specialized training or examples. In order to encourage and foster deeper insights within the community, we make our game-related data publicly available.																																	2024-09-11	PPRN:85339169		
J	Most, Elias R.; Haber, Alexander; Harris, Steven P.; Zhang, Ziyuan; Alford, Mark G.; Noronha, Jorge				Most, Elias/AAK-8709-2020; Noronha, Jorge/E-5783-2013						Emergence of microphysical bulk viscosity in binary neutron star post-merger dynamics								Arxiv											3	3;2024-08-31;https://www.arxiv.org/abs/2207.00442v2| 2;2022-07-01;https://www.arxiv.org/abs/2207.00442v1| 1;2022-07-01;https://www.arxiv.org/abs/2207.00442v1	arXiv:2207.00442			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 31 2024	2024	In nuclear matter in isolated neutron stars, the flavor content (e.g., proton fraction) is subject to weak interactions, establishing flavor (β-)equilibrium. However, there can be deviations from this equilibrium during the merger of two neutron stars. We study the resulting out-of-equilibrium dynamics during the collision by incorporating direct and modified Urca processes (in the neutrino-transparent regime) into general-relativistic hydrodynamics simulations with a simplified neutrino transport scheme. We demonstrate how weak-interaction-driven bulk viscosity in post-merger simulations can emerge and assess the bulk viscous dynamics of the resulting flow. We further place limits on the impact on the post-merger gravitational wave strain. Our results show that weak-interaction-driven bulk viscosity can potentially lead to a phase shift of the post-merger gravitational wave spectrum, although the effect is currently on the same level as the numerical errors of our simulation.																																	2024-09-11	PPRN:12199916		
J	Duisterhof, Bardienus P.; Mandi, Zhao; Yao, Yunchao; Liu, Jia-Wei; Seidenschwarz, Jenny; Shou, Mike Zheng; Ramanan, Deva; Song, Shuran; Birchfield, Stan; Wen, Bowen; Ichnowski, Jeffrey				Wen, Bowen/ACD-9179-2022; Shou, Mike Zheng/LXW-9197-2024						DeformGS: Scene Flow in Highly Deformable Scenes for Deformable Object Manipulation								Arxiv											2	2;2024-08-30;https://www.arxiv.org/abs/2312.00583v2| 1;2023-11-30;https://www.arxiv.org/abs/2312.00583v1	arXiv:2312.00583			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 30 2024	2024	Teaching robots to fold, drape, or reposition deformable objects such as cloth will unlock a variety of automation applications. While remarkable progress has been made for rigid object manipulation, manipulating deformable objects poses unique challenges, including frequent occlusions, infinite-dimensional state spaces and complex dynamics. Just as object pose estimation and tracking have aided robots for rigid manipulation, dense 3D tracking (scene flow) of highly deformable objects will enable new applications in robotics while aiding existing approaches, such as imitation learning or creating digital twins with real2sim transfer. We propose DeformGS, an approach to recover scene flow in highly deformable scenes, using simultaneous video captures of a dynamic scene from multiple cameras. DeformGS builds on recent advances in Gaussian splatting, a method that learns the properties of a large number of Gaussians for state-of-the-art and fast novel-view synthesis. DeformGS learns a deformation function to project a set of Gaussians with canonical properties into world space. The deformation function uses a neural-voxel encoding and a multilayer perceptron (MLP) to infer Gaussian position, rotation, and a shadow scalar. We enforce physics-inspired regularization terms based on conservation of momentum and isometry, which leads to trajectories with smaller trajectory errors. We also leverage existing foundation models SAM and XMEM to produce noisy masks, and learn a per-Gaussian mask for better physics-inspired regularization. DeformGS achieves high-quality 3D tracking on highly deformable scenes with shadows and occlusions. In experiments, DeformGS improves 3D tracking by an average of 55.8% compared to the state-of-the-art. With sufficient texture, DeformGS achieves a median tracking error of 3.3 mm on a cloth of 1.5 x 1.5 m in area. 																																	2024-09-07	PPRN:86357567		
J	Donnan, C.T.; Mclure, R.J.; Dunlop, J.S.; Mcleod, D.J.; Magee, D.; Arellano-Cordova, K.Z.; Barrufet, L.; Begley, R.; Bowler, R.A.A.; Carnall, A.C.; Cullen, F.; Ellis, R.S.; Fontana, A.; Illingworth, G.D.; Grogin, N.A.; Hamadouche, M.L.; Koekemoer, A.M.; Liu, F.-Y.; Mason, C.; Santini, P.; Stanton, T.M.				Bowler, Rebecca/HIK-2775-2022; Liu, Fengyuan/HKV-3788-2023; Ellis, Richard/ABL-1310-2022; Mason, Charlotte/IYJ-2820-2023; Koekemoer, Anton/F-8400-2014; Dunlop, James/ADB-7947-2022						JWST PRIMER: A new multi-field determination of the evolving galaxy UV luminosity function at redshifts z ≃ 9 − 15								Arxiv											3	3;2024-08-24;https://www.arxiv.org/abs/2403.03171v3| 2;2024-05-16;https://www.arxiv.org/abs/2403.03171v2| 1;2024-03-05;https://www.arxiv.org/abs/2403.03171v1	arXiv:2403.03171			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 24 2024	2024	We present a new determination of the evolving galaxy UV luminosity function (LF) over the redshift range 8.5 < z < 15.5 using a combination of several major Cycle-1 JWST imaging programmes- PRIMER, JADES and NGDEEP. This multi-field approach yields a total of ≃ 370 sq. arcmin of JWST /NIRCam imaging, reaching (5-σ) depths of ~ 30 AB mag in the deepest regions. We select a sample of 2548 galaxies with a significant probability of lying at high redshift ( p (z > 8 . 5 ) > 0 . 05) to undertake a statistical calculation of the UV LF. Our new measurements span ~ 4 magnitudes in UV luminosity at z = 9 − 12 . 5, placing new constraints on both the shape and evolution of the LF at early times. Our measurements yield a new estimate of the early evolution of cosmic star-formation rate density (pSFR) confirming the gradual decline deduced from early JWST studies, at least out to z ≃ 12. Finally we show that the observed early evolution of the galaxy UV LF (and pSFR) can be reproduced in a ΛCDM Universe, with no change in dust properties or star-formation efficiency required out to z ≃ 12. Instead, a progressive trend towards younger stellar population ages can reproduce the observations, and the typical ages required at z ≃ 8, 9, 10, and 11 all converge on ≃ 380 − 330 Myr after the Big Bang, indicative of a rapid emergence of early galaxies at z ≃ 12 − 13. This is consistent with the first indications of a steeper drop-off in pSFR we find beyond z ≃ 13, possibly reflecting the rapid evolution of the halo mass function at earlier times.																																	2024-09-04	PPRN:88028182		
J	Chen, Chong; Su, Jianzhong; Chen, Jiachi; Wang, Yanlin; Bi, Tingting; Yu, Jianxing; Wang, Yanli; Lin, Xingwei; Chen, Ting; Zheng, Zibin				Bi, Tingting/ABC-7609-2020; Su, Jianzhong/LLM-5730-2024; Zheng, WeiKang/HMP-4015-2023; Lin, Xingwei/LNP-6081-2024; Chen, Jiachi/HOC-4256-2023						When ChatGPT Meets Smart Contract Vulnerability Detection: How Far Are We?								Arxiv											3	3;2024-08-21;https://www.arxiv.org/abs/2309.05520v4| 2;2023-09-14;https://www.arxiv.org/abs/2309.05520v3| 1;2023-09-12;https://www.arxiv.org/abs/2309.05520v2	arXiv:2309.05520			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 21 2024	2024	With the development of blockchain technology, smart contracts have become an important component of blockchain applications. Despite their crucial role, the development of smart contracts may introduce vulnerabilities and potentially lead to severe consequences, such as financial losses. Meanwhile, large language models, represented by ChatGPT, have gained great attentions, showcasing great capabilities in code analysis tasks. In this paper, we presented an empirical study to investigate the performance of ChatGPT in identifying smart contract vulnerabilities. Initially, we evaluated ChatGPT's effectiveness using a publicly available smart contract dataset. Our findings discover that while ChatGPT achieves a high recall rate, its precision in pinpointing smart contract vulnerabilities is limited. Furthermore, ChatGPT's performance varies when detecting different vulnerability types. We delved into the root causes for the false positives generated by ChatGPT, and categorized them into four groups. Second, by comparing ChatGPT with other state-of-the-art smart contract vulnerability detection tools, we found that ChatGPT's F-score is lower than others for 3 out of the 7 vulnerabilities. In the case of the remaining 4 vulnerabilities, ChatGPT exhibits a slight advantage over these tools. Finally, we analyzed the limitation of ChatGPT in smart contract vulnerability detection, revealing that the robustness of ChatGPT in this field needs to be improved from two aspects: its uncertainty in answering questions; and the limited length of the detected code. In general, our research provides insights into the strengths and weaknesses of employing large language models, specifically ChatGPT, for the detection of smart contract vulnerabilities.																																	2024-08-31	PPRN:84989342		
J	Doshi, Ria; Walke, Homer; Mees, Oier; Dasari, Sudeep; Levine, Sergey										Scaling Cross-Embodied Learning: One Policy for Manipulation, Navigation, Locomotion and Aviation								Arxiv											1	1;2024-08-21;https://www.arxiv.org/abs/2408.11812v1	arXiv:2408.11812			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 21 2024	2024	Modern machine learning systems rely on large datasets to attain broad generalization, and this often poses a challenge in robot learning, where each robotic platform and task might have only a small dataset. By training a single policy across many different kinds of robots, a robot learning method can leverage much broader and more diverse datasets, which in turn can lead to better generalization and robustness. However, training a single policy on multi-robot data is challenging because robots can have widely varying sensors, actuators, and control frequencies. We propose CrossFormer, a scalable and flexible transformerbased policy that can consume data from any embodiment. We train CrossFormer on the largest and most diverse dataset to date, 900K trajectories across 20 different robot embodiments. We demonstrate that the same network weights can control vastly different robots, including single and dual arm manipulation systems, wheeled robots, quadcopters, and quadrupeds. Unlike prior work, our model does not require manual alignment of the observation or action spaces. Extensive experiments in the real world show that our method matches the performance of specialist policies tailored for each embodiment, while also significantly outperforming the prior state of the art in cross-embodiment learning.																																	2024-08-31	PPRN:91506205		
J	Feng, Guofeng; Chen, Siyan; Fu, Rong; Liao, Zimu; Wang, Yi; Liu, Tao; Pei, Zhilin; Li, Hengjie; Zhang, Xingcheng; Dai, Bo				陈, 思言/GZM-5402-2022; Zhang, Xingcheng/AAC-6392-2019; Pei, Zhilin/LYP-2983-2024						FlashGS: Efficient 3D Gaussian Splatting for Large-scale and High-resolution Rendering								Arxiv											2	2;2024-08-19;https://www.arxiv.org/abs/2408.07967v2| 1;2024-08-15;https://www.arxiv.org/abs/2408.07967v1	arXiv:2408.07967			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 19 2024	2024	This work introduces FlashGS, an open-source CUDA Python library 1 designed to facilitate the efficient differentiable rasterization of 3D Gaussian Splatting through algorithmic and kernel-level optimizations. FlashGS is developed based on the observations from a comprehensive analysis of the rendering process to enhance computational efficiency and bring the technique to wide adoption. The paper includes a suite of optimization strategies, encompassing redundancy elimination, efficient pipelining, refined control and scheduling mechanisms, and memory access optimizations, all of which are meticulously integrated to amplify the performance of the rasterization process. An extensive evaluation of FlashGS' performance has been conducted across a diverse spectrum of synthetic and real-world large-scale scenes, encompassing a variety of image resolutions. The empirical findings demonstrate that FlashGS consistently achieves an average 4x acceleration over mobile consumer GPUs, coupled with reduced memory consumption. These results underscore the superior performance and resource optimization capabilities of FlashGS, positioning it as a formidable tool in the domain of 3D rendering.																																	2024-08-28	PPRN:91414486		
J	Poddar, Sriyash; Wan, Yanming; Ivison, Hamish; Gupta, Abhishek; Jaques, Natasha										Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning								Arxiv											1	1;2024-08-19;https://www.arxiv.org/abs/2408.10075v1	arXiv:2408.10075			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 19 2024	2024	Reinforcement Learning from Human Feedback (RLHF) is a powerful paradigm for aligning foundation models to human values and preferences. However, current RLHF techniques cannot account for the naturally occurring differences in individual human preferences across a diverse population. When these differences arise, traditional RLHF frameworks simply average over them, leading to inaccurate rewards and poor performance for individual subgroups. To address the need for pluralistic alignment, we develop a class of multimodal RLHF methods. Our proposed techniques are based on a latent variable formulation - inferring a novel user-specific latent and learning reward models and policies conditioned on this latent without additional user-specific data. While conceptually simple, we show that in practice, this reward modeling requires careful algorithmic considerations around model architecture and reward scaling. To empirically validate our proposed technique, we first show that it can provide a way to combat underspecification in simulated control problems, inferring and optimizing user-specific reward functions. Next, we conduct experiments on pluralistic language datasets representing diverse user preferences and demonstrate improved reward function accuracy. We additionally show the benefits of this probabilistic framework in terms of measuring uncertainty, and actively learning user preferences. This work enables learning from diverse populations of users with divergent preferences, an important challenge that naturally occurs in problems from robot learning to foundation model alignment.																																	2024-08-28	PPRN:91496770		
J	Zelikman, Eric; Lorch, Eliana; Mackey, Lester; Kalai, Adam Tauman										Self-Taught Optimizer (STOP): Recursively Self-Improving Code Generation								Arxiv											2	2;2024-08-16;https://www.arxiv.org/abs/2310.02304v3| 1;2023-10-03;https://www.arxiv.org/abs/2310.02304v1	arXiv:2310.02304			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 16 2024	2024	Several recent advances in AI systems solve problems by providing a "scaffolding" program that structures multiple calls to language models (LMs) to generate better outputs. A scaffolding program is written in a programming language such as Python. In this work, we use a language-model-infused scaffolding program to improve itself. We start with a seed "improver" that improves an input program according to a given utility function by querying an LM several times and returning the best solution. We then run this seed improver to improve itself. Across a small set of downstream tasks, the resulting improved improver generates programs with significantly better performance than its seed improver. A variety of self-improvement strategies are proposed by the language model, including beam search, genetic algorithms, and simulated annealing. Since the language models themselves are not altered, this is not full recursive self-improvement. Nonetheless, it demonstrates that a modern language model, GPT-4 in our experiments, is capable of writing code that can call itself to improve itself. We consider concerns around the development of self-improving technologies and evaluate the frequency with which the generated code bypasses a sandbox.																																	2024-08-24	PPRN:85425628		
J	Liu, Shuo; Zhang, Hao-Kai; Yin, Shuai; Zhang, Shi-Xin; Yao, Hong				Zhang, Shi-Xin/OBN-7840-2025; Liu, Shuo/NRX-8151-2025						Quantum Mpemba effects in many-body localization systems								Arxiv											1	1;2024-08-14;https://www.arxiv.org/abs/2408.07750v1	arXiv:2408.07750			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 14 2024	2024	The nonequilibrium dynamics of quantum many-body systems have attracted growing attention due to various intriguing phenomena absent in equilibrium physics. One famous example is the quantum Mpemba effect, where the subsystem symmetry is restored faster under a symmetric quench from a more asymmetric initial state. The quantum Mpemba effect has been extensively studied in integrable and chaotic systems. In this Letter, we investigate symmetry restoration and quantum Mpemba effect in many-body localized systems with various initial states. We reveal that the symmetry can still be fully restored in many-body localization phases without approaching thermal equilibrium. Furthermore, we demonstrate that the presence of the quantum Mpemba effect is universal for any initial tilted product state, contrasting to the cases in the chaotic systems where the presence of the quantum Mpemba effect relies on the choice of initial states. We also provide a theoretical analysis of symmetry restoration and quantum Mpemba effects with the help of the effective model for many-body localization. This Letter not only sheds light on extending the quantum Mpemba effect to more non-equilibrium settings but also contributes to a deeper understanding of the many-body localization.																																	2024-08-23	PPRN:91413640		
J	Cai, Mu; Yang, Jianwei; Gao, Jianfeng; Lee, Yong Jae				Gao, Jianfeng/AAP-8200-2021; Cai, Mu/AAD-8827-2022						Matryoshka Multimodal Models								Arxiv											2	2;2024-07-29;https://www.arxiv.org/abs/2405.17430v2| 1;2024-05-27;https://www.arxiv.org/abs/2405.17430v1	arXiv:2405.17430			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 29 2024	2024	Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in visual-linguistic reasoning. These models first embed images into a fixed large number of visual tokens and then feed them into a Large Language Model (LLM). However, this design causes an excessive number of tokens for dense visual scenarios such as high-resolution images and videos, leading to great inefficiency. While token pruning/merging methods do exist, they produce a single length output for each image and do not afford flexibility in trading off information density v.s. efficiency. Inspired by the concept of Matryoshka Dolls, we propose M3: Matryoshka Multimodal Models, which learns to represent visual content as nested sets of visual tokens that capture information across multiple coarse-to-fine granularities. Our approach offers several unique benefits for LMMs: (1) One can explicitly control the visual granularity per test instance during inference, e.g. , adjusting the number of tokens used to represent an image based on the anticipated complexity or simplicity of the content; (2) M3 provides a framework for analyzing the granularity needed for existing datasets, where we find that COCO-style benchmarks only need around ~9 visual tokens to obtain accuracy similar to that of using all 576 tokens; (3) Our approach provides a foundation to explore the best trade-off between performance and visual token length at sample level, where our investigation reveals that a large gap exists between the oracle upper bound and current fixed-scale representations.																																	2024-08-06	PPRN:89061911		
J	Wu, Tianxing; Si, Chenyang; Jiang, Yuming; Huang, Ziqi; Liu, Ziwei				Si, ChenYang/HTS-0409-2023; Liu, Ziwei/AAG-6939-2021; wu, tianxing/GXH-6947-2022						FreeInit: Bridging Initialization Gap in Video Diffusion Models								Arxiv											2	2;2024-07-25;https://www.arxiv.org/abs/2312.07537v2| 1;2023-12-12;https://www.arxiv.org/abs/2312.07537v1	arXiv:2312.07537			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 25 2024	2024	Though diffusion-based video generation has witnessed rapid progress, the inference results of existing models still exhibit unsatisfactory temporal consistency and unnatural dynamics. In this paper, we delve deep into the noise initialization of video diffusion models, and discover an implicit training-inference gap that attributes to the unsatisfactory inference quality.Our key findings are: 1) the spatial-temporal frequency distribution of the initial noise at inference is intrinsically different from that for training, and 2) the denoising process is significantly influenced by the low-frequency components of the initial noise. Motivated by these observations, we propose a concise yet effective inference sampling strategy, FreeInit, which significantly improves temporal consistency of videos generated by diffusion models. Through iteratively refining the spatial-temporal low-frequency components of the initial latent during inference, FreeInit is able to compensate the initialization gap between training and inference, thus effectively improving the subject appearance and temporal consistency of generation results. Extensive experiments demonstrate that FreeInit consistently enhances the generation quality of various text-to-video diffusion models without additional training or fine-tuning.																																	2024-12-24	PPRN:86556986		
J	McElfresh, Duncan; Khandagale, Sujay; Valverde, Jonathan; Prasad, C Vishak; Feuer, Benjamin; Hegde, Chinmay; Ramakrishnan, Ganesh; Goldblum, Micah; White, Colin				Khandagale, Sujay/AAM-8046-2021; Prasad, C.Venkata/D-5559-2018; Valverde, Juan/J-4293-2012						When Do Neural Nets Outperform Boosted Trees on Tabular Data?								Arxiv											4	4;2024-07-15;https://www.arxiv.org/abs/2305.02997v4| 3;2023-10-30;https://www.arxiv.org/abs/2305.02997v3| 2;2023-10-17;https://www.arxiv.org/abs/2305.02997v2| 1;2023-05-04;https://www.arxiv.org/abs/2305.02997v1	arXiv:2305.02997			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 15 2024	2024	Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and question the importance of this debate. To this end, we conduct the largest tabular data analysis to date, comparing 19 algorithms across 176 datasets, and we find that the 'NN vs. GBDT' debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than choosing between NNs and GBDTs. A remarkable exception is the recently-proposed prior-data fitted network, TabPFN: although it is effectively limited to training sets of size 3000, we find that it outperforms all other algorithms on average, even when randomly sampling 3000 training datapoints. Next, we analyze dozens of metafeatures to determine what properties of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better than NNs at handling skewed or heavy-tailed feature distributions and other forms of dataset irregularities. Our insights act as a guide for practitioners to determine which techniques may work best on their dataset. Finally, with the goal of accelerating tabular data research, we release the TabZilla Benchmark Suite: a collection of the 36 'hardest' of the datasets we study. 																																	2024-07-25	PPRN:67332025		
J	Ha, Huy; Gao, Yihuai; Fu, Zipeng; Tan, Jie; Song, Shuran										UMI on Legs: Making Manipulation Policies Mobile with Manipulation-Centric Whole-body Controllers								Arxiv											1	1;2024-07-14;https://www.arxiv.org/abs/2407.10353v1	arXiv:2407.10353			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 14 2024	2024	We introduce UMI-on-Legs, a new framework that combines real-world and simulation data for quadruped manipulation systems. We scale task-centric data collection in the real world using a hand-held gripper (UMI), providing a cheap way to demonstrate task-relevant manipulation skills without a robot. Simultaneously, we scale robot-centric data in simulation by training whole-body controller for task-tracking without task simulation setups. The interface between these two policies is end-effector trajectories in the task frame, inferred by the manipulation policy and passed to the whole-body controller for tracking. We evaluate UMI-on-Legs on prehensile, non-prehensile, and dynamic manipulation tasks, and report over 70% success rate on all tasks. Lastly, we demonstrate the zero-shot cross-embodiment deployment of a pre-trained manipulation policy checkpoint from prior work, originally intended for a fixed-base robot arm, on our quadruped system. We believe this framework provides a scalable path towards learning expressive manipulation skills on dynamic robot embodiments. 																																	2024-07-23	PPRN:90819890		
J	Qi, Zekun; Dong, Runpei; Zhang, Shaochen; Geng, Haoran; Han, Chunrui; Ge, Zheng; Yi, Li; Ma, Kaisheng				Geng, Haoran/ISV-3533-2023; Qi, Zekun/OJV-3861-2025; Zhang, Shaochen/AAM-2792-2020						ShapeLLM: Universal 3D Object Understanding for Embodied Interaction								Arxiv											3	3;2024-07-12;https://www.arxiv.org/abs/2402.17766v3| 2;2024-03-06;https://www.arxiv.org/abs/2402.17766v2| 1;2024-02-27;https://www.arxiv.org/abs/2402.17766v1	arXiv:2402.17766			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 12 2024	2024	This paper presents ShapeLLM, the first 3D Multimodal Large Language Model (LLM) designed for embodied interaction, exploring a universal 3D object understanding with 3D point clouds and languages. ShapeLLM is built upon an improved 3D encoder by extending ReCon to ReCon++ that benefits from multi-view image distillation for enhanced geometry understanding. By utilizing ReCon++ as the 3D point cloud input encoder for LLMs, ShapeLLM is trained on constructed instruction-following data and tested on our newly human-curated benchmark, 3D MM-Vet. ReCon++ and ShapeLLM achieve state-of-the-art performance in 3D geometry understanding and language-unified 3D interaction tasks, such as embodied visual grounding. 																																	2024-07-23	PPRN:87921569		
J	Zhou, Kaitlyn; Hwang, Jena D.; Ren, Xiang; Sap, Maarten										Relying on the Unreliable: The Impact of Language Models' Reluctance to Express Uncertainty								Arxiv											2	2;2024-07-09;https://www.arxiv.org/abs/2401.06730v2| 1;2024-01-12;https://www.arxiv.org/abs/2401.06730v1	arXiv:2401.06730			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 09 2024	2024	As natural language becomes the default interface for human-AI interaction, there is a need for LMs to appropriately communicate uncertainties in downstream applications. In this work, we investigate how LMs incorporate confidence in responses via natural language and how downstream users behave in response to LM-articulated uncertainties. We examine publicly deployed models and find that LMs are reluctant to express uncertainties when answering questions even when they produce incorrect responses. LMs can be explicitly prompted to express confidences, but tend to be overconfident, resulting in high error rates (an average of 47%) among confident responses. We test the risks of LM overconfidence by conducting human experiments and show that users rely heavily on LM generations, whether or not they are marked by certainty. Lastly, we investigate the preference-annotated datasets used in post training alignment and find that humans are biased against texts with uncertainty. . Our work highlights new safety harms facing human-LM interactions and proposes design recommendations and mitigating strategies moving forward.																																	2024-07-21	PPRN:87157153		
J	Moon, Wonjun; Hyun, Sangeek; Lee, Subeen; Heo, Jae-Pil										Correlation-Guided Query-Dependency Calibration for Video Temporal Grounding								Arxiv											4	4;2024-07-03;https://www.arxiv.org/abs/2311.08835v4| 3;2024-03-30;https://www.arxiv.org/abs/2311.08835v3| 2;2023-11-18;https://www.arxiv.org/abs/2311.08835v2| 1;2023-11-15;https://www.arxiv.org/abs/2311.08835v1	arXiv:2311.08835			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jul 03 2024	2024	Temporal Grounding is to identify specific moments or highlights from a video corresponding to textual descriptions. Typical approaches in temporal grounding treat all video clips equally during the encoding process regardless of their semantic relevance with the text query. Therefore, we propose Correlation-Guided DEtection TRansformer (CG-DETR), exploring to provide clues for query-associated video clips within the cross-modal attention. First, we design an adaptive cross-attention with dummy tokens. Dummy tokens conditioned by text query take portions of the attention weights, preventing irrelevant video clips from being represented by the text query. Yet, not all words equally inherit the text query's correlation to video clips. Thus, we further guide the cross-attention map by inferring the fine-grained correlation between video clips and words. We enable this by learning a joint embedding space for high-level concepts, i.e., moment and sentence level, and inferring the clip-word correlation. Lastly, we exploit the moment-specific characteristics and combine them with the context of each video to form a moment-adaptive saliency detector. By exploiting the degrees of text engagement in each video clip, it precisely measures the highlightness of each clip. CG-DETR achieves state-of-the-art results on various benchmarks for temporal grounding. 																																	2024-07-21	PPRN:86173212		
J	Shen, Fei; Ye, Hu; Liu, Sibo; Zhang, Jun; Wang, Cong; Han, Xiao; Yang, Wei				沈, 飞/HKM-4286-2023; Liu, SiBo/C-6401-2018; Han, Xiao/GQZ-6090-2022						Boosting Consistency in Story Visualization with Rich-Contextual Conditional Diffusion Models								Arxiv											2	2;2024-07-03;https://www.arxiv.org/abs/2407.02482v2| 1;2024-07-02;https://www.arxiv.org/abs/2407.02482v1	arXiv:2407.02482			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 03 2024	2024	Recent research showcases the considerable potential of conditional diffusion models for generating consistent stories. However, current methods, which predominantly generate stories in an autoregressive and excessively caption-dependent manner, often underrate the contextual consistency and relevance of frames during sequential generation. To address this, we propose a novel Rich-contextual Conditional Diffusion Models (RCDMs), a two-stage approach designed to enhance story generation's semantic consistency and temporal consistency. Specifically, in the first stage, the frame-prior transformer diffusion model is presented to predict the frame semantic embedding of the unknown clip by aligning the semantic correlations between the captions and frames of the known clip. The second stage establishes a robust model with rich contextual conditions, including reference images of the known clip, the predicted frame semantic embedding of the unknown clip, and text embeddings of all captions. By jointly injecting these rich contextual conditions at the image and feature levels, RCDMs can generate semantic and temporal consistency stories. Moreover, RCDMs can generate consistent stories with a single forward inference compared to autoregressive models. Our qualitative and quantitative results demonstrate that our proposed RCDMs outperform in challenging scenarios. 																																	2024-07-20	PPRN:90669346		
J	Wu, Jiannan; Zhong, Muyan; Xing, Sen; Lai, Zeqiang; Liu, Zhaoyang; Chen, Zhe; Wang, Wenhai; Zhu, Xizhou; Lu, Lewei; Lu, Tong; Luo, Ping; Qiao, Yu; Dai, Jifeng				Qiao, Yu/ABD-5787-2021; pluo/GPG-2707-2022; Dai, Jifeng/HGU-8741-2022; Wang, Wen-Jing/HOH-7164-2023						VisionLLM v2: An End-to-End Generalist Multimodal Large Language Model for Hundreds of Vision-Language Tasks								Arxiv											2	2;2024-06-14;https://www.arxiv.org/abs/2406.08394v2| 1;2024-06-12;https://www.arxiv.org/abs/2406.08394v1	arXiv:2406.08394			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 14 2024	2024	We present VisionLLM v2, an end-to-end generalist multimodal large model (MLLM) that unifies visual perception, understanding, and generation within a single framework. Unlike traditional MLLMs limited to text output, VisionLLM v2 significantly broadens its application scope. It excels not only in conventional visual question answering (VQA) but also in open-ended, cross-domain vision tasks such as object localization, pose estimation, and image generation and editing. To this end, we propose a new information transmission mechanism termed "super link", as a medium to connect MLLM with task-specific decoders. It not only allows flexible transmission of task information and gradient feedback between the MLLM and multiple downstream decoders but also effectively resolves training conflicts in multi-tasking scenarios. In addition, to support the diverse range of tasks, we carefully collected and combed training data from hundreds of public vision and vision-language tasks. In this way, our model can be joint-trained end-to-end on hundreds of vision language tasks and generalize to these tasks using a set of shared parameters through different user prompts, achieving performance comparable to task-specific models. We believe VisionLLM v2 will offer a new perspective on the generalization of MLLMs.																																	2024-07-02	PPRN:89290808		
J	Zhang, Danyang; Shen, Zhennan; Xie, Rui; Zhang, Situo; Xie, Tianbao; Zhao, Zihan; Chen, Siyuan; Chen, Lu; Xu, Hongshen; Cao, Ruisheng; Yu, Kai				XU, Hongshen/HNS-5930-2023; Yu, Kai/M-2934-2019; Chen, Siyuan/LDF-1210-2024; Cao, Ruisheng/NFT-9188-2025						Mobile-Env: Building Qualified Evaluation Benchmarks for LLM-GUI Interaction								Arxiv											3	3;2024-06-13;https://www.arxiv.org/abs/2305.08144v4| 2;2024-02-24;https://www.arxiv.org/abs/2305.08144v3| 1;2023-05-14;https://www.arxiv.org/abs/2305.08144v1	arXiv:2305.08144			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 13 2024	2024	The Graphical User Interface (GUI) is pivotal for human interaction with the digital world, enabling efficient device control and the completion of complex tasks. Recent progress in Large Language Models (LLMs) and Vision Language Models (VLMs) offers the chance to create advanced GUI agents. To ensure their effectiveness, there's a pressing need for qualified benchmarks that provide trustworthy and reproducible evaluations - a challenge current benchmarks often fail to address. To tackle this issue, we introduce Mobile-Env, a comprehensive toolkit tailored for creating GUI benchmarks in the Android mobile environment. Mobile-Env offers an isolated and controllable setting for reliable evaluations, and accommodates intermediate instructions and rewards to reflect real-world usage more naturally. Utilizing Mobile-Env, we collect an open-world task set across various real-world apps and a fixed world set, WikiHow, which captures a significant amount of dynamic online contents for fully controllable and reproducible evaluation. We conduct comprehensive evaluations of LLM agents using these benchmarks. Our findings reveal that even advanced models (e.g., GPT-4V and LLaMA-3) struggle with tasks that are relatively simple for humans. This highlights a crucial gap in current models and underscores the importance of developing more capable foundation models and more effective GUI agent frameworks.1																																	2024-07-10	PPRN:69573311		
J	Bucher, Martin Juan Jose; Martini, Marco				Bucher, Martin/OVY-9233-2025						Fine-Tuned 'Small' LLMs (Still) Significantly Outperform Zero-Shot Generative AI Models in Text Classification								Arxiv											1	1;2024-06-12;https://www.arxiv.org/abs/2406.08660v1	arXiv:2406.08660			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 12 2024	2024	Generative AI offers a simple, prompt-based alternative to fine-tuning smaller BERT-style LLMs for text classification tasks. This promises to eliminate the need for manually labeled training data and task-specific model training. However, it remains an open question whether tools like ChatGPT can deliver on this promise. In this paper, we show that smaller, fine-tuned LLMs (still) consistently and significantly outperform larger, zero-shot prompted models in text classification. We compare three major generative AI models (ChatGPT with GPT-3.5/GPT-4 and Claude Opus) with several fine-tuned LLMs across a diverse set of classification tasks (sentiment, approval/disapproval, emotions, party positions) and text categories (news, tweets, speeches). We find that fine-tuning with application-specific training data achieves superior performance in all cases. To make this approach more accessible to a broader audience, we provide an easy-to-use toolkit alongside this paper. Our toolkit, accompanied by non-technical step-by-step guidance, enables users to select and fine-tune BERT-like LLMs for any classification task with minimal technical and computational effort.																																	2024-07-02	PPRN:89302326		
J	Chai, Linzheng; Liu, Shukai; Yang, Jian; Yin, Yuwei; Jin, Ke; Liu, Jiaheng; Sun, Tao; Zhang, Ge; Ren, Changyu; Guo, Hongcheng; Wang, Zekun; Wang, Boyang; Wu, Xianjie; Wang, Bing; Li, Tongliang; Yang, Liqun; Duan, Sufeng; Li, Zhoujun				zhou, sheng/GYJ-6012-2022; Yin, Yuwei/AGC-5865-2022; Sun, Tao/ORK-0166-2025; Wang, Boyang/GSJ-2617-2022; Yang, Jian/JXX-7911-2024; Ren, Changyu/KCK-9507-2024; Sun, Tao/AGJ-5617-2022; Yang, Liqun/F-7224-2010						McEval: Massively Multilingual Code Evaluation								Arxiv											1	1;2024-06-11;https://www.arxiv.org/abs/2406.07436v1	arXiv:2406.07436			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 11 2024	2024	Code large language models (LLMs) have shown remarkable advances in code understanding, completion, and generation tasks. Programming benchmarks, comprised of a selection of code challenges and corresponding test cases, serve as a standard to evaluate the capability of different LLMs in such tasks. However, most existing benchmarks primarily focus on Python and are still restricted to a limited number of languages, where other languages are translated from the Python samples (e.g. MultiPL-E) degrading the data diversity. To further facilitate the research of code LLMs, we propose a massively multilingual code benchmark covering 40 programming languages (McEval) with 16K test samples, which substantially pushes the limits of code LLMs in multilingual scenarios. The benchmark contains challenging code completion, understanding, and generation evaluation tasks with finely curated massively multilingual instruction corpora McEval-Instruct. In addition, we introduce an effective multilingual coder mCoder trained on McEval-Instruct to support multilingual programming language generation. Extensive experimental results on McEval show that there is still a difficult journey between open-source models and closed-source LLMs (e.g. GPT-series models) in numerous languages.																																	2024-07-04	PPRN:89285038		
J	Zhao, Yue; Xiong, Yuanjun; Kraehenbuehl, Philipp				Xiong, Yuanjun/JPX-0310-2023; Zhao, Yue/AGU-0409-2022						Image and Video Tokenization with Binary Spherical Quantization								Arxiv											1	1;2024-06-11;https://www.arxiv.org/abs/2406.07548v1	arXiv:2406.07548			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 11 2024	2024	We propose a new transformer-based image and video tokenizer with Binary Spherical Quantization (BSQ). BSQ projects the high-dimensional visual embedding to a lower-dimensional hypersphere and then applies binary quantization. BSQ is (1) parameter-efficient without an explicit codebook, (2) scalable to arbitrary token dimensions, and (3) compact: compressing visual data by up to 100 × with minimal distortion. Our tokenizer uses a transformer encoder and decoder with simple block-wise causal masking to support variable-length videos as input. The resulting BSQ-ViT achieves state-of-the-art visual reconstruction quality on image and video reconstruction benchmarks with 2.4 × throughput compared to the best prior methods. Furthermore, by learning an autoregressive prior for adaptive arithmetic coding, BSQ-ViT achieves comparable results on video compression with state-of-the-art video compression standards. BSQ-ViT also enables masked language models to achieve competitive image synthesis quality to GAN- and diffusion-based methods.																																	2024-07-04	PPRN:89284424		
J	Hou, Bairu; Liu, Yujian; Qian, Kaizhi; Andreas, Jacob; Chang, Shiyu; Zhang, Yang				Qian, Kaizhi/AAJ-2372-2020						Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling								Arxiv											2	2;2024-06-10;https://www.arxiv.org/abs/2311.08718v2| 1;2023-11-15;https://www.arxiv.org/abs/2311.08718v1	arXiv:2311.08718			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 10 2024	2024	Uncertainty decomposition refers to the task of decomposing the total uncertainty of a predictive model into aleatoric (data) uncertainty, resulting from inherent randomness in the data -generating process, and epistemic (model) uncertainty, resulting from missing information in the model’s training data. In large language models (LLMs) specifically, identifying sources of uncertainty is an important step toward improving reliability, trustworthiness, and interpretability, but remains an important open research question. In this paper, we introduce an uncertainty decomposition framework for LLMs, called input clarification ensembling, which can be applied to any pre -trained LLM. Our approach generates a set of clarifications for the input, feeds them into an LLM, and ensembles the corresponding predictions. We show that, when aleatoric uncertainty arises from ambiguity or under -specification in LLM inputs, this approach makes it possible to factor an (un-clarified) LLM’s predictions into separate aleatoric and epistemic terms, using a decomposition similar to the one employed by Bayesian neural networks. Empirical evaluations demonstrate that input clarification ensembling provides accurate and reliable uncertainty quantification on several language processing tasks. Code and data are available at https://github.com/ UCSB-NLP-Chang/llm_uncertainty. .																																	2024-07-04	PPRN:86172746		
J	Yao, Jiayi; Li, Hanchen; Liu, Yuhan; Ray, Siddhant; Cheng, Yihua; Zhang, Qizheng; Du, Kuntai; Lu, Shan; Jiang, Junchen				Yao, Jiayi/IXN-4828-2023; Cheng, Yihua/LDG-8022-2024						CacheBlend: Fast Large Language Model Serving for RAG with Cached Knowledge Fusion								Arxiv											2	2;2024-06-03;https://www.arxiv.org/abs/2405.16444v2| 1;2024-05-26;https://www.arxiv.org/abs/2405.16444v1	arXiv:2405.16444			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 03 2024	2024	Large language models (LLMs) often incorporate multiple text chunks in their inputs to provide the necessary contexts. To speed up the prefill of the long LLM inputs, one can pre-compute the KV cache of a text and re-use the KV cache when the context is reused as the prefix of another LLM input. However, the reused text chunks are not always the input prefix, and when they are not, their precomputed KV caches cannot be directly used since they ignore the text’s cross - attention with the preceding text in the LLM input. Thus, the benefits of reusing KV caches remain largely unrealized. This paper tackles just one question: when an LLM input contains multiple text chunks, how to quickly combine their precomputed KV caches in order to achieve the same generation quality as the expensive full prefill ( i.e., without reusing KV cache)? We present CACHEBLEND , , a scheme that reuses the pre-computed KV caches, regardless prefix or not, and selectively recomputes the KV values of a small subset of tokens to partially update each reused KV cache. In the meantime, the small extra delay for recomputing some tokens can be pipelined with the retrieval of KV caches within the same job, allowing CACHEBLEND to store KV caches in slower devices with more storage capacity while retrieving them without increasing the inference delay. By comparing CACHEBLEND with the state-of-the-art KV cache reusing schemes on three open -source LLMs of various sizes and four popular benchmark datasets of different tasks, we show that CACHEBLEND reduces time -to -first -token (TTFT) by 2.2–3.3× and increases the inference throughput by 2.8-5× , compared with full KV recompute, without compromising generation quality or incurring more storage cost.																																	2024-06-22	PPRN:89060672		
J	Nachmani, Eliya; Levkovitch, Alon; Hirsch, Roy; Salazar, Julian; Asawaroengchai, Chulayuth; Mariooryad, Soroosh; Rivlin, Ehud; Skerry-Ryan, Rj; Ramanovich, Michelle Tadmor				Salazar, Julian/HNQ-0995-2023						Spoken Question Answering and Speech Continuation Using Spectrogram-Powered LLM								Arxiv											3	3;2024-05-31;https://www.arxiv.org/abs/2305.15255v4| 2;2023-10-20;https://www.arxiv.org/abs/2305.15255v3| 1;2023-05-24;https://www.arxiv.org/abs/2305.15255v1	arXiv:2305.15255			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 31 2024	2024	We present Spectron, a novel approach to adapting pre-trained large language models (LLMs) to perform spoken question answering (QA) and speech continuation. By endowing the LLM with a pre-trained speech encoder, our model becomes able to take speech inputs and generate speech outputs. The entire system is trained end-to-end and operates directly on spectrograms, simplifying our architecture. Key to our approach is a training objective that jointly supervises speech recognition, text continuation, and speech synthesis using only paired speech-text pairs, enabling a 'cross-modal' chain-of-thought within a single decoding pass. Our method surpasses existing spoken language models in speaker preservation and semantic coherence. Furthermore, the proposed model improves upon direct initialization in retaining the knowledge of the original LLM as demonstrated through spoken QA datasets.																																	2024-06-19	PPRN:72713860		
J	Luo, Haoran; Haihong, E; Tang, Zichen; Peng, Shiyao; Guo, Yikai; Zhang, Wentai; Ma, Chenghao; Dong, Guanting; Song, Meina; Lin, Wei; Zhu, Yifan; Tuan, Luu Anh				Luu, Anh Tuan/AAG-3582-2021; dong, guanting/JGL-9364-2023; Zhu, Yifan/AAF-3987-2020; peng, shiyao/LNR-1452-2024; Lin, Wei/B-7995-2009; Zhang, Wentai/HPF-5359-2023						ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models								Arxiv											2	2;2024-05-30;https://www.arxiv.org/abs/2310.08975v2| 1;2023-10-13;https://www.arxiv.org/abs/2310.08975v1	arXiv:2310.08975			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	May 30 2024	2024	Knowledge Base Question Answering (KBQA) aims to answer natural language questions over large-scale knowledge bases (KBs), which can be summarized into two crucial steps: knowledge retrieval and semantic parsing. However, three core challenges remain: inefficient knowledge retrieval, mistakes of retrieval adversely impacting semantic parsing, and the complexity of previous KBQA methods. To tackle these challenges, we introduce ChatKBQA, a novel and simple generate-then-retrieve KBQA framework, which proposes first generating the logical form with fine-tuned LLMs, then retrieving and replacing entities and relations with an unsupervised retrieval method, to improve both generation and retrieval more directly. Experimental results show that ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, WebQSP, and CWQ. This work can also be regarded as a new paradigm for combining LLMs with knowledge graphs (KGs) for interpretable and knowledge-required question answering. Our code is publicly available1.																																	2024-08-24	PPRN:85616547		
J	Xie, Yueqi; Fang, Minghong; Pi, Renjie; Gong, Neil				Xie, Yueqi/JUV-7366-2023						GradSafe: Detecting Jailbreak Prompts for LLMs via Safety-Critical Gradient Analysis								Arxiv											1	1;2024-05-29;https://www.arxiv.org/abs/2402.13494v2	arXiv:2402.13494			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 29 2024	2024	Large Language Models (LLMs) face threats from jailbreak prompts. Existing methods for detecting jailbreak prompts are primarily online moderation APIs or finetuned LLMs. These strategies, however, often require extensive and resource-intensive data collection and training processes. In this study, we propose GradSafe, which effectively detects jailbreak prompts by scrutinizing the gradients of safety-critical parameters in LLMs. Our method is grounded in a pivotal observation: the gradients of an LLM's loss for jailbreak prompts paired with compliance response exhibit similar patterns on certain safety-critical parameters. In contrast, safe prompts lead to different gradient patterns. Building on this observation, GradSafe analyzes the gradients from prompts (paired with compliance responses) to accurately detect jailbreak prompts. We show that GradSafe, applied to Llama-2 without further training, outperforms Llama Guard, despite its extensive finetuning with a large dataset, in detecting jailbreak prompts. This superior performance is consistent across both zero-shot and adaptation scenarios, as evidenced by our evaluations on ToxicChat and XSTest. 																																	2024-06-16	PPRN:89113142		
J	Bahmani, Sherwin; Skorokhodov, Ivan; Rong, Victor; Wetzstein, Gordon; Guibas, Leonidas; Wonka, Peter; Tulyakov, Sergey; Park, Jeong Joon; Tagliasacchi, Andrea; Lindell, David B.				Lindell, David/JFT-0746-2023						4D-fy: Text-to-4D Generation Using Hybrid Score Distillation Sampling								Arxiv											2	2;2024-05-26;https://www.arxiv.org/abs/2311.17984v2| 1;2023-11-29;https://www.arxiv.org/abs/2311.17984v1	arXiv:2311.17984			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 26 2024	2024	Recent breakthroughs in text-to-4D generation rely on pre-trained text-to-image and text-to-video models to generate dynamic 3D scenes. However, current text-to-4D methods face a three-way tradeoff between the quality of scene appearance, 3D structure, and motion. For example, text-to-image models and their 3D-aware variants are trained on internet-scale image datasets and can be used to produce scenes with realistic appearance and 3D structure -- but no motion. Text-to-video models are trained on relatively smaller video datasets and can produce scenes with motion, but poorer appearance and 3D structure. While these models have complementary strengths, they also have opposing weaknesses, making it difficult to combine them in a way that alleviates this three-way tradeoff. Here, we introduce hybrid score distillation sampling, an alternating optimization procedure that blends supervision signals from multiple pre-trained diffusion models and incorporates benefits of each for high-fidelity text-to-4D generation. Using hybrid SDS, we demonstrate synthesis of 4D scenes with compelling appearance, 3D structure, and motion.																																	2024-06-08	PPRN:86336786		
J	Li, Zhe; Sun, Yipengjing; Zheng, Zerong; Wang, Lizhen; Zhang, Shengping; Liu, Yebin				Liu, Yebin/L-7393-2019; Wang, Lizhen/JXL-5347-2024; Li, Zhefan/MIQ-7700-2025; ZHENG, ZERONG/KVA-4699-2024						Animatable and Relightable Gaussians for High-fidelity Human Avatar Modeling								Arxiv											4	4;2024-05-25;https://www.arxiv.org/abs/2311.16096v4| 3;2024-03-31;https://www.arxiv.org/abs/2311.16096v3| 2;2024-03-15;https://www.arxiv.org/abs/2311.16096v2| 1;2023-11-27;https://www.arxiv.org/abs/2311.16096v1	arXiv:2311.16096			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 25 2024	2024	Modeling animatable human avatars from RGB videos is a long -standing and challenging problem. Recent works usually adopt MLP-based neural radiance fields (NeRF) to represent 3D humans, but it remains difficult for pure MLPs to regress pose-dependent garment details. To this end, we introduce Animatable Gaussians, a new avatar representation that leverages powerful 2D CNNs and 3D Gaussian splatting to create high-fidelity avatars. To associate 3D Gaussians with the animatable avatar, we learn a parametric template from the input videos, and then parameterize the template on two front & back canonical Gaussian maps where each pixel represents a 3D Gaussian. The learned template is adaptive to the wearing garments for modeling looser clothes like dresses. Such templateguided 2D parameterization enables us to employ a powerful StyleGAN-based CNN to learn the pose-dependent Gaussian maps for modeling detailed dynamic appearances. Furthermore, we introduce a pose projection strategy for better generalization given novel poses. To tackle the realistic relighting of animatable avatars, we introduce physically-based rendering into the avatar representation for decomposing avatar materials and environment illumination. Overall, our method can create lifelike avatars with dynamic, realistic, generalized and relightable appearances. Experiments show that our method outperforms other state -ofthe -art approaches.																																	2024-06-11	PPRN:86296043		
J	Bai, Jiesong; Yin, Yuhao; He, Qiyuan; Li, Yuanxian; Zhang, Xiaofeng				Li, Yuanxian/LDG-1023-2024; He, Qiyuan/J-1505-2014; Zhang, Xiaofeng/AHH-7408-2022						Retinexmamba: Retinex-based Mamba for Low-light Image Enhancement								Arxiv											2	2;2024-05-20;https://www.arxiv.org/abs/2405.03349v2| 1;2024-05-06;https://www.arxiv.org/abs/2405.03349v1	arXiv:2405.03349			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 20 2024	2024	In the field of low-light image enhancement, both traditional Retinex methods and advanced deep learning techniques such as Retinexformer have shown distinct advantages and limitations. Traditional Retinex methods, designed to mimic the human eye’s perception of brightness and color, decompose images into illumination and reflection components but struggle with noise management and detail preservation under low light conditions. Retinexformer enhances illumination estimation through traditional self-attention mechanisms, but faces challenges with insufficient interpretability and suboptimal enhancement effects. To overcome these limitations, this paper introduces the RetinexMamba architecture. RetinexMamba not only captures the physical intuitiveness of traditional Retinex methods but also integrates the deep learning framework of Retinexformer, leveraging the computational efficiency of State Space Models (SSMs) to enhance processing speed. This architecture features innovative illumination estimators and damage restorer mechanisms that maintain image quality during enhancement. Moreover, RetinexMamba replaces the IG-MSA (Illumination-Guided Multi-Head Attention) in Retinexformer with a Fused-Attention mechanism, improving the model’s interpretability. Experimental evaluations on the LOL dataset show that RetinexMamba outperforms existing deep learning approaches based on Retinex theory in both quantitative and qualitative metrics, confirming its effectiveness and superiority in enhancing low-light images.Code is available at https://github.com/YhuoyuH/RetinexMamba																																	2024-06-15	PPRN:88791339		
J	Athron, Peter; Fowlie, Andrew; Lu, Chih-Ting; Morris, Lachlan; Wu, Lei; Wu, Yongcheng; Xu, Zhongxiu				Chih-Ting, Lu/AAZ-6279-2021; Wu, Yik/C-1869-2009; Athron, Peter/AAR-4710-2021						Can supercooled phase transitions explain the gravitational wave background observed by pulsar timing arrays?								Arxiv											2	2;2024-05-16;https://www.arxiv.org/abs/2306.17239v4| 1;2023-08-03;https://www.arxiv.org/abs/2306.17239v3	arXiv:2306.17239			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 16 2024	2024	Several pulsar timing array collaborations recently reported evidence of a stochastic gravitational wave background (SGWB) at nHz frequencies. Whilst the SGWB could originate from the merger of supermassive black holes, it could be a signature of new physics near the 100 MeV scale. Supercooled first-order phase transitions (FOPTs) that end at the 100 MeV scale are intriguing explanations, because they could connect the nHz signal to new physics at the electroweak scale or beyond. Here, however, we provide a clear demonstration that it is not simple to create a nHz signal from a supercooled phase transition, due to two crucial issues that could rule out many proposed supercooled explanations and should be checked. As an example, we use a model based on non-linearly realized electroweak symmetry that has been cited as evidence for a supercooled explanation. First, we show that a FOPT cannot complete for the required transition temperature of around 100 MeV. Such supercooling implies a period of vacuum domination that hinders bubble percolation and transition completion. Second, we show that even if completion is not required or if this constraint is evaded, the Universe typically reheats to the scale of any physics driving the FOPT. The hierarchy between the transition and reheating temperature makes it challenging to compute the spectrum of the SGWB.																																	2024-06-01	PPRN:74243073		
J	Yi, Xin; Zheng, Shunfan; Wang, Linlin; Wang, Xiaoling; He, Liang				He, Liang/CAF-0477-2022						A safety realignment framework via subspace-oriented model fusion for large language models								Arxiv											1	1;2024-05-15;https://www.arxiv.org/abs/2405.09055v1	arXiv:2405.09055			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 15 2024	2024	The current safeguard mechanisms for large language models (LLMs) are indeed susceptible to jailbreak attacks, making them inherently fragile. Even the process of fine-tuning on apparently benign data for downstream tasks can jeopardize safety. One potential solution is to conduct safety fine-tuning subsequent to downstream fine-tuning. However, there’s a risk of catastrophic forgetting during safety fine-tuning, where LLMs may regain safety measures but lose the task -specific knowledge acquired during downstream fine-tuning. In this paper, we introduce a safety realignment framework through subspace -oriented model fusion (SOMF), aiming to combine the safeguard capabilities of initially aligned model and the current fine-tuned model into a realigned model. Our approach begins by disentangling all task vectors from the weights of each fine-tuned model. We then identify safetyrelated regions within these vectors by subspace masking techniques. Finally, we explore the fusion of the initial safely aligned LLM with all task vectors based on the identified safety subspace. We validate that our safety realignment framework satisfies the safety requirements of a single fine-tuned model as well as multiple models during their fusion. Our findings confirm that SOMF preserves safety without notably compromising performance on downstream tasks, including instruction following in Chinese, English, and Hindi, as well as problem -solving capabilities in Code and Math.																																	2024-06-11	PPRN:89072815		
J	Zhang, Hengrui; Zhang, Jiani; Srinivasan, Balasubramaniam; Shen, Zhengyuan; Qin, Xiao; Faloutsos, Christos; Rangwala, Huzefa; Karypis, George				Qin, Xiao/AAS-8645-2021; Shen, Zhengyuan/OUI-4612-2025						Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space								Arxiv											3	3;2024-05-11;https://www.arxiv.org/abs/2310.09656v3| 2;2024-02-12;https://www.arxiv.org/abs/2310.09656v2| 1;2023-10-14;https://www.arxiv.org/abs/2310.09656v1	arXiv:2310.09656			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	May 11 2024	2024	Recent advances in tabular data generation have greatly enhanced synthetic data quality. However, extending diffusion models to tabular data is challenging due to the intricately varied distributions and a blend of data types of tabular data. This paper introduces Tabsyn, a methodology that synthesizes tabular data by leveraging a diffusion model within a variational autoencoder (VAE) crafted latent space. The key advantages of the proposed Tabsyn include (1) Generality: the ability to handle a broad spectrum of data types by converting them into a single unified space and explicitly capture inter-column relations; (2) Quality: optimizing the distribution of latent embeddings to enhance the subsequent training of diffusion models, which helps generate high-quality synthetic data, (3) Speed: much fewer number of reverse steps and faster synthesis speed than existing diffusion-based methods. Extensive experiments on six datasets with five metrics demonstrate that Tabsyn outperforms existing methods. Specifically, it reduces the error rates by 86% and 67% for column-wise distribution and pair-wise column correlation estimations compared with the most competitive baselines.																																	2024-05-29	PPRN:85660411		
J	Kravtsov, Andrey; Belokurov, Vasily				Belokurov, Vasily/HLG-3187-2023						Stochastic star formation and the abundance of z>10&nbsp;UV-bright galaxies								Arxiv											1	1;2024-05-07;https://www.arxiv.org/abs/2405.04578v1	arXiv:2405.04578			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 07 2024	2024	We use a well-motivated galaxy formation framework to predict stellar masses, star formation rates (SFR), and ultraviolet (UV) luminosities of galaxy populations at redshifts z∈5−16, taking into account stochasticity of SFR in a controlled manner. We demonstrate that the model can match observational estimates of UV luminosity functions (LFs) at 5<z<10 with a modest level of SFR stochasticity, resulting in the scatter of absolute UV luminosity at a given halo mass of σMUV≈0.75. To match the observed UV LFs at z≈11−13 and z≈16 the SFR stochasticity should increase so that σMUV≈1−1.3 and ≈2, respectively. Model galaxies at z≈11−13 have stellar masses and SFRs in good agreement with existing measurements. The median fraction of the baryon budget that was converted into stars, f⋆, is only f⋆≈0.005−0.05, but a small fraction of galaxies at z=16 have f⋆>1 indicating that SFR stochasticity cannot be higher. We discuss several testable consequences of the increased SFR stochasticity at z>10. The increase of SFR stochasticity with increasing z, for example, prevents steepening of UV LF and even results in some flattening of UV LF at z≳13. The median stellar ages of model galaxies at z≈11−16 are predicted to decrease from ≈20−30 Myr for MUV≳−21 galaxies to ≈5−10 Myr for brighter ones. Likewise, the scatter in median stellar age is predicted to decrease with increasing luminosity. The scatter in the ratio of star formation rates averaged over 10 and 100 Myr should increase with redshift. Fluctuations of ionizing flux should increase at z>10 resulting in the increasing scatter in the line fluxes and their ratios for the lines sensitive to ionization parameter.																																	2024-06-04	PPRN:88980360		
J	Amatriain, Xavier										Prompt Design and Engineering: Introduction and Advanced Methods								Arxiv											4	4;2024-05-05;https://www.arxiv.org/abs/2401.14423v4| 3;2024-02-08;https://www.arxiv.org/abs/2401.14423v3| 2;2024-01-30;https://www.arxiv.org/abs/2401.14423v2| 1;2024-01-24;https://www.arxiv.org/abs/2401.14423v1	arXiv:2401.14423			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 05 2024	2024	Prompt design and engineering has rapidly become essential for maximizing the potential of large language models. In this paper, we introduce core concepts, advanced techniques like Chain-of-Thought and Reflection, and the principles behind building LLM-based agents. Finally, we provide a survey of tools for prompt engineers.																																	2024-05-28	PPRN:87371395		
J	Gouttenoire, Yann; Trifinopoulos, Sokratis; Valogiannis, Georgios; Vanvlasselaer, Miguel				Valogiannis, Georgios/GZH-1412-2022						Scrutinizing the Primordial Black Holes Interpretation of PTA Gravitational Waves and JWST Early Galaxies								Arxiv											2	2;2024-05-02;https://www.arxiv.org/abs/2307.01457v2| 1;2023-07-04;https://www.arxiv.org/abs/2307.01457v1	arXiv:2307.01457			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 02 2024	2024	Recent observations have granted to us two unique insights into the early universe: the presence of a low -frequency stochastic gravitational wave background detected by the NANOGrav and Pulsar Timing Array (PTA) experiments and the emergence of unusually massive galaxy candidates at high redshifts reported by the James Webb Space Telescope (JWST). In this letter, we consider the possibility that both observations have a common origin, namely primordial black holes (PBHs) in the mass range between 106M⊙ and 1013 M⊙ . While superheavy PBHs act as seeds for accelerated galaxy formation capable of explaining the JWST extreme galaxies, they can also form binary mergers that source gravitational waves which can be potentially identified as the PTA signal. The analysis is performed taking into account the constraints on the relevant region of the PBH parameter space including the novel bound imposed by the Ultraviolet Luminosity Function of galaxies observed by the Hubble Space Telescope. We conclude that PTA’s and JWST’s interpretations in terms of PBH binary mergers and Poissonian gas of PBHs, respectively, are strongly excluded.																																	2024-05-19	PPRN:73789070		
J	Shan, Shawn; Ding, Wenxin; Passananti, Josephine; Wu, Stanley; Zheng, Haitao; Zhao, Ben Y.				Zheng, Haitao/NSU-4933-2025						Nightshade: Prompt-Specific Poisoning Attacks on Text-to-Image Generative Models								Arxiv											3	3;2024-04-29;https://www.arxiv.org/abs/2310.13828v3| 2;2024-02-16;https://www.arxiv.org/abs/2310.13828v2| 1;2023-10-20;https://www.arxiv.org/abs/2310.13828v1	arXiv:2310.13828			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 29 2024	2024	Data poisoning attacks manipulate training data to introduce unexpected behaviors into machine learning models at training time. For text-to-image generative models with massive training datasets, current understanding of poisoning attacks suggests that a successful attack would require injecting millions of poison samples into their training pipeline. In this paper, we show that poisoning attacks can be successful on generative models. We observe that training data per concept can be quite limited in these models, making them vulnerable to prompt-specific poisoning attacks, which target a model's ability to respond to individual prompts. We introduce Nightshade, an optimized prompt-specific poisoning attack where poison samples look visually identical to benign images with matching text prompts. Nightshade poison samples are also optimized for potency and can corrupt an Stable Diffusion SDXL prompt in <100 poison samples. Nightshade poison effects "bleed through" to related concepts, and multiple attacks can composed together in a single prompt. Surprisingly, we show that a moderate number of Nightshade attacks can destabilize general features in a text-to-image generative model, effectively disabling its ability to generate meaningful images. Finally, we propose the use of Nightshade and similar tools as a last defense for content creators against web scrapers that ignore opt-out/do-not-crawl directives, and discuss possible implications for model trainers and content creators.																																	2024-05-09	PPRN:85759465		
J	Gim, In; Chen, Guojun; Lee, Seung-seob; Sarda, Nikhil; Khandelwal, Anurag; Zhong, Lin				Chen, Guojun/HRA-4222-2023						Prompt Cache: Modular Attention Reuse for Low-Latency Inference								Arxiv											2	2;2024-04-25;https://www.arxiv.org/abs/2311.04934v2| 1;2023-11-07;https://www.arxiv.org/abs/2311.04934v1	arXiv:2311.04934			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 25 2024	2024	We present Prompt Cache, an approach for accelerating inference for large language models (LLM) by reusing attention states across different LLM prompts. Many input prompts have overlapping text segments, such as system messages, prompt templates, and documents provided for context. Our key insight is that by precomputing and storing the attention states of these frequently occurring text segments on the inference server, we can efficiently reuse them when these segments appear in user prompts. Prompt Cache employs a schema to explicitly define such reusable text segments, called prompt modules. The schema ensures positional accuracy during attention state reuse and provides users with an interface to access cached states in their prompt. Using a prototype implementation, we evaluate Prompt Cache across several LLMs. We show that Prompt Cache significantly reduce latency in time-to-first-token, especially for longer prompts such as document-based question answering and recommendations. The improvements range from 8× for GPU-based inference to 60× for CPU-based inference, all while maintaining output accuracy and without the need for model parameter modifications.																																	2024-05-04	PPRN:86114360		
J	Hu, Senkang; Fang, Zhengru; Fang, Zihan; Deng, Yiqin; Chen, Xianhao; Fang, Yuguang				Fang, Zhengru/AAQ-3239-2021; Hu, Senkang/KYP-8998-2024; Deng, Yiqin/CAG-8820-2022; Fang, Yuguang/JJF-2146-2023; CHEN, XIANHAO/AAX-6311-2021						AgentsCoDriver: Large Language Model Empowered Collaborative Driving with Lifelong Learning								Arxiv											2	2;2024-04-21;https://www.arxiv.org/abs/2404.06345v2| 1;2024-04-09;https://www.arxiv.org/abs/2404.06345v1	arXiv:2404.06345			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 21 2024	2024	Connected and autonomous driving is developing rapidly in recent years. However, current autonomous driving systems, which are primarily based on data-driven approaches, exhibit deficiencies in interpretability, generalization, and continuing learning capabilities. In addition, the single-vehicle autonomous driving systems lack of the ability of collaboration and negotiation with other vehicles, which is crucial for the safety and efficiency of autonomous driving systems. In order to address these issues, we leverage large language models (LLMs) to develop a novel framework, AgentsCoDriver, to enable multiple vehicles to conduct collaborative driving. AgentsCoDriver consists of five modules: observation module, reasoning engine, cognitive memory module, reinforcement reflection module, and communication module. It can accumulate knowledge, lessons, and experiences over time by continuously interacting with the environment, thereby making itself capable of lifelong learning. In addition, by leveraging the communication module, different agents can exchange information and realize negotiation and collaboration in complex traffic environments. Extensive experiments are conducted and show the superiority of AgentsCoDriver.																																	2024-05-01	PPRN:88469110		
J	Kotha, Suhas; Springer, Jacob Mitchell; Raghunathan, Aditi										Understanding Catastrophic Forgetting in Language Models via Implicit Inference								Arxiv											2	2;2024-04-14;https://www.arxiv.org/abs/2309.10105v2| 1;2023-09-18;https://www.arxiv.org/abs/2309.10105v1	arXiv:2309.10105			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 14 2024	2024	We lack a systematic understanding of the effects of fine-tuning (via methods such as instruction-tuning or reinforcement learning from human feedback), particularly on tasks outside the narrow fine-tuning distribution. In a simplified scenario, we demonstrate that improving performance on tasks within the fine-tuning data distribution comes at the expense of capabilities on other tasks. We hypothesize that language models implicitly infer the task of the prompt and that fine-tuning skews this inference towards tasks in the fine-tuning distribution. To test this, we propose Conjugate Prompting, which artificially makes the task look farther from the fine-tuning distribution while requiring the same capability, and we find that this recovers some of the pretraining capabilities in our synthetic setup. Since real-world fine-tuning distributions are predominantly English, we apply conjugate prompting to recover pretrained capabilities in LLMs by simply translating the prompts to different languages. This allows us to recover in-context learning abilities lost via instruction tuning, natural reasoning capability lost during code fine-tuning, and, more concerningly, harmful content generation suppressed by safety fine-tuning in chatbots like ChatGPT.																																	2024-04-25	PPRN:85051409		
J	Zheng, Wenzhao; Song, Ruiqi; Guo, Xianda; Zhang, Chenming; Chen, Long				Guo, xianda/NJS-7584-2025; Zhang, Chenming/AAH-2363-2020						GenAD: Generative End-to-End Autonomous Driving								Arxiv											2	2;2024-04-07;https://www.arxiv.org/abs/2402.11502v3| 1;2024-02-20;https://www.arxiv.org/abs/2402.11502v2	arXiv:2402.11502			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 07 2024	2024	Directly producing planning results from raw sensors has been a long-desired solution for autonomous driving and has attracted increasing attention recently. Most existing end-to-end autonomous driving methods factorize this problem into perception, motion prediction, and planning. However, we argue that the conventional progressive pipeline still cannot comprehensively model the entire traffic evolution process, e.g., the future interaction between the ego car and other traffic participants and the structural trajectory prior. In this paper, we explore a new paradigm for end-to-end autonomous driving, where the key is to predict how the ego car and the surroundings evolve given past scenes. We propose GenAD, a generative framework that casts autonomous driving into a generative modeling problem. We propose an instance-centric scene tokenizer that first transforms the surrounding scenes into map-aware instance tokens. We then employ a variational autoencoder to learn the future trajectory distribution in a structural latent space for trajectory prior modeling. We further adopt a temporal model to capture the agent and ego movements in the latent space to generate more effective future trajectories. GenAD finally simultaneously performs motion prediction and planning by sampling distributions in the learned structural latent space conditioned on the instance tokens and using the learned temporal model to generate futures. Extensive experiments on the widely used nuScenes benchmark show that the proposed GenAD achieves state-of-the-art performance on vision-centric end-to-end autonomous driving with high efficiency. 																																	2024-04-21	PPRN:87779058		
J	Ke, Bingxin; Obukhov, Anton; Huang, Shengyu; Metzger, Nando; Rodrigo Caye, Daudt; Schindler, Konrad				Huang, Shengyu/IUM-4031-2023; Ke, Bingxin/JZQ-3911-2024						Repurposing Diffusion-Based Image Generators for Monocular Depth Estimation								Arxiv											2	2;2024-04-03;https://www.arxiv.org/abs/2312.02145v2| 1;2023-12-04;https://www.arxiv.org/abs/2312.02145v1	arXiv:2312.02145			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 03 2024	2024	Monocular depth estimation is a fundamental computer vision task. Recovering 3D depth from a single image is geometrically ill-posed and requires scene understanding, so it is not surprising that the rise of deep learning has led to a breakthrough. The impressive progress of monocular depth estimators has mirrored the growth in model capacity, from relatively modest CNNs to large Transformer architectures. Still, monocular depth estimators tend to struggle when presented with images with unfamiliar content and layout, since their knowledge of the visual world is restricted by the data seen during training, and challenged by zero-shot generalization to new domains. This motivates us to explore whether the extensive priors captured in recent generative diffusion models can enable better, more generalizable depth estimation. We introduce Marigold, a method for affine-invariant monocular depth estimation that is derived from Stable Diffusion and retains its rich prior knowledge. The estimator can be fine-tuned in a couple of days on a single GPU using only synthetic training data. It delivers state-of-the-art performance across a wide range of datasets, including over 20% performance gains in specific cases. 																																	2024-04-18	PPRN:86378359		
J	Merullo, Jack; Eickhoff, Carsten; Pavlick, Ellie				Eickhoff, Carsten/HCI-3263-2022						Language Models Implement Simple Word2Vec-style Vector Arithmetic								Arxiv											3	3;2024-04-03;https://www.arxiv.org/abs/2305.16130v3| 2;2023-10-12;https://www.arxiv.org/abs/2305.16130v2| 1;2023-05-25;https://www.arxiv.org/abs/2305.16130v1	arXiv:2305.16130			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 03 2024	2024	A primary criticism towards language models (LMs) is their inscrutability. This paper presents evidence that, despite their size and complexity, LMs sometimes exploit a simple vector arithmetic style mechanism to solve some relational tasks using regularities encoded in the hidden space of the model (e.g., Poland:Warsaw::China:Beijing). We investigate a range of language model sizes (from 124M parameters to 176B parameters) in an in -context learning setting, and find that for a variety of tasks (involving capital cities, uppercasing, and past -tensing) a key part of the mechanism reduces to a simple additive update typically applied by the feedforward (FFN) networks. We further show that this mechanism is specific to tasks that require retrieval from pretraining memory, rather than retrieval from local context. Our results contribute to a growing body of work on the interpretability of LMs, and offer reason to be optimistic that, despite the massive and non-linear nature of the models, the strategies they ultimately use to solve tasks can sometimes reduce to familiar and even intuitive algorithms.1																																	2024-04-18	PPRN:72714102		
J	Cha, Junbum; Kang, Wooyoung; Mun, Jonghwan; Roh, Byungseok										Honeybee: Locality-enhanced Projector for Multimodal LLM								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2312.06742v2| 1;2023-12-11;https://www.arxiv.org/abs/2312.06742v1	arXiv:2312.06742			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 01 2024	2024	In Multimodal Large Language Models (MLLMs), a visual projector plays a crucial role in bridging pre-trained vision encoders with LLMs, enabling profound visual understanding while harnessing the LLMs' robust capabilities. Despite the importance of the visual projector, it has been relatively less explored. In this study, we first identify two essential projector properties: (i) flexibility in managing the number of visual tokens, crucial for MLLMs' overall efficiency, and (ii) preservation of local context from visual features, vital for spatial understanding. Based on these findings, we propose a novel projector design that is both flexible and locality-enhanced, effectively satisfying the two desirable properties. Additionally, we present comprehensive strategies to effectively utilize multiple and multifaceted instruction datasets. Through extensive experiments, we examine the impact of individual design choices. Finally, our proposed MLLM, Honeybee, remarkably outperforms previous state-of-the-art methods across various benchmarks, including MME, MMBench, SEED-Bench, and LLaVA-Bench, achieving significantly higher efficiency. 																																	2024-04-17	PPRN:86555575		
J	Mirza, Adrian; Alampara, Nawaf; Kunchapu, Sreekanth; Emoekabu, Benedict; Krishnan, Aswanth; Gupta, Tanya; Wilhelmi, Mara; Okereke, Macjonathan; Asgari, Mehrdad; Eberhardt, Juliane; Elahi, Amir Mohammad; Glaubitz, Christina; Greiner, Maximilian; Holick, Caroline T.; Hoffmann, Tim; Klepsch, Lea C.; Koester, Yannik; Kreth, Fabian Alexander; Meyer, Jakob; Miret, Santiago; Peschel, Jan Matthias; Ringleb, Michael; Roesner, Nicole; Schreiber, Johanna; Schubert, Ulrich S.; Stafast, Leanne M.; Wonanke, Dinga; Pieler, Michael; Schwaller, Philippe; Jablonka, Kevin Maik				Okereke, Macjonathan/MEO-9767-2025; Gupta, Tanya/LDG-1869-2024; Wonanke, Dinga/AAY-7005-2021; Jablonka, Kevin Maik/AAP-9474-2020						Are large language models superhuman chemists?								Arxiv											1	1;2024-04-01;https://www.arxiv.org/abs/2404.01475v1	arXiv:2404.01475			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 01 2024	2024	Large language models (LLMs) have gained widespread interest due to their ability to process human language and perform tasks on which they have not been explicitly trained. This is relevant for the chemical sciences, which face the problem of small and diverse datasets that are frequently in the form of text. LLMs have shown promise in addressing these issues and are increasingly being harnessed to predict chemical properties, optimize reactions, and even design and conduct experiments autonomously. However, we still have only a very limited systematic understanding of the chemical reasoning capabilities of LLMs, which would be required to improve models and mitigate potential harms. Here, we introduce "ChemBench," an automated framework designed to rigorously evaluate the chemical knowledge and reasoning abilities of state-of-the-art LLMs against the expertise of human chemists. We curated more than 7,000 question-answer pairs for a wide array of subfields of the chemical sciences, evaluated leading open and closed-source LLMs, and found that the best models outperformed the best human chemists in our study on average. The models, however, struggle with some chemical reasoning tasks that are easy for human experts and provide overconfident, misleading predictions, such as about chemicals' safety profiles. These findings underscore the dual reality that, although LLMs demonstrate remarkable proficiency in chemical tasks, further research is critical to enhancing their safety and utility in chemical sciences. Our findings also indicate a need for adaptations to chemistry curricula and highlight the importance of continuing to develop evaluation frameworks to improve safe and useful LLMs.																																	2024-04-25	PPRN:88377825		
J	Pham, Chau Minh; Hoyle, Alexander; Sun, Simeng; Resnik, Philip; Iyyer, Mohit										TopicGPT: A Prompt-based Topic Modeling Framework								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2311.01449v2| 1;2023-11-02;https://www.arxiv.org/abs/2311.01449v1	arXiv:2311.01449			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 01 2024	2024	Topic modeling is a well-established technique for exploring text corpora. Conventional topic models (e.g., LDA) represent topics as bags of words that often require “reading the tea leaves” to interpret; additionally, they offer users minimal control over the formatting and specificity of resulting topics. To tackle these issues, we introduce TopicGPT, a prompt-based framework that uses large language models (LLMs) to uncover latent topics in a text collection. TopicGPT produces topics that align better with human categorizations compared to competing methods: it achieves a harmonic mean purity of 0.74 against human-annotated Wikipedia topics compared to 0.64 for the strongest baseline. Its topics are also interpretable, dispensing with ambiguous bags of words in favor of topics with natural language labels and associated free-form descriptions. Moreover, the framework is highly adaptable, allowing users to specify constraints and modify topics without the need for model retraining. By streamlining access to high-quality and interpretable topics, TopicGPT represents a compelling, humancentered approach to topic modeling.1																																	2024-04-18	PPRN:85983092		
J	Zhang, Lunjun; Xiong, Yuwen; Yang, Ze; Casas, Sergio; Hu, Rui; Urtasun, Raquel				Xiong, Yuwen/JFJ-4367-2023						Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion								Arxiv											4	4;2024-04-01;https://www.arxiv.org/abs/2311.01017v4| 3;2024-01-16;https://www.arxiv.org/abs/2311.01017v3| 2;2023-11-24;https://www.arxiv.org/abs/2311.01017v2| 1;2023-11-02;https://www.arxiv.org/abs/2311.01017v1	arXiv:2311.01017			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 01 2024	2024	Learning world models can teach an agent how the world works in an unsupervised manner. Even though it can be viewed as a special case of sequence modeling, progress for scaling world models on robotic applications such as autonomous driving has been somewhat less rapid than scaling language models with Generative Pre-trained Transformers (GPT). We identify two reasons as major bottlenecks: dealing with complex and unstructured observation space, and having a scalable generative model. Consequently, we propose Copilot4D, a novel world modeling approach that first tokenizes sensor observations with VQVAE, then predicts the future via discrete diffusion. To efficiently decode and denoise tokens in parallel, we recast Masked Generative Image Transformer as discrete diffusion and enhance it with a few simple changes, resulting in notable improvement. When applied to learning world models on point cloud observations, Copilot4D reduces prior SOTA Chamfer distance by more than 65% for 1s prediction, and more than 50% for 3s prediction, across NuScenes, KITTI Odometry, and Argoverse2 datasets. Our results demonstrate that discrete diffusion on tokenized agent experience can unlock the power of GPT-like unsupervised learning for robotics. [GRAPHICS]																																	2024-04-18	PPRN:85985213		
J	Li, Xiangyu; Yin, Xiaolong; Wiebe, Nathan; Chun, Jaehun; Schenter, Gregory K.; Cheung, Margaret S.; Muelmenstaedt, Johannes										Potential quantum advantage for simulation of fluid dynamics								Arxiv											2	2;2024-03-29;https://www.arxiv.org/abs/2303.16550v3| 1;2023-03-29;https://www.arxiv.org/abs/2303.16550v2	arXiv:2303.16550			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 29 2024	2024	Numerical simulation of turbulent fluid dynamics needs to either parameterize turbulence-which introduces large uncertainties-or explicitly resolve the smallest scales-which is prohibitively expensive. Here we provide evidence through analytic bounds and numerical studies that a potential quantum exponential speedup can be achieved to simulate the Navier-Stokes equations governing turbulence using quantum computing. Specifically, we provide a formulation of the lattice Boltzmann equation for which we give evidence that low-order Carleman linearization is much more accurate than previously believed for these systems and that for computationally interesting examples. This is achieved via a combination of reformulating the nonlinearity and accurately linearizing the dynamical equations, effectively trading nonlinearity for additional degrees of freedom that add negligible expense in the quantum solver. Based on this we apply a quantum algorithm for simulating the Carleman-linearized lattice Boltzmann equation and provide evidence that its cost scales logarithmically with system size, compared to polynomial scaling in the best known classical algorithms. This work suggests that an exponential quantum advantage may exist for simulating fluid dynamics, paving the way for simulating nonlinear multiscale transport phenomena in a wide range of disciplines using quantum computing.																																	2024-04-17	PPRN:56436916		
J	Yang, Zhiyu; Zhou, Zihan; Wang, Shuo; Cong, Xin; Han, Xu; Yan, Yukun; Liu, Zhenghao; Tan, Zhixing; Liu, Pengyuan; Yu, Dong; Liu, Zhiyuan; Shi, Xiaodong; Sun, Maosong				Yan, Yukun/KCY-0789-2024; LIU, ZHENGHAO/GRY-2799-2022; Liu, Zhiyuan/I-2233-2014; Yang, Zhiyu/JDC-8742-2023						MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization								Arxiv											2	2;2024-03-19;https://www.arxiv.org/abs/2402.11453v3| 1;2024-02-18;https://www.arxiv.org/abs/2402.11453v1	arXiv:2402.11453			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 19 2024	2024	Scientific data visualization plays a crucial role in research by enabling the direct display of complex information and assisting researchers in identifying implicit patterns. Despite its importance, the use of Large Language Models (LLMs) for scientific data visualization remains rather unexplored. In this study, we introduce MatPlotAgent, an efficient model-agnostic LLM agent framework designed to automate scientific data visualization tasks. Leveraging the capabilities of both code LLMs and multi-modal LLMs, MatPlotAgent consists of three core modules: query understanding, code generation with iterative debugging, and a visual feedback mechanism for error correction. To address the lack of benchmarks in this field, we present MatPlotBench, a high-quality benchmark consisting of 100 human-verified test cases. Additionally, we introduce a scoring approach that utilizes GPT-4V for automatic evaluation. Experimental results demonstrate that MatPlotAgent can improve the performance of various LLMs, including both commercial and open-source models. Furthermore, the proposed evaluation method shows a strong correlation with human-annotated scores.																																	2024-04-12	PPRN:87763239		
J	He, Jiaao; Zhai, Jidong				He, Jiaao/MCJ-9555-2025						FastDecode: High-Throughput GPU-Efficient LLM Serving using Heterogeneous Pipelines								Arxiv											1	1;2024-03-18;https://www.arxiv.org/abs/2403.11421v1	arXiv:2403.11421			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Mar 18 2024	2024	Cost of serving large language models (LLM) is high, but the expensive and scarce GPUs are poorly efficient when generating tokens sequentially, unless the batch of sequences is enlarged. However, the batch size is limited by some constantly reused intermediate results, namely KV-Cache. They occupy too much memory to fit more sequences into a GPU simultaneously. While they could be offloaded to host memory, the CPU-GPU bandwidth is an inevitable bottleneck. We find a way to decompose the transformer models into two parts of different characteristics, one of which includes the memory-bound KV-Cache accessing. Our key insight is that the aggregated memory capacity, bandwidth, and computing power of CPUs across multiple nodes is an efficient option to process this part. Performance improvement comes from reduced data transmission overhead and boosted GPU throughput to process the other model part. Moreover, we address efficiency challenges brought by heterogeneity at both temporal and inter-device scopes using scheduling and performance modeling techniques. Evaluation results show that our system achieves 1.88x - 5.04x the throughput of vLLM when serving modern LLMs with the same GPU.																																	2024-04-11	PPRN:88195885		
J	Colgain, E O; Sheikh-Jabbari, M.M.; Solomon, R; Dainotti, M G; Stojkovic, D				Dainotti, Maria/AAD-3896-2022; Sheikh-Jabbari, Mohammad/AAM-7848-2020						Putting Flat ΛCDM In The (Redshift) Bin								Arxiv											2	2;2024-03-16;https://www.arxiv.org/abs/2206.11447v3| 1;2022-06-23;https://www.arxiv.org/abs/2206.11447v1	arXiv:2206.11447			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 16 2024	2024	Flat ΛCDM cosmology is specified by two constant fitting parameters at the background level in the late Universe, the Hubble constant H0 and matter density (today) Ωm. Mathematically, H0 and Ωm are either integration constants arising from solving ordinary differential equations or are directly related to integration constants. Seen in this context, if fits of the ΛCDM model to cosmological probes at different redshifts lead to different (H0, Ωm) parameters, this is a mismatch between mathematics and observation. Here, in mock observational Hubble data (OHD) (geometric probes of expansion history) we demonstrate evolution in distributions of best fit parameters with effective redshift. As a result, considerably different (H0, Ωm) best fits from Planck-ΛCDM cannot be precluded in high redshift bins. We explore if OHD, Type Ia supernovae and standardisable quasar samples exhibit redshift evolution of best fit ΛCDM parameters. In all samples, we confirm a decreasing H0 and increasing Ωm trend with increasing bin redshift. Through comparison with mocks, we confirm that similar behaviour can arise randomly within the flat ΛCDM model with probabilities as low as p = 0.0021 (3.1 σ). We present complementary profile distribution analysis confirming the shifts in cosmological parameters in high redshift bins. In particular, we identify a redshift range where Planck (H0, Ωm) values are disfavoured at 99.6% (2.9σ) confidence level in a combination of OHD and supernovae data.																																	2024-04-11	PPRN:12186137		
J	Kollias, Dimitrios; Tzirakis, Panagiotis; Cowen, Alan; Zafeiriou, Stefanos; Kotsia, Irene; Baird, Alice; Gagne, Chris; Shao, Chunchang; Hu, Guanyu				Hu, Guanyu/KHX-2301-2024; Baird, Alice/AAA-5559-2021; KOLLIAS, DIMITRIOS/AAX-3397-2020; Cowen, Alan/S-3367-2019						The 6th Affective Behavior Analysis in-the-wild (ABAW) Competition								Arxiv											2	2;2024-03-12;https://www.arxiv.org/abs/2402.19344v3| 1;2024-02-29;https://www.arxiv.org/abs/2402.19344v1	arXiv:2402.19344			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 12 2024	2024	This paper describes the 6th Affective Behavior Analysis in -the -wild (ABAW) Competition, which is part of the respective Workshop held in conjunction with IEEE CVPR 2024. The 6th ABAW Competition addresses contemporary challenges in understanding human emotions and behaviors, crucial for the development of human -centered technologies. In more detail, the Competition focuses on affect related benchmarking tasks and comprises of five subchallenges: i) Valence -Arousal Estimation (the target is to estimate two continuous affect dimensions, valence and arousal), ii) Expression Recognition (the target is to recognise between the mutually exclusive classes of the 7 basic expressions and ’other’), iii) Action Unit Detection (the target is to detect 12 action units), iv) Compound Expression Recognition (the target is to recognise between the 7 mutually exclusive compound expression classes), and v) Emotional Mimicry Intensity Estimation (the target is to estimate six continuous emotion dimensions). In the paper, we present these Challenges, describe their respective datasets and challenge protocols (we outline the evaluation metrics) and present the baseline systems as well as their obtained performance. 																																	2024-04-08	PPRN:87988251		
J	Li, Kunchang; Wang, Yali; Li, Yizhuo; Wang, Yi; He, Yinan; Wang, Limin; Qiao, Yu				Li, Yizhuo/AAL-5705-2021; Li, Kunchang/KFA-4043-2024; Wang, Limin/AAE-3419-2019; Qiao, Yu/ABD-5787-2021						Unmasked Teacher: Towards Training-Efficient Video Foundation Models								Arxiv											2	2;2024-03-11;https://www.arxiv.org/abs/2303.16058v2| 1;2023-03-28;https://www.arxiv.org/abs/2303.16058v1	arXiv:2303.16058			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 11 2024	2024	Video Foundation Models (VFMs) have received limited exploration due to high computational costs and data scarcity. Previous VFMs rely on Image Foundation Models (IFMs), which face challenges in transferring to the video domain. Although VideoMAE has trained a robust ViT from limited data, its low-level reconstruction poses convergence difficulties and conflicts with high-level cross-modal alignment. This paper proposes a training-efficient method for temporal-sensitive VFMs that integrates the benefits of existing methods. To increase data efficiency, we mask out most of the low-semantics video tokens, but selectively align the unmasked tokens with IFM, which serves as the UnMasked Teacher (UMT). By providing semantic guidance, our method enables faster convergence and multimodal friendliness. With a progressive pre-training framework, our model can handle various tasks including scene-related, temporal-related, and complex video-language understanding. Using only public sources for pre-training in 6 days on 32 A100 GPUs, our scratch-built ViT-L/16 achieves state-of-the-art performances on various video tasks. The code and models will be released at https://github.com/OpenGVLab/unmasked_teacher.																																	2024-04-08	PPRN:50127014		
J	Raman, Shreyas Sundara; Cohen, Vanya; Idrees, Ifrah; Rosen, Eric; Mooney, Ray; Tellex, Stefanie; Paulius, David				Idrees, Ifrah/LDG-3302-2024						CAPE: Corrective Actions from Precondition Errors using Large Language Models								Arxiv											1	1;2024-03-09;https://www.arxiv.org/abs/2211.09935v3	arXiv:2211.09935			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 09 2024	2024	Extracting commonsense knowledge from a large language model (LLM) offers a path to designing intelligent robots. Existing approaches that leverage LLMs for planning are unable to recover when an action fails and often resort to retrying failed actions, without resolving the error's underlying cause. We propose a novel approach (CAPE) that attempts to propose corrective actions to resolve precondition errors during planning. CAPE improves the quality of generated plans by leveraging few-shot reasoning from action preconditions. Our approach enables embodied agents to execute more tasks than baseline methods while ensuring semantic correctness and minimizing re-prompting. In VirtualHome, CAPE generates executable plans while improving a human-annotated plan correctness metric from 28.89% to 49.63% over SayCan. Our improvements transfer to a Boston Dynamics Spot robot initialized with a set of skills (specified in language) and associated preconditions, where CAPE improves the correctness metric of the executed task plans by 76.49% compared to SayCan. Our approach enables the robot to follow natural language commands and robustly recover from failures, which baseline approaches largely cannot resolve or address inefficiently.																																	2024-05-18	PPRN:88709805		
J	Liang, Siyuan; Zhu, Mingli; Liu, Aishan; Wu, Baoyuan; Cao, Xiaochun; Chang, Ee-Chien				Liang, Siyuan/KHW-1891-2024; Wu, Baoyuan/C-8429-2013						BadCLIP: Dual-Embedding Guided Backdoor Attack on Multimodal Contrastive Learning								Arxiv											2	2;2024-03-04;https://www.arxiv.org/abs/2311.12075v3| 1;2023-11-20;https://www.arxiv.org/abs/2311.12075v1	arXiv:2311.12075			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 04 2024	2024	Studying backdoor attacks is valuable for model copyright protection and enhancing defenses. While existing backdoor attacks have successfully infected multimodal contrastive learning models such as CLIP, they can be easily countered by specialized backdoor defenses for MCL models. This paper reveals the threats in this practical scenario that backdoor attacks can remain effective even after defenses and introduces the emph{toolns} attack, which is resistant to backdoor detection and model fine-tuning defenses. To achieve this, we draw motivations from the perspective of the Bayesian rule and propose a dual-embedding guided framework for backdoor attacks. Specifically, we ensure that visual trigger patterns approximate the textual target semantics in the embedding space, making it challenging to detect the subtle parameter variations induced by backdoor learning on such natural trigger patterns. Additionally, we optimize the visual trigger patterns to align the poisoned samples with target vision features in order to hinder the backdoor unlearning through clean fine-tuning. Extensive experiments demonstrate that our attack significantly outperforms state-of-the-art baselines (+45.3% ASR) in the presence of SoTA backdoor defenses, rendering these mitigation and detection strategies virtually ineffective. Furthermore, our approach effectively attacks some more rigorous scenarios like downstream tasks. We believe that this paper raises awareness regarding the potential threats associated with the practical application of multimodal contrastive learning and encourages the development of more robust defense mechanisms.																																	2024-03-30	PPRN:86218726		
J	Alper, Jarod; Halpern-Leistner, Daniel; Heinloth, Jochen										EXISTENCE OF MODULI SPACES FOR ALGEBRAIC STACKS								Arxiv											2	2;2024-02-23;https://www.arxiv.org/abs/1812.01128v5| 1;2022-06-27;https://www.arxiv.org/abs/1812.01128v4	arXiv:1812.01128			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Feb 23 2024	2024	We provide necessary and sufficient conditions for when an algebraic stack admits a good moduli space and prove a semistable reduction theorem for points of algebraic stacks equipped with a Θ-stratification. These results provide a generalization of the Keel–Mori theorem to moduli problems whose objects have positive dimensional automorphism groups and give criteria on the moduli problem to have a separated or proper good moduli space. To illustrate our method, we apply these results to construct proper moduli spaces parameterizing semistable G -bundles on curves and moduli spaces for objects in abelian categories.																																	2024-03-25	PPRN:12351404		
J	Sadasivan, Vinu Sankar; Saha, Shoumik; Sriramanan, Gaurang; Kattakinda, Priyatham; Chegini, Atoosa; Feizi, Soheil										Fast Adversarial Attacks on Language Models In One GPU Minute								Arxiv											1	1;2024-02-23;https://www.arxiv.org/abs/2402.15570v1	arXiv:2402.15570			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 23 2024	2024	In this paper, we introduce a novel class of fast, beam search-based adversarial attack (BEAST) for Language Models (LMs). BEAST employs interpretable parameters, enabling attackers to balance between attack speed, success rate, and the readability of adversarial prompts. The computational efficiency of BEAST facilitates us to investigate its applications on LMs for jailbreaking, eliciting hallucinations, and privacy attacks. Our gradient-free targeted attack can jailbreak aligned LMs with high attack success rates within one minute. For instance, BEAST can jailbreak Vicuna-7B-v1.5 under one minute with a success rate of 89% when compared to a gradient-based baseline that takes over an hour to achieve 70% success rate using a single Nvidia RTX A6000 48GB GPU. Additionally, we discover a unique outcome wherein our untargeted attack induces hallucinations in LM chatbots. Through human evaluations, we find that our untargeted attack causes Vicuna-7B-v1.5 to produce ~15% more incorrect outputs when compared to LM outputs in the absence of our attack. We also learn that 22% of the time, BEAST causes Vicuna to generate outputs that are not relevant to the original prompt. Further, we use BEAST to generate adversarial prompts in a few seconds that can boost the performance of existing membership inference attacks for LMs. We believe that our fast attack, BEAST, has the potential to accelerate research in LM security and privacy. Our codebase is publicly available at https://github.com/vinusankars/BEAST.																																	2024-03-24	PPRN:87883292		
J	Zhang, He; Wu, Bang; Yuan, Xingliang; Pan, Shirui; Tong, Hanghang; Pei, Jian				Zhang, He/JHU-8285-2023; Yuan, Xingliang/Z-4306-2019						Trustworthy Graph Neural Networks: Aspects, Methods and Trends								Arxiv											1	1;2024-02-21;https://www.arxiv.org/abs/2205.07424v2	arXiv:2205.07424			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 21 2024	2024	Graph neural networks (GNNs) have emerged as a series of competent graph learning methods for diverse real -world scenarios, ranging from daily applications like recommendation systems and question answering to cutting-edge technologies such as drug discovery in life sciences and n-body simulation in astrophysics. However, task performance is not the only requirement for GNNs. Performance -oriented GNNs have exhibited potential adverse effects like vulnerability to adversarial attacks, unexplainable discrimination against disadvantaged groups, or excessive resource consumption in edge computing environments. To avoid these unintentional harms, it is necessary to build competent GNNs characterised by trustworthiness. To this end, we propose a comprehensive roadmap to build trustworthy GNNs from the view of the various computing technologies involved. In this survey, we introduce basic concepts and comprehensively summarise existing efforts for trustworthy GNNs from six aspects, including robustness, explainability, privacy, fairness, accountability, and environmental well-being. Additionally, we highlight the intricate cross -aspect relations between the above six aspects of trustworthy GNNs. Finally, we present a thorough overview of trending directions for facilitating the research and industrialisation of trustworthy GNNs.																																	2024-03-30	PPRN:87787768		
J	Bhardwaj, Rishabh; Anh, Do Duc; Poria, Soujanya				PORIA, SOUJANYA/KIJ-4789-2024						Language Models are Homer Simpson! Safety Re-Alignment of Fine-tuned Language Models through Task Arithmetic								Arxiv											1	1;2024-02-19;https://www.arxiv.org/abs/2402.11746v1	arXiv:2402.11746			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Feb 19 2024	2024	Aligned language models face a significant limitation as their fine-tuning often results in compromised safety. To tackle this, we propose a simple method RESTA that performs LLM safety realignment. RESTA stands for REstoring Safety through Task Arithmetic. At its core, it involves a simple arithmetic addition of a safety vector to the weights of the compromised model. We demonstrate the effectiveness of RESTA in both parameter -efficient and full fine-tuning, covering a wide range of downstream tasks, including instruction following in Chinese, English, and Hindi, as well as problem -solving capabilities in Code and Math. We also showcase the generalizability of RESTA on three existing safety evaluation benchmarks and a multilingual benchmark dataset proposed as a part of this work, consisting of 550 harmful questions covering 11 categories, each with 5 sub -categories of harm. Overall, RESTA decreases the harmfulness of the compromised model from 18.6% to 5.1% and from 9.2% to 1.5% in parameter -efficient and full finetuning, respectively, while maintaining most of the model’s performance on the task. We release the source codes at: https://github. com/declare-lab/resta.																																	2024-03-15	PPRN:87755063		
J	Chen, Kai; Xie, Enze; Chen, Zhe; Wang, Yibo; Hong, Lanqing; Li, Zhenguo; Yeung, Dit-Yan				zhang, Shifeng/HPH-0217-2023; Li, Jiaqi/HHN-8236-2022; Lv, Zhengtong/AAW-9611-2020						GeoDiffusion: Text-Prompted Geometric Control for Object Detection Data Generation								Arxiv											5	5;2024-02-17;https://www.arxiv.org/abs/2306.04607v8| 4;2024-02-04;https://www.arxiv.org/abs/2306.04607v7| 3;2023-12-28;https://www.arxiv.org/abs/2306.04607v6| 2;2023-10-17;https://www.arxiv.org/abs/2306.04607v5| 1;2023-06-09;https://www.arxiv.org/abs/2306.04607v2	arXiv:2306.04607			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 17 2024	2024	Diffusion models have attracted significant attention due to the remarkable ability to create content and generate data for tasks like image classification. However, the usage of diffusion models to generate the high -quality object detection data remains an underexplored area, where not only image -level perceptual quality but also geometric conditions such as bounding boxes and camera views are essential. Previous studies have utilized either copy -paste synthesis or layout -to -image (L2I) generation with specifically designed modules to encode the semantic layouts. In this paper, we propose the GEODIFFUSION, a simple framework that can flexibly translate various geometric conditions into text prompts and empower pre -trained text -to -image (T2I) diffusion models for high -quality detection data generation. Unlike previous L2I methods, our GEODIFFUSION is able to encode not only the bounding boxes but also extra geometric conditions such as camera views in selfdriving scenes. Extensive experiments demonstrate GEODIFFUSION outperforms previous L2I methods while maintaining 4× training time faster. To the best of our knowledge, this is the first work to adopt diffusion models for layout -to -image generation with geometric conditions and demonstrate that L2I-generated images can be beneficial for improving the performance of object detectors.																																	2024-03-19	PPRN:73236283		
J	Zhao, Linxi; Deng, Yihe; Zhang, Weitong; Gu, Quanquan				Zhang, Weitong/AHA-3224-2022						Mitigating Object Hallucination in Large Vision-Language Models via Classifier-Free Guidance								Arxiv											1	1;2024-02-13;https://www.arxiv.org/abs/2402.08680v1	arXiv:2402.08680			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 13 2024	2024	The advancement of Large Vision-Language Models (LVLMs) has increasingly highlighted the critical issue of their tendency to hallucinate non-existing objects in the images. To address this issue, previous works focused on using specially curated datasets or powerful LLMs (e.g., GPT-3.5) to rectify the outputs of LVLMs. However, these approaches require either expensive training/fine-tuning or API access to advanced LLMs to correct the model’s output postgeneration. In this paper, we tackle this challenge by introducing a framework called Mitigating hallucinAtion via classifieR-Free guIdaNcE (MARINE), which is both training-free and API-free, and can effectively and efficiently reduce object hallucinations during the generation process. Specifically, MARINE enriches the visual context of LVLMs by integrating existing open-source vision models, and employs classifier-free guidance to incorporate the additional object grounding features to improve the precision of LVLMs’ generations. Through comprehensive evaluations across 6 popular LVLMs with diverse evaluation metrics, we demonstrate the effectiveness of MARINE, which even outperforms existing fine-tuning-based methods. Remarkably, it not only reduces hallucinations but also improves the detailedness of LVLMs’ generations, as assessed by GPT-4V.																																	2024-05-25	PPRN:87674755		
J	DeLorenzo, Matthew; Chowdhury, Animesh Basak; Gohil, Vasudev; Thakur, Shailja; Karri, Ramesh; Garg, Siddharth; Rajendran, Jeyavijayan				Gohil, Vasudev/HPC-4496-2023						Make Every Move Count: LLM-based High-Quality RTL Code Generation Using MCTS								Arxiv											1	1;2024-02-05;https://www.arxiv.org/abs/2402.03289v1	arXiv:2402.03289			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Feb 05 2024	2024	Existing large language models (LLMs) for register transfer level code generation face challenges like compilation failures and suboptimal power, performance, and area (PPA) efficiency. This is due to the lack of PPA awareness in conventional transformer decoding algorithms. In response, we present an automated transformer decoding algorithm that integrates Monte Carlo tree-search for lookahead, guiding the transformer to produce compilable, functionally correct, and PPA-optimized code. Empirical evaluation with a fine-tuned language model on RTL codesets shows that our proposed technique consistently generates functionally correct code compared to prompting-only methods and effectively addresses the PPA-unawareness drawback of naive large language models. For the largest design generated by the state-of-the-art LLM (16-bit adder), our technique can achieve a 31.8% improvement in the area-delay product.																																	2024-05-25	PPRN:87517822		
J	Lee, Jean; Stevens, Nicholas; Han, Soyeon Caren; Song, Minseok				Lee, Jean/KPY-5829-2024						A Survey of Large Language Models in Finance (FinLLMs)								Arxiv											2	2;2024-02-04;https://www.arxiv.org/abs/2402.02315v1| 1;2024-02-04;https://www.arxiv.org/abs/2402.02315v1	arXiv:2402.02315			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 04 2024	2024	Large Language Models (LLMs) have shown remarkable capabilities across a wide variety of Natural Language Processing (NLP) tasks and have attracted attention from multiple domains, including financial services. Despite the extensive research into general-domain LLMs, and their immense potential in finance, Financial LLM (FinLLM) research remains limited. This survey provides a comprehensive overview of FinLLMs, including their history, techniques, performance, and opportunities and challenges. Firstly, we present a chronological overview of general-domain Pre-trained Language Models (PLMs) through to current FinLLMs, including the GPT-series, selected open-source LLMs, and financial LMs. Secondly, we compare five techniques used across financial PLMs and FinLLMs, including training methods, training data, and fine-tuning methods. Thirdly, we summarize the performance evaluations of six benchmark tasks and datasets. In addition, we provide eight advanced financial NLP tasks and datasets for developing more sophisticated FinLLMs. Finally, we discuss the opportunities and the challenges facing FinLLMs, such as hallucination, privacy, and efficiency. To support AI research in finance, we compile a collection of accessible datasets and evaluation benchmarks on GitHub.																																	2025-03-08	PPRN:87523254		
J	Gu, Xianfan; Wen, Chuan; Ye, Weirui; Song, Jiaming; Gao, Yang				Wen, Chuan/LIF-6638-2024; Song, Jiaming/KLC-6750-2024						Seer: Language Instructed Video Prediction with Latent Diffusion Models								Arxiv											2	2;2024-01-29;https://www.arxiv.org/abs/2303.14897v3| 1;2023-03-27;https://www.arxiv.org/abs/2303.14897v1	arXiv:2303.14897			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 29 2024	2024	Imagining the future trajectory is the key for robots to make sound planning and successfully reach their goals. Therefore, text-conditioned video prediction (TVP) is an essential task to facilitate general robot policy learning. To tackle this task and empower robots with the ability to foresee the future, we propose a sample and computation-efficient model, named textbf{Seer}, by inflating the pretrained text-to-image (T2I) stable diffusion models along the temporal axis. We enhance the U-Net and language conditioning model by incorporating computation-efficient spatial-temporal attention. Furthermore, we introduce a novel Frame Sequential Text Decomposer module that dissects a sentence's global instruction into temporally aligned sub-instructions, ensuring precise integration into each frame of generation. Our framework allows us to effectively leverage the extensive prior knowledge embedded in pretrained T2I models across the frames. With the adaptable-designed architecture, Seer makes it possible to generate high-fidelity, coherent, and instruction-aligned video frames by fine-tuning a few layers on a small amount of data. The experimental results on Something Something V2 (SSv2), Bridgedata and EpicKitchens-100 datasets demonstrate our superior video prediction performance with around 480-GPU hours versus CogVideo with over 12,480-GPU hours: achieving the 31% FVD improvement compared to the current SOTA model on SSv2 and 83.7% average preference in the human evaluation.																																	2024-02-15	PPRN:49740407		
J	Huang, Zhicheng; Jin, Xiaojie; Lu, Chengze; Hou, Qibin; Cheng, Ming-Ming; Fu, Dongmei; Shen, Xiaohui; Feng, Jiashi										Contrastive Masked Autoencoders are Stronger Vision Learners								Arxiv											2	2;2024-01-29;https://www.arxiv.org/abs/2207.13532v3| 1;2022-07-27;https://www.arxiv.org/abs/2207.13532v2	arXiv:2207.13532			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 29 2024	2024	Masked image modeling (MIM) has achieved promising results on various vision tasks. However, the limited discriminability of learned representation manifests there is still plenty to go for making a stronger vision learner. Towards this goal, we propose Contrastive Masked Autoencoders (CMAE), a new self -super vised pre-training method for learning more comprehensive and capable vision representations. By elaboratively unifying contrastive learning (CL) and masked image model (MIM) through novel designs, CMAE leverages their respective advantages and learns representations with both strong instance discriminability and local perceptibility. Specifically, CMAE consists of two branches where the online branch is an asymmetric encoder-decoder and the momentum branch is a momentum updated encoder. During training, the online encoder reconstructs original images from latent representations of masked images to learn holistic features. The momentum encoder, fed with the full images, enhances the feature discriminability via contrastive learning with its online counterpart. To make CL compatible with MIM, CMAE introduces two new components, i.e. pixel shifting for generating plausible positive views and feature decoder for complementing features of contrastive pairs. Thanks to these novel designs, CMAE effectively improves the representation quality and transfer performance over its MIM counterpart. CMAE achieves the state-of-the-art performance on highly competitive benchmarks of image classification, semantic segmentation and object detection. Notably, CMAE-Base achieves 85.3% top -1 accuracy on ImageNet and 52.5% mIoU on ADE20k, surpassing previous best results by 0.7% and 1.8% respectively. The source code is publicly accessible at https://github.com/ZhichengHuang/CMAE.																																	2024-05-25	PPRN:23222092		
J	Li, Yucheng; Guerin, Frank; Lin, Chenghua										An Open Source Data Contamination Report for Large Language Models								Arxiv											3	3;2024-01-29;https://www.arxiv.org/abs/2310.17589v3| 2;2023-12-18;https://www.arxiv.org/abs/2310.17589v2| 1;2023-10-26;https://www.arxiv.org/abs/2310.17589v1	arXiv:2310.17589			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 29 2024	2024	Data contamination in model evaluation has become increasingly prevalent with the growing popularity of large language models. It allows models to "cheat" via memorisation instead of displaying true capabilities. Therefore, contamination analysis has become an crucial part of reliable model evaluation to validate results. However, existing contamination analysis is usually conducted internally by large language model developers and often lacks transparency and completeness. This paper presents an extensive data contamination report for over 15 popular large language models across six popular multiple-choice QA benchmarks. We also introduce an open-source pipeline that enables the community to perform contamination analysis on customised data and models. Our experiments reveal varying contamination levels ranging from 1% to 45% across benchmarks, with the contamination degree increasing rapidly over time. Performance analysis of large language models indicates that data contamination does not necessarily lead to increased model metrics: while significant accuracy boosts of up to 14% and 7% are observed on contaminated C-Eval and Hellaswag benchmarks, only a minimal increase is noted on contaminated MMLU. We also find larger models seem able to gain more advantages than smaller models on contaminated test sets.																																	2024-05-25	PPRN:85916025		
J	Tan, Chenmien; Zhang, Ge; Fu, Jie				Zhang, Ge/A-9342-2010						Massive Editing for Large Language Models via Meta Learning								Arxiv											2	2;2024-01-25;https://www.arxiv.org/abs/2311.04661v3| 1;2023-11-09;https://www.arxiv.org/abs/2311.04661v2	arXiv:2311.04661			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 25 2024	2024	While large language models (LLMs) have enabled learning knowledge from the pre-training corpora, the acquired knowledge may be fundamentally incorrect or outdated over time, which necessitates rectifying the knowledge of the language model (LM) after the training. A promising approach involves employing a hyper-network to generate parameter shift, whereas existing hyper-networks suffer from inferior scalability in synchronous editing operation amount. To mitigate the problem, we propose the MAssive Language Model Editing Network (MALMEN), which formulates the parameter shift aggregation as the least square problem, subsequently updating the LM parameters using the normal equation. To accommodate editing multiple facts simultaneously with limited memory budgets, we separate the computation on the hyper-network and LM, enabling arbitrary batch size on both neural networks. Our method is evaluated by editing up to thousands of facts on LMs with different architectures, i.e., BERT-base, GPT-2, T5-XL (2.8B), and GPT-J (6B), across various knowledge-intensive NLP tasks, i.e., closed book fact-checking and question answering. Remarkably, MALMEN is capable of editing hundreds of times more facts than strong baselines with the identical hyper-network architecture and outperforms editor specifically designed for GPT.																																	2024-02-11	PPRN:86108967		
J	Engstrom, Logan; Feldmann, Axel; Madry, Aleksander										DsDm: Model-Aware Dataset Selection with Datamodels								Arxiv											1	1;2024-01-23;https://www.arxiv.org/abs/2401.12926v1	arXiv:2401.12926			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 23 2024	2024	When selecting data for training large-scale models, standard practice is to filter for examples that match human notions of data quality. Such filtering yields qualitatively clean datapoints that intuitively should improve model behavior. However, in practice the opposite can often happen: we find that selecting according to similarity with “high quality” data sources may not increase (and can even hurt) performance compared to randomly selecting data. To develop better methods for selecting data, we start by framing dataset selection as an optimization problem that we can directly solve for: given target tasks, a learning algorithm, and candidate data, select the subset that maximizes model performance. This framework thus avoids handpicked notions of data quality, and instead models explicitly how the learning process uses train datapoints to predict on the target tasks. Our resulting method greatly improves language model (LM) performance on both pre-specified tasks and previously unseen tasks. Specifically, choosing target tasks representative of standard LM problems and evaluating on diverse held-out benchmarks, our selected datasets provide a 2× compute multiplier over baseline methods.																																	2024-05-25	PPRN:87288661		
J	Lu, Keming; Yu, Bowen; Zhou, Chang; Zhou, Jingren				Bowen, Yu/MFH-7462-2025; Zhou, Mingyuan/AAE-8717-2021						Large Language Models are Superpositions of All Characters: Attaining Arbitrary Role-play via Self-Alignment								Arxiv											1	1;2024-01-23;https://www.arxiv.org/abs/2401.12474v1	arXiv:2401.12474			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 23 2024	2024	Considerable efforts have been invested in augmenting the role-playing proficiency of open-source large language models (LLMs) by emulating proprietary counterparts. Nevertheless, we posit that LLMs inherently harbor role-play capabilities, owing to the extensive knowledge of characters and potential dialogues ingrained in their vast training corpora. Thus, in this study, we introduce DITTO, a self-alignment method for role-play. DITTO capitalizes on character knowledge, encouraging an instruction-following LLM to simulate role-play dialogues as a variant of reading comprehension. This method creates a role-play training set comprising 4000 characters, surpassing the scale of currently available datasets by tenfold regarding the number of roles. Subsequently, we fine-tune the LLM using this self-generated dataset to augment its role-playing capabilities. Upon evaluating our meticulously constructed and reproducible role-play benchmark and the roleplay subset of MT-Bench, DITTO in various parameter scales consistently maintains a consistent role identity and provides accurate role-specific knowledge in multi-turn role-play conversations. Notably, it outperforms all open-source role-play baselines, showcasing performance levels comparable to advanced proprietary chatbots. Furthermore, we present the first comprehensive cross-supervision alignment experiment in the role-play domain, revealing that the intrinsic capabilities of LLMs confine the knowledge within role-play. Meanwhile, the role-play styles can be easily acquired with the guidance of smaller models. We open-source related resources in https://github.com/ OFA-Sys/Ditto.																																	2024-05-25	PPRN:87289184		
J	Huang, Jen-tse; Wang, Wenxuan; Li, Eric John; Lam, Man Ho; Ren, Shujie; Yuan, Youliang; Jiao, Wenxiang; Tu, Zhaopeng; Lyu, Michael R.				Huang, Jen-Tse/IRZ-7526-2023; Wang, Wenxuan/AAW-9073-2020; Lam, Man Ho/LRS-9509-2024; Tu, Zhaopeng/AAS-4259-2021						Who is ChatGPT? Benchmarking LLMs' Psychological Portrayal Using PsychoBench								Arxiv											2	2;2024-01-22;https://www.arxiv.org/abs/2310.01386v2| 1;2023-10-02;https://www.arxiv.org/abs/2310.01386v1	arXiv:2310.01386			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 22 2024	2024	Large Language Models (LLMs) have recently showcased their remarkable capacities, not only in natural language processing tasks but also across diverse domains such as clinical medicine, legal consultation, and education. LLMs become more than mere applications, evolving into assistants capable of addressing diverse user requests. This narrows the distinction between human beings and artificial intelligence agents, raising intriguing questions regarding the potential manifestation of personalities, temperaments, and emotions within LLMs. In this paper, we propose a framework, PsychoBench, for evaluating diverse psychological aspects of LLMs. Comprising thirteen scales commonly used in clinical psychology, PsychoBench further classifies these scales into four distinct categories: personality traits, interpersonal relationships, motivational tests, and emotional abilities. Our study examines five popular models, namely text-davinci-003, ChatGPT, GPT-4, LLaMA-2-7b, and LLaMA-2-13b. Additionally, we employ a jailbreak approach to bypass the safety alignment protocols and test the intrinsic natures of LLMs. We have made PsychoBench openly accessible via https://github.com/CUHK-ARISE/PsychoBench.																																	2024-05-25	PPRN:85349487		
J	Wang, Jinglong; Li, Xiawei; Zhang, Jing; Xu, Qingyuan; Zhou, Qin; Yu, Qian; Sheng, Lu; Xu, Dong				Zhang, Jing/HLQ-5887-2023; Wang, Jinlong/AAJ-3967-2020; Xu, Dong/A-3694-2011; Li, Xiawei/AAE-8423-2022; Yu, Qian/MIU-2512-2025						Diffusion Model is Secretly a Training-free Open Vocabulary Semantic Segmenter								Arxiv											2	2;2024-01-22;https://www.arxiv.org/abs/2309.02773v3| 1;2023-09-06;https://www.arxiv.org/abs/2309.02773v1	arXiv:2309.02773			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 22 2024	2024	The pre-trained text-image discriminative mod-els, such as CLIP, has been explored for open-vocabulary semantic segmentation with unsatisfac-tory results due to the loss of crucial localization information and awareness of object shapes. Re-cently, there has been a growing interest in expand-ing the application of generative models from gen-eration tasks to semantic segmentation. These ap-proaches utilize generative models either for gener-ating annotated data or extracting features to facili-tate semantic segmentation. This typically involves generating a considerable amount of synthetic data or requiring additional mask annotations. To this end, we uncover the potential of generative text -to-image diffusion models (e.g., Stable Diffusion) as highly efficient open-vocabulary semantic seg-menters, and introduce a novel training-free ap-proach named DiffSegmenter. The insight is that to generate realistic objects that are semantically faithful to the input text, both the complete ob-ject shapes and the corresponding semantics are im-plicitly learned by diffusion models. We discover that the object shapes are characterized by the self-attention maps while the semantics are indicated through the cross-attention maps produced by the denoising U-Net, forming the basis of our segmen-tation results. Additionally, we carefully design effective textual prompts and a category filtering mechanism to further enhance the segmentation re-sults. Extensive experiments on three benchmark datasets show that the proposed DiffSegmenter achieves impressive results for open-vocabulary se-mantic segmentation. The project page is avail-able at https://vcg-team.github.io/DiffSegmenter-webpage/.																																	2024-05-25	PPRN:84825350		
J	Zhuo, Terry Yue										ICE-Score: Instructing Large Language Models to Evaluate Code								Arxiv											2	2;2024-01-22;https://www.arxiv.org/abs/2304.14317v2| 1;2023-04-27;https://www.arxiv.org/abs/2304.14317v1	arXiv:2304.14317			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 22 2024	2024	Recent advancements in the field of natural language generation have facilitated the use of large language models to assess the quality of generated text. Although these models have shown promising results in tasks such as machine translation and summarization, their applicability in code intelligence tasks remains limited without human involvement. The complexity of programming concepts required for such tasks makes it difficult to develop evaluation metrics that align with human judgment. Token-matching-based metrics, such as BLEU, have demonstrated weak correlations with human practitioners in code intelligence tasks. Moreover, utilizing human-written test suites to evaluate functional correctness can be challenging in domains with low resources. To overcome these obstacles, we propose ICE-Score, a new evaluation metric via instructing large language models (LLMs) for code assessments. Our metric addresses the limitations of existing approaches by achieving superior correlations with functional correctness and human preferences, without the need for test oracles or references. We evaluate the efficacy of our metric on two different aspects (human preference and execution success) and four programming languages. Our results demonstrate that our metric surpasses state-ofthe-art metrics for code generation, delivering high levels of accuracy and consistency across various programming languages and tasks. We also make our evaluation metric and datasets available to the public1, encouraging further research in evaluating code intelligence tasks.																																	2024-02-07	PPRN:65705688		
J	Xu, Dejia; Yuan, Ye; Mardani, Morteza; Liu, Sifei; Song, Jiaming; Wang, Zhangyang; Vahdat, Arash				Song, Jiaming/KLC-6750-2024; Zhihua, Wang/AFO-5263-2022; Liu, Sifei/AGE-1968-2022						AGG: Amortized Generative 3D Gaussians for Single Image to 3D								Arxiv											1	1;2024-01-08;https://www.arxiv.org/abs/2401.04099v1	arXiv:2401.04099			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 08 2024	2024	Given the growing need for automatic 3D content creation pipelines, various 3D representations have been studied to generate 3D objects from a single image. Due to its superior rendering efficiency, 3D Gaussian splatting-based models have recently excelled in both 3D reconstruction and generation. 3D Gaussian splatting approaches for image to 3D generation are often optimization-based, requiring many computationally expensive score-distillation steps. To overcome these challenges, we introduce an Amortized Generative 3D Gaussian framework (AGG) that instantly produces 3D Gaussians from a single image, eliminating the need for per-instance optimization. Utilizing an intermediate hybrid representation, AGG decomposes the generation of 3D Gaussian locations and other appearance attributes for joint optimization. Moreover, we propose a cascaded pipeline that first generates a coarse representation of the 3D data and later upsamples it with a 3D Gaussian super-resolution module. Our method is evaluated against existing optimization-based 3D Gaussian frameworks and sampling-based pipelines utilizing other 3D representations, where AGG showcases competitive generation abilities both qualitatively and quantitatively while being several orders of magnitude faster. 																																	2024-05-25	PPRN:87051292		
J	Ang, Morris; Cai, Gefei; Sun, Xin; Wu, Baojun				Wu, Baojun/D-8513-2012; Ang, Morris/OLR-9778-2025						Integrability of Conformal Loop Ensemble: Imaginary DOZZ Formula and Beyond								Arxiv											2	2;2024-12-27;https://www.arxiv.org/abs/2107.01788v4| 1;2024-09-25;https://www.arxiv.org/abs/2107.01788v3	arXiv:2107.01788			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 27 2024	2024	The scaling limit of the probability that n points are on the same cluster for 2D critical percolation is believed to be governed by a conformal field theory (CFT). Although this is not fully understood, Delfino and Viti (2010) made a remarkable prediction on the exact value of a properly normalized three-point probability. It is expressed in terms of the imaginary DOZZ formula of Schomerus, Zamolodchikov and Kostov-Petkova, which extends the structure constants of minimal model CFTs to continuous parameters. Later, similar conjectures were made for scaling limits of random cluster models and O(n) loop models, representing certain three-point observables in terms of the imaginary DOZZ formula. Since the scaling limits of these models can be described by the conformal loop ensemble (CLE), such conjectures can be formulated as exact statements on CLE observables. In this paper, we prove Delfino and Viti’s conjecture on percolation as well as a conjecture of Ikhlef, Jacobsen and Saleur (2015) on the nesting loop statistics of CLE. Our proof is based on the coupling between CLE and Liouville quantum gravity on the sphere, and is inspired by the fact that after reparametrization, the imaginary DOZZ formula is the reciprocal of the three-point function of Liouville CFT. Recently, Nivesvivat, Jacobsen and Ribault systematically studied a CFT with a large class of CLE observables as its correlation functions, including the ones from these two conjectures. We believe that our framework admits sufficient flexibility to exactly solve the three-point functions for CLE observables with natural geometric interpretations, including those from this CFT. As a demonstration, we solve the case corresponding to three points lying on the same loop, where the answer is a variant of the imaginary DOZZ formula.																																	2025-02-15	PPRN:98871610		
J	Gao, Zitian; Niu, Boye; He, Xuzheng; Xu, Haotian; Liu, Hongzhang; Liu, Aiwei; Hu, Xuming; Wen, Lijie				Hu, Xuming/HTS-1538-2023						Interpretable Contrastive Monte Carlo Tree Search Reasoning								Arxiv											4	4;2024-12-25;https://www.arxiv.org/abs/2410.01707v3| 3;2024-10-11;https://www.arxiv.org/abs/2410.01707v2| 2;2024-10-02;https://www.arxiv.org/abs/2410.01707v1| 1;2024-10-02;https://www.arxiv.org/abs/2410.01707v1	arXiv:2410.01707			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 25 2024	2024	We propose SC-MCTS*: a novel Monte Carlo Tree Search (MCTS) reasoning algorithm for Large Language Models (LLMs), significantly improves both reasoning accuracy and speed. Our motivation comes from: 1. Previous MCTS LLM reasoning works often overlooked its biggest drawback--slower speed compared to CoT; 2. Previous research mainly used MCTS as a tool for LLM reasoning on various tasks with limited quantitative analysis or ablation studies of its components from reasoning interpretability perspective. 3. The reward model is the most crucial component in MCTS, however previous work has rarely conducted in-depth study or improvement of MCTS's reward models. Thus, we conducted extensive ablation studies and quantitative analysis on components of MCTS, revealing the impact of each component on the MCTS reasoning performance of LLMs. Building on this, (i) we designed a highly interpretable reward model based on the principle of contrastive decoding and (ii) achieved an average speed improvement of 51.9% per node using speculative decoding. Additionally, (iii) we improved UCT node selection strategy and backpropagation used in previous works, resulting in significant performance improvement. We outperformed o1-mini by an average of 17.4% on the Blocksworld multi-step reasoning dataset using Llama-3.1-70B with SC-MCTS*. 																																	2025-02-15	PPRN:100926304		
J	Chen, Fan; Mei, Song; Bai, Yu				Mei, Song/AFQ-2667-2022; Chen, Fan/NIS-6635-2025; Bai, Yu/AAG-7494-2020						Unified Algorithms for RL with Decision-Estimation Coefficients: PAC, Reward-Free, Preference-Based Learning, and Beyond								Arxiv											3	3;2024-12-22;https://www.arxiv.org/abs/2209.11745v4| 2;2024-04-29;https://www.arxiv.org/abs/2209.11745v3| 1;2022-09-23;https://www.arxiv.org/abs/2209.11745v1	arXiv:2209.11745			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 22 2024	2024	Modern Reinforcement Learning (RL) is more than just learning the optimal policy; Alternative learning goals such as exploring the environment, estimating the underlying model, and learning from preference feedback are all of practical importance. While provably sample-efficient algorithms for each specific goal have been proposed, these algorithms often depend strongly on the particular learning goal and thus admit different structures correspondingly. It is an urging open question whether these learning goals can rather be tackled by a single unified algorithm. We make progress on this question by developing a unified algorithm framework for a large class of learning goals, building on the Decision-Estimation Coefficient (DEC) framework. Our framework handles many learning goals such as no-regret RL, PAC RL, reward-free learning, model estimation, and preference-based learning, all by simply instantiating the same generic complexity measure called “Generalized DEC”, and a corresponding generic algorithm. The generalized DEC also yields a sample complexity lower bound for each specific learning goal. As applications, we propose “decouplable representation” as a natural sufficient condition for bounding generalized DECs, and use it to obtain many new sample-efficient results (and recover existing results) for a wide range of learning goals and problem classes as direct corollaries. Finally, as a connection, we re-analyze two existing optimistic model-based algorithms based on Posterior Sampling and Maximum Likelihood Estimation, showing that they enjoy sample complexity bounds under similar structural conditions as the DEC.																																	2025-02-02	PPRN:19316934		
J	Luo, Yongdong; Zheng, Xiawu; Yang, Xiao; Li, Guilin; Lin, Haojia; Huang, Jinfa; Ji, Jiayi; Chao, Fei; Luo, Jiebo; Ji, Rongrong										Video-RAG: Visually-aligned Retrieval-Augmented Long Video Comprehension								Arxiv											3	3;2024-12-20;https://www.arxiv.org/abs/2411.13093v3| 2;2024-12-19;https://www.arxiv.org/abs/2411.13093v2| 1;2024-11-20;https://www.arxiv.org/abs/2411.13093v1	arXiv:2411.13093			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 20 2024	2024	Existing large video-language models (LVLMs) struggle to comprehend long videos correctly due to limited context. To address this problem, fine-tuning long-context LVLMs and employing GPT-based agents have emerged as promising solutions. However, fine-tuning LVLMs would require extensive high-quality data and substantial GPU resources, while GPT-based agents would rely on proprietary models (e.g., GPT-4o). In this paper, we propose Video Retrieval- Augmented Generation (Video-RAG), a training-free and cost-effective pipeline that employs visually-aligned auxiliary texts to help facilitate cross-modality alignment while providing additional information beyond the visual content. Specifically, we leverage open-source external tools to extract visually-aligned information from pure video data (e.g., audio, optical character, and object detection), and incorporate the extracted information into an existing LVLM as auxiliary texts, alongside video frames and queries, in a plug-and-play manner. Our Video-RAG offers several key advantages: (i) lightweight with low computing overhead due to single-turn retrieval; (ii) easy implementation and compatibility with any LVLM; and (iii) significant, consistent performance gains across long video understanding benchmarks, including Video-MME, MLVU, and LongVideoBench. Notably, our model demonstrates superior performance over proprietary models like Gemini- 1.5-Pro and GPT-4o when utilized with a 72B model. 1																																	2025-01-29	PPRN:119300715		
J	Zhang, Zhexin; Cui, Shiyao; Lu, Yida; Zhou, Jingzhuo; Yang, Junxiao; Wang, Hongning; Huang, Minlie				ZHOU, Jingzhuo/MGA-0328-2025; Wang, Hongning/GPK-7527-2022; Cui, Shiyao/AAP-2707-2021						Agent-SafetyBench: Evaluating the Safety of LLM Agents								Arxiv											1	1;2024-12-19;https://www.arxiv.org/abs/2412.14470v1	arXiv:2412.14470			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 19 2024	2024	As large language models (LLMs) are increasingly deployed as agents, their integration into interactive environments and tool use introduce new safety challenges beyond those associated with the models themselves. However, the absence of comprehensive benchmarks for evaluating agent safety presents a significant barrier to effective assessment and further improvement. In this paper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to evaluate the safety of LLM agents. Agent-SafetyBench encompasses 349 interaction environments and 2,000 test cases, evaluating 8 categories of safety risks and covering 10 common failure modes frequently encountered in unsafe interactions. Our evaluation of 16 popular LLM agents reveals a concerning result: none of the agents achieves a safety score above 60%. This highlights significant safety challenges in LLM agents and underscores the considerable need for improvement. Through quantitative analysis, we identify critical failure modes and summarize two fundamental safety detects in current LLM agents: lack of robustness and lack of risk awareness. Furthermore, our findings suggest that reliance on defense prompts alone is insufficient to address these safety issues, emphasizing the need for more advanced and robust strategies. We release Agent-SafetyBench at url{https://github.com/thu-coai/Agent-SafetyBench} to facilitate further research and innovation in agent safety evaluation and improvement.																																	2025-01-28	PPRN:120065124		
J	Singh, Shivalika; Romanou, Angelika; Fourrier, Clementine; Adelani, David I.; Ngui, Jian Gang; Vila-Suero, Daniel; Limkonchotiwat, Peerat; Marchisio, Kelly; Leong, Wei Qi; Susanto, Yosephine; Ng, Raymond; Longpre, Shayne; Ko, Wei-Yin; Smith, Madeline; Bosselut, Antoine; Oh, Alice; Martins, Andre F.T.; Choshen, Leshem; Ippolito, Daphne; Ferrante, Enzo; Fadaee, Marzieh; Ermis, Beyza; Hooker, Sara				Torres Martins, Andre Filipe/JXL-9782-2024; Ermis, Beyza Hilal/KJO-2003-2024; Hostiuc, Sorin/I-2017-2019						Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation								Arxiv											1	1;2024-12-04;https://www.arxiv.org/abs/2412.03304v1	arXiv:2412.03304			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 04 2024	2024	Cultural biases in multilingual datasets pose significant challenges for their effectiveness as global benchmarks. These biases stem not only from language but also from the cultural knowledge required to interpret questions, reducing the practical utility of translated datasets like MMLU. Furthermore, translation often introduces artifacts that can distort the meaning or clarity of questions in the target language. A common practice in multilingual evaluation is to rely on machine-translated evaluation sets, but simply translating a dataset is insufficient to address these challenges. In this work, we trace the impact of both of these issues on multilingual evaluations and ensuing model performances. Our large-scale evaluation of state-of-the-art open and proprietary models illustrates that progress on MMLU depends heavily on learning Western- centric concepts, with 28% of all questions requiring culturally sensitive knowledge. Moreover, for questions requiring geographic knowledge, an astounding 84.9% focus on either North American or European regions. Rankings of model evaluations change depending on whether they are evaluated on the full portion or the subset of questions annotated as culturally sensitive, showing the distortion to model rankings when blindly relying on translated MMLU. We release Global-MMLU , an improved MMLU with evaluation coverage across 42 languages – with improved overall quality by engaging with compensated professional and community annotators to verify translation quality while also rigorously evaluating cultural biases present in the original dataset. This comprehensive Global-MMLU set also includes designated subsets labeled as culturally sensitive and culturally agnostic to allow for more holistic, complete evaluation.																																	2025-01-15	PPRN:119697978		
J	Chang, Kaiyan; Xu, Songcheng; Wang, Chenglong; Luo, Yingfeng; Liu, Xiaoqian; Xiao, Tong; Zhu, Jingbo				Wang, Chenglong/NTR-1949-2025; Xiao, Tong/AAP-5944-2020; Chang, Kaiyan/NXC-2014-2025						Efficient Prompting Methods for Large Language Models: A Survey								Arxiv											2	2;2024-12-02;https://www.arxiv.org/abs/2404.01077v2| 1;2024-04-01;https://www.arxiv.org/abs/2404.01077v1	arXiv:2404.01077			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 02 2024	2024	Prompting is a mainstream paradigm for adapting large language models to specific natural language processing tasks without modifying internal parameters. Therefore, detailed supplementary knowledge needs to be integrated into external prompts, which inevitably brings extra human efforts and computational burdens for practical applications. As an effective solution to mitigate resource consumption, Efficient Prompting Methods have attracted a wide range of attention. We provide mathematical expressions at a high level to deeply discuss Automatic Prompt Engineering for different prompt components and Prompt Compression in continuous and discrete spaces. Finally, we highlight promising future directions to inspire researchers interested in this field.																																	2025-01-11	PPRN:88360783		
J	Shao, Jiahao; Yang, Yuanbo; Zhou, Hongyu; Zhang, Youmin; Shen, Yujun; Guizilini, Vitor; Wang, Yue; Poggi, Matteo; Liao, Yiyi				Yang, Yuanbo/JUF-0729-2023; Zhang, Youmin/G-4730-2014; Zhou, Hongyu/ABD-3190-2021						Learning Temporally Consistent Video Depth from Video Diffusion Priors								Arxiv											1	1;2024-12-02;https://www.arxiv.org/abs/2406.01493v3	arXiv:2406.01493			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 02 2024	2024	This work addresses the challenge of streamed video depth estimation, which expects not only per-frame accuracy but, more importantly, cross-frame consistency. We argue that sharing contextual information between frames or clips is pivotal in fostering temporal consistency. Thus, instead of directly developing a depth estimator from scratch, we reformulate this predictive task into a conditional generation problem to provide contextual information within a clip and across clips. Specifically, we propose a consistent context-aware training and inference strategy for arbitrarily long videos to provide cross-clip context. We sample independent noise levels for each frame within a clip during training while using a sliding window strategy and initializing overlapping frames with previously predicted frames without adding noise. Moreover, we design an effective training strategy to provide context within a clip. Extensive experimental results validate our design choices and demonstrate the superiority of our approach, dubbed ChronoDepth.																																	2025-01-16	PPRN:119668327		
J	Liu, Xubo; Kong, Qiuqiang; Zhao, Yan; Liu, Haohe; Yuan, Yi; Liu, Yuzhuo; Xia, Rui; Wang, Yuxuan; Plumbley, Mark D.; Wang, Wenwu				Plumbley, Mark/A-7298-2008; liu, haohe/JBS-1030-2023; Liu, Xubo/HNR-3002-2023; Wang, Yuxuan/P-4470-2014; Zhao, Yan/IWM-3802-2023; wang, wenwu/HOF-4371-2023						Separate Anything You Describe								Arxiv											3	3;2024-12-01;https://www.arxiv.org/abs/2308.05037v3| 2;2023-10-27;https://www.arxiv.org/abs/2308.05037v2| 1;2023-08-09;https://www.arxiv.org/abs/2308.05037v1	arXiv:2308.05037			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 01 2024	2024	Language-queried audio source separation (LASS) is a new paradigm for computational auditory scene analysis (CASA). LASS aims to separate a target sound from an audio mixture given a natural language query, which provides a natural and scalable interface for digital audio applications. Recent works on LASS, despite attaining promising separation performance on specific sources (e.g., musical instruments, limited classes of audio events), are unable to separate audio concepts in the open domain. In this work, we introduce AudioSep, a foundation model for open-domain audio source separation with natural language queries. We train AudioSep on large-scale multimodal datasets and extensively evaluate its capabilities on numerous tasks including audio event separation, musical instrument separation, and speech enhancement. AudioSep demonstrates strong separation performance and impressive zero-shot generalization ability using audio captions or text labels as queries, substantially outperforming previous audio-queried and language-queried sound separation models. Specifically, AudioSep achieved strong results including a Signal-to-Distortion Ratio Improvement (SDRi) of 7.74 dB across 527 sound classes of the AudioSet; 9.14 dB on the VGGSound dataset; 8.22 dB on the AudioCaps dataset; 6.85 dB on the Clotho dataset; 10.51 dB on the MUSIC dataset; 10.04 dB on the ESC-50 dataset; 8.16 dB on the DCASE 2024 Task 9 dataset; and an SSNR of 9.21 dB on the VoicebankDemand dataset. 																																	2025-01-11	PPRN:74929230		
J	Butter, Anja; Huetsch, Nathan; Schweitzer, Sofia Palacios; Plehn, Tilman; Sorrenson, Peter; Spinner, Jonas										Jet Diffusion versus JetGPT -- Modern Networks for the LHC								Arxiv											2	2;2024-11-19;https://www.arxiv.org/abs/2305.10475v3| 1;2023-05-17;https://www.arxiv.org/abs/2305.10475v1	arXiv:2305.10475			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 19 2024	2024	We introduce two diffusion models and an autoregressive transformer for LHC physics simulations. Bayesian versions allow us to control the networks and capture training uncertainties. After illustrating their different density estimation methods for simple toy models, we discuss their advantages for Z plus jets event generation. While diffusion networks excel through their precision, the transformer scales best with the phase space dimensionality. Given the different training and evaluation speed, we expect LHC physics to benefit from dedicated use cases for normalizing flows, diffusion models, and autoregressive transformers.																																	2024-12-28	PPRN:70531957		
J	Konoplya, R.A.; Zhidenko, A.				Konoplya, Roman/HIU-0325-2022						First few overtones probe the event horizon geometry								Arxiv											2	2;2024-11-05;https://www.arxiv.org/abs/2209.00679v3| 1;2022-09-01;https://www.arxiv.org/abs/2209.00679v1	arXiv:2209.00679			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 05 2024	2024	It is broadly believed that quasinormal modes cannot tell the black-hole near-horizon geometry, because usually the low-lying modes are determined by the scattering of perturbations around the peak of the effective potential. Using the general parametrization of the black-hole spacetimes respecting the generic post-Newtonian asymptotic, we will show that tiny modifications of the Schwarzschild/Kerr geometry in a relatively small region near the event horizon lead to almost the same Schwarzschild/Kerr fundamental mode, but totally different first few overtones. Having in mind that the first several overtones affect the quasinormal ringing at its early and intermediate stage [M. Giesler, M. Isi, M. Scheel, and S. Teukolsky, Phys. Rev. X 9, 041060 (2019)], we argue that the near-horizon geometry could in principle be studied via the first few overtones of the quasinormal spectrum, which is important because corrections to the Einstein theory must modify precisely the near-horizon geometry, keeping the known weak field regime.																																	2024-11-27	PPRN:13698193		
J	Bjoernson, Emil; Kara, Ferdi; Kolomvakis, Nikolaos; Kosasih, Alva; Ramezani, Parisa; Salman, Murat Babek				Salman, Murat/AAZ-7883-2021; Björnson, Emil/AAD-4840-2019; Kosasih, Alva/AAH-2730-2021; Kara, Ferdi/J-2958-2019; Ramezani, Parisa/AAK-5671-2020; Kolomvakis, Nikolaos/JZD-9465-2024						Enabling 6G Performance in the Upper Mid-Band by Transitioning From Massive to Gigantic MIMO								Arxiv											2	2;2024-11-04;https://www.arxiv.org/abs/2407.05630v2| 1;2024-07-08;https://www.arxiv.org/abs/2407.05630v1	arXiv:2407.05630			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 04 2024	2024	The initial 6G networks will likely operate in the upper mid-band (7-24 GHz), which has decent propagation conditions but underwhelming new spectrum availability. In this paper, we explore whether we can anyway reach the ambitious 6G performance goals by evolving the multiple-input multiple-output (MIMO) technology from being massive to gigantic. We describe how many antennas are needed and can realistically be deployed, and what the peak user rate and degrees-of-freedom (DOF) can become. We further suggest a new deployment strategy that enables the utilization of radiative near-field effects in these bands for precise beamfocusing, localization, and sensing from a single base station site. Finally, we identify five open research challenges that must be overcome to efficiently use gigantic MIMO dimensions in 6G from hardware, cost, and algorithmic perspectives.																																	2024-12-16	PPRN:90739852		
J	Hu, Xiang; Fu, Hongyu; Wang, Jinge; Wang, Yifeng; Li, Zhikun; Xu, Renjun; Lu, Yu; Jin, Yaochu; Pan, Lili; Lan, Zhenzhong				Fu, Hongyu/OSH-2591-2025; Pan, Lili/HJH-9278-2023; Jin, Yaochu/GRY-7004-2022						Nova: An Iterative Planning and Search Approach to Enhance Novelty and Diversity of LLM Generated Ideas								Arxiv											2	2;2024-10-27;https://www.arxiv.org/abs/2410.14255v2| 1;2024-10-18;https://www.arxiv.org/abs/2410.14255v1	arXiv:2410.14255			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 27 2024	2024	Scientific innovation is pivotal for humanity, and harnessing large language models (LLMs) to generate research ideas could transform discovery. However, existing LLMs often produce simplistic and repetitive suggestions due to their limited ability in acquiring external knowledge for innovation. To address this problem, we introduce an enhanced planning and search methodology designed to boost the creative potential of LLM-based systems. Our approach involves an iterative process to purposely plan the retrieval of external knowledge, progressively enriching the idea generation with broader and deeper insights. Validation through automated and human assessments indicates that our framework substantially elevates the quality of generated ideas, particularly in novelty and diversity. The number of unique novel ideas produced by our framework is 3.4 times higher than without it. Moreover, our method outperforms the current state-of-the-art, generating at least 2.5 times more top-rated ideas based on 170 seed papers in a Swiss Tournament evaluation.																																	2024-12-11	PPRN:118452603		
J	Karpinska, Marzena; Thai, Katherine; Lo, Kyle; Goyal, Tanya; Iyyer, Mohit										One Thousand and One Pairs : A “novel” challenge for long-context language models								Arxiv											3	3;2024-10-22;https://www.arxiv.org/abs/2406.16264v3| 2;2024-07-18;https://www.arxiv.org/abs/2406.16264v2| 1;2024-06-24;https://www.arxiv.org/abs/2406.16264v1	arXiv:2406.16264			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 22 2024	2024	Synthetic long-context LLM benchmarks (e.g., “needle-in-the-haystack”) test only surfacelevel retrieval capabilities, but how well can long-context LLMs retrieve, synthesize, and reason over information across book-length inputs? We address this question by creating N O C HA , a dataset of 1,001 minimally different pairs of true and false claims about 67 recentlypublished English fictional books, written by human readers of those books. In contrast to existing long-context benchmarks, our annotators confirm that the largest share of pairs in N O C HA require global reasoning over the entire book to verify. Our experiments show that while human readers easily perform this task, it is enormously challenging for all ten long-context LLMs that we evaluate: no open-weight model performs above random chance (despite their strong performance on synthetic benchmarks), while GPT-4 O achieves the highest accuracy at 55.8%. Further analysis reveals that (1) on average, models perform much better on pairs that require only sentence-level retrieval vs. global reasoning; (2) model-generated explanations for their decisions are often inaccurate even for correctly-labeled claims; and (3) models perform substantially worse on speculative fiction books that contain extensive world-building. The methodology proposed in N O C HA allows for the evolution of the benchmark dataset and the easy analysis of future models.																																	2024-11-23	PPRN:89410244		
J	Chen, Nuo; Zheng, Zinan; Wu, Ning; Gong, Ming; Zhang, Dongmei; Li, Jia				Zheng, Zinan/LQK-1057-2024; Li, Jiaqi/HHN-8236-2022						Breaking Language Barriers in Multilingual Mathematical Reasoning: Insights and Observations								Arxiv											4	4;2024-10-16;https://www.arxiv.org/abs/2310.20246v5| 3;2023-11-28;https://www.arxiv.org/abs/2310.20246v4| 2;2023-11-07;https://www.arxiv.org/abs/2310.20246v3| 1;2023-11-01;https://www.arxiv.org/abs/2310.20246v2	arXiv:2310.20246			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 16 2024	2024	Existing research predominantly focuses on developing powerful language learning models (LLMs) for mathematical reasoning within monolingual languages, with few explorations in preserving efficacy in a multilingual context. To bridge this gap, this paper pioneers exploring and training powerful Multilingual Math Reasoning (xMR) LLMs. Firstly, by utilizing translation, we construct the first multilingual math reasoning instruction dataset, MGSM8KInstruct, encompassing ten distinct languages, thus addressing the issue of training data scarcity in xMR tasks. Based on the collected dataset, we propose different training strategies to build powerful xMR LLMs, named MathOctopus, notably outperform conventional open-source LLMs and exhibit superiority over ChatGPT in few-shot scenarios. Notably, MathOctopus-13B reaches 47.6% accuracy which exceeds ChatGPT 46.3% on MGSM testset. Beyond remarkable results, we unearth several pivotal observations and insights from extensive experiments: (1) When extending the rejection sampling strategy to the multilingual context, it proves effective for model performances, albeit limited. (2) Employing parallel corpora for math Supervised Fine-Tuning (SFT) across multiple languages not only significantly enhances model performance multilingually but also elevates their monolingual performance. This indicates that crafting multilingual corpora can be regarded as a vital strategy for enhancing model performance in a specific language, especially in mathematical reasoning tasks. For instance, MathOctopus-7B improves its counterparts that trained on English from 42.2% to 50.8% on GSM8K testset. 																																	2024-11-12	PPRN:85919126		
J	Ni, Jinjie; Xue, Fuzhao; Yue, Xiang; Deng, Yuntian; Shah, Mahir; Jain, Kabir; Neubig, Graham; You, Yang				Deng, yuntian/KIB-9835-2024						MixEval: Deriving Wisdom of the Crowd from LLM Benchmark Mixtures								Arxiv											2	2;2024-10-12;https://www.arxiv.org/abs/2406.06565v2| 1;2024-06-03;https://www.arxiv.org/abs/2406.06565v1	arXiv:2406.06565			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 12 2024	2024	Evaluating large language models (LLMs) is challenging. Traditional groundtruth-based benchmarks fail to capture the comprehensiveness and nuance of real-world queries, while LLM-as-judge benchmarks suffer from grading biases and limited query quantity. Both of them may also become contaminated over time. User-facing evaluation, such as Chatbot Arena, provides reliable signals but is costly and slow. In this work, we propose MixEval , a new paradigm for establishing efficient, gold-standard LLM evaluation by strategically mixing off-the-shelf benchmarks. It bridges (1) comprehensive and well-distributed real-world user queries and (2) efficient and fairly-graded ground-truth-based benchmarks, by matching queries mined from the web with similar queries from existing benchmarks. Based on MixEval , we further build MixEval-Hard , which offers more room for model improvement. Our benchmarks’ advantages lie in (1) a 0.96 model ranking correlation with Chatbot Arena arising from the highly impartial query distribution and grading mechanism, (2) fast, cheap, and reproducible execution (6% of the time and cost of MMLU), and (3) dynamic evaluation enabled by the rapid and stable data update pipeline. We provide extensive meta-evaluation and analysis for our and existing LLM benchmarks to deepen the community’s understanding of LLM evaluation and guide future research directions.																																	2024-11-11	PPRN:89278642		
J	Bansal, Hritik; Hosseini, Arian; Agarwal, Rishabh; Tran, Vinh Q.; Kazemi, Mehran										Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling								Arxiv											2	2;2024-10-07;https://www.arxiv.org/abs/2408.16737v2| 1;2024-08-29;https://www.arxiv.org/abs/2408.16737v1	arXiv:2408.16737			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 07 2024	2024	Training on high-quality synthetic data from strong language models (LMs) is a common strategy to improve the reasoning performance of LMs. In this work, we revisit whether this strategy is computeoptimal under a fixed inference budget (e.g., FLOPs). To do so, we investigate the trade-offs between generating synthetic data using a stronger but more expensive (SE) model versus a weaker but cheaper (WC) model. We evaluate the generated data across three key metrics: coverage, diversity, and false positive rate, and show that the data from WC models may have higher coverage and diversity, but also exhibit higher false positive rates. We then finetune LMs on data from SE and WC models in different settings: knowledge distillation, self-improvement, and a novel weak-to-strong improvement setup where a weaker LM teaches reasoning to a stronger LM. Our findings reveal that models finetuned on WC-generated data consistently outperform those trained on SE-generated data across multiple benchmarks and multiple choices of WC and SE models. These results challenge the prevailing practice of relying on SE models for synthetic data generation, suggesting that WC may be the compute-optimal approach for training advanced LM reasoners.																																	2024-10-29	PPRN:91782554		
J	Yang, John; Jimenez, Carlos E.; Zhang, Alex L.; Lieret, Kilian; Yang, Joyce; Wu, Xindi; Press, Ori; Muennighoff, Niklas; Synnaeve, Gabriel; Narasimhan, Karthik R.; Yang, Diyi; Wang, Sida I.; Press, Ofir										SWE-bench Multimodal: Do AI Systems Generalize to Visual Software Domains?								Arxiv											1	1;2024-10-04;https://www.arxiv.org/abs/2410.03859v1	arXiv:2410.03859			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 04 2024	2024	Autonomous systems for software engineering are now capable of fixing bugs and developing features. These systems are commonly evaluated on SWE-bench (Jimenez et al., 2024a), which assesses their ability to solve software issues from GitHub repositories. However, SWE-bench uses only Python repositories, with problem statements presented predominantly as text and lacking visual elements such as images. This limited coverage motivates our inquiry into how existing systems might perform on unrepresented software engineering domains (e.g., front-end, game development, DevOps), which use different programming languages and paradigms. Therefore, we propose SWE-bench Multimodal (SWE-bench M), to evaluate systems on their ability to fix bugs in visual, user-facing JavaScript software. SWE-bench M features 617 task instances collected from 17 JavaScript libraries used for web interface design, diagramming, data visualization, syntax highlighting, and interactive mapping. Each SWE-bench M task instance contains at least one image in its problem statement or unit tests. Our analysis finds that top-performing SWE-bench systems struggle with SWE-bench M, revealing limitations in visual problem-solving and cross-language generalization. Lastly, we show that SWE-agent's flexible language-agnostic features enable it to substantially outperform alternatives on SWE-bench M, resolving 12% of task instances compared to 6% for the next best system.																																	2024-10-26	PPRN:104277103		
J	Xu, Mingxue; Xu, Yao Lei; Mandic, Danilo P.				Xu, Mingxue/ODJ-3963-2025						TensorGPT: Efficient Compression of Large Language Models based on Tensor-Train Decomposition								Arxiv											1	1;2024-10-03;https://www.arxiv.org/abs/2307.00526v2	arXiv:2307.00526			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 03 2024	2024	High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. However, this high dimensionality also introduces considerable model parameters and prohibitively high model storage and memory requirements, which is particularly unaffordable for low-end devices. Targeting no extra training data and insufficient computation cases, we propose a training-free model compression approach based on the Tensor-Train Decomposition (TTD), whereby each pre-trained token embedding is converted into a lower-dimensional Matrix Product State (MPS). We then comprehensively investigate the low-rank structures extracted by this approach, in terms of the compression ratio, the language task performance, and latency on a typical low-end device (i.e. Raspberry Pi). Taking GPT family models (i.e. GPT-2 and CerebrasGPT) as case studies, our approach theoretically results in 46.89%  fewer parameters of the entire model, with a compression ratio 39.38× - 65.64×  for the embedding layers. With different hyperparameter choices, the model compressed with our approach can achieve a comparable language task performance to the original model with around 2.0× embedding layer compression. This empirically proves the existence of low-rank structure in GPT family models, and demonstrates that about half of the parameters in the embedding layers are redundant.																																	2024-10-25	PPRN:103989801		
J	Liu, Yue; He, Xiaoxin; Xiong, Miao; Fu, Jinlan; Deng, Shumin; Hooi, Bryan				Deng, Shumin/AAP-7003-2021						FlipAttack: Jailbreak LLMs via Flipping								Arxiv											1	1;2024-10-02;https://www.arxiv.org/abs/2410.02832v1	arXiv:2410.02832			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 02 2024	2024	This paper proposes a simple yet effective jailbreak attack named FlipAttack against black-box LLMs. First, from the autoregressive nature, we reveal that LLMs tend to understand the text from left to right and find that they struggle to comprehend the text when noise is added to the left side. Motivated by these insights, we propose to disguise the harmful prompt by constructing left-side noise merely based on the prompt itself, then generalize this idea to 4 flipping modes. Second, we verify the strong ability of LLMs to perform the text-flipping task, and then develop 4 variants to guide LLMs to denoise, understand, and execute harmful behaviors accurately. These designs keep FlipAttack universal, stealthy, and simple, allowing it to jailbreak black-box LLMs within only 1 query. Experiments on 8 LLMs demonstrate the superiority of FlipAttack. Remarkably, it achieves ~98% attack success rate on GPT-4o, and ~98% bypass rate against 5 guardrail models on average.  [Graphics]																																	2024-10-25	PPRN:103903531		
J	Ding, Hanxing; Pang, Liang; Wei, Zihao; Shen, Huawei; Cheng, Xueqi				Pang, Liang/CAA-7686-2022; Wei, Zihao/HTP-6362-2023						<italic>Retrieve Only When It Needs</italic>: Adaptive Retrieval Augmentation for Hallucination Mitigation in Large Language Models								Arxiv											2	2;2024-09-29;https://www.arxiv.org/abs/2402.10612v2| 1;2024-02-16;https://www.arxiv.org/abs/2402.10612v1	arXiv:2402.10612			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 29 2024	2024	Hallucinations pose a significant challenge for the practical implementation of large language models (LLMs). The utilization of parametric knowledge in generating factual content is constrained by the limited knowledge of LLMs, potentially resulting in internal hallucinations. While incorporating external information can help fill knowledge gaps, it also introduces the risk of irrelevant information, thereby increasing the likelihood of external hallucinations. A careful and balanced integration of the parametric knowledge within LLMs with external information is crucial to alleviate hallucinations. In this study, we present Rowen, a novel approach that enhances LLMs with a selective retrieval augmentation process tailored to address hallucinated outputs. This process is governed by a multilingual semantic-aware detection module, which evaluates the consistency of the perturbed responses across various languages for the same queries. Upon detecting inconsistencies indicative of hallucinations, Rowen activates the retrieval of external information to rectify the model outputs. Rowen adeptly harmonizes the intrinsic parameters in LLMs with external knowledge sources, effectively mitigating hallucinations by ensuring a balanced integration of internal reasoning and external evidence. Through a comprehensive empirical analysis, we demonstrate that Rowen surpasses the current state-of-the-art in both detecting and mitigating hallucinated content within the outputs of LLMs1.																																	2024-10-09	PPRN:87798071		
J	Miret, Santiago; Krishnan, N M Anoop										Are LLMs Ready for Real-World Materials Discovery?								Arxiv											2	2;2024-09-25;https://www.arxiv.org/abs/2402.05200v2| 1;2024-02-07;https://www.arxiv.org/abs/2402.05200v1	arXiv:2402.05200			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 25 2024	2024	Large Language Models (LLMs) create exciting possibilities to accelerate scientific discovery and knowledge dissemination in materials science. While LLMs have been successfully applied to select scientific problems and rudimentary challenges, they currently fall short of being practical materials science tools. In this perspective, we show relevant failure cases of LLMs in materials science that reveal current limitations of LLMs related to comprehending and reasoning over complex, interconnected materials science knowledge. Given those shortcomings, we outline a framework for developing Materials Science LLMs (MatSci-LLMs) that are grounded in domain knowledge, which can enable hypothesis generation followed by hypothesis testing. The path to attaining performant MatSci-LLMs rests, in large part, on building high-quality, multi-modal datasets sourced from scientific literature, where various information extraction challenges persist. As such, we describe key materials science information extraction challenges which need to be overcome to build large-scale, multi-modal datasets that capture valuable materials science knowledge. Aiming to bring a coherent effort to address these challenges, we outline a roadmap for applying MatSci-LLMs for real-world materials discovery through six interacting steps: 1. Materials Query; 2. Data Retrieval; 3. Materials Design; 4. Insilico Evaluation; 5. Experiment Planning; 6. Experiment Execution. Finally, we discuss some of the broader implications of the MatSciLLMs on the society at large in terms of sustainability, inclusivity and policy making.																																	2024-10-08	PPRN:87568864		
J	Li, Kai; Chen, Guo; Yang, Runxuan; Hu, Xiaolin				Hu, Xiaolin/JGD-2248-2023; Li, Kai/OIS-2902-2025						SPMamba: State-space model is all you need in speech separation								Arxiv											2	2;2024-09-10;https://www.arxiv.org/abs/2404.02063v2| 1;2024-04-02;https://www.arxiv.org/abs/2404.02063v1	arXiv:2404.02063			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 10 2024	2024	Existing CNN-based speech separation models face local receptive field limitations and cannot effectively capture long time dependencies. Although LSTM and Transformer-based speech separation models can avoid this problem, their high complexity makes them face the challenge of computational resources and inference efficiency when dealing with long audio. To address this challenge, we introduce an innovative speech separation method called SPMamba. This model builds upon the robust TF-GridNet architecture, replacing its traditional BLSTM modules with bidirectional Mamba modules. These modules effectively model the spatiotemporal relationships between the time and frequency dimensions, allowing SPMamba to capture long-range dependencies with linear computational complexity. Specifically, the bidirectional processing within the Mamba modules enables the model to utilize both past and future contextual information, thereby enhancing separation performance. Extensive experiments conducted on public datasets, including WSJ0-2Mix, WHAM!, and Libri2Mix, as well as the newly constructed Echo2Mix dataset, demonstrated that SPMamba significantly outperformed existing state-of-the-art models, achieving superior results while also reducing computational complexity. These findings highlighted the effectiveness of SPMamba in tackling the intricate challenges of speech separation in complex environments.																																	2024-09-26	PPRN:88377313		
J	Dong, Yihong; Ding, Jiazheng; Jiang, Xue; Li, Ge; Li, Zhuo; Jin, Zhi				Jin, Zhi/E-1288-2013; Ding, Jiazheng/OAJ-7200-2025; Dong, Yihong/LCE-6194-2024						CodeScore: Evaluating Code Generation by Learning Code Execution								Arxiv											2	2;2024-09-05;https://www.arxiv.org/abs/2301.09043v4| 1;2023-12-01;https://www.arxiv.org/abs/2301.09043v3	arXiv:2301.09043			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 05 2024	2024	A proper code evaluation metric (CEM) profoundly impacts the evolution of code generation, which is an important research field in NLP and software engineering. Prevailing match-based CEMs (e.g., BLEU, Accuracy, and CodeBLEU) suffer from two significant drawbacks. 1. They primarily measure the surface differences between codes without considering their functional equivalence. However, functional equivalence is pivotal in evaluating the effectiveness of code generation, as different codes can perform identical operations. 2. They are predominantly designed for the Ref-only input format. However, code evaluation necessitates versatility in input formats. Aside from Ref-only, there are NL-only and Ref&NL formats, which existing match-based CEMs cannot effectively accommodate. In this paper, we propose CodeScore, a large language model (LLM)-based CEM, which estimates the functional correctness of generated code on three input types. To acquire CodeScore, we present UniCE, a unified code generation learning framework, for LLMs to learn code execution (i.e., learning PassRatio and Executability of generated code) with unified input. Extensive experimental results on multiple code evaluation datasets demonstrate that CodeScore absolutely improves up to 58.87% correlation with functional correctness compared to other CEMs, achieves state-of-the-art performance, and effectively handles three input formats.																																	2024-09-15	PPRN:86282181		
J	Zhang, Jiajie; Bai, Yushi; Lv, Xin; Gu, Wanjun; Liu, Danqing; Zou, Minhao; Cao, Shulin; Hou, Lei; Dong, Yuxiao; Feng, Ling; Li, Juanzi				Gu, Wanjun/B-3998-2010						LongCite: Enabling LLMs to Generate Fine-grained Citations in Long-context QA								Arxiv											1	1;2024-09-05;https://www.arxiv.org/abs/2409.02897v2	arXiv:2409.02897			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 05 2024	2024	Though current long-context large language models (LLMs) have demonstrated impressive capacities in answering user questions based on extensive text, the lack of citations in their responses makes user verification difficult, leading to concerns about their trustworthiness due to their potential hallucinations. In this work, we aim to enable long-context LLMs to generate responses with fine-grained sentence-level citations, improving their faithfulness and verifiability. We first introduce LongBench-Cite, an automated benchmark for assessing current LLMs' performance in Long-Context Question Answering with Citations (LQAC), revealing considerable room for improvement. To this end, we propose CoF (Coarse to Fine), a novel pipeline that utilizes off-the-shelf LLMs to automatically generate long-context QA instances with precise sentence-level citations, and leverage this pipeline to construct LongCite-45k, a large-scale SFT dataset for LQAC. Finally, we train LongCite-8B and LongCite-9B using the LongCite-45k dataset, successfully enabling their generation of accurate responses and fine-grained sentence-level citations in a single output. The evaluation results on LongBench-Cite show that our trained models achieve state-of-the-art citation quality, surpassing advanced proprietary models including GPT-4o. We also discover that SFT with citation information effectively reduces hallucinations and enables a more uniform utilization of context.																																	2024-09-18	PPRN:91754702		
J	Xu, Yiheng; Su, Hongjin; Xing, Chen; Mi, Boyu; Liu, Qian; Shi, Weijia; Hui, Binyuan; Zhou, Fan; Liu, Yitao; Xie, Tianbao; Cheng, Zhoujun; Zhao, Siheng; Kong, Lingpeng; Wang, Bailin; Xiong, Caiming; Yu, Tao				米, 博宇/AAR-2894-2021; Zhou, Fan/AAG-9824-2019; Yu, Tao/E-3335-2016; kong, lingpeng/NHQ-3170-2025; Bin/B-6414-2019						Lemur: Harmonizing Natural Language and Code for Language Agents								Arxiv											3	3;2024-08-24;https://www.arxiv.org/abs/2310.06830v2| 2;2023-10-10;https://www.arxiv.org/abs/2310.06830v1| 1;2023-10-10;https://www.arxiv.org/abs/2310.06830v1	arXiv:2310.06830			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 24 2024	2024	We introduce Lemur and Lemur-Chat, openly accessible language models optimized for both natural language and coding capabilities to serve as the backbone of versatile language agents. The evolution from language chat models to functional language agents demands that models not only master human interaction, reasoning, and planning but also ensure grounding in the relevant environments. This calls for a harmonious blend of language and coding capabilities in the models. Lemur and Lemur-Chat are proposed to address this necessity, demonstrating balanced proficiencies in both domains, unlike existing open-source models that tend to specialize in either. Through meticulous pre-training using a code-intensive corpus and instruction fine-tuning on text and code data, our models achieve state-of-the-art averaged performance across diverse text and coding benchmarks among open-source models. Comprehensive experiments demonstrate Lemur's superiority over existing open-source models and its proficiency across various agent tasks involving human communication, tool usage, and interaction under fully- and partially- observable environments. The harmonization between natural and programming languages enables Lemur-Chat to significantly narrow the gap with proprietary models on agent abilities, providing key insights into developing advanced open-source agents adept at reasoning, planning, and operating seamlessly across environments.																																	2024-09-04	PPRN:85521016		
J	Zhuge, Mingchen; Wang, Wenyi; Kirsch, Louis; Faccio, Francesco; Khizbullin, Dmitrii; Schmidhuber, Juergen				Khizbullin, Dmitrii/KSM-5227-2024						Language Agents as Optimizable Graphs								Arxiv											1	1;2024-08-22;https://www.arxiv.org/abs/2402.16823v3	arXiv:2402.16823			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 22 2024	2024	Various human-designed prompt engineering techniques have been proposed to improve problem solvers based on Large Language Models (LLMs), yielding many disparate code bases. We unify these approaches by describing LLM-based agents as computational graphs. The nodes implement functions to process multimodal data or query LLMs, and the edges describe the information flow between operations. Graphs can be recursively combined into larger composite graphs representing hierarchies of inter-agent collaboration (where edges connect operations of different agents). Our novel automatic graph optimizers (1) refine node-level LLM prompts (node optimization) and (2) improve agent orchestration by changing graph connectivity (edge optimization). Experiments demonstrate that our framework can be used to efficiently develop, integrate, and automatically improve various LLM agents. The code can be found here.																																	2024-08-31	PPRN:91505916		
J	Maamari, Karime; Abubaker, Fadhil; Jaroslawicz, Daniel; Mhedhbi, Amine										The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models								Arxiv											2	2;2024-08-18;https://www.arxiv.org/abs/2408.07702v2| 1;2024-08-14;https://www.arxiv.org/abs/2408.07702v1	arXiv:2408.07702			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Aug 18 2024	2024	Schema linking is a crucial step in Text-to-SQL pipelines. Its goal is to retrieve the relevant tables and columns of a target database for a user's query while disregarding irrelevant ones. However, imperfect schema linking can often exclude required columns needed for accurate query generation. In this work, we revisit schema linking when using the latest generation of large language models (LLMs). We find empirically that newer models are adept at utilizing relevant schema elements during generation even in the presence of large numbers of irrelevant ones. As such, our Text-to-SQL pipeline entirely forgoes schema linking in cases where the schema fits within the model's context window in order to minimize issues due to filtering required schema elements. Furthermore, instead of filtering contextual information, we highlight techniques such as augmentation, selection, and correction, and adopt them to improve the accuracy of our Text-to-SQL pipeline. Our approach ranks first on the BIRD benchmark achieving an accuracy of 71.83%.																																	2024-08-28	PPRN:91376253		
J	Shi, Yahao; Wu, Yanmin; Wu, Chenming; Liu, Xing; Zhao, Chen; Feng, Haocheng; Zhang, Jian; Zhou, Bin; Ding, Errui; Wang, Jingdong										GIR: 3D Gaussian Inverse Rendering for Relightable Scene Factorization								Arxiv											2	2;2024-08-15;https://www.arxiv.org/abs/2312.05133v2| 1;2023-12-08;https://www.arxiv.org/abs/2312.05133v1	arXiv:2312.05133			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 15 2024	2024	This paper presents a 3D Gaussian Inverse Rendering (GIR) method, employing 3D Gaussian representations to effectively factorize the scene into material properties, light, and geometry. The key contributions lie in three-fold. We compute the normal of each 3D Gaussian using the shortest eigenvector, with a directional masking scheme forcing accurate normal estimation without external supervision. We adopt an efficient voxel-based indirect illumination tracing scheme that stores direction-aware outgoing radiance in each 3D Gaussian to disentangle secondary illumination for approximating multi-bounce light transport. To further enhance the illumination disentanglement, we represent a high-resolution environmental map with a learnable lowresolution map and a lightweight, fully convolutional network. Our method achieves state-of-the-art performance in both relighting and novel view synthesis tasks among the recently proposed inverse rendering methods while achieving real-time rendering. This substantiates our proposed method’s efficacy and broad applicability, highlighting its potential as an influential tool in various real-time interactive graphics applications such as material editing and relighting. The code will be released at https://github.com/guduxiaolang/GIR.																																	2024-08-23	PPRN:86527629		
J	Kirchner, Jan Hendrik; Chen, Yining; Edwards, Harri; Leike, Jan; McAleese, Nat; Burda, Yuri				Chen, Yining/MBI-0491-2025						PROVER- VERIFIER GAMES IMPROVE LEGIBILITY OF LLM OUTPUTS								Arxiv											2	2;2024-08-01;https://www.arxiv.org/abs/2407.13692v2| 1;2024-07-18;https://www.arxiv.org/abs/2407.13692v1	arXiv:2407.13692			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 01 2024	2024	One way to increase confidence in the outputs of Large Language Models (LLMs) is to support them with reasoning that is clear and easy to check -- a property we call legibility. We study legibility in the context of solving grade-school math problems and show that optimizing chain-of-thought solutions only for answer correctness can make them less legible. To mitigate the loss in legibility, we propose a training algorithm inspired by Prover-Verifier Game from Anil et al. (2021). Our algorithm iteratively trains small verifiers to predict solution correctness, "helpful" provers to produce correct solutions that the verifier accepts, and "sneaky" provers to produce incorrect solutions that fool the verifier. We find that the helpful prover's accuracy and the verifier's robustness to adversarial attacks increase over the course of training. Furthermore, we show that legibility training transfers to time-constrained humans tasked with verifying solution correctness. Over course of LLM training human accuracy increases when checking the helpful prover's solutions, and decreases when checking the sneaky prover's solutions. Hence, training for checkability by small verifiers is a plausible technique for increasing output legibility. Our results suggest legibility training against small verifiers as a practical avenue for increasing legibility of large LLMs to humans, and thus could help with alignment of superhuman models.																																	2024-08-09	PPRN:90881004		
J	Chen, Canyu; Huang, Baixiang; Li, Zekun; Chen, Zhaorun; Lai, Shiyang; Xu, Xiongxiao; Gu, Jia-Chen; Gu, Jindong; Yao, Huaxiu; Xiao, Chaowei; Yan, Xifeng; Wang, William Yang; Torr, Philip; Song, Dawn; Shu, Kai				Chen, Canyu/KFT-0519-2024; Huang, Baixiang/LNQ-7071-2024; Xiao, Chaowei/AAT-8772-2021; Yao, Huaxiu/V-3516-2019; SHU, Kai/OEN-5324-2025; Chen, Zhaorun/AAT-1611-2021						Can Editing LLMs Inject Harm?								Arxiv											2	2;2024-07-31;https://www.arxiv.org/abs/2407.20224v2| 1;2024-07-29;https://www.arxiv.org/abs/2407.20224v1	arXiv:2407.20224			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 31 2024	2024	Knowledge editing techniques have been increasingly adopted to efficiently correct the false or outdated knowledge in Large Language Models (LLMs), due to the high cost of retraining from scratch. Meanwhile, one critical but under-explored question is: can knowledge editing be used to inject harm into LLMs? In this paper, we propose to reformulate knowledge editing as a new type of safety threat for LLMs, namely Editing Attack, and conduct a systematic investigation with a newly constructed dataset EditAttack. Specifically, we focus on two typical safety risks of Editing Attack including Misinformation Injection and Bias Injection. For the risk of misinformation injection, we first categorize it into commonsense misinformation injection and long-tail misinformation injection. Then, we find that editing attacks can inject both types of misinformation into LLMs, and the effectiveness is particularly high for commonsense misinformation injection. For the risk of bias injection, we discover that not only can biased sentences be injected into LLMs with high effectiveness, but also one single biased sentence injection can cause a bias increase in general outputs of LLMs, which are even highly irrelevant to the injected sentence, indicating a catastrophic impact on the overall fairness of LLMs. Then, we further illustrate the high stealthiness of editing attacks, measured by their impact on the general knowledge and reasoning capacities of LLMs, and show the hardness of defending editing attacks with empirical evidence. Our discoveries demonstrate the emerging misuse risks of knowledge editing techniques on compromising the safety alignment of LLMs.																																	2024-08-08	PPRN:91141825		
J	Zhang, Boyang; Tan, Yicong; Shen, Yun; Salem, Ahmed; Backes, Michael; Zannettou, Savvas; Zhang, Yang				Salem, Ahmed/NGR-3453-2025; Zhang, Boyang/JRY-0893-2023						Breaking Agents: Compromising Autonomous LLM Agents Through Malfunction Amplification								Arxiv											1	1;2024-07-30;https://www.arxiv.org/abs/2407.20859v1	arXiv:2407.20859			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 30 2024	2024	Recently, autonomous agents built on large language models (LLMs) have experienced significant development and are being deployed in real-world applications. These agents can extend the base LLM's capabilities in multiple ways. For example, a well-built agent using GPT-3.5-Turbo as its core can outperform the more advanced GPT-4 model by leveraging external components. More importantly, the usage of tools enables these systems to perform actions in the real world, moving from merely generating text to actively interacting with their environment. Given the agents' practical applications and their ability to execute consequential actions, it is crucial to assess potential vulnerabilities. Such autonomous systems can cause more severe damage than a standalone language model if compromised. While some existing research has explored harmful actions by LLM agents, our study approaches the vulnerability from a different perspective. We introduce a new type of attack that causes malfunctions by misleading the agent into executing repetitive or irrelevant actions. We conduct comprehensive evaluations using various attack methods, surfaces, and properties to pinpoint areas of susceptibility. Our experiments reveal that these attacks can induce failure rates exceeding 80% in multiple scenarios. Through attacks on implemented and deployable agents in multi-agent scenarios, we accentuate the realistic risks associated with these vulnerabilities. To mitigate such attacks, we propose self-examination detection methods. However, our findings indicate these attacks are difficult to detect effectively using LLMs alone, highlighting the substantial risks associated with this vulnerability.																																	2024-08-06	PPRN:91158113		
J	Chen, Zehui; Liu, Kuikun; Wang, Qiuchen; Liu, Jiangning; Zhang, Wenwei; Chen, Kai; Zhao, Feng				Zhang, Wenwei/HKO-4277-2023; Zhao, Feng/NGQ-9015-2025						MindSearch: Mimicking Human Minds Elicits Deep AI Searcher								Arxiv											1	1;2024-07-29;https://www.arxiv.org/abs/2407.20183v1	arXiv:2407.20183			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 29 2024	2024	Information seeking and integration is a complex cognitive task that consumes enormous time and effort. Inspired by the remarkable progress of Large Language Models, recent works attempt to solve this task by combining LLMs and search engines. However, these methods still obtain unsatisfying performance due to three challenges: (1) complex requests often cannot be accurately and completely retrieved by the search engine once (2) corresponding information to be integrated is spread over multiple web pages along with massive noise, and (3) a large number of web pages with long contents may quickly exceed the maximum context length of LLMs. Inspired by the cognitive process when humans solve these problems, we introduce MindSearch to mimic the human minds in web information seeking and integration, which can be instantiated by a simple yet effective LLM-based multi-agent framework. The WebPlanner models the human mind of multi-step information seeking as a dynamic graph construction process: it decomposes the user query into atomic sub-questions as nodes in the graph and progressively extends the graph based on the search result from WebSearcher. Tasked with each sub-question, WebSearcher performs hierarchical information retrieval with search engines and collects valuable information for WebPlanner. The multi-agent design of MindSearch enables the whole framework to seek and integrate information parallelly from larger-scale (e.g., more than 300) web pages in 3 minutes, which is worth 3 hours of human effort. MindSearch demonstrates significant improvement in the response quality in terms of depth and breadth, on both close-set and open-set QA problems. Besides, responses from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web and Perplexity.ai applications, which implies that MindSearch can already deliver a competitive solution to the proprietary AI search engine.																																	2024-08-04	PPRN:91142979		
J	Franciolini, Gabriele; Racco, Davide; Rompineve, Fabrizio				Rompineve, Fabrizio/AAN-4560-2020; Racco, Davide/HZJ-8429-2023						Footprints of the QCD Crossover on Cosmological Gravitational Waves at Pulsar Timing Arrays								Arxiv											2	2;2024-07-24;https://www.arxiv.org/abs/2306.17136v3| 1;2023-06-29;https://www.arxiv.org/abs/2306.17136v1	arXiv:2306.17136			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 24 2024	2024	Pulsar Timing Arrays (PTAs) have reported evidence for a stochastic gravitational wave (GW) background at nHz frequencies, possibly originating in the early Universe. We show that the spectral shape of the low-frequency (causality) tail of GW signals sourced at temperatures around T≳1 GeV is distinctively affected by confinement of strong interactions (QCD), due to the corresponding sharp decrease in the number of relativistic species. Bayesian analyses in the NANOGrav 15 years and the previous International PTA datasets reveal a significant improvement in the fit with respect to cubic power-law spectra, previously employed for the causality tail. This suggests that the inclusion of Standard Model effects on GWs can have a potentially decisive impact on model selection.																																	2024-07-31	PPRN:73640150		
J	Yao, Jiawei; Wu, Tong; Zhang, Xiaofeng				Yao, Jiawei/KJE-4634-2024; wu, tong/ITV-6896-2023; Zhang, Xiaofeng/AHH-7408-2022						Improving Depth Gradient Continuity in Transformers: A Comparative Study on Monocular Depth Estimation with CNN								Arxiv											3	3;2024-07-23;https://www.arxiv.org/abs/2308.08333v4| 2;2023-12-06;https://www.arxiv.org/abs/2308.08333v3| 1;2023-08-16;https://www.arxiv.org/abs/2308.08333v1	arXiv:2308.08333			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 23 2024	2024	Monocular depth estimation is an ongoing challenge in computer vision. Recent progress with Transformer models has demonstrated notable advantages over conventional CNNs in this area. However, there's still a gap in understanding how these models prioritize different regions in 2D images and how these regions affect depth estimation performance. To explore the differences between Transformers and CNNs, we employ a sparse pixel approach to contrastively analyze the distinctions between the two. Our findings suggest that while Transformers excel in handling global context and intricate textures, they lag behind CNNs in preserving depth gradient continuity. To further enhance the performance of Transformer models in monocular depth estimation, we propose the Depth Gradient Refinement (DGR) module that refines depth estimation through high-order differentiation, feature fusion, and recalibration. Additionally, we leverage optimal transport theory, treating depth maps as spatial probability distributions, and employ the optimal transport distance as a loss function to optimize our model. Experimental results demonstrate that models integrated with the plug-and-play Depth Gradient Refinement (DGR) module and the proposed loss function enhance performance without increasing complexity and computational costs on both outdoor KITTI and indoor NYU-Depth-v2 datasets. This research not only offers fresh insights into the distinctions between Transformers and CNNs in depth estimation but also paves the way for novel depth estimation methodologies.																																	2024-07-31	PPRN:78354144		
J	Costarelli, Anthony; Allen, Mat; Hauksson, Roman; Sodunke, Grace; Hariharan, Suhas; Cheng, Carlson; Li, Wenjie; Clymer, Joshua; Yadav, Arjun				Li, Wenjie/IZQ-0727-2023						GameBench: Evaluating Strategic Reasoning Abilities of LLM Agents								Arxiv											2	2;2024-07-22;https://www.arxiv.org/abs/2406.06613v2| 1;2024-06-07;https://www.arxiv.org/abs/2406.06613v1	arXiv:2406.06613			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 22 2024	2024	Large language models have demonstrated remarkable few-shot performance on many natural language understanding tasks. Despite several demonstrations of using large language models in complex, strategic scenarios, there lacks a comprehensive framework for evaluating agents’ performance across various types of reasoning found in games. To address this gap, we introduce G AME B ENCH , a cross-domain benchmark for evaluating strategic reasoning abilities of LLM agents. We focus on 9 different game environments, where each covers at least one axis of key reasoning skill identified in strategy games, and select games for which strategy explanations are unlikely to form a significant portion of models’ pretraining corpuses. Our evaluations use GPT-3 and GPT-4 in their base form along with two scaffolding frameworks designed to enhance strategic reasoning ability: Chain-of-Thought (CoT) prompting and Reasoning Via Planning (RAP). Our results show that none of the tested models match human performance, and at worst GPT-4 performs worse than random action. CoT and RAP both improve scores but not to comparable human levels. 																																	2024-07-28	PPRN:89282716		
J	Qu, Haoxuan; Rahmani, Hossein; Xu, Li; Williams, Bryan; Liu, Jun				Williams, Bryan/A-5021-2009; Rahmani, Hossein/S-5134-2019						Recent Advances of Continual Learning in Computer Vision: An Overview								Arxiv											3	3;2024-07-18;https://www.arxiv.org/abs/2109.11369v4| 2;2023-11-30;https://www.arxiv.org/abs/2109.11369v3| 1;2021-09-23;https://www.arxiv.org/abs/2109.11369v2	arXiv:2109.11369			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 18 2024	2024	In contrast to batch learning where all training data is available at once, continual learning represents a family of methods that accumulate knowledge and learn continuously with data available in sequential order. Similar to the human learning process with the ability of learning, fusing, and accumulating new knowledge coming at different time steps, continual learning is considered to have high practical significance. Hence, continual learning has been studied in various artificial intelligence tasks. In this paper, we present a comprehensive review of the recent progress of continual learning in computer vision. In particular, the works are grouped by their representative techniques, including regularization, knowledge distillation, memory, generative replay, parameter isolation, and a combination of the above techniques. For each category of these techniques, both its characteristics and applications in computer vision are presented. At the end of this overview, several subareas, where continuous knowledge accumulation is potentially helpful while continual learning has not been well studied, are discussed.																																	2024-07-26	PPRN:13493411		
J	Liu, Guanlin; Wang, Yu; Zhao, Wen				Zhao, Wen/KRQ-2107-2024						Impact of LRG1 and LRG2 in DESI 2024 BAO data on dark energy evolution								Arxiv											2	2;2024-07-12;https://www.arxiv.org/abs/2407.04385v2| 1;2024-07-05;https://www.arxiv.org/abs/2407.04385v1	arXiv:2407.04385			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 12 2024	2024	Recent measurements of baryon acoustic oscillations (BAO) by the Dark Energy Spectroscopic Instrument (DESI) suggest a preference for a dynamic dark energy model over a cosmological constant. This conclusion emerges from the combination of DESI's BAO data with observations of the Cosmic Microwave Background (CMB) and various type Ia supernova (SN Ia) catalogues. The deviation observed in the cosmological constant (Λ) reflects a departure from the standard cosmological model. Testing this deviation involves examining the consistency between cosmological parameters derived from early and late-time observations. Specifically, we focus on the matter density parameter ωm=Ωmh2 and introduce ratio(ωm) to assess consistency, which is defined as the ratio of ωm values constrained by high and low-redshift measurements. This ratio serves as a metric for quantifying deviations from the ΛCDM model. In this paper, we find that the DESI BAO+CMB yields ratio(ωm)=1.0171±0.0066. Upon excluding the LRG1 and LRG2 data in DESI BAO, this ratio adjusts to ratio(ωm)=1.0100±0.0082. This shift, corresponding to a change from 2.6σ to 1.2σ, indicates that the deviation from the ΛCDM model is predominantly driven by these two samples from the DESI BAO measurements. To substantiate this conclusion, we utilized two cosmological model-independent methods to reconstruct the cosmic expansion history. Both reconstructions of the Hubble parameter H(z) indicate that the evolving features of dark energy are determined by the combined LRG1 and LRG2 data. Therefore, different methods have reached the same conclusion, namely the importance of accurately measuring the BAO feature in LRG1 and LRG2 data.																																	2024-07-23	PPRN:90732386		
J	Ma, Yubo; Zang, Yuhang; Chen, Liangyu; Chen, Meiqi; Jiao, Yizhu; Li, Xinze; Lu, Xinyuan; Liu, Ziyu; Ma, Yan; Dong, Xiaoyi; Zhang, Pan; Pan, Liangming; Jiang, Yu-Gang; Wang, Jiaqi; Cao, Yixin; Sun, Aixin				WANG, JIAQI/KBB-8837-2024; Lu, Xinyuan/MSX-3675-2025; Li, Xinze/HSE-6841-2023; cao, yixin/ABV-6408-2022; Pan, Liangming/LIF-2753-2024; Zang, Yuhang/AES-3018-2022; Sun, Aixin/A-9852-2008; Dong, Xiaoyi/AAC-8666-2019; Ma, Yubo/AAK-2005-2021						MMLongBench-Doc: Benchmarking Long-context Document Understanding with Visualizations								Arxiv											2	2;2024-07-10;https://www.arxiv.org/abs/2407.01523v2| 1;2024-07-01;https://www.arxiv.org/abs/2407.01523v1	arXiv:2407.01523			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jul 10 2024	2024	Understanding documents with rich layouts and multi-modal components is a long-standing and practical task. Recent Large Vision-Language Models (LVLMs) have made remarkable strides in various tasks, particularly in single-page document understanding (DU). However, their abilities on long-context DU remain an open problem. This work presents MMLongBench-Doc, a long-context, multi-modal benchmark comprising 1,062 expert-annotated questions. Distinct from previous datasets, it is constructed upon 130 lengthy PDF-formatted documents with an average of 49.4 pages and 20,971 textual tokens. Towards comprehensive evaluation, answers to these questions rely on pieces of evidence from (1) different sources (text, image, chart, table, and layout structure) and (2) various locations (i.e. page number). Moreover, 33.2% of the questions are cross-page questions requiring evidence across multiple pages. 22.8% of the questions are designed to be unanswerable for detecting potential hallucinations. Experiments on 14 LVLMs demonstrate that long-context DU greatly challenges current models. Notably, the best-performing model, GPT-4o, achieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores 31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse performance than their LLM counterparts which are fed with lossy-parsed OCR documents. These results validate the necessity of future research toward more capable long-context LVLMs. Project Page: https://mayubo2333.github.io/MMLongBench-Doc																																	2024-07-21	PPRN:90652946		
J	Ju, Xuan; Gao, Yiming; Zhang, Zhaoyang; Yuan, Ziyang; Wang, Xintao; Zeng, Ailing; Xiong, Yu; Xu, Qiang; Shan, Ying				Yuan, Ziyang/GYV-1658-2022; Zhang, Yang/I-4284-2014						MiraData: A Large-Scale Video Dataset with Long Durations and Structured Captions								Arxiv											1	1;2024-07-08;https://www.arxiv.org/abs/2407.06358v1	arXiv:2407.06358			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 08 2024	2024	Sora's high-motion intensity and long consistent videos have significantly impacted the field of video generation, attracting unprecedented attention. However, existing publicly available datasets are inadequate for generating Sora-like videos, as they mainly contain short videos with low motion intensity and brief captions. To address these issues, we propose MiraData, a high-quality video dataset that surpasses previous ones in video duration, caption detail, motion strength, and visual quality. We curate MiraData from diverse, manually selected sources and meticulously process the data to obtain semantically consistent clips. GPT-4V is employed to annotate structured captions, providing detailed descriptions from four different perspectives along with a summarized dense caption. To better assess temporal consistency and motion intensity in video generation, we introduce MiraBench, which enhances existing benchmarks by adding 3D consistency and tracking-based motion strength metrics. MiraBench includes 150 evaluation prompts and 17 metrics covering temporal consistency, motion strength, 3D consistency, visual quality, text-video alignment, and distribution similarity. To demonstrate the utility and effectiveness of MiraData, we conduct experiments using our DiT-based video generation model, MiraDiT. The experimental results on MiraBench demonstrate the superiority of MiraData, especially in motion strength.																																	2024-07-21	PPRN:90751292		
J	Amayuelas, Alfonso; Wong, Kyle; Pan, Liangming; Chen, Wenhu; Wang, William				Pan, Liangming/LIF-2753-2024						Knowledge of Knowledge: <italic>Exploring Known-Unknowns Uncertainty with Large Language Models</italic>								Arxiv											3	3;2024-07-02;https://www.arxiv.org/abs/2305.13712v3| 2;2024-06-20;https://www.arxiv.org/abs/2305.13712v2| 1;2023-05-23;https://www.arxiv.org/abs/2305.13712v1	arXiv:2305.13712			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 02 2024	2024	This paper investigates the capabilities of Large Language Models (LLMs) in the context of understanding their knowledge and uncertainty over questions. Specifically, we focus on addressing known-unknown questions, characterized by high uncertainty due to the absence of definitive answers. To facilitate our study, we collect a new dataset with Known-Unknown Questions (KUQ) and establish a categorization framework to clarify the origins of uncertainty in such queries. Subsequently, we examine the performance of open-source LLMs, fine-tuned using this dataset, in distinguishing between known and unknown queries within open-ended question-answering scenarios. The fine-tuned models demonstrated a significant improvement, achieving a considerable increase in F1-score relative to their pre-fine-tuning state. Through a comprehensive analysis, we reveal insights into the models' improved uncertainty articulation and their consequent efficacy in multi-agent debates. These findings help us understand how LLMs can be trained to identify and express uncertainty, improving our knowledge of how they understand and express complex or unclear information.																																	2024-07-20	PPRN:71604810		
J	Duan, Yuanxing; Wei, Fangyin; Dai, Qiyu; He, Yuhang; Chen, Wenzheng; Chen, Baoquan				he, yuhang/GVP-6700-2022; Chen, Wenzheng/AAW-2088-2021						4D-Rotor Gaussian Splatting: Towards Efficient Novel View Synthesis for Dynamic Scenes								Arxiv											3	3;2024-07-02;https://www.arxiv.org/abs/2402.03307v3| 2;2024-02-07;https://www.arxiv.org/abs/2402.03307v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.03307v1	arXiv:2402.03307			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 02 2024	2024	We consider the problem of novel-view synthesis (NVS) for dynamic scenes. Recent neural approaches have accomplished exceptional NVS results for static 3D scenes, but extensions to 4D time-varying scenes remain non-trivial. Prior efforts often encode dynamics by learning a canonical space plus implicit or explicit deformation fields, which struggle in challenging scenarios like sudden movements or generating high-fidelity renderings. In this paper, we introduce 4D Gaussian Splatting (4DRotorGS), a novel method that represents dynamic scenes with anisotropic 4D XYZT Gaussians, inspired by the success of 3D Gaussian Splatting in static scenes. We model dynamics at each timestamp by temporally slicing the 4D Gaussians, which naturally compose dynamic 3D Gaussians and can be seamlessly projected into images. As an explicit spatial-temporal representation, 4DRotorGS demonstrates powerful capabilities for modeling complicated dynamics and fine details--especially for scenes with abrupt motions. We further implement our temporal slicing and splatting techniques in a highly optimized CUDA acceleration framework, achieving real-time inference rendering speeds of up to 277 FPS on an RTX 3090 GPU and 583 FPS on an RTX 4090 GPU. Rigorous evaluations on scenes with diverse motions showcase the superior efficiency and effectiveness of 4DRotorGS, which consistently outperforms existing methods both quantitatively and qualitatively.																																	2024-07-19	PPRN:87524192		
J	Hsiao, Tiger Yu-Yang; Abdurro'uf; Coe, Dan; Larson, Rebecca L.; Jung, Intae; Mingozzi, Matilde; Dayal, Pratika; Kumari, Nimisha; Kokorev, Vasily; Vikaeus, Anton; Brammer, Gabriel; Furtak, Lukas J.; Adamo, Angela; Andrade-Santos, Felipe; Antwi-Danso, Jacqueline; Bradac, Marusa; Bradley, Larry D.; Broadhurst, Tom; Carnall, Adam C.; Conselice, Christopher J.; Diego, Jose M.; Donahue, Megan; Eldridge, Jan J.; Fujimoto, Seiji; Henry, Alaina; Hernandez, Svea; Hutchison, Taylor A.; James, Bethan L.; Norman, Colin; Park, Hyunbae; Pirzkal, Norbert; Postman, Marc; Ricotti, Massimo; Rigby, Jane R.; Vanzella, Eros; Welch, Brian; Wilkins, Stephen M.; Windhorst, Rogier A.; Xu, Xinfeng; Zackrisson, Erik; Zitrin, Adi				Abdurro'uf/ABB-9156-2021; Eldridge, Jan/KFA-2853-2024; Kokorev, Vasily/GPK-2541-2022; Kumari, Nimisha/AFS-1631-2022; dayal, Pratika/AAD-4237-2019; Brammer, Gabriel/AAB-4859-2020; Rigby, Jane/D-4588-2012; Ricotti, Massimo/LXA-2067-2024; Conselice, Christopher/B-4348-2013; Mingozzi, Matilde/GQY-8008-2022; Broadhurst, Thomas/AAF-9891-2019; Diego, Jose/I-2511-2015						<italic>JWST </italic>NIRSpec spectroscopy of the triply-lensedz= 10.17galaxy MACS0647–JD								Arxiv											2	2;2024-07-02;https://www.arxiv.org/abs/2305.03042v2| 1;2023-05-04;https://www.arxiv.org/abs/2305.03042v1	arXiv:2305.03042			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 02 2024	2024	We present JWST/NIRSpec prism spectroscopy of MACS0647-JD, the triply-lensed z∼11 candidate discovered in HST imaging and spatially resolved by JWST imaging into two components A and B. Spectroscopy of component A yields a spectroscopic redshift z=10.17 based on 7 detected emission lines: CIII] λλ1907,1909, [OII] λ3727, [NeIII] λ3869, [NeIII] λ3968, Hδ λ4101, Hγ λ4340, and [OIII] λ4363. These are the second-most distant detections of these emission lines to date, in a galaxy observed just 460 million years after the Big Bang. Based on observed and extrapolated line flux ratios we derive a gas-phase metallicity Z= log(O/H) = 7.5−8.0, or (0.06−0.2) Z⊙, ionization parameter log(U) ∼−1.9±0.2, and an ionizing photon production efficiency log(ξion)=25.2±0.2erg−1 Hz. The spectrum has a softened Lyman-α break, evidence for a strong Lyα damping wing, suggesting that MACS0647-JD was unable to ionize its surroundings beyond its immediate vicinity (RHII≪1 pMpc). The Lyα damping wing also suppresses the F150W photometry, explaining the slightly overestimated photometric redshift z=10.6±0.3. MACS0647-JD has a stellar mass log(M/M⊙) = 8.1±0.3, including ∼ 6×107M⊙ in component A, most of which formed recently (within ∼ 20 Myr) with a star formation rate 2±1M⊙ / yr, all within an effective radius 70±24pc. The smaller component B (r∼20) pc is likely older (∼100 Myr) with more dust (AV∼0.1 mag), as found previously. Spectroscopy of a fainter companion galaxy C separated by a distance of ∼3kpc reveals a Lyman break consistent with z=10.17. MACS0647-JD is likely the most distant galaxy merger known.																																	2024-08-05	PPRN:67321388		
J	Liu, Chenxi; Yang, Sun; Xu, Qianxiong; Li, Zhishuai; Long, Cheng; Li, Ziyue; Zhao, Rui				Li, Ziyue/JXW-6558-2024; Long, Cheng/KXR-2733-2024						Spatial-Temporal Large Language Model for Traffic Prediction								Arxiv											4	4;2024-06-18;https://www.arxiv.org/abs/2401.10134v3| 3;2024-01-23;https://www.arxiv.org/abs/2401.10134v2| 2;2024-01-18;https://www.arxiv.org/abs/2401.10134v1| 1;2024-07-01;	arXiv:2401.10134			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 01 2024	2024	Traffic prediction, an essential component for intelligent transportation systems, endeavours to use historical data to foresee future traffic features at specific locations. Although existing traffic prediction models often emphasize developing complex neural network structures, their accuracy has not improved. Recently, large language models have shown outstanding capabilities in time series analysis. Differing from existing models, LLMs progress mainly through parameter expansion and extensive pretraining while maintaining their fundamental structures. Motivated by these developments, we propose a Spatial-Temporal Large Language Model (ST-LLM) for traffic prediction. In the ST-LLM, we define timesteps at each location as tokens and design a spatial-temporal embedding to learn the spatial location and global temporal patterns of these tokens. Additionally, we integrate these embeddings by a fusion convolution to each token for a unified spatial-temporal representation. Furthermore, we innovate a partially frozen attention strategy to adapt the LLM to capture global spatial-temporal dependencies for traffic prediction. Comprehensive experiments on real traffic datasets offer evidence that ST-LLM is a powerful spatial-temporal learner that outperforms state-of-the-art models. Notably, the ST-LLM also exhibits robust performance in both few-shot and zero-shot prediction scenarios. 																																	2024-11-18	PPRN:87224197		
J	Zhao, Tianchen; Fang, Tongcheng; Liu, Enshu; Wan, Rui; Soedarmadji, Widyadewi; Li, Shiyao; Lin, Zinan; Dai, Guohao; Yan, Shengen; Yang, Huazhong; Ning, Xuefei; Wang, Yu				Li, Shiyao/OYE-4903-2025; Liu, Enshu/OTH-2681-2025; Lin, Zinan/NGS-1685-2025; yang, huazhong/ACF-0711-2022						ViDiT-Q: Efficient and Accurate Quantization of Diffusion Transformers for Image and Video Generation								Arxiv											2	2;2024-06-30;https://www.arxiv.org/abs/2406.02540v2| 1;2024-06-04;https://www.arxiv.org/abs/2406.02540v1	arXiv:2406.02540			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 30 2024	2024	Diffusion transformers (DiTs) have exhibited remarkable performance in visual generation tasks, such as generating realistic images or videos based on textual instructions. However, larger model sizes and multi-frame processing for video generation lead to increased computational and memory costs, posing challenges for practical deployment on edge devices. Post-Training Quantization (PTQ) is an effective method for reducing memory costs and computational complexity. When quantizing diffusion transformers, we find that applying existing diffusion quantization methods designed for U-Net faces challenges in preserving quality. After analyzing the major challenges for quantizing diffusion transformers, we design an improved quantization scheme: "ViDiT-Q": Video and Image Diffusion Transformer Quantization) to address these issues. Furthermore, we identify highly sensitive layers and timesteps hinder quantization for lower bit-widths. To tackle this, we improve ViDiT-Q with a novel metric-decoupled mixed-precision quantization method (ViDiT-Q-MP). We validate the effectiveness of ViDiT-Q across a variety of text-to-image and video models. While baseline quantization methods fail at W8A8 and produce unreadable content at W4A8, ViDiT-Q achieves lossless W8A8 quantization. ViDiTQ-MP achieves W4A8 with negligible visual quality degradation, resulting in a 2.5x memory optimization and a 1.5x latency speedup.																																	2024-07-18	PPRN:89261000		
J	Fan, Zhihao; Tang, Jialong; Chen, Wei; Wang, Siyuan; Wei, Zhongyu; Xi, Jun; Huang, Fei; Zhou, Jingren				Tang, Jialong/JMC-2179-2023; Zhou, Mingyuan/AAE-8717-2021						AI Hospital: Benchmarking Large Language Models in a Multi-agent Medical Interaction Simulator								Arxiv											4	4;2024-06-28;https://www.arxiv.org/abs/2402.09742v4| 3;2024-06-27;https://www.arxiv.org/abs/2402.09742v3| 2;2024-02-21;https://www.arxiv.org/abs/2402.09742v2| 1;2024-02-15;https://www.arxiv.org/abs/2402.09742v1	arXiv:2402.09742			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 28 2024	2024	Artificial intelligence has significantly advanced healthcare, particularly through large language models (LLMs) that excel in medical question answering benchmarks. However, their real-world clinical application remains limited due to the complexities of doctor-patient interactions. To address this, we introduce textbf{AI Hospital}, a multi-agent framework simulating dynamic medical interactions between emph{Doctor} as player and NPCs including emph{Patient}, emph{Examiner}, emph{Chief Physician}. This setup allows for realistic assessments of LLMs in clinical scenarios. We develop the Multi-View Medical Evaluation (MVME) benchmark, utilizing high-quality Chinese medical records and NPCs to evaluate LLMs' performance in symptom collection, examination recommendations, and diagnoses. Additionally, a dispute resolution collaborative mechanism is proposed to enhance diagnostic accuracy through iterative discussions. Despite improvements, current LLMs exhibit significant performance gaps in multi-turn interactions compared to one-step approaches. Our findings highlight the need for further research to bridge these gaps and improve LLMs' clinical diagnostic capabilities. 																																	2024-07-17	PPRN:87704216		
J	Halawi, Danny; Wei, Alexander; Wallace, Eric; Wang, Tony T.; Haghtalab, Nika; Steinhardt, Jacob				Wei, Alex/AAS-2098-2021						Covert Malicious Finetuning: Challenges in Safeguarding LLM Adaptation								Arxiv											1	1;2024-06-28;https://www.arxiv.org/abs/2406.20053v1	arXiv:2406.20053			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 28 2024	2024	Black-box finetuning is an emerging interface for adapting state-of-the-art language models to user needs. However, such access may also let malicious actors undermine model safety. To demonstrate the challenge of defending finetuning interfaces, we introduce covert malicious finetuning, a method to compromise model safety via finetuning while evading detection. Our method constructs a malicious dataset where every individual datapoint appears innocuous, but finetuning on the dataset teaches the model to respond to encoded harmful requests with encoded harmful responses. Applied to GPT-4, our method produces a finetuned model that acts on harmful instructions 99% of the time and avoids detection by defense mechanisms such as dataset inspection, safety evaluations, and input/output classifiers. Our findings question whether black-box finetuning access can be secured against sophisticated adversaries.																																	2024-07-17	PPRN:90630986		
J	Li, Yuan; Huang, Yue; Wang, Hongyi; Zhang, Xiangliang; Zou, James; Sun, Lichao				Wang, Hongyi/KMA-5952-2024; Zhang, Xiangliang/GXF-6961-2022						Quantifying AI Psychology: A Psychometrics Benchmark for Large Language Models								Arxiv											1	1;2024-06-25;https://www.arxiv.org/abs/2406.17675v1	arXiv:2406.17675			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 25 2024	2024	Large Language Models (LLMs) have demonstrated exceptional task-solving capabilities, increasingly adopting roles akin to human-like assistants. The broader integration of LLMs into society has sparked interest in whether they manifest psychological attributes, and whether these attributes are stable-inquiries that could deepen the understanding of their behaviors. Inspired by psychometrics, this paper presents a framework for investigating psychology in LLMs, including psychological dimension identification, assessment dataset curation, and assessment with results validation. Following this framework, we introduce a comprehensive psychometrics benchmark for LLMs that covers six psychological dimensions: personality, values, emotion, theory of mind, motivation, and intelligence. This benchmark includes thirteen datasets featuring diverse scenarios and item types. Our findings indicate that LLMs manifest a broad spectrum of psychological attributes. We also uncover discrepancies between LLMs' self-reported traits and their behaviors in real-world scenarios. This paper demonstrates a thorough psychometric assessment of LLMs, providing insights into reliable evaluation and potential applications in AI and social sciences.																																	2024-07-15	PPRN:89512942		
J	Chen, Jianhui; Wang, Xiaozhi; Yao, Zijun; Bai, Yushi; Hou, Lei; Li, Juanzi				Wang, Xiaozhi/IQT-4844-2023						Finding Safety Neurons in Large Language Models								Arxiv											1	1;2024-06-20;https://www.arxiv.org/abs/2406.14144v1	arXiv:2406.14144			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 20 2024	2024	Large language models (LLMs) excel in various capabilities but also pose safety risks such as generating harmful content and misinformation, even after safety alignment. In this paper, we explore the inner mechanisms of safety alignment from the perspective of mechanistic interpretability, focusing on identifying and analyzing safety neurons within LLMs that are responsible for safety behaviors. We propose generation-time activation contrasting to locate these neurons and dynamic activation patching to evaluate their causal effects. Experiments on multiple recent LLMs show that: (1) Safety neurons are sparse and effective. We can restore $90$% safety performance with intervention only on about $5$% of all the neurons. (2) Safety neurons encode transferrable mechanisms. They exhibit consistent effectiveness on different red-teaming datasets. The finding of safety neurons also interprets "alignment tax". We observe that the identified key neurons for safety and helpfulness significantly overlap, but they require different activation patterns of the shared neurons. Furthermore, we demonstrate an application of safety neurons in detecting unsafe outputs before generation. Our findings may promote further research on understanding LLM alignment. The source codes will be publicly released to facilitate future research.																																	2024-07-10	PPRN:89376941		
J	Xie, Qianqian; Han, Weiguang; Chen, Zhengyu; Xiang, Ruoyu; Zhang, Xiao; He, Yueru; Xiao, Mengxi; Li, Dong; Dai, Yongfu; Feng, Duanyu; Xu, Yijing; Kang, Haoqiang; Kuang, Ziyan; Yuan, Chenhan; Yang, Kailai; Luo, Zheheng; Zhang, Tianlin; Liu, Zhiwei; Xiong, Guojun; Deng, Zhiyang; Jiang, Yuechen; Yao, Zhiyuan; Li, Haohang; Yu, Yangyang; Hu, Gang; Huang, Jiajia; Liu, Xiao-Yang; Lopez-Lira, Alejandro; Wang, Benyou; Lai, Yanzhao; Wang, Hao; Peng, Min; Ananiadou, Sophia; Huang, Jimin				Liu, Xiao-Yang/AAZ-8384-2020; YAO, Zhiyuan/GRO-1180-2022; Li, Haohang/HSF-3194-2023; PENG, MINXUAN/LLM-9318-2024; huang, jiajia/AGX-8911-2022; Chen, Zhengyu/V-8873-2019; Zhang, Tianlin/V-8168-2019; Yang, Kailai/KIB-2102-2024; Feng, Duanyu/OML-4880-2025; Deng, Zhiyang/KJL-7132-2024; HU, GANG/JXL-4828-2024; Wang, Benyou/Y-5146-2019						FinBen: A Holistic Financial Benchmark for Large Language Models								Arxiv											2	2;2024-06-19;https://www.arxiv.org/abs/2402.12659v2| 1;2024-02-20;https://www.arxiv.org/abs/2402.12659v1	arXiv:2402.12659			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 19 2024	2024	LLMs have transformed NLP and shown promise in various fields, yet their potential in finance is underexplored due to a lack of comprehensive evaluation benchmarks, the rapid development of LLMs, and the complexity of financial tasks. In this paper, we introduce FinBen, the first extensive open-source evaluation benchmark, including 36 datasets spanning 24 financial tasks, covering seven critical aspects: information extraction (IE), textual analysis, question answering (QA), text generation, risk management, forecasting, and decision-making. FinBen offers several key innovations: a broader range of tasks and datasets, the first evaluation of stock trading, novel agent and Retrieval-Augmented Generation (RAG) evaluation, and three novel open-source evaluation datasets for text summarization, question answering, and stock trading. Our evaluation of 15 representative LLMs, including GPT-4, ChatGPT, and the latest Gemini, reveals several key findings: While LLMs excel in IE and textual analysis, they struggle with advanced reasoning and complex tasks like text generation and forecasting. GPT-4 excels in IE and stock trading, while Gemini is better at text generation and forecasting. Instruction-tuned LLMs improve textual analysis but offer limited benefits for complex tasks such as QA. FinBen has been used to host the first financial LLMs shared task at the FinNLP-AgentScen workshop during IJCAI-2024, attracting 12 teams. Their novel solutions outperformed GPT-4, showcasing FinBen's potential to drive innovation in financial LLMs. All datasets, results, and codes are released for the research community1.																																	2024-07-10	PPRN:87772394		
J	Niu, Dantong; Sharma, Yuvan; Biamby, Giscard; Quenum, Jerome; Bai, Yutong; Shi, Baifeng; Darrell, Trevor; Herzig, Roei				Herzig, Roei/JEP-6447-2023						LLARVA: Vision-Action Instruction Tuning Enhances Robot Learning								Arxiv											1	1;2024-06-17;https://www.arxiv.org/abs/2406.11815v1	arXiv:2406.11815			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 17 2024	2024	In recent years, instruction-tuned Large Multimodal Models (LMMs) have been successful at several tasks, including image captioning and visual question answering; yet leveraging these models remains an open question for robotics. Prior LMMs for robotics applications have been extensively trained on language and action data, but their ability to generalize in different settings has often been less than desired. To address this, we introduce LLARVA, a model trained with a novel instruction tuning method that leverages structured prompts to unify a range of robotic learning tasks, scenarios, and environments. Additionally, we show that predicting intermediate 2-D representations, which we refer to as "visual traces", can help further align vision and action spaces for robot learning. We generate 8.5M image-visual trace pairs from the Open X-Embodiment dataset in order to pre-train our model, and we evaluate on 12 different tasks in the RLBench simulator as well as a physical Franka Emika Panda 7-DoF robot. Our experiments yield strong performance, demonstrating that LLARVA - using 2-D and language representations - performs well compared to several contemporary baselines, and can generalize across various robot environments and configurations.																																	2024-07-04	PPRN:89347821		
J	Chen, Jiawei; Yang, Dingkang; Wu, Tong; Jiang, Yue; Hou, Xiaolu; Li, Mingcheng; Wang, Shunli; Xiao, Dongling; Li, Ke; Zhang, Lihua				W, SL/GYT-9946-2022; Hou, Xiaolu/AAM-3034-2021; Li, Ke/KSM-7426-2024						Detecting and Evaluating Medical Hallucinations in Large Vision Language Models								Arxiv											1	1;2024-06-14;https://www.arxiv.org/abs/2406.10185v1	arXiv:2406.10185			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 14 2024	2024	Large Vision Language Models (LVLMs) are increasingly integral to healthcare applications, including medical visual question answering and imaging report generation. While these models inherit the robust capabilities of foundational Large Language Models (LLMs), they also inherit susceptibility to hallucinations-a significant concern in high-stakes medical contexts where the margin for error is minimal. However, currently, there are no dedicated methods or benchmarks for hallucination detection and evaluation in the medical field. To bridge this gap, we introduce Med-HallMark, the first benchmark specifically designed for hallucination detection and evaluation within the medical multimodal domain. This benchmark provides multi-tasking hallucination support, multifaceted hallucination data, and hierarchical hallucination categorization. Furthermore, we propose the MediHall Score, a new medical evaluative metric designed to assess LVLMs' hallucinations through a hierarchical scoring system that considers the severity and type of hallucination, thereby enabling a granular assessment of potential clinical impacts. We also present MediHallDetector, a novel Medical LVLM engineered for precise hallucination detection, which employs multitask training for hallucination detection. Through extensive experimental evaluations, we establish baselines for popular LVLMs using our benchmark. The findings indicate that MediHall Score provides a more nuanced understanding of hallucination impacts compared to traditional metrics and demonstrate the enhanced performance of MediHallDetector. We hope this work can significantly improve the reliability of LVLMs in medical applications. All resources of this work will be released soon.																																	2024-07-02	PPRN:89327949		
J	Wang, Junke; Jiang, Yi; Yuan, Zehuan; Peng, Binyue; Wu, Zuxuan; Jiang, Yu-Gang				wang, junke/KRP-4527-2024						OmniTokenizer: A Joint Image-Video Tokenizer for Visual Generation								Arxiv											1	1;2024-06-13;https://www.arxiv.org/abs/2406.09399v1	arXiv:2406.09399			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 13 2024	2024	Tokenizer, serving as a translator to map the intricate visual data into a compact latent space, lies at the core of visual generative models. Based on the finding that existing tokenizers are tailored to image or video inputs, this paper presents OmniTokenizer, a transformer -based tokenizer for joint image and video tokenization. OmniTokenizer is designed with a spatial -temporal decoupled architecture, which integrates window and causal attention for spatial and temporal modeling. To exploit the complementary nature of image and video data, we further propose a progressive training strategy, where OmniTokenizer is first trained on image data on a fixed resolution to develop the spatial encoding capacity and then jointly trained on image and video data on multiple resolutions to learn the temporal dynamics. OmniTokenizer, for the first time, handles both image and video inputs within a unified framework and proves the possibility of realizing their synergy. Extensive experiments demonstrate that OmniTokenizer achieves state-of-the-art (SOTA) reconstruction performance on various image and video datasets, e.g., , 1.11 reconstruction FID on ImageNet and 42 reconstruction FVD on UCF-101, beating the previous SOTA methods by 13% and 26%, respectively. Additionally, we also show that when integrated with OmniTokenizer, both language model -based approaches and diffusion models can realize advanced visual synthesis performance, underscoring the superiority and versatility of our method.																																	2024-07-02	PPRN:89302974		
J	Ma, Siyuan; Luo, Weidi; Wang, Yu; Liu, Xiaogeng				Liu, Xiaogeng/KIJ-1671-2024; Ma, Siyuan/IVV-8174-2023						Visual-RolePlay: Universal Jailbreak Attack on MultiModal Large Language Models via Role-playing Image Character								Arxiv											2	2;2024-06-12;https://www.arxiv.org/abs/2405.20773v2| 1;2024-05-25;https://www.arxiv.org/abs/2405.20773v1	arXiv:2405.20773			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 12 2024	2024	With the advent and widespread deployment of Multimodal Large Language Models (MLLMs), ensuring their safety has become increasingly critical. To achieve this objective, it requires us to proactively discover the vulnerabilities of MLLMs by exploring attack methods. Thus, structure -based jailbreak attacks, where harmful semantic content is embedded within images, have been proposed to mislead the models. However, previous structure -based jailbreak methods mainly focus on transforming the format of malicious queries, such as converting harmful content into images through typography, which lacks sufficient jailbreak effectiveness and generalizability. To address these limitations, we first introduce the concept of “Role-play” into MLLM jailbreak attacks and propose a novel and effective method called Visual Role-play (VRP). Specifically, VRP leverages Large Language Models to generate detailed descriptions of high -risk characters and create corresponding images based on the descriptions. When paired with benign role-play instruction texts, these high -risk character images effectively mislead MLLMs into generating malicious responses by enacting characters with negative attributes. We further extend our VRP method into a universal setup to demonstrate its generalizability. Extensive experiments on popular benchmarks show that VRP outperforms the strongest baselines, Query relevant [36] and FigStep [14], by an average Attack Success Rate (ASR) margin of 14.3% across all models.																																	2024-07-10	PPRN:89131598		
J	Gupta, Akshat; Rao, Anurag; Anumanchipalli, Gopala										Model Editing at Scale leads to Gradual and Catastrophic Forgetting								Arxiv											4	4;2024-06-10;https://www.arxiv.org/abs/2401.07453v4| 3;2024-05-22;https://www.arxiv.org/abs/2401.07453v3| 2;2024-02-20;https://www.arxiv.org/abs/2401.07453v2| 1;2024-01-15;https://www.arxiv.org/abs/2401.07453v1	arXiv:2401.07453			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 10 2024	2024	Editing knowledge in large language models is an attractive capability to have which allows us to correct incorrectly learnt facts during pre-training, as well as update the model with an ever-growing list of new facts. While existing model editing techniques have shown promise, they are usually evaluated using metrics for reliability, specificity and generalization over one or few edits. We argue that for model editing to have practical utility, we must be able to make multiple edits to the same model. With this in mind, we evaluate the current model editing methods at scale, focusing on two state of the art methods: ROME and MEMIT. We find that as the model is edited sequentially with multiple facts, it continually forgets previously edited facts and the ability to perform downstream tasks. This forgetting happens in two phases -- an initial gradual but progressive forgetting phase followed by abrupt or catastrophic forgetting phase. Both gradual and catastrophic forgetting limit the usefulness of model editing methods at scale -- the former making model editing less effective as multiple edits are made to the model while the latter caps the scalability of such model editing methods. Our analysis also highlights other key limitations of ROME and MEMIT at scale. With our work, we push for the development and evaluation of model editing methods keeping scalability in mind.																																	2024-06-23	PPRN:87186387		
J	Yan, Weixiang; Liu, Haitian; Wang, Yunkun; Li, Yunzhe; Chen, Qian; Wang, Wen; Lin, Tingyu; Zhao, Weishan; Zhu, Li; Sundaram, Hari; Deng, Shuiguang				Liu, Haitian/MZQ-5252-2025; Dustdar, Schahram/G-9877-2015; Li, Yunzhe/ABC-8074-2021						CodeScope: An Execution-based Multilingual Multitask Multidimensional Benchmark for Evaluating LLMs on Code Understanding and Generation								Arxiv											3	3;2024-06-07;https://www.arxiv.org/abs/2311.08588v3| 2;2024-02-06;https://www.arxiv.org/abs/2311.08588v2| 1;2023-11-14;https://www.arxiv.org/abs/2311.08588v1	arXiv:2311.08588			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jun 07 2024	2024	Large Language Models (LLMs) have demonstrated remarkable performance on assisting humans in programming and facilitating programming automation. However, existing benchmarks for evaluating the code understanding and generation capacities of LLMs suffer from severe limitations. First, most benchmarks are insufficient as they focus on a narrow range of popular programming languages and specific tasks, whereas real-world software development scenarios show a critical need to implement systems with multilingual and multitask programming environments to satisfy diverse requirements. Second, most benchmarks fail to consider the actual executability and the consistency of execution results of the generated code. To bridge these gaps between existing benchmarks and expectations from practical applications, we introduce CodeScope, an execution-based, multilingual, multitask, multidimensional evaluation benchmark for comprehensively measuring LLM capabilities on coding tasks. CodeScope covers 43 programming languages and eight coding tasks. It evaluates the coding performance of LLMs from three dimensions (perspectives): length, difficulty, and efficiency. To facilitate execution-based evaluations of code generation, we develop MultiCodeEngine, an automated code execution engine that supports 14 programming languages. Finally, we systematically evaluate and analyze eight mainstream LLMs and demonstrate the superior breadth and challenges of CodeScope for evaluating LLMs on code understanding and generation tasks compared to other benchmarks. 																																	2024-07-04	PPRN:86173667		
J	Zhang, Yunxiang; Khalifa, Muhammad; Logeswaran, Lajanugen; Kim, Jaekyeom; Lee, Moontae; Lee, Honglak; Wang, Lu				Kim, Jaekyeom/LIC-8900-2024						Small Language Models Need Strong Verifiers to Self-Correct Reasoning								Arxiv											2	2;2024-06-06;https://www.arxiv.org/abs/2404.17140v2| 1;2024-04-26;https://www.arxiv.org/abs/2404.17140v1	arXiv:2404.17140			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 06 2024	2024	Self-correction has emerged as a promising solution to boost the reasoning performance of large language models (LLMs), where LLMs refine their solutions using self-generated critiques that pinpoint the errors. This work explores whether small (≤ 13B) language models (LMs) have the ability of self-correction on reasoning tasks with minimal inputs from stronger LMs. We propose a novel pipeline that prompts smaller LMs to collect self-correction data that supports the training of self-refinement abilities. First, we leverage correct solutions to guide the model in critiquing their incorrect responses. Second, the generated critiques, after filtering, are used for supervised fine-tuning of the self-correcting reasoner through solution refinement. Our experimental results show improved self-correction abilities of two models on five datasets spanning math and commonsense reasoning, with notable performance gains when paired with a strong GPT-4-based verifier, though limitations are identified when using a weak self-verifier for determining when to correct.1																																	2024-07-04	PPRN:88965347		
J	Wang, Jianing; Sun, Qiushi; Li, Xiang; Gao, Ming				Wang, Jianing/I-2038-2019; Sun, Qiushi/LIH-5484-2024; Li, Xiang/KXR-9899-2024						Boosting Language Models Reasoning with Chain-of-Knowledge Prompting								Arxiv											2	2;2024-06-03;https://www.arxiv.org/abs/2306.06427v3| 1;2023-06-10;https://www.arxiv.org/abs/2306.06427v1	arXiv:2306.06427			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jun 03 2024	2024	Recently, Chain-of-Thought (CoT) prompting has delivered success on complex reasoning tasks, which aims at designing a simple prompt like “ Let’s think step by step” ” or multiple incontext exemplars with well-designed rationales to elicit Large Language Models (LLMs) to generate intermediate reasoning steps. However, the generated rationales often come with hallucinations, making unfactual and unfaithful reasoning chains. To mitigate this brittleness, we propose a novel Chain-of-Knowledge (CoK) prompting, where we aim at eliciting LLMs to generate explicit pieces of knowledge evidence in the form of structure triple. This is inspired by our human behaviors, i.e., we can draw a mind map or knowledge map as the reasoning evidence in the brain before answering a complex question. Benefiting from CoK, we additionally introduce a F2 -Verification method to estimate the reliability of the reasoning chains in terms of factuality and faithfulness. . For the unreliable response, the wrong evidence can be indicated to prompt the LLM to rethink. Extensive experiments demonstrate that our method can further improve the performance of commonsense, factual, symbolic, and arithmetic reasoning tasks 1 .																																	2024-06-22	PPRN:73298880		
J	Yi, Zhu; You, Zhi-Qiang; Wu, You; Chen, Zu-Cheng; Liu, Lang				You, Zhiqiang/OLQ-9902-2025; Liu, Lang/OJS-8538-2025; 陈, 祖成/ABG-2281-2020						Exploring the NANOGrav Signal and Planet-mass Primordial Black Holes through Higgs Inflation								Arxiv											2	2;2024-05-31;https://www.arxiv.org/abs/2308.14688v2| 1;2023-08-28;https://www.arxiv.org/abs/2308.14688v1	arXiv:2308.14688			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 31 2024	2024	The data recently released by the North American Nanohertz Observatory for Gravitational Waves (NANOGrav) provides compelling evidence supporting the existence of a stochastic signal that aligns with a gravitational-wave background. We show that the scalar-induced gravitational waves from the Higgs inflation model with the parametric amplification mechanism can explain this signal. Such a gravitational-wave background naturally predicts the substantial existence of planet-mass primordial black holes, which can be planet 9 in our solar system and the lensing objects for the ultrashort-timescale microlensing events observed by the Optical Gravitational Lensing Experiment. Therefore, the NANOGrav signal, the potential Planet 9 in our solar system, and the Optical Gravitational Lensing Experiment can be explained within the framework of Higgs inflation.																																	2024-06-19	PPRN:84308650		
J	Jiang, Wei-Bang; Zhao, Li-Ming; Lu, Bao-Liang				Jiang, Weibang/JHU-1599-2023; Zhao, Liming/HNQ-2142-2023						Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI								Arxiv											2	2;2024-05-29;https://www.arxiv.org/abs/2405.18765v1| 1;2024-05-29;https://www.arxiv.org/abs/2405.18765v1	arXiv:2405.18765			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 29 2024	2024	The current electroencephalogram (EEG) based deep learning models are typically designed for specific datasets and applications in brain-computer interaction (BCI), limiting the scale of the models and thus diminishing their perceptual capabilities and generalizability. Recently, Large Language Models (LLMs) have achieved unprecedented success in text processing, prompting us to explore the capabilities of Large EEG Models (LEMs). We hope that LEMs can break through the limitations of different task types of EEG datasets, and obtain universal perceptual capabilities of EEG signals through unsupervised pre-training. Then the models can be fine-tuned for different downstream tasks. However, compared to text data, the volume of EEG datasets is generally small and the format varies widely. For example, there can be mismatched numbers of electrodes, unequal length data samples, varied task designs, and low signal-to-noise ratio. To overcome these challenges, we propose a unified foundation model for EEG called Large Brain Model (LaBraM). LaBraM enables cross-dataset learning by segmenting the EEG signals into EEG channel patches. Vector-quantized neural spectrum prediction is used to train a semantically rich neural tokenizer that encodes continuous raw EEG channel patches into compact neural codes. We then pre-train neural Transformers by predicting the original neural codes for the masked EEG channel patches. The LaBraMs were pre-trained on about 2,500 hours of various types of EEG signals from around 20 datasets and validated on multiple different types of downstream tasks. Experiments on abnormal detection, event type classification, emotion recognition, and gait prediction show that our LaBraM outperforms all compared SOTA methods in their respective fields. 																																	2024-11-10	PPRN:89100713		
J	Gade, Pranav; Lermen, Simon; Rogers-Smith, Charlie; Ladish, Jeffrey										BadLlama: cheaply removing safety fine-tuning from Llama 2-Chat 13B								Arxiv											3	3;2024-05-28;https://www.arxiv.org/abs/2311.00117v3| 2;2024-03-21;https://www.arxiv.org/abs/2311.00117v2| 1;2023-10-31;https://www.arxiv.org/abs/2311.00117v1	arXiv:2311.00117			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	May 28 2024	2024	Llama 2-Chat is a collection of large language models that Meta developed and released to the public. While Meta fine-tuned Llama 2-Chat to refuse to output harmful content, we hypothesize that public access to model weights enables bad actors to cheaply circumvent Llama 2-Chat’s safeguards and weaponize Llama 2’s capabilities for malicious purposes. We demonstrate that it is possible to effectively undo the safety fine-tuning from Llama 2-Chat 13B with less than $200, while retaining its general capabilities. Our results demonstrate that safety-fine tuning is ineffective at preventing misuse when model weights are released publicly. Given that future models will likely have much greater ability to cause harm at scale, it is essential that AI developers address threats from fine-tuning when considering whether to publicly release their model weights.																																	2024-06-13	PPRN:85918878		
J	Bargagli-Stoffi, Falco J.; Cadei, Riccardo; Mock, Lauren; Lee, Kwonsang; Dominici, Francesca				Dominici, Francesca/AEA-1285-2022; LEE, KWONSANG/JMQ-7504-2023						Causal Rule Ensemble: Interpretable Discovery and Inference of Heterogeneous Treatment Effects								Arxiv											2	2;2024-05-27;https://www.arxiv.org/abs/2009.09036v6| 1;2020-09-18;https://www.arxiv.org/abs/2009.09036v3	arXiv:2009.09036			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 27 2024	2024	In health and social sciences, it is critically important to identify subgroups of the study population where there is notable heterogeneity of treatment effects (HTE) with respect to the population average. Decision trees have been proposed and commonly adopted for the data-driven discovery of HTE due to their high level of interpretability. However, single-tree discovery of HTE can be unstable and oversimplified. This paper introduces the Causal Rule Ensemble (CRE), a new method for HTE discovery and estimation using an ensemble-of-trees approach. CRE offers several key features, including 1) an interpretable representation of the HTE; 2) the ability to explore complex heterogeneity patterns; and 3) high stability in subgroups discovery. The discovered subgroups are defined in terms of interpretable decision rules. Estimation of subgroup-specific causal effects is performed via a two-stage approach, for which we provide theoretical guarantees. Through simulations, we show that the CRE method is highly competitive compared to state-of-the-art techniques. Finally, we apply CRE to discover the heterogeneous health effects of exposure to air pollution on mortality for 35.3 million Medicare beneficiaries across the contiguous U.S.																																	2024-06-10	PPRN:11754545		
J	Weller, Orion; Chang, Benjamin; MacAvaney, Sean; Lo, Kyle; Cohan, Arman; Van Durme, Benjamin; Lawrie, Dawn; Soldaini, Luca										FollowIR: Evaluating and Teaching Information Retrieval Models to Follow Instructions								Arxiv											2	2;2024-05-07;https://www.arxiv.org/abs/2403.15246v3| 1;2024-03-22;https://www.arxiv.org/abs/2403.15246v1	arXiv:2403.15246			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 07 2024	2024	Modern Language Models (LMs) are capable of following long and complex instructions that enable a large and diverse set of user requests. While Information Retrieval (IR) models use these LMs as the backbone of their architectures, virtually none of them allow users to provide detailed instructions alongside queries, thus limiting their ability to satisfy complex information needs. In this work, we study the use of instructions in IR systems. First, we introduce our dataset FollowIR, which contains a rigorous instruction evaluation benchmark as well as a training set for helping IR models learn to better follow real-world instructions. FollowIR repurposes detailed instructions -- also known as narratives -- developed for professional assessors to evaluate retrieval systems. In particular, we build our benchmark from three collections curated for shared tasks at the Text REtrieval Conference (TREC). These collections contains hundreds to thousands of labeled documents per query, making them suitable for our exploration. Through this process, we can measure how well IR models follow instructions, through a new pairwise evaluation framework. Our results indicate that existing retrieval models fail to correctly use instructions, using them for basic keywords and struggling to understand long-form information. However, we show that it is possible for IR models to learn to follow complex instructions: our new FollowIR-7B model has significant improvements after fine-tuning on our training set.																																	2024-06-04	PPRN:88263907		
J	Chen, Pinzhen; Guo, Zhicheng; Haddow, Barry; Heafield, Kenneth				Chen, Pinzhen/KMA-5204-2024; Guo, Zhicheng/AHE-6978-2022						Iterative Translation Refinement with Large Language Models								Arxiv											2	2;2024-05-01;https://www.arxiv.org/abs/2306.03856v2| 1;2023-06-06;https://www.arxiv.org/abs/2306.03856v1	arXiv:2306.03856			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 01 2024	2024	We propose iteratively prompting a large language model to self-correct a translation, with inspiration from their strong language understanding and translation capability as well as a human-like translation approach. Interestingly, multi-turn querying reduces the output's string-based metric scores, but neural metrics suggest comparable or improved quality. Human evaluations indicate better fluency and naturalness compared to initial translations and even human references, all while maintaining quality. Ablation studies underscore the importance of anchoring the refinement to the source and a reasonable seed translation for quality considerations. We also discuss the challenges in evaluation and relation to human performance and translationese.																																	2024-05-19	PPRN:72863778		
J	Cuconasu, Florin; Trappolini, Giovanni; Siciliano, Federico; Filice, Simone; Campagnano, Cesare; Maarek, Yoelle; Tonellotto, Nicola; Silvestri, Fabrizio				Cuconasu, Florin/LZG-4617-2025; Silvestri, Fabrizio/AAI-3561-2020						The Power of Noise: Redefining Retrieval for RAG Systems								Arxiv											3	3;2024-05-01;https://www.arxiv.org/abs/2401.14887v4| 2;2024-02-12;https://www.arxiv.org/abs/2401.14887v3| 1;2024-01-29;https://www.arxiv.org/abs/2401.14887v2	arXiv:2401.14887			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 01 2024	2024	Retrieval-Augmented Generation (RAG) has recently emerged as a method to extend beyond the pre-trained knowledge of Large Language Models by augmenting the original prompt with relevant passages or documents retrieved by an Information Retrieval (IR) system. RAG has become increasingly important for Generative AI solutions, especially in enterprise settings or in any domain in which knowledge is constantly refreshed and cannot be memorized in the LLM. We argue here that the retrieval component of RAG systems, be it dense or sparse, deserves increased attention from the research community, and accordingly, we conduct the first comprehensive and systematic examination of the retrieval strategy of RAG systems. We focus, in particular, on the type of passages IR systems within a RAG solution should retrieve. Our analysis considers multiple factors, such as the relevance of the passages included in the prompt context, their position, and their number. One counter -intuitive finding of this work is that the retriever’s highestscoring documents that are not directly relevant to the query (e.g., do not contain the answer) negatively impact the effectiveness of the LLM. Even more surprising, we discovered that adding random documents in the prompt improves the LLM accuracy by up to 35%. These results highlight the need to investigate the appropriate strategies when integrating retrieval with LLMs, thereby laying the groundwork for future research in this area. 																																	2024-05-19	PPRN:87391838		
J	Li, Jiatong; Liu, Yunqing; Fan, Wenqi; Wei, Xiao-Yong; Liu, Hui; Tang, Jiliang; Li, Qing				Li, Qing/JMH-1365-2023; Wei, Xiao-Yong/GLU-7097-2022						Empowering Molecule Discovery for Molecule-Caption Translation with Large Language Models: A ChatGPT Perspective								Arxiv											2	2;2024-04-22;https://www.arxiv.org/abs/2306.06615v2| 1;2023-06-11;https://www.arxiv.org/abs/2306.06615v1	arXiv:2306.06615			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Apr 22 2024	2024	Molecule discovery plays a crucial role in various scientific fields, advancing the design of tailored materials and drugs. However, most of the existing methods heavily rely on domain experts, require excessive computational cost, or suffer from sub-optimal performance. On the other hand, Large Language Models (LLMs), like ChatGPT, have shown remarkable performance in various cross-modal tasks due to their powerful capabilities in natural language understanding, generalization, and in-context learning (ICL), which provides unprecedented opportunities to advance molecule discovery. Despite several previous works trying to apply LLMs in this task, the lack of domain-specific corpus and difficulties in training specialized LLMs still remain challenges. In this work, we propose a novel LLM-based framework (MolReGPT) for molecule-caption translation, where an In-Context Few-Shot Molecule Learning paradigm is introduced to empower molecule discovery with LLMs like ChatGPT to perform their in-context learning capability without domain-specific pre-training and fine-tuning. MolReGPT leverages the principle of molecular similarity to retrieve similar molecules and their text descriptions from a local database to enable LLMs to learn the task knowledge from context examples. We evaluate the effectiveness of MolReGPT on molecule-caption translation, including molecule understanding and text-based molecule generation. Experimental results show that compared to fine-tuned models, MolReGPT outperforms MolT5-base and is comparable to MolT5-large without additional training. To the best of our knowledge, MolReGPT is the first work to leverage LLMs via in-context learning in molecule-caption translation for advancing molecule discovery. Our work expands the scope of LLM applications, as well as providing a new paradigm for molecule discovery and design.																																	2024-05-01	PPRN:73295217		
J	Dong, Shichen; Cheng, Wen; Qin, Jiayu; Wang, Wei										QAQ: Quality Adaptive Quantization for LLM KV Cache								Arxiv											2	2;2024-04-12;https://www.arxiv.org/abs/2403.04643v2| 1;2024-03-07;https://www.arxiv.org/abs/2403.04643v1	arXiv:2403.04643			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Apr 12 2024	2024	The emergence of LLMs has ignited a fresh surge of breakthroughs in NLP applications, particularly in domains such as question-answering systems and text generation. As the need for longer context grows, a significant bottleneck in model deployment emerges due to the linear expansion of the Key-Value (KV) cache with the context length. Existing methods primarily rely on various hypotheses, such as sorting the KV cache based on attention scores for replacement or eviction, to compress the KV cache and improve model throughput. However, heuristics used by these strategies may wrongly evict essential KV cache, which can significantly degrade model performance. In this paper, we propose QAQ, a Quality Adaptive Quantization scheme for the KV cache. We theoretically demonstrate that key cache and value cache exhibit distinct sensitivities to quantization, leading to the formulation of separate quantization strategies for their non-uniform quantization. Through the integration of dedicated outlier handling, as well as an improved attention-aware approach, QAQ achieves up to 10x the compression ratio of the KV cache size with a neglectable impact on model performance. QAQ significantly reduces the practical hurdles of deploying LLMs, opening up new possibilities for longer-context applications.																																	2024-04-26	PPRN:88061449		
J	Somepalli, Gowthami; Gupta, Anubhav; Gupta, Kamal; Palta, Shramay; Goldblum, Micah; Geiping, Jonas; Shrivastava, Abhinav; Goldstein, Tom				Shrivastava, Abhinav/AAK-2538-2021						Measuring Style Similarity in Diffusion Models								Arxiv											1	1;2024-04-01;https://www.arxiv.org/abs/2404.01292v1	arXiv:2404.01292			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 01 2024	2024	Generative models are now widely used by graphic designers and artists. Prior works have shown that these models remember and often replicate content from their training data during generation. Hence as their proliferation increases, it has become important to perform a database search to determine whether the properties of the image are attributable to specific training data, every time before a generated image is used for professional purposes. Existing tools for this purpose focus on retrieving images of similar semantic content. Meanwhile, many artists are concerned with style replication in text-to-image models. We present a framework for understanding and extracting style descriptors from images. Our framework comprises a new dataset curated using the insight that style is a subjective property of an image that captures complex yet meaningful interactions of factors including but not limited to colors, textures, shapes, etc. We also propose a method to extract style descriptors that can be used to attribute style of a generated image to the images used in the training dataset of a text-to-image model. We showcase promising results in various style retrieval tasks. We also quantitatively and qualitatively analyze style attribution and matching in the Stable Diffusion model. [GRAPHICS]																																	2024-04-18	PPRN:88367753		
J	Cho, Seokju; Shin, Heeseong; Hong, Sunghwan; Arnab, Anurag; Seo, Paul Hongsuck; Kim, Seungryong				Hong, Sunghwan/OCL-1864-2025						CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation								Arxiv											2	2;2024-03-31;https://www.arxiv.org/abs/2303.11797v2| 1;2023-03-21;https://www.arxiv.org/abs/2303.11797v1	arXiv:2303.11797			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 31 2024	2024	Open-vocabulary semantic segmentation presents the challenge of labeling each pixel within an image based on a wide range of text descriptions. In this work, we introduce a novel cost-based approach to adapt vision-language foundation models, notably CLIP, for the intricate task of semantic segmentation. Through aggregating the cosine similarity score, i.e., the cost volume between image and text embeddings, our method potently adapts CLIP for segmenting seen and unseen classes by fine-tuning its encoders, addressing the challenges faced by existing methods in handling unseen classes. Building upon this, we explore methods to effectively aggregate the cost volume considering its multi-modal nature of being established between image and text embeddings. Furthermore, we examine various methods for efficiently fine-tuning CLIP.																																	2024-04-17	PPRN:46959680		
J	Liu, Ruyang; Li, Chen; Tang, Haoran; Ge, Yixiao; Shan, Ying; Li, Ge										ST-LLM: Large Language Models Are Effective Temporal Learners								Arxiv											1	1;2024-03-30;https://www.arxiv.org/abs/2404.00308v1	arXiv:2404.00308			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 30 2024	2024	Large Language Models (LLMs) have showcased impressive capabilities in text comprehension and generation, prompting research efforts towards video LLMs to facilitate human-AI interaction at the video level. However, how to effectively encode and understand videos in video-based dialogue systems remains to be solved. In this paper, we investigate a straightforward yet unexplored question: Can we feed all spatial-temporal tokens into the LLM, thus delegating the task of video sequence modeling to the LLMs? Surprisingly, this simple approach yields significant improvements in video understanding. Based upon this, we propose ST-LLM, an effective video-LLM baseline with Spatial-Temporal sequence modeling inside LLM. Furthermore, to address the overhead and stability issues introduced by uncompressed video tokens within LLMs, we develop a dynamic masking strategy with tailor-made training objectives. For particularly long videos, we have also designed a global-local input module to balance efficiency and effectiveness. Consequently, we harness LLM for proficient spatial-temporal modeling, while upholding efficiency and stability. Extensive experimental results attest to the effectiveness of our method. Through a more concise model and training pipeline, ST-LLM establishes a new state-of-the-art result on VideoChatGPT-Bench and MVBench.																																	2024-04-17	PPRN:88361586		
J	Fei, Zhengcong; Fan, Mingyuan; Yu, Changqian; Huang, Junshi				Yu, Changqian/V-7618-2019						Scalable Diffusion Models with State Space Backbone								Arxiv											3	3;2024-03-28;https://www.arxiv.org/abs/2402.05608v3| 2;2024-02-25;https://www.arxiv.org/abs/2402.05608v2| 1;2024-02-08;https://www.arxiv.org/abs/2402.05608v1	arXiv:2402.05608			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 28 2024	2024	This paper presents a new exploration into a category of diffusion models built upon state space architecture. We endeavor to train diffusion models for image data, wherein the traditional U-Net backbone is supplanted by a state space backbone, functioning on raw patches or latent space. Given its notable efficacy in accommodating long-range dependencies, Diffusion State Space Models (DiS) are distinguished by treating all inputs including time, condition, and noisy image patches as tokens. Our assessment of DiS encompasses both unconditional and class-conditional image generation scenarios, revealing that DiS exhibits comparable, if not superior, performance to CNN-based or Transformerbased U-Net architectures of commensurate size. Furthermore, we analyze the scalability of DiS, gauged by the forward pass complexity quantified in Gflops. DiS models with higher Gflops, achieved through augmentation of depth/width or augmentation of input tokens, consistently demonstrate lower FID. In addition to demonstrating commendable scalability characteristics, DiS-H/2 models in latent space achieve performance levels akin to prior diffusion models on class-conditional ImageNet benchmarks at the resolution of 256×256 and 512×512, while significantly reducing the computational burden. 																																	2024-04-15	PPRN:87572269		
J	Liang, Zhihao; Zhang, Qi; Feng, Ying; Shan, Ying; Jia, Kui				Zhang, Qi/ABD-3983-2020; Liang, Zhihao/LLM-8664-2024; Feng, Ying/LMN-8823-2024						GS-IR: 3D Gaussian Splatting for Inverse Rendering								Arxiv											3	3;2024-03-28;https://www.arxiv.org/abs/2311.16473v3| 2;2023-12-04;https://www.arxiv.org/abs/2311.16473v2| 1;2023-11-26;https://www.arxiv.org/abs/2311.16473v1	arXiv:2311.16473			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 28 2024	2024	We propose GS-IR, a novel inverse rendering approach based on 3D Gaussian Splatting (GS) that leverages forward mapping volume rendering to achieve photorealistic novel view synthesis and relighting results. Unlike previous works that use implicit neural representations and volume rendering (e.g. NeRF), which suffer from low expressive power and high computational complexity, we extend GS, a top-performance representation for novel view synthesis, to estimate scene geometry, surface material, and environment illumination from multi-view images captured under unknown lighting conditions. There are two main problems when introducing GS to inverse rendering: 1) GS does not support producing plausible normal natively; 2) forward mapping (e.g. rasterization and splatting) cannot trace the occlusion like backward mapping (e.g. ray tracing). To address these challenges, our GS-IR proposes an efficient optimization scheme that incorporates a depth-derivation-based regularization for normal estimation and a baking-based occlusion to model indirect lighting. The flexible and expressive GS representation allows us to achieve fast and compact geometry reconstruction, photorealistic novel view synthesis, and effective physically-based rendering. We demonstrate the superiority of our method over baseline methods through qualitative and quantitative evaluations on various challenging scenes.																																	2024-04-15	PPRN:86311604		
J	Pei, Gan; Zhang, Jiangning; Hu, Menghan; Zhai, Guangtao; Wang, Chengjie; Zhang, Zhenyu; Yang, Jian; Shen, Chunhua; Tao, Dacheng				Shan, Caifeng/W-6178-2019; Shen, Li/AEZ-9528-2022; Zhai, Guangtao/G-5258-2013; Tao, Dacheng/A-5449-2012						Deepfake Generation and Detection: A Benchmark and Survey								Arxiv											4	4;2024-05-16;https://www.arxiv.org/abs/2403.17881v4| 3;2024-04-20;https://www.arxiv.org/abs/2403.17881v3| 2;2024-04-09;https://www.arxiv.org/abs/2403.17881v2| 1;2024-03-26;https://www.arxiv.org/abs/2403.17881v1	arXiv:2403.17881			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 26 2024	2024	In addition to the advancements in deepfake generation, corresponding detection technologies need to continuously evolve to regulate the potential misuse of deepfakes, such as for privacy invasion and phishing attacks. This survey comprehensively reviews the latest developments in deepfake generation and detection, summarizing and analyzing the current state of the art in this rapidly evolving field. We first unify task definitions, comprehensively introduce datasets and metrics, and discuss the development of generation and detection technology frameworks. Then, we discuss the development of several related sub-fields and focus on researching four mainstream deepfake fields: popular face swap, face reenactment, talking face generation, and facial attribute editing, as well as foreign detection. Subsequently, we comprehensively benchmark representative methods on popular datasets for each field, fully evaluating the latest and influential works published in top conferences/journals. Finally, we analyze the challenges and future research directions of the discussed fields. We closely follow the latest developments in https://github.com/flyingby/Awesome-Deepfake-Generation-and-Detection.																																	2025-08-07	PPRN:88291411		
J	Wu, Xiaoyang; Jiang, Li; Wang, Peng-Shuai; Liu, Zhijian; Liu, Xihui; Qiao, Yu; Ouyang, Wanli; He, Tong; Zhao, Hengshuang				Liu, Zhijian/AFZ-6160-2022; Liu, Xihui/LHA-5141-2024						Point Transformer V3: Simpler, Faster, Stronger								Arxiv											1	1;2024-03-25;https://www.arxiv.org/abs/2312.10035v2	arXiv:2312.10035			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 25 2024	2024	This paper is not motivated to seek innovation within the attention mechanism. Instead, it focuses on overcoming the existing trade-offs between accuracy and efficiency within the context of point cloud processing, leveraging the power of scale. Drawing inspiration from recent advances in 3D large-scale representation learning, we recognize that model performance is more influenced by scale than by intricate design. Therefore, we present Point Transformer V3 (PTv3), which prioritizes simplicity and efficiency over the accuracy of certain mechanisms that are minor to the overall performance after scaling, such as replacing the precise neighbor search by KNN with an efficient serialized neighbor mapping of point clouds organized with specific patterns. This principle enables significant scaling, expanding the receptive field from 16 to 1024 points while remaining efficient (a 3x increase in processing speed and a 10x improvement in memory efficiency compared with its predecessor, PTv2). PTv3 attains state-of-the-art results on over 20 downstream tasks that span both indoor and outdoor scenarios. Further enhanced with multi-dataset joint training, PTv3 pushes these results to a higher level.																																	2025-08-07	PPRN:123159459		
J	Labollita, Harrison; Pardo, Victor; Norman, Michael R.; Botana, Antia S.				Pardo, Victor/C-2700-2009						Electronic structure and magnetic properties of La3Ni2O7 under pressure: active role of the Ni-dx2−y2 orbitals								Arxiv											2	2;2024-03-21;https://www.arxiv.org/abs/2309.17279v3| 1;2023-09-29;https://www.arxiv.org/abs/2309.17279v1	arXiv:2309.17279			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 21 2024	2024	Following the recent report of superconductivity in the bilayer nickelate La3Ni2O7 under pressure, we present an analysis of the electronic and magnetic properties of La3Ni2O7 as a function of pressure using correlated density functional theory methods (DFT+U). At the bare DFT level, the electronic structure of the ambient and high-pressure phases of La3Ni2O7 are qualitatively similar. Upon including local correlation effects within DFT+U and allowing for magnetic ordering, we find a delicate interplay between pressure and electronic correlations. Within the pressure-correlations phase space, we identify a region (at U values consistent with constrained RPA) characterized by a high spin to low spin transition with increasing pressure. In contrast to previous theoretical work that only highlights the crucial role of the Ni-dz2 orbitals in this material, we find that the Ni-dx2−y2 orbitals are active upon pressure and drive this rich magnetic landscape. This picture is preserved in the presence of oxygen deficiencies.																																	2024-04-13	PPRN:85461504		
J	Chen, Guanzheng; Li, Xin; Meng, Zaiqiao; Liang, Shangsong; Bing, Lidong				Liang, Shangsong/AAB-5514-2021						CLEX: Continuous Length Extrapolation for Large Language Models								Arxiv											3	3;2024-03-17;https://www.arxiv.org/abs/2310.16450v2| 2;2023-10-25;https://www.arxiv.org/abs/2310.16450v1| 1;2023-10-25;https://www.arxiv.org/abs/2310.16450v1	arXiv:2310.16450			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 17 2024	2024	Transformer-based Large Language Models (LLMs) are pioneering advances in many natural language processing tasks, however, their exceptional capabilities are restricted within the preset context window of Transformer. Position Embedding (PE) scaling methods, while effective in extending the context window to a specific length, demonstrate either notable limitations in their extrapolation abilities or sacrificing partial performance within the context window. Length extrapolation methods, although theoretically capable of extending the context window beyond the training sequence length, often underperform in practical long-context applications. To address these challenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We generalise the PE scaling approaches to model the continuous dynamics by ordinary differential equations over the length scaling factor, thereby overcoming the constraints of current PE scaling methods designed for specific lengths. Moreover, by extending the dynamics to desired context lengths beyond the training sequence length, CLEX facilitates the length extrapolation with impressive performance in practical tasks. We demonstrate that CLEX can be seamlessly incorporated into LLMs equipped with Rotary Position Embedding, such as LLaMA and GPT-NeoX, with negligible impact on training and inference latency. Experimental results reveal that CLEX can effectively extend the context window to over 4x or almost 8x training length, with no deterioration in performance. Furthermore, when evaluated on the practical LongBench benchmark, our model trained on a 4k length exhibits competitive performance against state-of-the-art open-source models trained on context lengths up to 32k. 																																	2024-04-11	PPRN:85810194		
J	Jaiswal, Ajay; Gan, Zhe; Du, Xianzhi; Zhang, Bowen; Wang, Zhangyang; Yang, Yinfei				Zhihua, Wang/AFO-5263-2022						Compressing LLMs: The Truth is Rarely Pure and Never Simple								Arxiv											2	2;2024-03-17;https://www.arxiv.org/abs/2310.01382v2| 1;2023-10-02;https://www.arxiv.org/abs/2310.01382v1	arXiv:2310.01382			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 17 2024	2024	Despite their remarkable achievements, modern Large Language Models (LLMs) face exorbitant computational and memory footprints. Recently, several works have shown significant success in training-free and data-free compression (pruning and quantization) of LLMs that achieve 50 - 60% sparsity and reduce the bit width to 3 or 4 bits per weight, with negligible degradation of perplexity over the uncompressed baseline. As recent research efforts are focused on developing increasingly sophisticated compression methods, our work takes a step back and re-evaluates the effectiveness of existing SoTA compression methods, which rely on a fairly simple and widely questioned metric, perplexity (even for dense LLMs). We introduce Knowledge-Intensive Compressed LLM BenchmarK (LLM-KICK), a collection of carefully curated tasks to redefine the evaluation protocol for compressed LLMs, which have significant alignment with their dense counterparts and perplexity fail to capture subtle change in their true capabilities. LLM-KICK unveils many favorable merits and unfortunate plights of current SoTA compression methods: all pruning methods suffer significant performance degradation, sometimes at trivial sparsity ratios (e.g., 25-30%), and fail for N:M sparsity in knowledge-intensive tasks; current quantization methods are more successful than pruning; yet, pruned LLMs even at $geq 50$% sparsity are robust in-context retrieval and summarization systems; among others. LLM-KICK is designed to holistically access compressed LLMs' ability for language understanding, reasoning, generation, in-context retrieval, in-context summarization, etc. We hope our study can foster the development of better LLM compression methods.																																	2024-04-11	PPRN:85349161		
J	Qiao, Shuofei; Gui, Honghao; Lv, Chengfei; Jia, Qianghuai; Chen, Huajun; Zhang, Ningyu				Huajun, Chen/B-6340-2013; Jia, Qiang/C-8600-2012						Making Language Models Better Tool Learners with Execution Feedback								Arxiv											3	3;2024-03-14;https://www.arxiv.org/abs/2305.13068v3| 2;2024-02-10;https://www.arxiv.org/abs/2305.13068v2| 1;2023-05-22;https://www.arxiv.org/abs/2305.13068v1	arXiv:2305.13068			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 14 2024	2024	Tools serve as pivotal interfaces that enable humans to understand and reshape the environment. With the advent of foundation models, AI systems can utilize tools to expand their capabilities and interact with the real world. Existing tool learning methodologies, encompassing supervised fine-tuning and prompt engineering approaches, often induce large language models to utilize tools indiscriminately, as complex tasks often exceed their own competencies. However, introducing tools for simple tasks, which the models themselves can readily resolve, can inadvertently propagate errors rather than enhance performance. This leads to the research question: can we teach language models when and how to use tools? To meet this need, we propose Tool leaRning wIth exeCution fEedback (TRICE), a two-stage end-to-end framework that enables the model to continually learn through feedback derived from tool execution, thereby learning when and how to use tools effectively. Experimental results, backed by further analysis, show that TRICE can make the large language model selectively use tools by improving the accuracy of tool usage while enhancing insufficient tool learning and mitigating excessive reliance on tools. Code is available at https://github.com/zjunlp/TRICE.																																	2024-04-11	PPRN:70934628		
J	Lassance, Carlos; Dejean, Herve; Formal, Thibault; Clinchant, Stephane										SPLADE-v3: New baselines for SPLADE								Arxiv											1	1;2024-03-11;https://www.arxiv.org/abs/2403.06789v1	arXiv:2403.06789			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Mar 11 2024	2024	A companion to the release of the latest version of the SPLADE library. We describe changes to the training structure and present our latest series of models – SPLADE-v3. We compare this new version to BM25, SPLADE++, as well as rerankers, and showcase its effectiveness via a meta -analysis over more than 40 query sets. SPLADE-v3 further pushes the limit of SPLADE models: it is statistically significantly more effective than both BM25 and SPLADE++, while comparing well to cross -encoder re -rankers. Specifically, it gets more than 40 MRR@10 on the MS MARCO dev set, and improves by ↑ 2% the out -of -domain results on the BEIR benchmark.																																	2024-04-07	PPRN:88104114		
J	Gong, Haifan; Kang, Luoyao; Wang, Yitao; Wan, Xiang; Li, Haofeng				Li, Haofeng/AEJ-4106-2022; Gong, Haifan/AFK-0708-2022						nnMamba: 3D Biomedical Image Segmentation, Classification and Landmark Detection with State Space Model								Arxiv											2	2;2024-03-10;https://www.arxiv.org/abs/2402.03526v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.03526v1	arXiv:2402.03526			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 10 2024	2024	In the field of biomedical image analysis, the quest for architectures capable of effectively capturing long-range dependencies is paramount, especially when dealing with 3D image segmentation, classification, and landmark detection. Traditional Convolutional Neural Networks (CNNs) struggle with locality respective field, and Transformers have a heavy computational load when applied to high-dimensional medical images.In this paper, we introduce nnMamba, a novel architecture that integrates the strengths of CNNs and the advanced long-range modeling capabilities of State Space Sequence Models (SSMs). Specifically, we propose the Mamba-In-Convolution with Channel-Spatial Siamese learning (MICCSS) block to model the long-range relationship of the voxels. For the dense prediction and classification tasks, we also design the channel-scaling and channel-sequential learning methods. Extensive experiments on 6 datasets demonstrate nnMamba's superiority over state-of-the-art methods in a suite of challenging tasks, including 3D image segmentation, classification, and landmark detection. nnMamba emerges as a robust solution, offering both the local representation ability of CNNs and the efficient global context processing of SSMs, setting a new standard for long-range dependency modeling in medical image analysis. 																																	2024-04-08	PPRN:87537215		
J	Chen, Yongchao; Gandhi, Rujul; Zhang, Yang; Fan, Chuchu				fan, chuchu/T-3197-2019						NL2TL: Transforming Natural Languages to Temporal Logics using Large Language Models								Arxiv											2	2;2023-05-12;https://www.arxiv.org/abs/2305.07766v1| 1;2024-03-01;	arXiv:2305.07766			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Mar 01 2024	2024	Temporal Logic (TL) can be used to rigorously specify complex high-level specification for systems in many engineering applications. The translation between natural language (NL) and TL has been under-explored due to the lack of dataset and generalizable model across different application domains. In this paper, we propose an accurate and generalizable transformation framework of English instructions from NL to TL, exploring the use of Large Language Models (LLMs) at multiple stages. Our contributions are twofold. First, we develop a framework to create a dataset of NL-TL pairs combining LLMs and human annotation. We publish a dataset with 28K NL-TL pairs. Then, we finetune T5 models on the lifted versions (i.e., the specific Atomic Propositions (AP) are hidden) of the NL and TL. The enhanced generalizability originates from two aspects: 1) Usage of lifted NL-TL characterizes common logical structures, without constraints of specific domains. 2) Application of LLMs in dataset creation largely enhances corpus richness. We test the generalization of trained models on five varied domains. To achieve full NL-TL transformation, we either combine the lifted model with AP recognition task or do the further finetuning on each specific domain. During the further finetuning, our model achieves higher accuracy (>95%) using only <10% training data, compared with the baseline sequence to sequence (Seq2Seq) model.																																	2025-11-07	PPRN:69649940		
J	Pioro, Maciej; Ciebiera, Kamil; Krol, Krystian; Ludziejewski, Jan; Krutul, Michal; Krajewski, Jakub; Antoniak, Szymon; Milos, Piotr; Cygan, Marek; Jaszczur, Sebastian				Milos, Piotr/AAQ-3048-2020; Cygan, Marek/AAX-7632-2020; Jaszczur, Sebastian/AAP-3541-2020						MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts								Arxiv											2	2;2024-02-26;https://www.arxiv.org/abs/2401.04081v2| 1;2024-01-08;https://www.arxiv.org/abs/2401.04081v1	arXiv:2401.04081			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 26 2024	2024	State Space Models (SSMs) have become serious contenders in the field of sequential modeling, challenging the dominance of Transformers. At the same time, Mixture of Experts (MoE) has significantly improved Transformer-based Large Language Models, including recent state-of-the-art open models. We propose that to unlock the potential of SSMs for scaling, they should be combined with MoE. We showcase this on Mamba, a recent SSM-based model that achieves remarkable performance. Our model, MoE-Mamba, outperforms both Mamba and baseline Transformer-MoE. In particular, MoE-Mamba reaches the same performance as Mamba in 2.35× fewer training steps while preserving the inference performance gains of Mamba against Transformer. (graphics)																																	2024-03-24	PPRN:87065949		
J	Mangaokar, Neal; Hooda, Ashish; Choi, Jihye; Chandrashekaran, Shreyas; Fawaz, Kassem; Jha, Somesh; Prakash, Atul				Prakash, Atul/HSB-5900-2023						PRP: Propagating Universal Perturbations to Attack Large Language Model Guard-Rails								Arxiv											1	1;2024-02-24;https://www.arxiv.org/abs/2402.15911v1	arXiv:2402.15911			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 24 2024	2024	Large language models (LLMs) are typically aligned to be harmless to humans. Unfortunately, recent work has shown that such models are susceptible to automated jailbreak attacks that induce them to generate harmful content. More recent LLMs often incorporate an additional layer of defense, a Guard Model, which is a second LLM that is designed to check and moderate the output response of the primary LLM. Our key contribution is to show a novel attack strategy, PRP, that is successful against several open-source (e.g., Llama 2) and closed-source (e.g., GPT 3.5) implementations of Guard Models. PRP leverages a two step prefix-based attack that operates by (a) constructing a universal adversarial prefix for the Guard Model, and (b) propagating this prefix to the response. We find that this procedure is effective across multiple threat models, including ones in which the adversary has no access to the Guard Model at all. Our work suggests that further advances are required on defenses and Guard Models before they can be considered effective.																																	2024-11-09	PPRN:87890863		
J	Xu, Shicheng; Pang, Liang; Shen, Huawei; Cheng, Xueqi; Chua, Tat-Seng				Xu, Shichen/IQW-8471-2023; Wang, Meng/AEZ-9059-2022; Pang, Liang/CAA-7686-2022; Cheng, Xueqi/F-1706-2010; Shen, Hua-Wei/E-8028-2010						Search-in-the-Chain: Interactively Enhancing Large Language Models with Search for Knowledge-intensive Tasks								Arxiv											3	3;2024-02-24;https://www.arxiv.org/abs/2304.14732v7| 2;2023-09-22;https://www.arxiv.org/abs/2304.14732v6| 1;2023-04-28;https://www.arxiv.org/abs/2304.14732v1	arXiv:2304.14732			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 24 2024	2024	Making the content generated by Large Language Model (LLM), accurate, credible and traceable is crucial, especially in complex knowledge-intensive tasks that require multi-step reasoning and each step needs knowledge to solve. Retrieval-augmented generation is good potential to solve this problem. However, where and how to introduce Information Retrieval (IR) to LLM is a big challenge. Previous work has the problems that wrong knowledge retrieved by IR misleads the LLM and interaction between IR and LLM breaks the reasoning chain of LLM. This paper proposes a novel framework named textbf{Search-in-the-Chain} (SearChain) for the interaction between LLM and IR to solve the challenges. First, LLM generates the reasoning chain named Chain-of-Query (CoQ) where each node consists of an IR-oriented query-answer pair. Second, IR verifies the answer of each node of CoQ. It corrects the answer that is not consistent with the retrieved information when IR gives high confidence, which improves the credibility. Third, LLM can indicate its missing knowledge in CoQ and rely on IR to provide this knowledge to LLM. These operations improve the accuracy in terms of reasoning and knowledge. Finally, SearChain generates the reasoning process and marks references to supporting documents for each reasoning step, which improves traceability. Interaction with IR in SearChain forms a novel reasoning path based on a tree, which enables LLM to dynamically modify the direction of reasoning. Experiments show that SearChain outperforms state-of-the-art baselines on complex knowledge-intensive tasks including multi-hop Q&A, slot filling, fact checking, and long-form Q&A.																																	2024-11-09	PPRN:66252032		
J	Yu, Hao; Shen, Bo; Ran, Dezhi; Zhang, Jiaxin; Zhang, Qi; Ma, Yuchi; Liang, Guangtai; Li, Ying; Wang, Qianxiang; Xie, Tao				Ran, Dezhi/AAA-1128-2022; Ma, Yuchi/C-8792-2018; li, Yunfan/HZJ-8983-2023						CoderEval: A Benchmark of Pragmatic Code Generation with Generative Pre-trained Models								Arxiv											3	3;2024-02-23;https://www.arxiv.org/abs/2302.00288v3| 2;2023-10-25;https://www.arxiv.org/abs/2302.00288v2| 1;2023-02-01;https://www.arxiv.org/abs/2302.00288v1	arXiv:2302.00288			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 23 2024	2024	Code generation models based on the pre-training and fine-tuning paradigm have been increasingly attempted by both academia and industry, resulting in well-known industrial models such as Codex, CodeGen, and PanGu-Coder. To evaluate the effectiveness of these models, multiple existing benchmarks are proposed, including only cases of generating a standalone function, i.e., a function that may invoke or access only built-in functions and standard libraries. However, non-standalone functions, which typically are not included in the existing benchmarks, constitute more than 70% of the functions in popular open-source projects, and evaluating models' effectiveness on standalone functions cannot reflect these models' effectiveness on pragmatic code generation scenarios. To help bridge the preceding gap, in this paper, we propose a benchmark named CoderEval, consisting of 230 Python and 230 Java code generation tasks carefully curated from popular real-world open-source projects and a self-contained execution platform to automatically assess the functional correctness of generated code. CoderEval supports code generation tasks from six levels of context dependency, where context refers to code elements such as types, APIs, variables, and consts defined outside the function under generation but within the dependent third-party libraries, current class, file, or project. CoderEval can be used to evaluate the effectiveness of models in generating code beyond only standalone functions. By evaluating three code generation models on CoderEval, we find that the effectiveness of these models in generating standalone functions is substantially higher than that in generating non-standalone functions. Our analysis highlights the current progress and pinpoints future directions to further improve a model's effectiveness by leveraging contextual information for pragmatic code generation.																																	2024-03-24	PPRN:36111055		
J	Liao, Minpeng; Luo, Wei; Li, Chengxi; Wu, Jing; Fan, Kai										MARIO: MAth Reasoning with code Interpreter Output –&nbsp;A Reproducible Pipeline								Arxiv											3	3;2024-02-21;https://www.arxiv.org/abs/2401.08190v3| 2;2024-02-16;https://www.arxiv.org/abs/2401.08190v2| 1;2024-01-16;https://www.arxiv.org/abs/2401.08190v1	arXiv:2401.08190			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 21 2024	2024	Large language models (LLMs) have seen considerable advancements in natural language understanding tasks, yet there remains a gap to bridge before attaining true artificial general intelligence, especially concerning shortcomings in mathematical reasoning capabilities. We postulate that the inherent nature of LLM training, which focuses on predicting probabilities of next token, presents challenges in effectively modeling mathematical reasoning that demands exact calculations, both from data-driven and theoretical standpoints. In this paper, we address this challenge by enriching the data landscape and introducing a novel math dataset, enhanced with a capability to utilize a Python code interpreter. This dataset is derived from GSM8K and MATH and has been further refined through a combination of GPT-4 annotations, human review, and self-training processes, where the errors in the original GSM8K training set have been fixed. Additionally, we propose a tentative, easily replicable protocol for the fine-tuning of math-specific LLMs, which has led to a significant improvement in the performance of a 7B-parameter LLM on the GSM8K and MATH datasets. We are committed to advancing the field of mathematical reasoning in LLMs.																																	2024-03-21	PPRN:87190879		
J	Ma, Kaixin; Zhang, Hongming; Wang, Hongwei; Pan, Xiaoman; Yu, Wenhao; Yu, Dong				Zhang, Hongming/ABF-8690-2021; Wang, Hongwei/HFT-3345-2022						LASER: LLM Agent with State-Space Exploration for Web Navigation								Arxiv											2	2;2024-02-21;https://www.arxiv.org/abs/2309.08172v2| 1;2023-09-15;https://www.arxiv.org/abs/2309.08172v1	arXiv:2309.08172			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 21 2024	2024	Apr;49(8):084004. Available from: http://dx.doi.org/10.1088/0953-4075/49/8/ 084004. 47 Pauls HL, Zank GP, Williams LL. Interaction medium. Journal of Geophysical Research: Available from: https://doi.org/10.1029%2F95ja02023. 48 Osterbrock DE. The Heating of the Magnetohydrodynamic Waves. The Astrophysical https://doi.org/10.1086%2F147165. 49 Wargnier QM, Martínez-Sykora J, Hansteen Collision Frequency in the Solar Atmosphere. Available from:https://doi.org/10.3847%2F1538-4357%2Fac6e62. 50 Díaz AJ, Khomenko E, Collados M. compressible plasmas: One fluid approach. Available from:http://dx.doi.org/10.1051/0004-6361/201322147. 51 Carlsson M. A computer program for solving in moving or static atmospheres. Uppsala 52 Rutten RJ. Radiative Transfer in Stellar Atmospheres; 53 Lukin VS, Khomenko E., Popescu Braileanu induced by Rayleigh-Taylor instability in Royal Society of London Series A. 2024;this 54 Leake JE, DeVore CR, Thayer JP, Burns and Neutral Gas Coupling in the Sun’s Chromosphere Space Science Reviews. 2014 oct;184(1-4):107–172. 1007%2Fs11214-014-0103-1. 55 Hunana P, Passot T, Khomenko E, Martínez-Gómez Generalized Fluid Models of the Braginskii																																	2024-07-23	PPRN:85048070		
J	Lin, Yukang; Han, Haonan; Gong, Chaoqun; Xu, Zunnan; Zhang, Yachao; Li, Xiu				ZHANG, Yachao/AAM-5411-2021; Xu, Zunnan/LLL-4337-2024						Consistent123: One Image to Highly Consistent 3D Asset Using Case-Aware Diffusion Priors								Arxiv											2	2;2024-02-20;https://www.arxiv.org/abs/2309.17261v2| 1;2023-09-29;https://www.arxiv.org/abs/2309.17261v1	arXiv:2309.17261			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 20 2024	2024	Reconstructing 3D objects from a single image guided by pretrained diffusion models has demonstrated promising outcomes. However, due to utilizing the case-agnostic rigid strategy, their generalization ability to arbitrary cases and the 3D consistency of reconstruction are still poor. In this work, we propose Consistent123, a case-aware two-stage method for highly consistent 3D asset reconstruction from one image with both 2D and 3D diffusion priors. In the first stage, Consistent123 utilizes only 3D structural priors for sufficient geometry exploitation, with a CLIP-based case-aware adaptive detection mechanism embedded within this process. In the second stage, 2D texture priors are introduced and progressively take on a dominant guiding role, delicately sculpting the details of the 3D model. Consistent123 aligns more closely with the evolving trends in guidance requirements, adaptively providing adequate 3D geometric initialization and suitable 2D texture refinement for different objects. Consistent123 can obtain highly 3D-consistent reconstruction and exhibits strong generalization ability across various objects. Qualitative and quantitative experiments show that our method significantly outperforms state-of-the-art image-to-3D methods.																																	2024-03-22	PPRN:85338253		
J	Xu, Zhiyang; Feng, Chao; Shao, Rulin; Ashby, Trevor; Shen, Ying; Jin, Di; Cheng, Yu; Wang, Qifan; Huang, Lifu				feng, chao/GOV-4453-2022						Vision-Flan: Scaling Human-Labeled Tasks in Visual Instruction Tuning								Arxiv											1	1;2024-02-18;https://www.arxiv.org/abs/2402.11690v1	arXiv:2402.11690			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 18 2024	2024	Despite vision -language models’ (VLMs) remarkable capabilities as versatile visual assistants, two substantial challenges persist within the existing VLM frameworks: (1) lacking task diversity in pretraining and visual instruction tuning, and (2) annotation error and bias in GPT-4 synthesized instruction tuning data. Both challenges lead to issues such as poor generalizability, hallucination, and catastrophic forgetting. To address these challenges, we construct VISION -FLAN, the most diverse publicly available visual instruction tuning dataset to date, comprising 187 diverse tasks and 1,664,261 instances sourced from academic datasets, and each task is accompanied by an expert -written instruction. In addition, we propose a two -stage instruction tuning framework, in which VLMs are firstly finetuned on VISION - FLAN and further tuned on GPT-4 synthesized data. We find this two -stage tuning framework significantly outperforms the traditional single -stage visual instruction tuning framework and achieves the state-of-the-art performance across a wide range of multi -modal evaluation benchmarks. Finally, we conduct indepth analyses to understand visual instruction tuning and our findings reveal that: (1) GPT-4 synthesized data does not substantially enhance VLMs’ capabilities but rather modulates the model’s responses to human -preferred formats; (2) A minimal quantity (e.g., 1,000) of GPT4 synthesized data can effectively align VLM responses with human -preference; (3) Visual instruction tuning mainly helps large -language models (LLMs) to understand visual features.																																	2024-03-19	PPRN:87761667		
J	Chang, Zhiyuan; Li, Mingyang; Liu, Yi; Wang, Junjie; Wang, Qing; Liu, Yang				Liu, Yang/D-2306-2013; chang, zhiyuan/MTB-7872-2025; LIU, YI/LUY-0513-2024; junjie2001, wang/JXM-3649-2024						Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues								Arxiv											2	2;2024-02-16;https://www.arxiv.org/abs/2402.09091v2| 1;2024-02-14;https://www.arxiv.org/abs/2402.09091v1	arXiv:2402.09091			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 16 2024	2024	With the development of LLMs, the security threats of LLMs are getting more and more attention. Numerous jailbreak attacks have been proposed to assess the security defense of LLMs. Current jailbreak attacks primarily utilize scenario camouflage techniques. However their explicitly mention of malicious intent will be easily recognized and defended by LLMs. In this paper, we propose an indirect jailbreak attack approach, Puzzler, which can bypass the LLM's defense strategy and obtain malicious response by implicitly providing LLMs with some clues about the original malicious query. In addition, inspired by the wisdom of "When unable to attack, defend" from Sun Tzu's Art of War, we adopt a defensive stance to gather clues about the original malicious query through LLMs. Extensive experimental results show that Puzzler achieves a query success rate of 96.6% on closed-source LLMs, which is 57.9%-82.7% higher than baselines. Furthermore, when tested against the state-of-the-art jailbreak detection approaches, Puzzler proves to be more effective at evading detection compared to baselines.																																	2024-02-27	PPRN:87684002		
J	Deng, Gelei; Liu, Yi; Wang, Kailong; Li, Yuekang; Zhang, Tianwei; Liu, Yang				Liu, Yang/D-2306-2013; Wang, Kailong/NLO-6290-2025; Zhang, Tianwei/AAV-8818-2020; Li, Yuekang/U-9646-2019; LIU, YI/LUY-0513-2024						Pandora: Jailbreak GPTs by Retrieval Augmented Generation Poisoning								Arxiv											1	1;2024-02-13;https://www.arxiv.org/abs/2402.08416v1	arXiv:2402.08416			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 13 2024	2024	Large Language Models~(LLMs) have gained immense popularity and are being increasingly applied in various domains. Consequently, ensuring the security of these models is of paramount importance. Jailbreak attacks, which manipulate LLMs to generate malicious content, are recognized as a significant vulnerability. While existing research has predominantly focused on direct jailbreak attacks on LLMs, there has been limited exploration of indirect methods. The integration of various plugins into LLMs, notably Retrieval Augmented Generation~(RAG), which enables LLMs to incorporate external knowledge bases into their response generation such as GPTs, introduces new avenues for indirect jailbreak attacks.   To fill this gap, we investigate indirect jailbreak attacks on LLMs, particularly GPTs, introducing a novel attack vector named Retrieval Augmented Generation Poisoning. This method, Pandora, exploits the synergy between LLMs and RAG through prompt manipulation to generate unexpected responses. Pandora uses maliciously crafted content to influence the RAG process, effectively initiating jailbreak attacks. Our preliminary tests show that Pandora successfully conducts jailbreak attacks in four different scenarios, achieving higher success rates than direct attacks, with 64.3% for GPT-3.5 and 34.8% for GPT-4.																																	2024-05-25	PPRN:87675392		
J	Tjuatja, Lindia; Chen, Valerie; Wu, Sherry Tongshuang; Talwalkar, Ameet; Neubig, Graham										Do LLMs exhibit human-like response biases? A case study in survey design								Arxiv											4	4;2024-02-06;https://www.arxiv.org/abs/2311.04076v5| 3;2024-01-15;https://www.arxiv.org/abs/2311.04076v3| 2;2023-11-29;https://www.arxiv.org/abs/2311.04076v2| 1;2023-11-07;https://www.arxiv.org/abs/2311.04076v1	arXiv:2311.04076			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 06 2024	2024	As large language models (LLMs) become more capable, there is growing excitement about the possibility of using LLMs as proxies for humans in real-world tasks where subjective labels are desired, such as in surveys and opinion polling. One widely-cited barrier to the adoption of LLMs as proxies for humans in subjective tasks is their sensitivity to prompt wording - but interestingly, humans also display sensitivities to instruction changes in the form of response biases. We investigate the extent to which LLMs reflect human response biases, if at all. We look to survey design, where human response biases caused by changes in the wordings of "prompts" have been extensively explored in social psychology literature. Drawing from these works, we design a dataset and framework to evaluate whether LLMs exhibit human-like response biases in survey questionnaires. Our comprehensive evaluation of nine models shows that popular open and commercial LLMs generally fail to reflect human-like behavior, particularly in models that have undergone RLHF. Furthermore, even if a model shows a significant change in the same direction as humans, we find that they are sensitive to perturbations that do not elicit significant changes in humans. These results highlight the pitfalls of using LLMs as human proxies, and underscore the need for finer-grained characterizations of model behavior. 																																	2024-02-22	PPRN:86076361		
J	Cheng, Qinyuan; Sun, Tianxiang; Liu, Xiangyang; Zhang, Wenwei; Yin, Zhangyue; Li, Shimin; Li, Linyang; He, Zhengfu; Chen, Kai; Qiu, Xipeng				Zhang, Yinyan/S-7675-2019; Liu, Xiangyang/AAL-9517-2020; Zhang, Wenwei/HKO-4277-2023; Sun, Tianxiang/AAA-7123-2022; Qiu, Xipeng/G-4071-2011; Cheng, Qinyuan/LDN-9770-2024						Can AI Assistants Know What They Don't Know?								Arxiv											2	2;2024-01-28;https://www.arxiv.org/abs/2401.13275v2| 1;2024-01-24;https://www.arxiv.org/abs/2401.13275v1	arXiv:2401.13275			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 28 2024	2024	Recently, AI assistants based on large language models (LLMs) show surprising performance in many tasks, such as dialogue, solving math problems, writing code, and using tools. Although LLMs possess intensive world knowledge, they still make factual errors when facing some knowledge intensive tasks, like open-domain question answering. These untruthful responses from the AI assistant may cause significant risks in practical applications. We believe that an AI assistant's refusal to answer questions it does not know is a crucial method for reducing hallucinations and making the assistant truthful. Therefore, in this paper, we ask the question "Can AI assistants know what they don't know and express them through natural language?" To answer this question, we construct a model-specific "I don't know" (Idk) dataset for an assistant, which contains its known and unknown questions, based on existing open-domain question answering datasets. Then we align the assistant with its corresponding Idk dataset and observe whether it can refuse to answer its unknown questions after alignment. Experimental results show that after alignment with Idk datasets, the assistant can refuse to answer most its unknown questions. For questions they attempt to answer, the accuracy is significantly higher than before the alignment.																																	2024-05-25	PPRN:87317367		
J	Zuegner, Daniel; Guennemann, Stephan										Adversarial Attacks on Graph Neural Networks via Meta Learning								Arxiv											2	2;2024-01-28;https://www.arxiv.org/abs/1902.08412v2| 1;2019-02-22;https://www.arxiv.org/abs/1902.08412v1	arXiv:1902.08412			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 28 2024	2024	Deep learning models for graphs have advanced the state of the art on many tasks. Despite their recent success, little is known about their robustness. We investigate training time attacks on graph neural networks for node classification that perturb the discrete graph structure. Our core principle is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. Our experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings. Remarkably, the perturbations created by our algorithm can misguide the graph neural networks such that they perform worse than a simple baseline that ignores all relational information. Our attacks do not assume any knowledge about or access to the target classifiers.																																	2024-02-15	PPRN:50707641		
J	Borusyak, Kirill; Jaravel, Xavier; Spiess, Jann										Revisiting Event Study Designs: Robust and Efficient Estimation								Arxiv											3	3;2024-01-16;https://www.arxiv.org/abs/2108.12419v5| 2;2023-09-18;https://www.arxiv.org/abs/2108.12419v4| 1;2021-08-27;https://www.arxiv.org/abs/2108.12419v2	arXiv:2108.12419			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 16 2024	2024	We develop a framework for difference-in-differences designs with staggered treatment adoption and heterogeneous causal effects. We show that conventional regression-based estimators fail to provide unbiased estimates of relevant estimands absent strong restrictions on treatment effect homogeneity. We then derive the efficient estimator addressing this challenge, which takes an intuitive “imputation” form when treatment-effect heterogeneity is unrestricted. We characterize the asymptotic behavior of the estimator, propose tools for inference, and develop tests for identifying assumptions. Our method applies with time-varying controls, in triple-difference designs, and with certain non-binary treatments. We show the practical relevance of our results in a simulation study and an application. Studying the consumption response to tax rebates in the United States, we find that the notional marginal propensity to consume is between 8 and 11 percent in the first quarter — about half as large as benchmark estimates used to calibrate macroeconomic models — and predominantly occurs in the first month after the rebate.																																	2024-05-25	PPRN:12135641		
J	Hertz, Amir; Voynov, Andrey; Fruchter, Shlomi; Cohen-Or, Daniel										Style Aligned Image Generation via Shared Attention								Arxiv											2	2;2024-01-11;https://www.arxiv.org/abs/2312.02133v2| 1;2023-12-04;https://www.arxiv.org/abs/2312.02133v1	arXiv:2312.02133			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 11 2024	2024	Large-scale Text-to-Image (T2I) models have rapidly gained prominence across creative fields, generating visually compelling outputs from textual prompts. However, controlling these models to ensure consistent style remains challenging, with existing methods necessitating fine-tuning and manual intervention to disentangle content and style. In this paper, we introduce StyleAligned, a novel technique designed to establish style alignment among a series of generated images. By employing minimal 'attention sharing' during the diffusion process, our method maintains style consistency across images within T2I models. This approach allows for the creation of style-consistent images using a reference style through a straightforward inversion operation. Our method's evaluation across diverse styles and text prompts demonstrates high-quality synthesis and fidelity, underscoring its efficacy in achieving consistent style across various inputs.																																	2024-01-27	PPRN:86379724		
J	Xu, Zhijian; Zeng, Ailing; Xu, Qiang				Xu, Zhijian/E-1309-2013						FITS: Modeling Time Series with 10k&nbsp;Parameters								Arxiv											3	3;2024-01-05;https://www.arxiv.org/abs/2307.03756v3| 2;2023-09-22;https://www.arxiv.org/abs/2307.03756v2| 1;2023-07-06;https://www.arxiv.org/abs/2307.03756v1	arXiv:2307.03756			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 05 2024	2024	In this paper, we introduce FITS, a lightweight yet powerful model for time series analysis. Unlike existing models that directly process raw time-domain data, FITS operates on the principle that time series can be manipulated through interpolation in the complex frequency domain, achieving performance comparable to state-of-the-art models for time series forecasting and anomaly detection tasks. Notably, FITS accomplishes this with a svelte profile of just about 10k parameters, making it ideally suited for edge devices and paving the way for a wide range of applications.																																	2024-05-25	PPRN:73864170		
J	Zhang, David Junhao; Li, Dongxu; Le, Hung; Shou, Mike Zheng; Xiong, Caiming; Sahoo, Doyen				Shou, Mike Zheng/LXW-9197-2024; LI, DONGXU/GNM-6998-2022						Moonshot: Towards Controllable Video Generation and Editing with Multimodal Conditions								Arxiv											1	1;2024-01-03;https://www.arxiv.org/abs/2401.01827v1	arXiv:2401.01827			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 03 2024	2024	Most existing video diffusion models (VDMs) are limited to mere text conditions. Thereby, they are usually lacking in control over visual appearance and geometry structure of the generated videos. This work presents Moonshot, a new video generation model that conditions simultaneously on multimodal inputs of image and text. The model builts upon a core module, called multimodal video block (MVB), which consists of conventional spatialtemporal layers for representing video features, and a decoupled cross-attention layer to address image and text inputs for appearance conditioning. In addition, we carefully design the model architecture such that it can optionally integrate with pre-trained image ControlNet modules for geometry visual conditions, without needing of extra training overhead as opposed to prior methods. Experiments show that with versatile multimodal conditioning mechanisms, Moonshot demonstrates significant improvement on visual quality and temporal consistency compared to existing models. In addition, the model can be easily repurposed for a variety of generative applications, such as personalized video generation, image animation and video editing, unveiling its potential to serve as a fundamental architecture for controllable video generation. 																																	2024-01-11	PPRN:86943855		
J	Roberts-Borsani, Guido; Treu, Tommaso; Shapley, Alice; Fontana, Adriano; Pentericci, Laura; Castellano, Marco; Morishita, Takahiro; Bergamini, Pietro; Rosati, Piero				Treu, Tommaso/KYP-7127-2024						Between the Extremes: A JWST Spectroscopic Benchmark for High-redshift Galaxies Using ~500 Confirmed Sources at Z ≥ 5								Arxiv											2	2;2024-12-17;https://www.arxiv.org/abs/2403.07103v2| 1;2024-03-11;https://www.arxiv.org/abs/2403.07103v1	arXiv:2403.07103			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 17 2024	2024	The exceptional spectra of the most luminous z>10 sources observed so far have challenged our understanding of early galaxy evolution, requiring a new observational benchmark for meaningful interpretation. As such, we construct spectroscopic templates representative of high-redshift, star-forming populations, using 482 confirmed sources at z=5.0−12.9 with JWST/NIRSpec prism observations, and report on their average properties. We find z=5−11 galaxies are dominated by blue UV continuum slopes (β=−2.3 to −2.7) and reduced Balmer indices, characteristic of dust-poor and young systems, with a shift towards bluer slopes and younger ages with redshift. The evolution is mirrored by ubiquitous CIII] detections across all redshifts (rest-frame equivalent widths of =5−14 Å), which increase in strength towards early times. Rest-frame optical lines reveal elevated ratios (O32=7−31, R23=5−8, and Ne3O2=1−2) and subsolar metallicities (log O/H=7.3−7.9), typical of ionization conditions and metallicities rarely observed in z∼0 populations. Within our sample, we identify 57 Lyα emitters, which we stack and compare to a matched sample of nonemitters. The former are characterized by more extreme ionizing conditions with enhanced CIII], CIV, and HeII+[OIII] line emission, younger stellar populations from Balmer jumps, and a more pristine interstellar medium seen through bluer UV slopes and elevated rest-frame optical line ratios. The novel comparison illustrates important intrinsic differences between the two populations, with implications for Lyα visibility. The spectral templates derived here represent a new observational benchmark with which to interpret high-redshift sources, lifting our constraints on their global properties to unprecedented heights and extending out to the earliest of cosmic times.																																	2025-01-25	PPRN:88118036		
J	Shorinwa, Ola; Mei, Zhiting; Lidard, Justin; Ren, Allen Z.; Majumdar, Anirudha										A Survey on Uncertainty Quantification of Large Language Models: Taxonomy, Open Research Challenges, and Future Directions								Arxiv											1	1;2024-12-07;https://www.arxiv.org/abs/2412.05563v1	arXiv:2412.05563			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 07 2024	2024	The remarkable performance of large language models (LLMs) in content generation, coding, and common-sense reasoning has spurred widespread integration into many facets of society. However, integration of LLMs raises valid questions on their reliability and trustworthiness, given their propensity to generate hallucinations: plausible, factually-incorrect responses, which are expressed with striking confidence. Previous work has shown that hallucinations and other non-factual responses generated by LLMs can be detected by examining the uncertainty of the LLM in its response to the pertinent prompt, driving significant research efforts devoted to quantifying the uncertainty of LLMs. This survey seeks to provide an extensive review of existing uncertainty quantification methods for LLMs, identifying their salient features, along with their strengths and weaknesses. We present existing methods within a relevant taxonomy, unifying ostensibly disparate methods to aid understanding of the state of the art. Furthermore, we highlight applications of uncertainty quantification methods for LLMs, spanning chatbot and textual applications to embodied artificial intelligence applications in robotics. We conclude with open research challenges in uncertainty quantification of LLMs, seeking to motivate future research.																																	2025-01-17	PPRN:119791483		
J	Rodriguez, Juan A.; Puri, Abhay; Agarwal, Shubham; Laradji, Issam H.; Rodriguez, Pau; Rajeswar, Sai; Vazquez, David; Pal, Christopher; Pedersoli, Marco				Vázquez, David/P-3306-2019						StarVector: Generating Scalable Vector Graphics Code from Images and Text								Arxiv											2	2;2024-12-04;https://www.arxiv.org/abs/2312.11556v2| 1;2023-12-17;https://www.arxiv.org/abs/2312.11556v1	arXiv:2312.11556			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 04 2024	2024	Scalable Vector Graphics (SVGs) are vital for modern image rendering due to their scalability and versatility. Previous SVG generation methods have focused on curve-based vectorization, lacking semantic understanding, often producing artifacts, and struggling with SVG primitives beyond path curves. To address these issues, we introduce StarVector, a multimodal large language model for SVG generation. It performs image vectorization by understanding image semantics and using SVG primitives for compact, precise outputs. Unlike traditional methods, StarVector works directly in the SVG code space, leveraging visual understanding to apply accurate SVG primitives. To train StarVector, we create SVG-Stack, a diverse dataset of 2M samples that enables generalization across vectorization tasks and precise use of primitives like ellipses, polygons, and text. We address challenges in SVG evaluation, showing that pixel-based metrics like MSE fail to capture the unique qualities of vector graphics. We introduce SVG-Bench, a benchmark across 10 datasets, and 3 tasks: Image-to-SVG, Text-to-SVG generation, and diagram generation. Using this setup, StarVector achieves state-of-the-art performance, producing more compact and semantically rich SVGs.																																	2025-01-15	PPRN:86726730		
J	Ding, Zhiguo; Schober, Robert; Poor, H. Vincent				Ding, Zhiguo/B-9805-2017; Poor, H./S-5027-2016; Schober, Robert/ABC-9480-2020						Flexible-Antenna Systems: A Pinching-Antenna Perspective								Arxiv											1	1;2024-12-03;https://www.arxiv.org/abs/2412.02376v1	arXiv:2412.02376			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 03 2024	2024	Flexible-antenna systems have recently received significant research interest due to their capability to reconfigure wireless channels intelligently. This paper focuses on a new type of flexible-antenna technology, termed pinching antennas, which can be realized by applying small dielectric particles on a waveguide. Analytical results are first developed for the simple case with a single pinching antenna and a single waveguide, where the unique feature of the pinching-antenna system to create strong line-of-sight links and mitigate large-scale path loss is demonstrated. An advantageous feature of pinching-antenna systems is that multiple pinching antennas can be activated on a single waveguide at no extra cost; however, they must be fed with the same signal. This feature motivates the application of non-orthogonal multiple access (NOMA), and analytical results are provided to demonstrate the superior performance of NOMA-assisted pinching-antenna systems. Finally, the case with multiple pinching antennas and multiple waveguides is studied, which resembles a classical multiple-input single-input (MISO) interference channel. By exploiting the capability of pinching antennas to reconfigure the wireless channel, it is revealed that a performance upper bound on the interference channel becomes achievable, where the achievability conditions are also identified. Computer simulation results are presented to verify the developed analytical results and demonstrate the superior performance of pinching-antenna systems.																																	2025-01-15	PPRN:119687368		
J	Li, Xiang; Qiu, Kai; Chen, Hao; Kuen, Jason; Gu, Jiuxiang; Raj, Bhiksha; Lin, Zhe				林, Z/HHD-0305-2022; Kuen, Jason/AAA-1809-2020						ImageFolder: Autoregressive Image Generation with Folded Tokens								Arxiv											3	3;2024-12-03;https://www.arxiv.org/abs/2410.01756v3| 2;2024-10-15;https://www.arxiv.org/abs/2410.01756v2| 1;2024-10-02;https://www.arxiv.org/abs/2410.01756v1	arXiv:2410.01756			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 03 2024	2024	Image tokenizers are crucial for visual generative models, e.g., diffusion models (DMs) and autoregressive (AR) models, as they construct the latent representation for modeling. Increasing token length is a common approach to improve the image reconstruction quality. However, tokenizers with longer token lengths are not guaranteed to achieve better generation quality. There exists a trade-off between reconstruction and generation quality regarding token length. In this paper, we investigate the impact of token length on both image reconstruction and generation and provide a flexible solution to the tradeoff. We propose ImageFolder, a semantic tokenizer that provides spatially aligned image tokens that can be folded during autoregressive modeling to improve both generation efficiency and quality. To enhance the representative capability without increasing token length, we leverage dual-branch product quantization to capture different contexts of images. Specifically, semantic regularization is introduced in one branch to encourage compacted semantic information while another branch is designed to capture the remaining pixel-level details. Extensive experiments demonstrate the superior quality of image generation and shorter token length with ImageFolder tokenizer.																																	2025-01-15	PPRN:100933898		
J	Jia, Xiaosong; Yang, Zhenjie; Li, Qifeng; Zhang, Zhiyuan; Yan, Junchi				zhiyuan, zhang/E-5774-2019; Jia, Xiaosong/IWE-2802-2023						Bench2Drive: Towards Multi-Ability Benchmarking of Closed-Loop End-To-End Autonomous Driving								Arxiv											3	3;2024-11-27;https://www.arxiv.org/abs/2406.03877v3| 2;2024-06-11;https://www.arxiv.org/abs/2406.03877v2| 1;2024-06-06;https://www.arxiv.org/abs/2406.03877v1	arXiv:2406.03877			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Nov 27 2024	2024	In an era marked by the rapid scaling of foundation models, autonomous driving technologies are approaching a transformative threshold where end-to-end autonomous driving (E2E-AD) emerges due to its potential of scaling up in the data-driven manner. However, existing E2E-AD methods are mostly evaluated under the open-loop log-replay manner with L2 errors and collision rate as metrics (e.g., in nuScenes), which could not fully reflect the driving performance of algorithms as recently acknowledged in the community. For those E2E-AD methods evaluated under the closed-loop protocol, they are tested in fixed routes (e.g., Town05Long and Longest6 in CARLA) with the driving score as metrics, which is known for high variance due to the unsmoothed metric function and large randomness in the long route. Besides, these methods usually collect their own data for training, which makes algorithm-level fair comparison infeasible. To fulfill the paramount need of comprehensive, realistic, and fair testing environments for Full Self-Driving (FSD), we present Bench2Drive, the first benchmark for evaluating E2E-AD systems’ multiple abilities in a closed-loop manner. Bench2Drive’s official training data consists of 2 million fully annotated frames, collected from 13638 short clips uniformly distributed under 44 interactive scenarios (cut-in, overtaking, detour, etc), 23 weathers (sunny, foggy, rainy, etc), and 12 towns (urban, village, university, etc) in CARLA v2. Its evaluation protocol requires E2E-AD models to pass 44 interactive scenarios under different locations and weathers which sums up to 220 routes and thus provides a comprehensive and disentangled assessment about their driving capability under different situations. We implement state-of-the-art E2E-AD models and evaluate them in Bench2Drive, providing insights regarding current status and future directions.																																	2025-01-10	PPRN:89249167		
J	Gao, Shanghua; Koker, Teddy; Queen, Owen; Hartvigsen, Thomas; Tsiligkaridis, Theodoros; Zitnik, Marinka										UniTS: A Unified Multi-Task Time Series Model								Arxiv											3	3;2024-11-25;https://www.arxiv.org/abs/2403.00131v3| 2;2024-05-29;https://www.arxiv.org/abs/2403.00131v2| 1;2024-02-29;https://www.arxiv.org/abs/2403.00131v1	arXiv:2403.00131			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 25 2024	2024	Although pre-trained transformers and reprogrammed text-based LLMs have shown strong performance on time series tasks, the best-performing architectures vary widely across tasks, with most models narrowly focused on specific areas, such as time series forecasting. Unifying predictive and generative time series tasks within a single model remains challenging. We introduce UniTS, a unified multi-task time series model that utilizes task tokenization to integrate predictive and generative tasks into a single framework. UniTS employs a modified transformer block to capture universal time series representations, enabling transferability from a heterogeneous, multi-domain pre-training dataset-characterized by diverse dynamic patterns, sampling rates, and temporal scales-to a wide range of downstream datasets with varied task specifications and data domains. Tested on 38 datasets across human activity sensors, healthcare, engineering, and finance, UniTS achieves superior performance compared to 12 forecasting models, 20 classification models, 18 anomaly detection models, and 16 imputation models, including adapted text-based LLMs. UniTS also demonstrates strong few-shot and prompt capabilities when applied to new domains and tasks. In single-task settings, UniTS outperforms competitive task-specialized time series models. 																																	2025-01-08	PPRN:87996479		
J	Deng, Yihe; Lu, Pan; Yin, Fan; Hu, Ziniu; Shen, Sheng; Gu, Quanquan; Zou, James; Chang, Kai-Wei; Wang, Wei				Chang, Kai-Wei/AAJ-7874-2020; Hu, Ziniu/HJI-4899-2023						Enhancing Large Vision Language Models with Self-Training on Image Comprehension								Arxiv											1	1;2024-11-24;https://www.arxiv.org/abs/2405.19716v2	arXiv:2405.19716			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 24 2024	2024	Large vision language models (LVLMs) integrate large language models (LLMs) with pre-trained vision encoders, thereby activating the perception capability of the model to understand image inputs for different queries and conduct subsequent reasoning. Improving this capability requires high-quality vision-language data, which is costly and labor-intensive to acquire. Self-training approaches have been effective in single-modal settings to alleviate the need for labeled data by leveraging model's own generation. However, effective self-training remains a challenge regarding the unique visual perception and reasoning capability of LVLMs. To address this, we introduce Self-Training on Image Comprehension (STIC), which emphasizes a self-training approach specifically for image comprehension. First, the model self-constructs a preference dataset for image descriptions using unlabeled images. Preferred responses are generated through a step-by-step prompt, while dis-preferred responses are generated from either corrupted images or misleading prompts. To further self-improve reasoning on the extracted visual information, we let the model reuse a small portion of existing instruction-tuning data and append its self-generated image descriptions to the prompts. We validate the effectiveness of STIC across seven different benchmarks, demonstrating substantial performance gains of 4.0% on average while using 70% less supervised fine-tuning data than the current method. Further studies investigate various components of STIC and highlight its potential to leverage vast quantities of unlabeled images for self-training. Code and data are made publicly available.																																	2025-01-08	PPRN:89110554		
J	Long, Junfeng; Ren, Junli; Shi, Moji; Wang, Zirui; Huang, Tao; Luo, Ping; Pang, Jiangmiao				Luo, Ping/HGE-7623-2022; Long, Junfeng/KCZ-2128-2024; 王, 梓睿/IUN-3605-2023						Learning Humanoid Locomotion with Perceptive Internal Model								Arxiv											1	1;2024-11-21;https://www.arxiv.org/abs/2411.14386v1	arXiv:2411.14386			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 21 2024	2024	In contrast to quadruped robots that can navigate diverse terrains using a "blind" policy, humanoid robots require accurate perception for stable locomotion due to their high degrees of freedom and inherently unstable morphology. However, incorporating perceptual signals often introduces additional disturbances to the system, potentially reducing its robustness, generalizability, and efficiency. This paper presents the Perceptive Internal Model (PIM), which relies on onboard, continuously updated elevation maps centered around the robot to perceive its surroundings. We train the policy using ground-truth obstacle heights surrounding the robot in simulation, optimizing it based on the Hybrid Internal Model (HIM), and perform inference with heights sampled from the constructed elevation map. Unlike previous methods that directly encode depth maps or raw point clouds, our approach allows the robot to perceive the terrain beneath its feet clearly and is less affected by camera movement or noise. Furthermore, since depth map rendering is not required in simulation, our method introduces minimal additional computational costs and can train the policy in 3 hours on an RTX 4090 GPU. We verify the effectiveness of our method across various humanoid robots, various indoor and outdoor terrains, stairs, and various sensor configurations. Our method can enable a humanoid robot to continuously climb stairs and has the potential to serve as a foundational algorithm for the development of future humanoid control methods.																																	2024-12-31	PPRN:119317275		
J	Dunefsky, Jacob; Chlenski, Philippe; Nanda, Neel										Transcoders Find Interpretable LLM Feature Circuits								Arxiv											2	2;2024-11-06;https://www.arxiv.org/abs/2406.11944v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11944v1	arXiv:2406.11944			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 06 2024	2024	A key goal in mechanistic interpretability is circuit analysis: finding sparse sub- graphs of models corresponding to specific behaviors or capabilities. However, MLP sublayers make fine-grained circuit analysis on transformer-based language models difficult. In particular, interpretable features—such as those found by sparse autoencoders (SAEs)—are typically linear combinations of extremely many neurons, each with its own nonlinearity to account for. Circuit analysis in this setting thus either yields intractably large circuits or fails to disentangle local and global behavior. To address this we explore transcoders, which seek to faithfully approximate a densely activating MLP layer with a wider, sparsely-activating MLP layer. We introduce a novel method for using transcoders to perform weights-based circuit analysis through MLP sublayers. The resulting circuits neatly factorize into input-dependent and input-invariant terms. We then successfully train transcoders on language models with 120M, 410M, and 1.4B parameters, and find them to perform at least on par with SAEs in terms of sparsity, faithfulness, and human- interpretability. Finally, we apply transcoders to reverse-engineer unknown circuits in the model, and we obtain novel insights regarding the “greater-than circuit” in GPT2-small. Our results suggest that transcoders can prove effective in decomposing model computations involving MLPs into interpretable circuits. Code is available at https://github.com/jacobdunefsky/transcoder_circuits/.																																	2024-12-16	PPRN:89361280		
J	Herde, Maximilian; Raonic, Bogdan; Rohner, Tobias; Kappeli, Roger; Molinaro, Roberto; de Bezenac, Emmanuel; Mishra, Siddhartha				Molinaro, Roberto/AAM-9963-2021						Poseidon: Efficient Foundation Models for PDEs								Arxiv											2	2;2024-11-05;https://www.arxiv.org/abs/2405.19101v2| 1;2024-05-29;https://www.arxiv.org/abs/2405.19101v1	arXiv:2405.19101			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Nov 05 2024	2024	We introduce Poseidon, a foundation model for learning the solution operators of PDEs. It is based on a multiscale operator transformer, with time-conditioned layer norms that enable continuous-in-time evaluations. A novel training strategy leveraging the semi-group property of time-dependent PDEs to allow for significant scaling-up of the training data is also proposed. Poseidon is pretrained on a diverse, large scale dataset for the governing equations of fluid dynamics. It is then evaluated on a suite of 15 challenging downstream tasks that include a wide variety of PDE types and operators. We show that Poseidon exhibits excellent performance across the board by outperforming baselines significantly, both in terms of sample efficiency and accuracy. Poseidon also generalizes very well to new physics that is not seen during pretraining. Moreover, Poseidon scales with respect to model and data size, both for pretraining and for downstream tasks. Taken together, our results showcase the surprising ability of Poseidon to learn effective representations from a very small set of PDEs during pretraining in order to generalize well to unseen and unrelated PDEs downstream, demonstrating its potential as an effective, general purpose PDE foundation model. 																																	2024-12-09	PPRN:91461546		
J	Liu, Fei; Yao, Yiming; Guo, Ping; Yang, Zhiyuan; Zhao, Zhe; Lin, Xi; Tong, Xialiang; Yuan, Mingxuan; Lu, Zhichao; Wang, Zhenkun; Zhang, Qingfu				Guo, Ping/KIE-2429-2024; Zhang, Qingfu/K-4320-2015						A Systematic Survey on Large Language Models for Algorithm Design								Arxiv											3	3;2024-11-01;https://www.arxiv.org/abs/2410.14716v3| 2;2024-10-28;https://www.arxiv.org/abs/2410.14716v2| 1;2024-10-11;https://www.arxiv.org/abs/2410.14716v1	arXiv:2410.14716			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 01 2024	2024	Algorithm Design (AD) is crucial for effective problem-solving across various domains. The advent of Large Language Models (LLMs) has notably enhanced the automation and innovation within this field, offering new perspectives and promising solutions. Over the past three years, the integration of LLMs into AD (LLM4AD) has seen substantial progress, with applications spanning optimization, machine learning, mathematical reasoning, and scientific discovery. Given the rapid advancements and expanding scope of this field, a systematic review is both timely and necessary. This paper provides a systematic review of LLM4AD. First, we offer an overview and summary of existing studies. Then, we introduce a taxonomy and review the literature across four dimensions: the roles of LLMs, search methods, prompt methods, and application domains with a discussion of potential and achievements of LLMs in AD. Finally, we identify current challenges and highlight several promising directions for future research.																																	2024-12-06	PPRN:118757992		
J	Wen, Bosi; Ke, Pei; Gu, Xiaotao; Wu, Lindong; Huang, Hao; Zhou, Jinfeng; Li, Wenchuang; Hu, Binxin; Gao, Wendy; Xu, Jiaxin; Liu, Yiming; Tang, Jie; Wang, Hongning; Huang, Minlie				Zhou, Jinfeng/JYP-1934-2024; Liu, Yi/HTN-4916-2023; Wang, Hongning/GPK-7527-2022						Benchmarking Complex Instruction-Following with Multiple Constraints Composition								Arxiv											3	3;2024-10-31;https://www.arxiv.org/abs/2407.03978v3| 2;2024-07-11;https://www.arxiv.org/abs/2407.03978v2| 1;2024-07-04;https://www.arxiv.org/abs/2407.03978v1	arXiv:2407.03978			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 31 2024	2024	Instruction following is one of the fundamental capabilities of large language models (LLMs). As the ability of LLMs is constantly improving, they have been increasingly applied to deal with complex human instructions in real-world scenarios. Therefore, how to evaluate the ability of complex instruction-following of LLMs has become a critical research problem. Existing benchmarks mainly focus on modeling different types of constraints in human instructions while neglecting the composition of different constraints, which is an indispensable constituent in complex instructions. To this end, we propose ComplexBench, a benchmark for comprehensively evaluating the ability of LLMs to follow complex instructions composed of multiple constraints. We propose a hierarchical taxonomy for complex instructions, including 4 constraint types, 19 constraint dimensions, and 4 composition types, and manually collect a high-quality dataset accordingly. To make the evaluation reliable, we augment LLM-based evaluators with rules to effectively verify whether generated texts can satisfy each constraint and composition. Furthermore, we obtain the final evaluation score based on the dependency structure determined by different composition types. ComplexBench identifies significant deficiencies in existing LLMs when dealing with complex instructions with multiple constraints composition.1																																	2024-12-06	PPRN:90733584		
J	Yang, Jingyun; Cao, Zi-ang; Deng, Congyue; Antonova, Rika; Song, Shuran; Bohg, Jeannette				Yang, Jingyun/AAS-4711-2021; Bohg, Jeannette/AAD-4010-2019						EquiBot: SIM(3)-Equivariant Diffusion Policy for Generalizable and Data Efficient Learning								Arxiv											2	2;2024-10-29;https://www.arxiv.org/abs/2407.01479v2| 1;2024-07-01;https://www.arxiv.org/abs/2407.01479v1	arXiv:2407.01479			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 29 2024	2024	Building effective imitation learning methods that enable robots to learn from limited data and still generalize across diverse real-world environments is a long-standing problem in robot learning. We propose Equibot, a robust, data-efficient, and generalizable approach for robot manipulation task learning. Our approach combines SIM(3)-equivariant neural network architectures with diffusion models. This ensures that our learned policies are invariant to changes in scale, rotation, and translation, enhancing their applicability to unseen environments while retaining the benefits of diffusion-based policy learning such as multi-modality and robustness. We show on a suite of 6 simulation tasks that our proposed method reduces the data requirements and improves generalization to novel scenarios. In the real world, with 10 variations of 6 mobile manipulation tasks, we show that our method can easily generalize to novel objects and scenes after learning from just 5 minutes of human demonstrations in each task.																																	2024-11-30	PPRN:90675544		
J	Chen, Yifan; Epperly, Ethan N.; Tropp, Joel A.; Webber, Robert J.				Tropp, Joel/B-1283-2013; Chen, Yifan/ODK-0885-2025; Webber, Robert/JXN-9427-2024						Randomly pivoted Cholesky: Practical approximation of a kernel matrix with few entry evaluations								Arxiv											3	3;2024-10-22;https://www.arxiv.org/abs/2207.06503v6| 2;2023-12-12;https://www.arxiv.org/abs/2207.06503v5| 1;2022-07-13;https://www.arxiv.org/abs/2207.06503v2	arXiv:2207.06503			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 22 2024	2024	The randomly pivoted partial Cholesky algorithm (RPCholesky) computes a factorized rank-k approximation of an N x N positive-semidefinite (psd) matrix. RPCholesky requires only (k + 1)N entry evaluations and O(k2 N) additional arithmetic operations, and it can be implemented with just a few lines of code. The method is particularly useful for approximating a kernel matrix. This paper offers a thorough new investigation of the empirical and theoretical behavior of this fundamental algorithm. For matrix approximation problems that arise in scientific machine learning, experiments show that RPCholesky matches or beats the performance of alternative algorithms. Moreover, RPCholesky provably returns low-rank approximations that are nearly optimal. The simplicity, effectiveness, and robustness of RPCholesky strongly support its use in scientific computing and machine learning applications.																																	2024-11-23	PPRN:11057348		
J	Zhou, Yuan; Wang, Qiuyue; Cai, Yuxuan; Yang, Huan				Cai, Yuxuan/MCJ-4969-2025						Allegro: Open the Black Box of Commercial-Level Video Generation Model								Arxiv											1	1;2024-10-20;https://www.arxiv.org/abs/2410.15458v1	arXiv:2410.15458			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 20 2024	2024	Significant advancements have been made in the field of video generation, with the open-source community contributing a wealth of research papers and tools for training high-quality models. However, despite these efforts, the available information and resources remain insufficient for achieving commercial-level performance. In this report, we open the black box and introduce $textbf{Allegro}$, an advanced video generation model that excels in both quality and temporal consistency. We also highlight the current limitations in the field and present a comprehensive methodology for training high-performance, commercial-level video generation models, addressing key aspects such as data, model architecture, training pipeline, and evaluation. Our user study shows that Allegro surpasses existing open-source models and most commercial models, ranking just behind Hailuo and Kling. 																																	2024-11-20	PPRN:118759375		
J	Agashe, Saaket; Han, Jiuzhou; Gan, Shuyu; Yang, Jiachen; Li, Ang; Wang, Xin Eric				Jiao, Licheng/JOZ-0842-2023; Wang, Xin/ABD-3905-2020						Agent S: An Open Agentic Framework that Uses Computers Like a Human								Arxiv											1	1;2024-10-10;https://www.arxiv.org/abs/2410.08164v1	arXiv:2410.08164			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 10 2024	2024	We present Agent S, an open agentic framework that enables autonomous interaction with computers through a Graphical User Interface (GUI), aimed at transforming human-computer interaction by automating complex, multi-step tasks. Agent S aims to address three key challenges in automating computer tasks: acquiring domain-specific knowledge, planning over long task horizons, and handling dynamic, non-uniform interfaces. To this end, Agent S introduces experience-augmented hierarchical planning, which learns from external knowledge search and internal experience retrieval at multiple levels, facilitating efficient task planning and subtask execution. In addition, it employs an Agent-Computer Interface (ACI) to better elicit the reasoning and control capabilities of GUI agents based on Multimodal Large Language Models (MLLMs). Evaluation on the OSWorld benchmark shows that Agent S outperforms the baseline by 9.37% on success rate (an 83.6% relative improvement) and achieves a new state-of-the-art. Comprehensive analysis highlights the effectiveness of individual components and provides insights for future improvements. Furthermore, Agent S demonstrates broad generalizability to different operating systems on a newly-released WindowsAgentArena benchmark. 																																	2024-11-01	PPRN:105777712		
J	Aleithan, Reem; Xue, Haoran; Mohajer, Mohammad Mahdi; Nnorom, Elijah; Uddin, Gias; Wang, Song										SWE-Bench+: Enhanced Coding Benchmark for LLMs								Arxiv											1	1;2024-10-10;https://www.arxiv.org/abs/2410.06992v2	arXiv:2410.06992			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 10 2024	2024	Large Language Models (LLMs) in Software Engineering (SE) can offer assistance for coding. To facilitate a rigorous evaluation of LLMs in practical coding contexts, Carlos et al. introduced the SWE-bench dataset, which comprises 2,294 real-world GitHub issues and their corresponding pull requests, collected from 12 widely used Python repositories. Several impressive LLM-based toolkits recently are developed and evaluated on this dataset. However, a systematic evaluation of the quality of SWE-bench remains missing. In this paper, we addressed this gap by presenting an empirical analysis of the SWE-bench dataset. We conducted a manual screening of instances where SWEAgent + GPT-4 successfully resolved issues by comparing the model-generated patches with the actual pull requests. SWE-Agent+GPT-4 was at the top of SWE-bench leaderboard during the time of our study. Our analysis reveals some critical issues with the SWE-bench dataset: 1) 32.67% of the successful patches involve cheating as the solutions were directly provided in the issue report or the comments. We refer to as solution leakage problem. 2) 31.08% of the passed patches are suspicious patches due to weak test cases, i.e., the tests were not adequate to verify the correctness of a patch. When we filtered out these problematic issues, the resolution rate of SWE-Agent+GPT-4 dropped from 12.47% to 3.97%. We also observed that the same data quality issues also exist in the two variants of SWE-bench, i.e., SWE-bench Lite and SWE-Bench Verified. In addition, over 94% of the issues were created before LLM's knowledge cutoff dates, posing potential data leakage issues. The critical problem in the current versions of SWE-bench dataset motivated us to refine it to build a more rigorous evaluation dataset SWE-Bench+ . We created SWE-bench+ by collecting GitHub issues that were created after the training cutoff dates of the LLMs to prevent the potential data leakage problem. We also ensure that the issues collected do not contain solutions in their reports or comments. After carefully analyzing the passed instances from the SWE-Agent + GPT-4 model with the new dataset, SWE-Bench+ , we observed a decline in the pass rate, dropping from 3.97% (as seen on the refined SWE-Bench ) to a resolution rate of 0.55%. We further evaluated SWE-RAG + GPT-4 , SWE-RAG + GPT-3.5 , and AutoCodeRover + GPT-4o models on the new dataset to verify our findings, where the resolution rates of the models drop significantly, which are 0.73%, 0.55%, and 3.83%, respectively.																																	2024-10-25	PPRN:105778401		
J	Wang, Qiuheng; Shi, Yukai; Ou, Jiarong; Chen, Rui; Lin, Ke; Wang, Jiahao; Jiang, Boyuan; Yang, Haotian; Zheng, Mingwu; Tao, Xin; Yang, Fei; Wan, Pengfei; Zhang, Di				jiahao, wang/ADP-2362-2022; Yang, Haotian/LCE-5972-2024						Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content								Arxiv											1	1;2024-10-10;https://www.arxiv.org/abs/2410.08260v1	arXiv:2410.08260			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 10 2024	2024	As visual generation technologies continue to advance, the scale of video datasets has expanded rapidly, and the quality of these datasets is critical to the performance of video generation models. We argue that temporal splitting, detailed captions, and video quality filtering are three key factors that determine dataset quality. However, existing datasets exhibit various limitations in these areas. To address these challenges, we introduce Koala-36M, a large-scale, high-quality video dataset featuring accurate temporal splitting, detailed captions, and superior video quality. The core of our approach lies in improving the consistency between fine-grained conditions and video content. Specifically, we employ a linear classifier on probability distributions to enhance the accuracy of transition detection, ensuring better temporal consistency. We then provide structured captions for the splitted videos, with an average length of 200 words, to improve text-video alignment. Additionally, we develop a Video Training Suitability Score (VTSS) that integrates multiple sub-metrics, allowing us to filter high-quality videos from the original corpus. Finally, we incorporate several metrics into the training process of the generation model, further refining the fine-grained conditions. Our experiments demonstrate the effectiveness of our data processing pipeline and the quality of the proposed Koala-36M dataset.																																	2024-11-03	PPRN:110111422		
J	Xia, Lianghao; Kao, Ben; Huang, Chao										OpenGraph: Towards Open Graph Foundation Models								Arxiv											4	4;2024-10-09;https://www.arxiv.org/abs/2403.01121v4| 3;2024-09-24;https://www.arxiv.org/abs/2403.01121v3| 2;2024-03-28;https://www.arxiv.org/abs/2403.01121v2| 1;2024-03-02;https://www.arxiv.org/abs/2403.01121v1	arXiv:2403.01121			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 09 2024	2024	Graph learning has become essential in various domains, including recommendation systems and social network analysis. Graph Neural Networks (GNNs) have emerged as promising techniques for encoding structural information and improving performance in tasks like link prediction and node classification. However, a key challenge remains: the difficulty of generalizing to unseen graph data with different properties. In this work, we propose a novel graph foundation model, called OpenGraph, to address this challenge. Our approach tackles several technical obstacles. Firstly, we enhance data augmentation using a large language model (LLM) to overcome data scarcity in real-world scenarios. Secondly, we introduce a unified graph tokenizer that enables the model to generalize effectively to diverse graph data, even when encountering unseen properties during training. Thirdly, our developed scalable graph transformer captures node-wise dependencies within the global topological context. Extensive experiments validate the effectiveness of our framework. By adapting OpenGraph to new graph characteristics and comprehending diverse graphs, our approach achieves remarkable zero-shot graph learning performance across various settings. 																																	2024-10-29	PPRN:88019219		
J	Meng, Fanqing; Liao, Jiaqi; Tan, Xinyu; Shao, Wenqi; Lu, Quanfeng; Zhang, Kaipeng; Cheng, Yu; Li, Dianqi; Qiao, Yu; Luo, Ping				pluo/GPG-2707-2022; Meng, fanqing/AAE-7775-2022; Qiao, Yu/ABD-5787-2021; Tan, Xinyu/AAX-9273-2021						Towards World Simulator: Crafting Physical Commonsense-Based Benchmark for Video Generation								Arxiv											1	1;2024-10-07;https://www.arxiv.org/abs/2410.05363v1	arXiv:2410.05363			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 07 2024	2024	Text-to-video (T2V) models like Sora have made significant strides in visualizing complex prompts, which is increasingly viewed as a promising path towards constructing the universal world simulator. Cognitive psychologists believe that the foundation for achieving this goal is the ability to understand intuitive physics. However, the capacity of these models to accurately represent intuitive physics remains largely unexplored. To bridge this gap, we introduce PhyGenBench, a comprehensive textbf{Phy}sics textbf{Gen}eration textbf{Ben}chmark designed to evaluate physical commonsense correctness in T2V generation. PhyGenBench comprises 160 carefully crafted prompts across 27 distinct physical laws, spanning four fundamental domains, which could comprehensively assesses models' understanding of physical commonsense. Alongside PhyGenBench, we propose a novel evaluation framework called PhyGenEval. This framework employs a hierarchical evaluation structure utilizing appropriate advanced vision-language models and large language models to assess physical commonsense. Through PhyGenBench and PhyGenEval, we can conduct large-scale automated assessments of T2V models' understanding of physical commonsense, which align closely with human feedback. Our evaluation results and in-depth analysis demonstrate that current models struggle to generate videos that comply with physical commonsense. Moreover, simply scaling up models or employing prompt engineering techniques is insufficient to fully address the challenges presented by PhyGenBench (e.g., dynamic scenarios). We hope this study will inspire the community to prioritize the learning of physical commonsense in these models beyond entertainment applications. 																																	2024-10-29	PPRN:105760788		
J	Jiang, Yixing; Irvin, Jeremy; Wang, Ji Hun; Chaudhry, Muhammad Ahmed; Chen, Jonathan H.; Ng, Andrew Y.										Many-Shot In-Context Learning in Multimodal Foundation Models								Arxiv											2	2;2024-10-04;https://www.arxiv.org/abs/2405.09798v2| 1;2024-05-16;https://www.arxiv.org/abs/2405.09798v1	arXiv:2405.09798			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 04 2024	2024	Large language models are effective at few-shot in-context learning (ICL). Recent advancements in multimodal foundation models have enabled unprecedentedly long context windows, presenting an opportunity to explore their capability to perform ICL with many more demonstrating examples. In this work, we evaluate the performance of multimodal foundation models scaling from few-shot to many-shot ICL. We benchmark GPT-4o and Gemini 1.5 Pro across 14 datasets spanning multiple domains (natural imagery, medical imagery, remote sensing, and molecular imagery) and tasks (image classification, visual QA, and object localization). We observe that many-shot ICL, including up to almost 2,000 demonstrating examples, leads to substantial improvements compared to few-shot (<100 examples) ICL across all of the datasets. Further, Gemini 1.5 Pro performance continues to improve log-linearly up to the maximum number of tested examples on many datasets. We also find open-weights multimodal foundation models like Llama 3.2-Vision do not benefit from the demonstrating examples, highlighting an important gap between open and closed multimodal foundation models. Given the high inference costs required for many-shot ICL, we also explore the impact of batching multiple queries in a single API call. We show that batching up to 50 queries can lead to performance improvements under zero-shot and many-shot ICL, with substantial gains in the zero-shot setting on multiple datasets, while drastically reducing per-query cost and latency. Finally, while GPT-4o and Gemini 1.5 Pro achieve similar zero-shot performance across the datasets, Gemini 1.5 Pro learns more quickly than GPT-4o on most datasets. Our results suggest that many-shot ICL could enable users to efficiently adapt multimodal foundation models to new applications and domains. 																																	2024-10-27	PPRN:89077297		
J	Xu, Mengda; Xu, Zhenjia; Xu, Yinghao; Chi, Cheng; Wetzstein, Gordon; Veloso, Manuela; Song, Shuran				Chi, Cheng/GSE-4960-2022; Xu, Yinghao/NEU-2017-2025						Flow as the Cross-Domain Manipulation Interface								Arxiv											2	2;2024-10-04;https://www.arxiv.org/abs/2407.15208v2| 1;2024-07-21;https://www.arxiv.org/abs/2407.15208v1	arXiv:2407.15208			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 04 2024	2024	We present Im2Flow2Act, a scalable learning framework that enables robots to acquire real-world manipulation skills without the need of real-world robot training data. The key idea behind Im2Flow2Act is to use object flow as the manipulation interface, bridging domain gaps between different embodiments (i.e., human and robot) and training environments (i.e., real-world and simulated). Im2Flow2Act comprises two components: a flow generation network and a flow-conditioned policy. The flow generation network, trained on human demonstration videos, generates object flow from the initial scene image, conditioned on the task description. The flow-conditioned policy, trained on simulated robot play data, maps the generated object flow to robot actions to realize the desired object movements. By using flow as input, this policy can be directly deployed in the real world with a minimal sim-to-real gap. By leveraging real-world human videos and simulated robot play data, we bypass the challenges of teleoperating physical robots in the real world, resulting in a scalable system for diverse tasks. We demonstrate Im2Flow2Act's capabilities in a variety of real-world tasks, including the manipulation of rigid, articulated, and deformable objects.																																	2024-10-26	PPRN:91025594		
J	Wang, Ruiyi; Milani, Stephanie; Chiu, Jamie C.; Zhi, Jiayin; Eack, Shaun M.; Labrum, Travis; Murphy, Samuel M.; Jones, Nev; Hardy, Kate; Shen, Hong; Fang, Fei; Chen, Zhiyu Zoey				王, 瑞义/I-8563-2018; Jones, Nev/JMP-4489-2023						PATIENT-ψ : Using Large Language Models to Simulate Patients for Training Mental Health Professionals								Arxiv											3	3;2024-10-03;https://www.arxiv.org/abs/2405.19660v3| 2;2024-06-18;https://www.arxiv.org/abs/2405.19660v2| 1;2024-05-30;https://www.arxiv.org/abs/2405.19660v1	arXiv:2405.19660			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 03 2024	2024	Mental illness remains one of the most critical public health issues. Despite its importance, many mental health professionals highlight a disconnect between their training and actual real-world patient practice. To help bridge this gap, we propose PATIENT-ψ, a novel patient simulation framework for cognitive behavior therapy (CBT) training. To build PATIENT-ψ, we construct diverse patient cognitive models based on CBT principles and use large language models (LLMs) programmed with these cognitive models to act as a simulated therapy patient. We propose an interactive training scheme, PATIENT-ψ-TRAINER , for mental health trainees to practice a key skill in CBT – formulating the cognitive model of the patient – through role-playing a therapy session with PATIENT-ψ. To evaluate PATIENT-ψ, we conducted a comprehensive user study of 13 mental health trainees and 20 experts. The results demonstrate that practice using PATIENT-ψ-TRAINER enhances the perceived skill acquisition and confidence of the trainees beyond existing forms of training such as textbooks, videos, and role-play with non-patients. Based on the experts’ perceptions, PATIENT-ψ is perceived to be closer to real patient interactions than GPT-4, and PATIENT-ψ-TRAINER holds strong promise to improve trainee competencies. 																																	2024-10-24	PPRN:89113121		
J	Smith, David; Myers, Joseph Samuel; Kaplan, Craig S.; Goodman-Strauss, Chaim										A chiral aperiodic monotile								Arxiv											1	1;2024-09-28;https://www.arxiv.org/abs/2305.17743v2	arXiv:2305.17743			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 28 2024	2024	The recently discovered "hat" aperiodic monotile mixes unreflected and reflected tiles in every tiling it admits, leaving open the question of whether a single shape can tile aperiodically using translations and rotations alone. We show that a close relative of the hat - the equilateral member of the continuum to which it belongs - is a weakly chiral aperiodic monotile: it admits only non-periodic tilings if we forbid reflections by fiat. Furthermore, by modifying this polygon's edges we obtain a family of shapes called Spectres that are strictly chiral aperiodic monotiles: they admit only chiral non-periodic tilings based on a hierarchical substitution system.																																	2024-11-09	PPRN:100734231		
J	Shi, Zhenmei; Ming, Yifei; Nguyen, Xuan-Phi; Liang, Yingyu; Joty, Shafiq				Shi, Zhenmei/KBA-9650-2024; Ming, Yifei/KIA-5069-2024						Discovering the Gems in Early Layers: Accelerating Long-Context LLMs with 1000x Input Token Reduction								Arxiv											1	1;2024-09-25;https://www.arxiv.org/abs/2409.17422v1	arXiv:2409.17422			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 25 2024	2024	Large Language Models (LLMs) have demonstrated remarkable capabilities in handling long context inputs, but this comes at the cost of increased computational resources and latency. Our research introduces a novel approach for the long context bottleneck to accelerate LLM inference and reduce GPU memory consumption. Our research demonstrates that LLMs can identify relevant tokens in the early layers before generating answers to a query. Leveraging this insight, we propose an algorithm that uses early layers of an LLM as filters to select and compress input tokens, significantly reducing the context length for subsequent processing. Our method, GemFilter, demonstrates substantial improvements in both speed and memory efficiency compared to existing techniques, such as standard attention and SnapKV/H2O. Notably, it achieves a 2.4 × speedup and 30% reduction in GPU memory usage compared to SOTA methods. Evaluation on the Needle in a Haystack task shows that GemFilter significantly outperforms standard attention, SnapKV and demonstrates comparable performance on the LongBench challenge. GemFilter is simple, training-free, and broadly applicable across different LLMs. Crucially, it provides interpretability by allowing humans to inspect the selected input sequence. These findings not only offer practical benefits for LLM deployment, but also enhance our understanding of LLM internal mechanisms, paving the way for further optimizations in LLM design and inference. 																																	2024-10-09	PPRN:100650273		
J	Fan, Ying; Lee, Kangwook										Optimizing DDPM Sampling with Shortcut Fine-Tuning								Arxiv											2	2;2024-09-19;https://www.arxiv.org/abs/2301.13362v4| 1;2023-01-31;https://www.arxiv.org/abs/2301.13362v2	arXiv:2301.13362			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 19 2024	2024	In this study, we propose Shortcut Fine-Tuning (SFT), a new approach for addressing the challenge of fast sampling of pretrained Denoising Diffusion Probabilistic Models (DDPMs). SFT advocates for the fine-tuning of DDPM samplers through the direct minimization of Integral Probability Metrics (IPM), instead of learning the backward diffusion process. This enables samplers to discover an alternative and more efficient sampling shortcut, deviating from the backward diffusion process. Inspired by a control perspective, we propose a new algorithm SFT-PG: Shortcut Fine-Tuning with Policy Gradient, and prove that under certain assumptions, gradient descent of diffusion models with respect to IPM is equivalent to performing policy gradient. To our best knowledge, this is the first attempt to utilize reinforcement learning (RL) methods to train diffusion models. Through empirical evaluation, we demonstrate that our fine-tuning method can further enhance existing fast DDPM samplers, resulting in sample quality comparable to or even surpassing that of the full-step model across various datasets.																																	2024-10-21	PPRN:36115502		
J	Lambrides, Erini; Garofali, Kristen; Larson, Rebecca; Ptak, Andrew; Chiaberge, Marco; Long, Arianna S.; Hutchison, Taylor A.; Norman, Colin; Mckinney, Jed; Akins, Hollis B.; Berg, Danielle A.; Chisholm, John; Civano, Francesca; Cloonan, Aidan P.; Endsley, Ryan; Faisst, Andreas L.; Gilli, Roberto; Gillman, Steven; Hirschmann, Michaela; Kartaltepe, Jeyhan S.; Kocevski, Dale D.; Kokorev, Vasily; Pacucci, Fabio; Richardson, Chris T.; Stiavelli, Massimo; Whalen, Kelly E.				Lambrides, Erini/ABB-2618-2021; Kartaltepe, Jeyhan/ABI-1561-2020; Endsley, Ryan/AAJ-5103-2021; Kokorev, Vasily/GPK-2541-2022						The Case for Super-Eddington Accretion: Connecting Weak X-ray and UV Line Emission in <italic>JWST </italic>Broad-Line AGN During the First Gyr of Cosmic Time								Arxiv											1	1;2024-09-19;https://www.arxiv.org/abs/2409.13047v1	arXiv:2409.13047			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 19 2024	2024	A multitude of JWST studies reveal a surprising over-abundance of over-massive accreting super-massive blackholes (SMBHs) -- leading to a deepening tension between theory and observation in the first billion years of cosmic time. Across X-ray to infrared wavelengths, models built off of pre-JWST predictions fail to easily reproduce observed AGN signatures (or lack thereof), driving uncertainty around the true nature of these sources. Using a sample of JWST AGN identified via their broadened Halpha emission and covered by the deepest X-ray surveys, we find neither any measurable X-ray emission nor any detection of high-ionization emission lines frequently associated with accreting SMBHs. We propose that these sources are accreting at or beyond the Eddington limit, which reduces the need for efficient production of heavy SMBH seeds at cosmic dawn. Using a theoretical model of super-Eddington accretion, we can produce the observed relative dearth of both X-ray and ultraviolet emission, as well as the high Balmer decrements, without the need for significant dust attenuation. This work indicates that super-Eddington accretion is easily achieved through-out the early Universe, and further study is required to determine what environments are required to trigger this mode of black hole growth.																																	2025-01-24	PPRN:94108974		
J	Yang, Xingyi; Wang, Xinchao				Yang, Xingyi/IXD-1298-2023						Kolmogorov-Arnold Transformer								Arxiv											1	1;2024-09-16;https://www.arxiv.org/abs/2409.10594v1	arXiv:2409.10594			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Sep 16 2024	2024	Transformers stand as the cornerstone of mordern deep learning. Traditionally, these models rely on multi-layer perceptron (MLP) layers to mix the information between channels. In this paper, we introduce the Kolmogorov–Arnold Transformer (KAT), a novel architecture that replaces MLP layers with Kolmogorov-Arnold Network (KAN) layers to enhance the expressiveness and performance of the model. Integrating KANs into transformers, however, is no easy feat, especially when scaled up. Specifically, we identify three key challenges: (C1) Base function . The standard B-spline function used in KANs is not optimized for parallel computing on modern hardware, resulting in slower inference speeds. (C2) Parameter and Computation Inefficiency . KAN requires a unique function for each input-output pair, making the computation extremely large. (C3) Weight initialization . The initialization of weights in KANs is particularly challenging due to their learnable activation functions, which are critical for achieving convergence in deep neural networks. To overcome the aforementioned challenges, we propose three key solutions: (S1) Rational basis . We replace B-spline functions with rational functions to improve compatibility with modern GPUs. By implementing this in CUDA, we achieve faster computations. (S2) Group KAN . We share the activation weights through a group of neurons, to reduce the computational load without sacrificing performance. (S3) Variance-preserving initialization . We carefully initialize the activation weights to make sure that the activation variance is maintained across layers. With these designs, KAT scales effectively and readily outperforms traditional MLP-based transformers. We demonstrate the advantages of KAT across various tasks, including image recognition, object detection, and semantic segmentation. It consistently enhances performance over the standard transformer architectures of different model sizes. 																																	2024-09-29	PPRN:91941205		
J	Giadikiaroglou, Panagiotis; Lymperaiou, Maria; Filandrianos, Giorgos; Stamou, Giorgos										Puzzle Solving using Reasoning of Large Language Models: A Survey								Arxiv											3	3;2024-09-14;https://www.arxiv.org/abs/2402.11291v3| 2;2024-04-20;https://www.arxiv.org/abs/2402.11291v2| 1;2024-02-17;https://www.arxiv.org/abs/2402.11291v1	arXiv:2402.11291			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Sep 14 2024	2024	Exploring the capabilities of Large Language Models (LLMs) in puzzle solving unveils critical insights into their potential and challenges in AI, marking a significant step towards understanding their applicability in complex reasoning tasks. This survey leverages a unique taxonomy -- dividing puzzles into rule-based and rule-less categories -- to critically assess LLMs through various methodologies, including prompting techniques, neuro-symbolic approaches, and fine-tuning. Through a critical review of relevant datasets and benchmarks, we assess LLMs' performance, identifying significant challenges in complex puzzle scenarios. Our findings highlight the disparity between LLM capabilities and human-like reasoning, particularly in those requiring advanced logical inference. The survey underscores the necessity for novel strategies and richer datasets to advance LLMs' puzzle-solving proficiency and contribute to AI's logical reasoning and creative problem-solving advancements.																																	2024-12-24	PPRN:87761982		
J	Ning, Lin; Liu, Luyang; Wu, Jiaxing; Wu, Neo; Berlowitz, Devora; Prakash, Sushant; Green, Bradley; O'Banion, Shawn; Xie, Jun										User-LLM: Efficient LLM Contextualization with User Embeddings								Arxiv											2	2;2024-09-09;https://www.arxiv.org/abs/2402.13598v2| 1;2024-02-21;https://www.arxiv.org/abs/2402.13598v1	arXiv:2402.13598			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 09 2024	2024	Large language models (LLMs) have achieved remarkable success across various domains, but effectively incorporating complex and potentially noisy user timeline data into LLMs remains a challenge. Current approaches often involve translating user timelines into text descriptions before feeding them to LLMs, which can be inefficient and may not fully capture the nuances of user behavior. Inspired by how LLMs are effectively integrated with images through direct embeddings, we propose User-LLM, a novel framework that leverages user embeddings to directly contextualize LLMs with user history interactions. These embeddings, generated by a user encoder pretrained using self-supervised learning on diverse user interactions, capture latent user behaviors and interests as well as their evolution over time. We integrate these user embeddings with LLMs through cross-attention, enabling LLMs to dynamically adapt their responses based on the context of a user's past actions and preferences. Our approach achieves significant efficiency gains by representing user timelines directly as embeddings, leading to substantial inference speedups of up to 78.1X. Comprehensive experiments on MovieLens, Amazon Review, and Google Local Review datasets demonstrate that User-LLM outperforms text-prompt-based contextualization on tasks requiring deep user understanding, with improvements of up to 16.33%, particularly excelling on long sequences that capture subtle shifts in user behavior. Furthermore, the incorporation of Perceiver layers streamlines the integration between user encoders and LLMs, yielding additional computational savings.																																	2024-09-26	PPRN:87787756		
J	Li, Ruochen; Patel, Teerth; Wang, Qingyun; Du, Xinya				Wang, Qingyun/G-2309-2010; Li, Ruochen/HHC-6630-2022						MLR-Copilot: Autonomous Machine Learning Research based on Large Language Models Agents								Arxiv											3	3;2024-09-02;https://www.arxiv.org/abs/2408.14033v2| 2;2024-08-26;https://www.arxiv.org/abs/2408.14033v1| 1;2024-08-26;https://www.arxiv.org/abs/2408.14033v1	arXiv:2408.14033			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 02 2024	2024	Machine learning research, crucial for technological advancements and innovation, often faces significant challenges due to its inherent complexity, slow pace of experimentation, and the necessity for specialized expertise. Motivated by this, we present a new systematic framework, autonomous Machine Learning Research with large language models (MLR-Copilot), designed to enhance machine learning research productivity through the automatic generation and implementation of research ideas using Large Language Model (LLM) agents. The framework consists of three phases: research idea generation, experiment implementation, and implementation execution. First, existing research papers are used to generate hypotheses and experimental plans vis IdeaAgent powered by LLMs. Next, the implementation generation phase translates these plans into executables with ExperimentAgent. This phase leverages retrieved prototype code and optionally retrieves candidate models and data. Finally, the execution phase, also managed by ExperimentAgent, involves running experiments with mechanisms for human feedback and iterative debugging to enhance the likelihood of achieving executable research outcomes. We evaluate our framework on five machine learning research tasks and the experimental results show the framework's potential to facilitate the research progress and innovations.																																	2024-09-12	PPRN:91543289		
J	Pappalardi, Silvia; Fritzsch, Felix; Prosen, Tomaz				Prosen, Tomaz/F-1369-2011; Pappalardi, Silvia/NEU-5874-2025						Full Eigenstate Thermalization via Free Cumulants in Quantum Lattice Systems								Arxiv											2	2;2024-09-02;https://www.arxiv.org/abs/2303.00713v4| 1;2023-03-01;https://www.arxiv.org/abs/2303.00713v1	arXiv:2303.00713			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 02 2024	2024	The Eigenstate-Thermalization-Hypothesis (ETH) has been established as the general framework to understand quantum statistical mechanics. Only recently has the attention been paid to so-called full ETH, which accounts for higher-order correlations among matrix elements, and that can be rationalized theoretically using the language of Free Probability. In this work, we perform the first numerical investigation of the full ETH in physical many-body systems with local interactions by testing the decomposition of higher-order correlators into thermal free cumulants for local operators. We perform exact diagonalization on two classes of local non-integrable (chaotic) quantum many-body systems: spin chain Hamiltonians and Floquet brickwork unitary circuits. We show that the dynamics of four-time correlation functions are encoded in fourth-order free cumulants, as predicted by ETH. Their dependence on frequency encodes the physical properties of local many-body systems and distinguishes them from structureless, rotationally invariant ensembles of random matrices.																																	2024-09-12	PPRN:41257172		
J	Guo, Han; Greengard, Philip; Xing, Eric P.; Kim, Yoon										LQ-LoRA: Low-rank Plus Quantized Matrix Decomposition for Efficient Language Model Finetuning								Arxiv											4	4;2024-08-27;https://www.arxiv.org/abs/2311.12023v4| 3;2024-06-30;https://www.arxiv.org/abs/2311.12023v3| 2;2024-01-17;https://www.arxiv.org/abs/2311.12023v2| 1;2023-11-20;https://www.arxiv.org/abs/2311.12023v1	arXiv:2311.12023			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 27 2024	2024	We propose a simple approach for memory-efficient adaptation of pretrained language models. Our approach uses an iterative algorithm to decompose each pretrained matrix into a high-precision low-rank component and a memory-efficient quantized component. During finetuning, the quantized component remains fixed and only the low-rank component is updated. We present an integer linear programming formulation of the quantization component which enables dynamic configuration of quantization parameters (e.g., bit-width, block size) for each matrix given an overall target memory budget. We further explore a data-aware version of the algorithm which uses an approximation of the Fisher information matrix to weight the reconstruction objective during matrix decomposition. Experiments on finetuning RoBERTa and LLaMA-2 (7B and 70B) demonstrate that our low-rank plus quantized matrix decomposition approach (LQ-LoRA) outperforms strong QLoRA and GPTQ-LoRA baselines and enables aggressive quantization to sub-3 bits with only minor performance degradations. When finetuned on a language modeling calibration dataset, LQ-LoRA can also be used for model compression; in this setting our 2.75-bit LLaMA-2-70B model (which has 2.85 bits on average when including the low-rank components and requires 27GB of GPU memory) performs respectably compared to the 16-bit baseline.1																																	2024-09-06	PPRN:86210953		
J	Khirodkar, Rawal; Bagautdinov, Timur; Martinez, Julieta; Zhaoen, Su; James, Austin; Selednik, Peter; Anderson, Stuart; Saito, Shunsuke										Sapiens: Foundation for Human Vision Models								Arxiv											2	2;2024-08-27;https://www.arxiv.org/abs/2408.12569v3| 1;2024-08-22;https://www.arxiv.org/abs/2408.12569v1	arXiv:2408.12569			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 27 2024	2024	We present Sapiens, a family of models for four fundamental human-centric vision tasks -- 2D pose estimation, body-part segmentation, depth estimation, and surface normal prediction. Our models natively support 1K high-resolution inference and are extremely easy to adapt for individual tasks by simply fine-tuning models pretrained on over 300 million in-the-wild human images. We observe that, given the same computational budget, self-supervised pretraining on a curated dataset of human images significantly boosts the performance for a diverse set of human-centric tasks. The resulting models exhibit remarkable generalization to in-the-wild data, even when labeled data is scarce or entirely synthetic. Our simple model design also brings scalability -- model performance across tasks improves as we scale the number of parameters from 0.3 to 2 billion. Sapiens consistently surpasses existing baselines across various human-centric benchmarks. We achieve significant improvements over the prior state-of-the-art on Humans-5K (pose) by 7.6 mAP, Humans-2K (part-seg) by 17.1 mIoU, Hi4D (depth) by 22.4% relative RMSE, and THuman2 (normal) by 53.5% relative angular error. 																																	2024-09-06	PPRN:91506787		
J	Zhu, Kan; Zhao, Yilong; Zhao, Liangyu; Zuo, Gefei; Gu, Yile; Xie, Dedong; Gao, Yufei; Xu, Qinyu; Tang, Tian; Ye, Zihao; Kamahori, Keisuke; Lin, Chien-Yu; Wang, Stephanie; Krishnamurthy, Arvind; Kasikci, Baris				Ye, Zihao/HKM-8264-2023; Gao, Yufei/AAX-3459-2021; Zhao, Liangyu/IAO-7294-2023						NanoFlow: Towards Optimal Large Language Model Serving Throughput								Arxiv											1	1;2024-08-22;https://www.arxiv.org/abs/2408.12757v1	arXiv:2408.12757			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 22 2024	2024	The increasing usage of Large Language Models (LLMs) has resulted in a surging demand for planet-scale serving systems, where tens of thousands of GPUs continuously serve hundreds of millions of users. Consequently, throughput (under reasonable latency constraints) has emerged as a key metric that determines serving systems' performance. To boost throughput, various methods of inter-device parallelism (e.g., data, tensor, pipeline) have been explored. However, existing methods do not consider overlapping the utilization of different resources within a single device, leading to underutilization and sub-optimal performance. We propose NanoFlow, a novel serving framework that exploits intra-device parallelism, which overlaps the usage of resources including compute, memory, and network within a single device through operation co-scheduling. To exploit intra-device parallelism, NanoFlow introduces two key innovations: First, NanoFlow splits requests into nano-batches at the granularity of operations, which breaks the dependency of sequential operations in LLM inference and enables overlapping; then, to get benefit from overlapping, NanoFlow uses an operation-level pipeline with execution unit scheduling, which partitions the device's functional units and simultaneously executes different operations in each unit. NanoFlow automates the pipeline setup using a parameter search algorithm, which enables easily porting NanoFlow to different models. We implement NanoFlow on NVIDIA GPUs and evaluate end-to-end serving throughput on several popular models such as LLaMA-2-70B, Mixtral 8x7B, LLaMA-3-8B, etc.. With practical workloads, NanoFlow provides 1.91x throughput boost compared to state-of-the-art serving systems achieving 59% to 72% of optimal throughput across ported models.																																	2024-09-03	PPRN:91525717		
J	Lin, Xi Victoria; Shrivastava, Akshat; Luo, Liang; Iyer, Srinivasan; Lewis, Mike; Ghosh, Gargi; Zettlemoyer, Luke; Aghajanyan, Armen										MoMa: Efficient Early-Fusion Pre-training with Mixture of Modality-Aware Experts								Arxiv											3	3;2024-08-12;https://www.arxiv.org/abs/2407.21770v3| 2;2024-08-06;https://www.arxiv.org/abs/2407.21770v2| 1;2024-07-31;https://www.arxiv.org/abs/2407.21770v1	arXiv:2407.21770			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 12 2024	2024	We introduce MoMa, a novel modality-aware mixture-of-experts (MoE) architecture designed for pre-training mixed-modal, early-fusion language models. MoMa processes images and text in arbitrary sequences by dividing expert modules into modality-specific groups. These groups exclusively process designated tokens while employing learned routing within each group to maintain semantically informed adaptivity. Our empirical results reveal substantial pre-training efficiency gains through this modality-specific parameter allocation. Under a 1-trillion-token training budget, the MoMa 1.4B model, featuring 4 text experts and 4 image experts, achieves impressive FLOPs savings: 3.7x overall, with 2.6x for text and 5.2x for image processing compared to a compute-equivalent dense baseline, measured by pre-training loss. This outperforms the standard expert-choice MoE with 8 mixed-modal experts, which achieves 3× × overall FLOPs savings (3x for text, 2.8x for image). Combining MoMa with mixture-of-depths (MoD) further improves pretraining FLOPs savings to 4.2x overall (text: 3.4x, image: 5.3x), although this combination hurts performance in causal inference due to increased sensitivity to router accuracy. These results demonstrate MoMa’s potential to significantly advance the efficiency of mixed-modal, early-fusion language model pre-training, paving the way for more resource-efficient and capable multimodal AI systems.																																	2024-08-22	PPRN:91178155		
J	Cheng, Hongrong; Zhang, Miao; Shi, Javen Qinfeng				Cheng, Hongrong/LUY-6167-2024						A Survey on Deep Neural Network Pruning-Taxonomy, Comparison, Analysis, and Recommendations								Arxiv											2	2;2024-08-09;https://www.arxiv.org/abs/2308.06767v2| 1;2023-08-13;https://www.arxiv.org/abs/2308.06767v1	arXiv:2308.06767			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 09 2024	2024	Modern deep neural networks, particularly recent large language models, come with massive model sizes that require significant computational and storage resources. To enable the deployment of modern models on resource-constrained environments and to accelerate inference time, researchers have increasingly explored pruning techniques as a popular research direction in neural network compression. More than three thousand pruning papers have been published from 2020 to 2024. However, there is a dearth of up-to-date comprehensive review papers on pruning. To address this issue, in this survey, we provide a comprehensive review of existing research works on deep neural network pruning in a taxonomy of 1) universal/specific speedup, 2) when to prune, 3) how to prune, and 4) fusion of pruning and other compression techniques. We then provide a thorough comparative analysis of eight pairs of contrast settings for pruning (e.g., unstructured/structured, one-shot/iterative, data-free/data-driven, initialized/pre-trained weights, etc.) and explore several emerging topics, including pruning for large language models, vision transformers, diffusion models, and large multimodal models, post-training pruning, and different levels of supervision for pruning to shed light on the commonalities and differences of existing methods and lay the foundation for further method development. Finally, we provide some valuable recommendations on selecting pruning methods and prospect several promising research directions for neural network pruning. To facilitate future research on deep neural network pruning, we summarize broad pruning applications (e.g., adversarial robustness, natural language understanding, etc.) and build a curated collection of datasets, networks, and evaluations on different applications. We maintain a repository on https://github.com/hrcheng1066/awesome-pruning that serves as a comprehensive resource for neural network pruning papers and corresponding open-source codes. We will keep updating this repository to include the latest advancements in the field.																																	2024-08-21	PPRN:77243403		
J	Choudhury, Sayantan; Dey, Kritartha; Karde, Ahaskar; Panda, Sudhakar; Sami, M.										Primordial non-Gaussianity as a saviour for PBH overproduction in SIGWs generated by Pulsar Timing Arrays for Galileon inflation								Arxiv											3	3;2024-07-29;https://www.arxiv.org/abs/2310.11034v3| 2;2023-10-19;https://www.arxiv.org/abs/2310.11034v2| 1;2023-10-17;https://www.arxiv.org/abs/2310.11034v1	arXiv:2310.11034			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 29 2024	2024	We investigate the explicit role of negative local non-Gaussianity, fNL, in suppressing the abundance of primordial black holes (PBHs) in the single-field model of Galileon inflation. PBH formation requires significantly enhancing the scalar power spectrum, which greatly affects their abundance. The associated frequencies in the nHz regime are also sensitive to the generation of scalar-induced gravitational waves (SIGWs) which may explain the current data from the pulsar timing arrays (PTAs). Our analysis using the threshold statistics on the compaction function demonstrates that Galileon theory not only avoids PBH overproduction using the curvature perturbation enhancements that give fNL∼ O(−6), but also generates SIGWs that conform well with the PTA data.																																	2024-08-04	PPRN:85679663		
J	Ding, Han; Li, Yinheng; Wang, Junhao; Chen, Hang				Ding, Han/AAM-7527-2020						Large Language Model Agent in Financial Trading: A Survey								Arxiv											1	1;2024-07-26;https://www.arxiv.org/abs/2408.06361v1	arXiv:2408.06361			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 26 2024	2024	Trading is a highly competitive task that requires a combination of strategy, knowledge, and psychological fortitude. With the recent success of large language models(LLMs), it is appealing to apply the emerging intelligence of LLM agents in this competitive arena and understanding if they can outperform professional traders. In this survey, we provide a comprehensive review of the current research on using LLMs as agents in financial trading. We summarize the common architecture used in the agent, the data inputs, and the performance of LLM trading agents in backtesting as well as the challenges presented in these research. This survey aims to provide insights into the current state of LLM-based financial trading agents and outline future research directions in this field.																																	2024-08-22	PPRN:91369493		
J	Hammoud, Hasan Abed Al Kader; Itani, Hani; Pizzati, Fabio; Torr, Philip H.S; Bibi, Adel; Ghanem, Bernard										SynthCLIP: Are We Ready for a Fully Synthetic CLIP Training?								Arxiv											2	2;2024-07-18;https://www.arxiv.org/abs/2402.01832v2| 1;2024-02-02;https://www.arxiv.org/abs/2402.01832v1	arXiv:2402.01832			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 18 2024	2024	We present SynthCLIP, a CLIP model trained on entirely synthetic text-image pairs. Leveraging recent text-to-image (TTI) networks and large language models (LLM), we generate synthetic datasets of images and corresponding captions at scale, with no human intervention. In this work, we provide an analysis on CLIP models trained on synthetic data. We provide insights on the data generation strategy, number of samples required, scaling trends, and resulting properties. We also introduce SynthCI-30M, a purely synthetic dataset comprising 30 million captioned images.  .																																	2024-07-26	PPRN:87517747		
J	Huang, Chi-Pin; Chang, Kai-Po; Tsai, Chung-Ting; Lai, Yung-Hsuan; Yang, Fu-En; Wang, Yu-Chiang Frank				Yang, Fu-En/LQJ-3668-2024; Wang, Yu-Chiang/AAE-7478-2021						Receler: Reliable Concept Erasing of Text-to-Image Diffusion Models via Lightweight Erasers								Arxiv											2	2;2024-07-18;https://www.arxiv.org/abs/2311.17717v3| 1;2024-03-14;https://www.arxiv.org/abs/2311.17717v2	arXiv:2311.17717			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 18 2024	2024	Concept erasure in text-to-image diffusion models aims to disable pre-trained diffusion models from generating images related to a target concept. To perform reliable concept erasure, the properties of robustness and locality are desirable. The former refrains the model from producing images associated with the target concept for any paraphrased or learned prompts, while the latter preserves its ability in generating images with non-target concepts. In this paper, we propose Reliable Concept Erasing via Lightweight Erasers (Receler). It learns a lightweight Eraser to perform concept erasing while satisfying the above desirable properties through the proposed concept-localized regularization and adversarial prompt learning scheme. Experiments with various concepts verify the superiority of Receler over previous methods.																																	2024-07-26	PPRN:88144931		
J	Uehara, Masatoshi; Zhao, Yulai; Biancalani, Tommaso; Levine, Sergey				ZHAO, YULAI/JLL-5344-2023; Biancalani, Tommaso/Q-2010-2016						Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review								Arxiv											1	1;2024-07-18;https://www.arxiv.org/abs/2407.13734v1	arXiv:2407.13734			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 18 2024	2024	This tutorial provides a comprehensive survey of methods for fine-tuning diffusion models to optimize downstream reward functions. While diffusion models are widely known to provide excellent generative modeling capability, practical applications in domains such as biology require generating samples that maximize some desired metric (e.g., translation efficiency in RNA, docking score in molecules, stability in protein). In these cases, the diffusion model can be optimized not only to generate realistic samples but also to maximize the measure of interest explicitly. Such methods are based on concepts from reinforcement learning (RL). We explain the application of various RL algorithms, including PPO, differentiable optimization, rewardweighted MLE, value-weighted sampling, and path consistency learning, tailored specifically for fine-tuning diffusion models. We aim to explore fundamental aspects such as the strengths and limitations of different RL-based fine-tuning algorithms across various scenarios, the benefits of RL-based fine-tuning compared to non-RL-based approaches, and the formal objectives of RL-based fine-tuning (target distributions). Additionally, we aim to examine their connections with related topics such as classifier guidance, Gflownets, flow-based diffusion models, path integral control theory, and sampling from unnormalized distributions such as MCMC. The code of this tutorial is available at https://github.com/masa-ue/RLfinetuning Diffusion Bioseq.																																	2024-07-26	PPRN:90885804		
J	Gu, Geonmo; Chun, Sanghyuk; Kim, Wonjae; Jun, Heejae; Kang, Yoohoon; Yun, Sangdoo										CompoDiff: Versatile Composed Image Retrieval With Latent Diffusion								Arxiv											4	4;2024-07-16;https://www.arxiv.org/abs/2303.11916v4| 3;2024-02-25;https://www.arxiv.org/abs/2303.11916v3| 2;2023-10-04;https://www.arxiv.org/abs/2303.11916v2| 1;2023-03-21;https://www.arxiv.org/abs/2303.11916v1	arXiv:2303.11916			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 16 2024	2024	This paper proposes a novel diffusion-based model, CompoDiff, for solving zero-shot Composed Image Retrieval (ZS-CIR) with latent diffusion. This paper also introduces a new synthetic dataset, named SynthTriplets18M, with 18.8 million reference images, conditions, and corresponding target image triplets to train CIR models. CompoDiff and SynthTriplets18M tackle the shortages of the previous CIR approaches, such as poor generalizability due to the small dataset scale and the limited types of conditions. CompoDiff not only achieves a new state-of-the-art on four ZS-CIR benchmarks, including FashionIQ, CIRR, CIRCO, and GeneCIS, but also enables a more versatile and controllable CIR by accepting various conditions, such as negative text, and image mask conditions. CompoDiff also shows the controllability of the condition strength between text and image queries and the trade-off between inference speed and performance, which are unavailable with existing CIR methods. 																																	2024-07-25	PPRN:46957126		
J	Yang, Yang; Wang, Wen; Peng, Liang; Song, Chaotian; Chen, Yao; Li, Hengjia; Yang, Xiaolong; Lu, Qinglin; Cai, Deng; Wu, Boxi; Liu, Wei				Li, Hengjia/KBQ-1856-2024						LoRA-Composer: Leveraging Low-Rank Adaptation for Multi-Concept Customization in Training-Free Diffusion Models								Arxiv											2	2;2024-07-11;https://www.arxiv.org/abs/2403.11627v2| 1;2024-03-18;https://www.arxiv.org/abs/2403.11627v1	arXiv:2403.11627			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jul 11 2024	2024	Customization generation techniques have significantly advanced the synthesis of specific concepts across varied contexts. Multi-concept customization emerges as the challenging task within this domain. Existing approaches often rely on training a fusion matrix of multiple Low-Rank Adaptations (LoRAs) to merge various concepts into a single image. However, we identify this straightforward method faces two major challenges: 1) concept confusion, where the model struggles to preserve distinct individual characteristics, and 2) concept vanishing, where the model fails to generate the intended subjects. To address these issues, we introduce LoRA-Composer, a training-free framework designed for seamlessly integrating multiple LoRAs, thereby enhancing the harmony among different concepts within generated images. LoRA-Composer addresses concept vanishing through concept injection constraints, enhancing concept visibility via an expanded cross-attention mechanism. To combat concept confusion, concept isolation constraints are introduced, refining the self-attention computation. Furthermore, latent re-initialization is proposed to effectively stimulate concept-specific latent within designated regions. Our extensive testing showcases a notable enhancement in LoRA-Composer's performance compared to standard baselines, especially when eliminating the image-based conditions like canny edge or pose estimations.																																	2024-07-23	PPRN:88196623		
J	Luo, Junwei; Pang, Zhen; Zhang, Yongjun; Wang, Tingzhu; Wang, Linlin; Dang, Bo; Lao, Jiangwei; Wang, Jian; Chen, Jingdong; Tan, Yihua; Li, Yansheng				Liu, Xinyi/ABN-2511-2022; Li, Yansheng/AAU-6392-2021; Dang, Bo/LIG-0956-2024; Luo, Junwei/LDE-9786-2024						SkySenseGPT: A Fine-Grained Instruction Tuning Dataset and Model for Remote Sensing Vision-Language Understanding								Arxiv											2	2;2024-07-08;https://www.arxiv.org/abs/2406.10100v2| 1;2024-06-14;https://www.arxiv.org/abs/2406.10100v1	arXiv:2406.10100			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 08 2024	2024	Remote Sensing Large Multi-Modal Models (RSLMMs) are developing rapidly and showcase significant capabilities in remote sensing imagery (RSI) comprehension. However, due to the limitations of existing datasets, RSLMMs have shortcomings in understanding the rich semantic relations among objects in complex remote sensing scenes. To unlock RSLMMs’ complex comprehension ability, we propose a large-scale instruction tuning dataset FIT-RS, containing 1,800,851 instruction samples. FIT-RS covers common interpretation tasks and innovatively introduces several complex comprehension tasks of escalating difficulty, ranging from relation reasoning to image-level scene graph generation. Based on FIT-RS, we build the FIT-RSFG benchmark. Furthermore, we establish a new benchmark to evaluate the fine-grained relation comprehension capabilities of LMMs, named FIT-RSRC. Based on combined instruction data, we propose SkySenseGPT, which achieves outstanding performance on both public datasets and FIT-RSFG, surpassing existing RSLMMs. We hope the FIT-RS dataset can enhance the relation comprehension capability of RSLMMs and provide a large-scale fine-grained data source for the remote sensing community. 																																	2024-07-21	PPRN:89334726		
J	Doerig, Adrien; Kietzmann, Tim C; Allen, Emily; Wu, Yihan; Naselaris, Thomas; Kay, Kendrick; Charest, Ian				Kay, Kendrick/A-4344-2009; Charest, Ian/P-1736-2016; Kietzman, Tim/AAA-5771-2019						Visual representations in the human brain are aligned with large language models								Arxiv											2	2;2024-07-06;https://www.arxiv.org/abs/2209.11737v2| 1;2022-09-23;https://www.arxiv.org/abs/2209.11737v1	arXiv:2209.11737			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 06 2024	2024	The human brain extracts complex information from visual inputs, including objects, their spatial and semantic interrelations, and their interactions with the environment. However, a quantitative approach for studying this information remains elusive. Here, we test whether the contextual information encoded in large language models (LLMs) is beneficial for modelling the complex visual information extracted by the brain from natural scenes. We show that LLM embeddings of scene captions successfully characterise brain activity evoked by viewing the natural scenes. This mapping captures selectivities of different brain areas, and is sufficiently robust that accurate scene captions can be reconstructed from brain activity. Using carefully controlled model comparisons, we then proceed to show that the accuracy with which LLM representations match brain representations derives from the ability of LLMs to integrate complex information contained in scene captions beyond that conveyed by individual words. Finally, we train deep neural network models to transform image inputs into LLM representations. Remarkably, these networks learn representations that are better aligned with brain representations than a large number of state-of-the-art alternative models, despite being trained on orders-of-magnitude less data. Overall, our results suggest that LLM embeddings of scene captions provide a representational format that accounts for complex information extracted by the brain from visual inputs.																																	2024-07-21	PPRN:17044868		
J	Tang, Wenpin; Zhao, Hanyang				Zhao, Hanyang/HLW-9612-2023						Score-based Diffusion Models via Stochastic Differential Equations -- a Technical Tutorial								Arxiv											2	2;2024-06-22;https://www.arxiv.org/abs/2402.07487v2| 1;2024-02-12;https://www.arxiv.org/abs/2402.07487v1	arXiv:2402.07487			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 22 2024	2024	so we have � ( ρ − n − 1) L + t − x 0 < x ρ ( x, t ) = 2 t ( ρ −n ) L + t −x z ( t ) 2 t																																	2024-07-12	PPRN:87637279		
J	Din, Alexander Yom; Karidi, Taelin; Choshen, Leshem; Geva, Mor										Jump to Conclusions: Short-Cutting Transformers With Linear Transformations								Arxiv											2	2;2024-06-18;https://www.arxiv.org/abs/2303.09435v2| 1;2023-03-16;https://www.arxiv.org/abs/2303.09435v1	arXiv:2303.09435			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 18 2024	2024	Transformer-based language models create hidden representations of their inputs at every layer, but only use final-layer representations for prediction. This obscures the internal decision-making process of the model and the utility of its intermediate representations. One way to elucidate this is to cast the hidden representations as final representations, bypassing the transformer computation in-between. In this work, we suggest a simple method for such casting, using linear transformations. This approximation far exceeds the prevailing practice of inspecting hidden representations from all layers, in the space of the final layer. Moreover, in the context of language modeling, our method produces more accurate predictions from hidden layers, across various model scales, architectures, and data distributions. This allows "peeking" into intermediate representations, showing that GPT-2 and BERT often predict the final output already in early layers. We then demonstrate the practicality of our method to recent early exit strategies, showing that when aiming, for example, at retention of 95% accuracy, our approach saves additional 7.9% layers for GPT-2 and 5.4% layers for BERT. Last, we extend our method to linearly approximate sub-modules, finding that attention is most tolerant to this change.																																	2024-07-06	PPRN:46905354		
J	Xu, Wenda; Zhu, Guanglei; Zhao, Xuandong; Pan, Liangming; Li, Lei; Wang, William Yang				Li, Zheng/CYW-7700-2022; Zhao, Xuandong/LIG-4204-2024; Pan, Liangming/LIF-2753-2024; Xu, Wenda/LZE-6253-2025						Pride and Prejudice: LLM Amplifies Self-Bias in Self-Refinement								Arxiv											1	1;2024-06-18;https://www.arxiv.org/abs/2402.11436v2	arXiv:2402.11436			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 18 2024	2024	Recent studies show that large language models (LLMs) improve their performance through self-feedback on certain tasks while degrade on others. We discovered that such a contrary is due to LLM's bias in evaluating their own output. In this paper, we formally define LLM's self-bias - the tendency to favor its own generation - using two statistics. We analyze six LLMs (GPT-4, GPT-3.5, Gemini, LLaMA2, Mixtral and DeepSeek) on translation, constrained text generation, and mathematical reasoning tasks. We find that self-bias is prevalent in all examined LLMs across multiple languages and tasks. Our analysis reveals that while the self-refine pipeline improves the fluency and understandability of model outputs, it further amplifies self-bias. To mitigate such biases, we discover that larger model size and external feedback with accurate assessment can significantly reduce bias in the self-refine pipeline, leading to actual performance improvement in downstream tasks. The code and data are released at https://github.com/xu1998hz/llm_self_bias.																																	2025-08-07	PPRN:123164767		
J	Ayyamperumal, Suriya Ganesh; Ge, Limin										Current state of LLM Risks and AI Guardrails								Arxiv											1	1;2024-06-16;https://www.arxiv.org/abs/2406.12934v1	arXiv:2406.12934			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 16 2024	2024	Large language models (LLMs) have become increasingly sophisticated, leading to widespread deployment in sensitive applications where safety and reliability are paramount. However, LLMs have inherent risks accompanying them, including bias, potential for unsafe actions, dataset poisoning, lack of explainability, hallucinations, and non-reproducibility. These risks necessitate the development of "guardrails" to align LLMs with desired behaviors and mitigate potential harm. This work explores the risks associated with deploying LLMs and evaluates current approaches to implementing guardrails and model alignment techniques. We examine intrinsic and extrinsic bias evaluation methods and discuss the importance of fairness metrics for responsible AI development. The safety and reliability of agentic LLMs (those capable of real-world actions) are explored, emphasizing the need for testability, fail-safes, and situational awareness. Technical strategies for securing LLMs are presented, including a layered protection model operating at external, secondary, and internal levels. System prompts, Retrieval-Augmented Generation (RAG) architectures, and techniques to minimize bias and protect privacy are highlighted. Effective guardrail design requires a deep understanding of the LLM's intended use case, relevant regulations, and ethical considerations. Striking a balance between competing requirements, such as accuracy and privacy, remains an ongoing challenge. This work underscores the importance of continuous research and development to ensure the safe and responsible use of LLMs in real-world applications.																																	2024-07-10	PPRN:89380272		
J	Singla, Vasu; Yue, Kaiyu; Paul, Sukriti; Shirkavand, Reza; Jayawardhana, Mayuka; Ganjdanesh, Alireza; Huang, Heng; Bhatele, Abhinav; Somepalli, Gowthami; Goldstein, Tom										From Pixels to Prose: A Large Dataset of Dense Image Captions								Arxiv											1	1;2024-06-14;https://www.arxiv.org/abs/2406.10328v1	arXiv:2406.10328			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 14 2024	2024	Training large vision-language models requires extensive, high-quality image-text pairs. Existing web-scraped datasets, however, are noisy and lack detailed image descriptions. To bridge this gap, we introduce PixelProse, a comprehensive dataset of over 16M (million) synthetically generated captions, leveraging cutting-edge vision-language models for detailed and accurate descriptions. To ensure data integrity, we rigorously analyze our dataset for problematic content, including child sexual abuse material (CSAM), personally identifiable information (PII), and toxicity. We also provide valuable metadata such as watermark presence and aesthetic scores, aiding in further dataset filtering. We hope PixelProse will be a valuable resource for future vision-language research. PixelProse is available at https://huggingface.co/datasets/tomg-group-umd/pixelprose																																	2024-07-04	PPRN:89352366		
J	Wei, Tianwen; Zhu, Bo; Zhao, Liang; Cheng, Cheng; Li, Biye; Lu, Weiwei; Cheng, Peng; Zhang, Jianhao; Zhang, Xiaoyu; Zeng, Liang; Wang, Xiaokun; Ma, Yutuan; Hu, Rui; Yan, Shuicheng; Fang, Han; Zhou, Yahui				Wang, Xiaokun/D-7461-2018; Wei, Tianwen/GSM-9595-2022; yan, shuicheng/HCH-9860-2022; Lu, Weiwei/ABF-8744-2020; Zhang, Xiaoyu/GQY-4651-2022						Skywork-MoE: A Deep Dive into Training Techniques for Mixture-of-Experts Language Models								Arxiv											1	1;2024-06-03;https://www.arxiv.org/abs/2406.06563v1	arXiv:2406.06563			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 03 2024	2024	In this technical report, we introduce the training methodologies implemented in the development of Skywork-MoE, a high-performance mixture-of-experts (MoE) large language model (LLM) with 146 billion parameters and 16 experts. It is initialized from the pre-existing dense checkpoints of our Skywork-13B model. We explore the comparative effectiveness of upcycling versus training from scratch initializations. Our findings suggest that the choice between these two approaches should consider both the performance of the existing dense checkpoints and the MoE training budget. We highlight two innovative techniques: gating logit normalization, which improves expert diversification, and adaptive auxiliary loss coefficients, allowing for layer-specific adjustment of auxiliary loss coefficients. Our experimental results validate the effectiveness of these methods. Leveraging these techniques and insights, we trained our upcycled Skywork-MoE on a condensed subset of our SkyPile corpus. The evaluation results demonstrate that our model delivers strong performance across a wide range of benchmarks.																																	2024-07-11	PPRN:89282764		
J	Liu, Xiaoqun; Liang, Jiacheng; Ye, Muchao; Xi, Zhaohan				Liang, Jiacheng/JPX-6118-2023						Robustifying Safety-Aligned Large Language Models through Clean Data Curation								Arxiv											2	2;2024-05-31;https://www.arxiv.org/abs/2405.19358v2| 1;2024-05-24;https://www.arxiv.org/abs/2405.19358v1	arXiv:2405.19358			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 31 2024	2024	Large language models (LLMs) are vulnerable when trained on datasets containing harmful content, which leads to potential jailbreaking attacks in two scenarios: the integration of harmful texts within crowdsourced data used for pre-training and direct tampering with LLMs through fine-tuning. In both scenarios, adversaries can compromise the safety alignment of LLMs, exacerbating malfunctions. Motivated by the need to mitigate these adversarial influences, our research aims to enhance safety alignment by either neutralizing the impact of malicious texts in pre-training datasets or increasing the difficulty of jailbreaking during downstream fine-tuning. In this paper, we propose a data curation framework designed to counter adversarial impacts in both scenarios. Our method operates under the assumption that we have no prior knowledge of attack details, focusing solely on curating clean texts. We introduce an iterative process aimed at revising texts to reduce their perplexity as perceived by LLMs, while simultaneously preserving their text quality. By pre-training or fine-tuning LLMs with curated clean texts, we observe a notable improvement in LLM robustness regarding safety alignment against harmful queries. For instance, when pre-training LLMs using a crowdsourced dataset containing 5% harmful instances, adding an equivalent amount of curated texts significantly mitigates the likelihood of providing harmful responses in LLMs and reduces the attack success rate by 71%. Our study represents a significant step towards mitigating the risks associated with training-based jailbreaking and fortifying the secure utilization of LLMs.																																	2024-06-19	PPRN:89113539		
J	Ankner, Zachary; Blakeney, Cody; Sreenivasan, Kartik; Marion, Max; Leavitt, Matthew L.; Paul, Mansheej										Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models								Arxiv											1	1;2024-05-30;https://www.arxiv.org/abs/2405.20541v1	arXiv:2405.20541			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	May 30 2024	2024	In this work, we investigate whether small language models can determine highquality subsets of large-scale text datasets that improve the performance of larger language models. While existing work has shown that pruning based on the perplexity of a larger model can yield high -quality data, we investigate whether smaller models can be used for perplexity -based pruning and how pruning is affected by the domain composition of the data being pruned. We demonstrate that for multiple dataset compositions, perplexity -based pruning of pretraining data can significantly improve downstream task performance: pruning based on perplexities computed with a 125 million parameter model improves the average performance on downstream tasks of a 3 billion parameter model by up to 2.04 and achieves up to a 1.45× .45 × reduction in pretraining steps to reach commensurate baseline performance. Furthermore, we demonstrate that such perplexity -based data pruning also yields downstream performance gains in the over -trained and data -constrained regimes.																																	2024-06-17	PPRN:89118231		
J	Gilyen, Andras; Chen, Chi-Fang; Doriguello, Joao F.; Kastoryano, Michael J.										Quantum generalizations of Glauber and Metropolis dynamics								Arxiv											1	1;2024-05-30;https://www.arxiv.org/abs/2405.20322v1	arXiv:2405.20322			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 30 2024	2024	Classical Markov Chain Monte Carlo methods have been essential for simulating statistical physical systems and have proven well applicable to other systems with complex degrees of freedom. Motivated by the statistical physics origins, Chen, Kastoryano, and Gilyén [CKG23] proposed a continuous-time quantum thermodynamic analog to Glauber dynamic that is (i) exactly detailed balanced, (ii) efficiently implementable, and (iii) quasi-local for geometrically local systems. Physically, their construction gives a smooth variant of the Davies’ generator derived from weak system-bath interaction. In this work, we give an efficiently implementable discrete-time quantum counterpart to Metropolis sampling that also enjoys the desirable features (i)-(iii). Also, we give an alternative highly coherent quantum generalization of detailed balanced dynamics that resembles another physically derived master equation, and propose a smooth interpolation between this and earlier constructions. We study generic properties of all constructions, including the uniqueness of the fixed-point and the locality of the resulting operators. We hope our results provide a systematic approach to the possible quantum generalizations of classical Glauber and Metropolis dynamics.																																	2024-06-16	PPRN:89113885		
J	Golovneva, Olga; Wang, Tianlu; Weston, Jason; Sukhbaatar, Sainbayar				Wang, Tianlu/IST-5357-2023						Contextual Position Encoding: <italic>Learning to Count What's Important</italic>								Arxiv											1	1;2024-05-30;https://www.arxiv.org/abs/2405.18719v2	arXiv:2405.18719			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 30 2024	2024	The attention mechanism is a critical component of Large Language Models (LLMs) that allows tokens in a sequence to interact with each other, but is order-invariant. Incorporating position encoding (PE) makes it possible to address by position, such as attending to the i-th token. However, current PE methods use token counts to derive position, and thus cannot generalize to higher levels of abstraction, such as attending to the i-th sentence. In this paper, we propose a new position encoding method, Contextual Position Encoding (CoPE), that allows positions to be conditioned on context by incrementing position only on certain tokens determined by the model. This allows more general position addressing such as attending to the $i$-th particular word, noun, or sentence. We show that CoPE can solve the selective copy, counting and Flip-Flop tasks where popular position embeddings fail, and improves perplexity on language modeling and coding tasks.																																	2024-06-16	PPRN:89113063		
J	Li, Cong; Hu, Mengli; Li, Zhilin; Wang, Yang; Chen, Wanyu; Thiagarajan, Balasubramanian; Leandersson, Mats; Polley, Craig; Kim, Timur; Liu, Hui; Fulga, Cosma; Vergniory, Maia G.; Janson, Oleg; Tjernberg, Oscar; van den Brink, Jeroen				Kim, Timur/AAE-3029-2019; Vergniory, Maia/AAB-2833-2019; HU, Mengli/KGM-0548-2024; Li, Zhilin/LFT-9918-2024; van den Brink, Jeroen/E-5670-2011						Topological Weyl Altermagnetism in CrSb								Arxiv											2	2;2024-05-30;https://www.arxiv.org/abs/2405.14777v2| 1;2024-05-23;https://www.arxiv.org/abs/2405.14777v1	arXiv:2405.14777			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 30 2024	2024	Altermagnets constitute a novel, third fundamental class of collinear magnetic ordered materials, alongside with ferro- and antiferromagnets. They share with conventional antiferromagnets the feature of a vanishing net magnetization. At the same time they show a spin-splitting of electronic bands, just as in ferromagnets, caused by the atomic exchange interaction. On the other hand, topology has recently revolutionized our understanding of condensed matter physics, introducing new phases of matter classified by intrinsic topological order. Here we connect the worlds of altermagnetism and topology, showing that the electronic structure of the altermagnet CrSb is topological and hosts a novel Weyl semimetallic state. Using high-resolution and spin angleresolved photoemission spectroscopy, we observe a large momentum-dependent spin-splitting in CrSb, reaching up to 1 eV, that induces altermagnetic Weyl nodes with an associated magnetic quantum number. At the surface we observe their spin-polarized topological Fermi-arcs. This establishes that in altermagnets the large energy scale intrinsic to the spin-splitting - orders of magnitude larger than the relativistic spin-orbit coupling - creates its own realm of robust electronic topology.																																	2024-06-16	PPRN:88990191		
J	Biderman, Stella; Schoelkopf, Hailey; Sutawika, Lintang; Gao, Leo; Tow, Jonathan; Abbasi, Baber; Aji, Alham Fikri; Ammanamanchi, Pawan Sasanka; Black, Sidney; Clive, Jordan; DiPofi, Anthony; Etxaniz, Julen; Fattori, Benjamin; Forde, Jessica Zosa; Foster, Charles; Hsu, Jeffrey; Jaiswal, Mimansa; Lee, Wilson Y.; Li, Haonan; Lovering, Charles; Muennighoff, Niklas; Pavlick, Ellie; Phang, Jason; Skowron, Aviya; Tan, Samson; Tang, Xiangru; Wang, Kevin A.; Winata, Genta Indra; Yvon, Francois; Zou, Andy				Foster, Charles/GSE-4406-2022; Zou, Andy/MGU-4410-2025; Li, Haonan/IAQ-4402-2023						Lessons from the Trenches on Reproducible Evaluation of Language Models								Arxiv											2	2;2024-05-29;https://www.arxiv.org/abs/2405.14782v2| 1;2024-05-23;https://www.arxiv.org/abs/2405.14782v1	arXiv:2405.14782			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	May 29 2024	2024	Effective evaluation of language models remains an open challenge in NLP. Researchers and engineers face methodological issues such as the sensitivity of models to evaluation setup, difficulty of proper comparisons across methods, and the lack of reproducibility and transparency. In this paper we draw on three years of experience in evaluating large language models to provide guidance and lessons for researchers. First, we provide an overview of common challenges faced in language model evaluation. Second, we delineate best practices for addressing or lessening the impact of these challenges on research. Third, we present the Language Model Evaluation Harness (lm-eval): an open source library for independent, reproducible, and extensible evaluation of language models that seeks to address these issues. We describe the features of the library as well as case studies in which the library has been used to alleviate these methodological concerns.																																	2024-08-25	PPRN:88989820		
J	Cristofoli, Andrea; Gonzo, Riccardo; Moynihan, Nathan; O'Connell, Donal; Ross, Alasdair; Sergola, Matteo; White, Chris D.				Moynihan, Nathan/AAN-6092-2020; Gonzo, Riccardo/ISS-8626-2023						The Uncertainty Principle and Classical Amplitudes								Arxiv											2	2;2024-05-29;https://www.arxiv.org/abs/2112.07556v3| 1;2024-04-16;https://www.arxiv.org/abs/2112.07556v2	arXiv:2112.07556			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 29 2024	2024	We study the variance in the measurement of observables during scattering events, as computed using amplitudes. The classical regime, characterised by negligible uncertainty, emerges as a consequence of an infinite set of relationships among multileg, multiloop amplitudes in a momentum-transfer expansion. We discuss two non-trivial examples in detail: the six-point tree and the five-point one-loop amplitudes in scalar QED. We interpret these relationships in terms or a coherent exponentiation of radiative effects in the classical limit which generalises the eikonal formula, and show how to recover the impulse, including radiation reaction, from this generalised eikonal. Finally, we incorporate the physics of spin into our framework.																																	2024-06-16	PPRN:88557248		
J	Sandstrom, Erik; Tateno, Keisuke; Oechsle, Michael; Niemeyer, Michael; Van Gool, Luc; Oswald, Martin R.; Tombari, Federico				Oswald, Martin/AAM-2779-2021						Splat-SLAM: Globally Optimized RGB-only SLAM with 3D Gaussians								Arxiv											1	1;2024-05-26;https://www.arxiv.org/abs/2405.16544v1	arXiv:2405.16544			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	May 26 2024	2024	3D Gaussian Splatting has emerged as a powerful representation of geometry and appearance for RGB-only dense Simultaneous Localization and Mapping (SLAM), as it provides a compact dense map representation while enabling efficient and high-quality map rendering. However, existing methods show significantly worse reconstruction quality than competing methods using other 3D representations, e.g. neural points clouds, since they either do not employ global map and pose optimization or make use of monocular depth. In response, we propose the first RGB-only SLAM system with a dense 3D Gaussian map representation that utilizes all benefits of globally optimized tracking by adapting dynamically to keyframe pose and depth updates by actively deforming the 3D Gaussian map. Moreover, we find that refining the depth updates in inaccurate areas with a monocular depth estimator further improves the accuracy of the 3D reconstruction. Our experiments on the Replica, TUM-RGBD, and ScanNet datasets indicate the effectiveness of globally optimized 3D Gaussians, as the approach achieves superior or on par performance with existing RGB-only SLAM methods methods in tracking, mapping and rendering accuracy while yielding small map sizes and fast runtimes. The source code is available at https://github.com/eriksandstroem/Splat-SLAM. .																																	2024-06-11	PPRN:89074584		
J	Xia, Yiyu; Han, Zhongdong; Watanabe, Kenji; Taniguchi, Takashi; Shan, Jie; Mak, Kin Fai				Watanabe, Kenji/H-2825-2011; TANIGUCHI, Takashi/H-2718-2011; Mak, Kin/E-9004-2015						Unconventional superconductivity in twisted bilayer WSe2								Arxiv											1	1;2024-05-23;https://www.arxiv.org/abs/2405.14784v1	arXiv:2405.14784			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	May 23 2024	2024	Moiré materials have enabled the realization of flat electron bands and quantum phases that are driven by strong correlations associated with flat bands1-5. Superconductivity has been observed, but solely, in graphene moiré materials6-11. The absence of robust superconductivity in moiré materials beyond graphene, such as semiconductor moiré materials5,has remained a mystery and challenged our current understanding of superconductivity in flat bands. Here, we report the observation of robust superconductivity in 3.65-degree twisted bilayer WSe2 which hosts a honeycomb moiré lattice12,13.  Superconductivity emerges at half-band filling and under small sublattice potential differences, where the moiré band is a flat Chern band12,13. The optimal superconducting transition temperature is about 220 mK and constitutes 2% of the effective Fermi temperature; the latter is comparable to the value in high-temperature cuprate superconductors14,15 and suggests strong pairing. The superconductor borders on two distinct metals below and above half-band filling; it undergoes a continuous transition to a correlated insulator by tuning the sublattice potential difference. The observed superconductivity on the verge of Coulombinduced charge localization suggests roots in strong electron correlations14,16.																																	2024-06-05	PPRN:88989375		
J	Hayes, Jamie; Shumailov, Ilia; Triantafillou, Eleni; Khalifa, Amr; Papernot, Nicolas										Inexact Unlearning Needs More Careful Evaluations to Avoid a False Sense of Privacy								Arxiv											1	1;2024-05-21;https://www.arxiv.org/abs/2403.01218v3	arXiv:2403.01218			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 21 2024	2024	The high cost of model training makes it increasingly desirable to develop techniques for unlearning. These techniques seek to remove the influence of a training example without having to retrain the model from scratch. Intuitively, once a model has unlearned, an adversary that interacts with the model should no longer be able to tell whether the unlearned example was included in the model’s training set or not. In the privacy literature, this is known as membership inference. In this work, we discuss adaptations of Membership Inference Attacks (MIAs) to the setting of unlearning (leading to their “U-MIA” counterparts). We propose a categorization of existing U-MIAs into “population U-MIAs”, where the same attacker is instantiated for all examples, and “per-example U-MIAs”, where a dedicated attacker is instantiated for each example. We show that the latter category, wherein the attacker tailors its membership prediction to each example under attack, is significantly stronger. Indeed, our results show that the commonly used U-MIAs in the unlearning literature overestimate the privacy protection afforded by existing unlearning techniques on both vision and language models. Our investigation reveals a large variance in the vulnerability of different examples to per-example U-MIAs. In fact, several unlearning algorithms lead to a reduced vulnerability for some, but not all, examples that we wish to unlearn, at the expense of increasing it for other examples. Notably, we find that the privacy protection for the remaining training examples may worsen as a consequence of unlearning. We also discuss the fundamental difficulty of equally protecting all examples using existing unlearning schemes, due to the different rates at which different examples are unlearned. We demonstrate that naive attempts at tailoring unlearning stopping criteria to different examples fail to alleviate these issues.																																	2024-08-23	PPRN:91460098		
J	Makelov, Aleksandar; Lange, George; Nanda, Neel										Towards Principled Evaluations of Sparse Autoencoders for Interpretability and Control								Arxiv											1	1;2024-05-20;https://www.arxiv.org/abs/2405.08366v3	arXiv:2405.08366			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 20 2024	2024	Disentangling model activations into meaningful features is a central problem in interpretability. However, the absence of ground-truth for these features in realistic scenarios makes validating recent approaches, such as sparse dictionary learning, elusive. To address this challenge, we propose a framework for evaluating feature dictionaries in the context of specific tasks, by comparing them against emph{supervised} feature dictionaries. First, we demonstrate that supervised dictionaries achieve excellent approximation, control, and interpretability of model computations on the task. Second, we use the supervised dictionaries to develop and contextualize evaluations of unsupervised dictionaries along the same three axes. We apply this framework to the indirect object identification (IOI) task using GPT-2 Small, with sparse autoencoders (SAEs) trained on either the IOI or OpenWebText datasets. We find that these SAEs capture interpretable features for the IOI task, but they are less successful than supervised features in controlling the model. Finally, we observe two qualitative phenomena in SAE training: feature occlusion (where a causally relevant concept is robustly overshadowed by even slightly higher-magnitude ones in the learned features), and feature over-splitting (where binary features split into many smaller, less interpretable features). We hope that our framework will provide a useful step towards more objective and grounded evaluations of sparse dictionary learning methods.																																	2024-06-15	PPRN:89097985		
J	Wu, Minghao; Yuan, Yulin; Haffari, Gholamreza; Wang, Longyue										(Perhaps) Beyond Human Translation: Harnessing Multi-Agent Collaboration for Translating Ultra-Long Literary Texts								Arxiv											1	1;2024-05-20;https://www.arxiv.org/abs/2405.11804v1	arXiv:2405.11804			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 20 2024	2024	Recent advancements in machine translation (MT) have significantly enhanced translation quality across various domains. However, the translation of literary texts remains a formidable challenge due to their complex language, figurative expressions, and cultural nuances. In this work, we introduce a novel multi-agent framework based on large language models (LLMs) for literary translation, implemented as a company called TransAgents, which mirrors traditional translation publication process by leveraging the collective capabilities of multiple agents, to address the intricate demands of translating literary works. To evaluate the effectiveness of our system, we propose two innovative evaluation strategies: Monolingual Human Preference (MHP) and Bilingual LLM Preference (BLP). MHP assesses translations from the perspective of monolingual readers of the target language, while BLP uses advanced LLMs to compare translations directly with the original texts. Empirical findings indicate that despite lower d-BLEU scores, translations from TransAgents are preferred by both human evaluators and LLMs over human-written references, particularly in genres requiring domain-specific knowledge. We also highlight the strengths and limitations of TransAgents through case studies and suggests directions for future research. [GRAPHICS]																																	2024-06-15	PPRN:89093139		
J	Shen, Yuanjun; Tang, Boyi; Gao, Shuai; Tong, Kin-Fai; Wong, Hang; Wong, Kai-Kit; Zhang, Yangyang				TANG, BOYI/LIC-1038-2024; WONG, Hei/AAM-7006-2020; Wong, Kai-Kit/OUH-7591-2025; Tong, Kin-Fai/ABJ-5379-2022; Shen, Yuanjun/HSG-0624-2023						Design and Implementation of mmWave Surface Wave Enabled Fluid Antennas and Experimental Results for Fluid Antenna Multiple Access								Arxiv											1	1;2024-05-15;https://www.arxiv.org/abs/2405.09663v1	arXiv:2405.09663			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 15 2024	2024	While multiple-input multiple-output (MIMO) technologies continue to advance, concerns arise as to how MIMO can remain scalable if more users are to be accommodated with an increasing number of antennas at the base station (BS) in the upcoming sixth generation (6G). Recently, the concept of fluid antenna system (FAS) has emerged, which promotes position flexibility to enable transmitter channel state information (CSI)-free spatial multiple access on one radio frequency (RF) chain. On the theoretical side, the fluid antenna multiple access (FAMA) approach offers a scalable alternative to massive MIMO spatial multiplexing. However, FAMA lacks experimental validation and the hardware implementation of FAS remains a mysterious approach. The aim of this paper is to provide a novel hardware design for FAS and evaluate the performance of FAMA using experimental data. Our FAS design is based on a dynamically reconfigurable “fluid” radiator which is capable of adjusting its position within a predefined space. One singlechannel fluid antenna (SCFA) and one double-channel fluid antenna (DCFA) are designed, electromagnetically simulated, fabricated, and measured. The measured radiation patterns of prototypes are imported into channel and network models for evaluating their performance in FAMA. The experimental results demonstrate that in the 5G millimeter-wave (mmWave) bands (24-30 GHz), the FAS prototypes can vary their gain up to an averaged value of 11 dBi. In the case of 4-user FAMA, the doublechannel FAS can significantly reduce outage probability by 57 % and increases the multiplexing gain to 2.27 when compared to a static omnidirectional antenna.																																	2024-06-12	PPRN:89084071		
J	Juravsky, Jordan; Brown, Bradley; Ehrlich, Ryan; Fu, Daniel Y.; Re, Christopher; Mirhoseini, Azalia				Fu, Daniel/KLC-3860-2024						Hydragen: High-Throughput LLM Inference with Shared Prefixes								Arxiv											2	2;2024-05-13;https://www.arxiv.org/abs/2402.05099v2| 1;2024-02-07;https://www.arxiv.org/abs/2402.05099v1	arXiv:2402.05099			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 13 2024	2024	Transformer-based large language models (LLMs) are now deployed to hundreds of millions of users. LLM inference is commonly performed on batches of sequences that share a prefix, such as few-shot examples or a chatbot system prompt. Decoding in this large-batch setting can be bottlenecked by the attention operation, which reads large key-value (KV) caches from memory and computes inefficient matrix-vector products for every sequence in the batch. In this work, we introduce Hydragen, a hardware-aware exact implementation of attention with shared prefixes. Hydragen computes attention over the shared prefix and unique suffixes separately. This decomposition enables efficient prefix attention by batching queries together across sequences, reducing redundant memory reads and enabling the use of hardware-friendly matrix multiplications. Our method can improve end-to-end CodeLlama-13b throughput by up to 32x against competitive baselines, with speedup growing with the batch size and shared prefix length. Hydragen also enables the use of very long shared contexts: with a large batch size, increasing the prefix length from 1K to 16K tokens decreases Hydragen throughput by less than 15%, while the throughput of baselines drops by over 90%. Hydragen generalizes beyond simple prefix-suffix decomposition and can be applied to tree-based prompt sharing patterns, allowing us to further reduce inference time on competitive programming problems by 55%. Our code is available at https://github.com/jordan-benjamin/hydragen. .																																	2024-06-08	PPRN:87561768		
J	Jones, Cameron R.; Bergen, Benjamin K.				Jones, Cameron/JFA-2531-2023						People cannot distinguish GPT-4 from a human in a Turing test								Arxiv											1	1;2024-05-09;https://www.arxiv.org/abs/2405.08007v1	arXiv:2405.08007			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 09 2024	2024	We evaluated 3 systems (ELIZA, GPT-3.5 and GPT-4) in a randomized, controlled, and preregistered Turing test. Human participants had a 5 minute conversation with either a human or an AI, and judged whether or not they thought their interlocutor was human. GPT-4 was judged to be a human 54% of the time, outperforming ELIZA (22%) but lagging behind actual humans (67%). The results provide the first robust empirical demonstration that any artificial system passes an interactive 2-player Turing test. The results have implications for debates around machine intelligence and, more urgently, suggest that deception by current AI systems may go undetected. Analysis of participants' strategies and reasoning suggests that stylistic and socio-emotional factors play a larger role in passing the Turing test than traditional notions of intelligence.																																	2024-06-08	PPRN:89045940		
J	Yang, Xikang; Tang, Xuehai; Hu, Songlin; Han, Jizhong				Yang, Xikang/KVY-4167-2024						Chain of Attack: a Semantic-Driven Contextual Multi-Turn attacker for LLM								Arxiv											1	1;2024-05-09;https://www.arxiv.org/abs/2405.05610v1	arXiv:2405.05610			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 09 2024	2024	Large language models (LLMs) have achieved remarkable performance in various natural language processing tasks, especially in dialogue systems. However, LLM may also pose security and moral threats, especially in multi round conversations where large models are more easily guided by contextual content, resulting in harmful or biased responses. In this paper, we present a novel method to attack LLMs in multi-turn dialogues, called CoA (Chain of Attack). CoA is a semantic-driven contextual multi-turn attack method that adaptively adjusts the attack policy through contextual feedback and semantic relevance during multi-turn of dialogue with a large model, resulting in the model producing unreasonable or harmful content. We evaluate CoA on different LLMs and datasets, and show that it can effectively expose the vulnerabilities of LLMs, and outperform existing attack methods. Our work provides a new perspective and tool for attacking and defending LLMs, and contributes to the security and ethical assessment of dialogue systems.																																	2024-06-04	PPRN:88978864		
J	Liu, Xiao; Zhang, Chenxu; Zhang, Lei				Zhang, Chenxu/IZP-8606-2023; Zhang, Lei/P-8881-2014						Vision Mamba: A Comprehensive Survey and Taxonomy								Arxiv											1	1;2024-05-07;https://www.arxiv.org/abs/2405.04404v1	arXiv:2405.04404			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 07 2024	2024	State Space Model (SSM) is a mathematical model used to describe and analyze the behavior of dynamic systems. This model has witnessed numerous applications in several fields, including control theory, signal processing, economics and machine learning. In the field of deep learning, state space models are used to process sequence data, such as time series analysis, natural language processing (NLP) and video understanding. By mapping sequence data to state space, long-term dependencies in the data can be better captured. In particular, modern SSMs have shown strong representational capabilities in NLP, especially in long sequence modeling, while maintaining linear time complexity. Notably, based on the latest state-space models, Mamba merges time-varying parameters into SSMs and formulates a hardware-aware algorithm for efficient training and inference. Given its impressive efficiency and strong long-range dependency modeling capability, Mamba is expected to become a new AI architecture that may outperform Transformer. Recently, a number of works have attempted to study the potential of Mamba in various fields, such as general vision, multi-modal, medical image analysis and remote sensing image analysis, by extending Mamba from natural language domain to visual domain. To fully understand Mamba in the visual domain, we conduct a comprehensive survey and present a taxonomy study. This survey focuses on Mamba's application to a variety of visual tasks and data types, and discusses its predecessors, recent advances and far-reaching impact on a wide range of domains. Since Mamba is now on an upward trend, please actively notice us if you have new findings, and new progress on Mamba will be included in this survey in a timely manner and updated on the Mamba project at https://github.com/lx6c78/Vision-Mamba-A-Comprehensive-Survey-and-Taxonomy.																																	2024-06-04	PPRN:88980342		
J	Huang, Kaixuan; Qu, Yuanhao; Cousins, Henry; Johnson, William A.; Yin, Di; Shah, Mihir; Zhou, Denny; Altman, Russ; Wang, Mengdi; Cong, Le				Altman, Russ/HRC-9623-2023; Cong, Le/M-9981-2013; Qu, Yuanhao/LYO-7668-2024						CRISPR-GPT: An LLM Agent for Automated Design of Gene-Editing Experiments								Arxiv											1	1;2024-04-27;https://www.arxiv.org/abs/2404.18021v1	arXiv:2404.18021			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 27 2024	2024	The introduction of genome engineering technology has transformed biomedical research, making it possible to make precise changes to genetic information. However, creating an efficient gene-editing system requires a deep understanding of CRISPR technology, and the complex experimental systems under investigation. While Large Language Models (LLMs) have shown promise in various tasks, they often lack specific knowledge and struggle to accurately solve biological design problems. In this work, we introduce CRISPR-GPT, an LLM agent augmented with domain knowledge and external tools to automate and enhance the design process of CRISPR-based gene-editing experiments. CRISPR-GPT leverages the reasoning ability of LLMs to facilitate the process of selecting CRISPR systems, designing guide RNAs, recommending cellular delivery methods, drafting protocols, and designing validation experiments to confirm editing outcomes. We showcase the potential of CRISPR-GPT for assisting non-exp ert researchers with gene-editing experiments from scratch and validate the agent’s effectiveness in a real -world use case. Furthermore, we explore the ethical and regulatory considerations associated with automated gene-editing design, highlighting the need for responsible and transparent use of these tools. Our work aims to bridge the gap between beginner biological researchers and CRISPR genome engineering techniques, and demonstrate the potential of LLM agents in facilitating complex biological discovery tasks.																																	2024-05-16	PPRN:88697203		
J	Ledwith, Patrick J.; Vishwanath, Ashvin; Parker, Daniel E.										Vortexability: A Unifying Criterion for Ideal Fractional Chern Insulators								Arxiv											2	2;2024-04-19;https://www.arxiv.org/abs/2209.15023v3| 1;2022-09-29;https://www.arxiv.org/abs/2209.15023v1	arXiv:2209.15023			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 19 2024	2024	Fractional Chern insulators realize the remarkable physics of the fractional quantum Hall effect (FQHE) in crystalline systems with Chern bands. The lowest Landau level (LLL) is known to host the FQHE, but not all Chern bands are suitable for realizing fractional Chern insulators (FCI). Previous approaches to stabilizing FCIs focused on mimicking the LLL through momentum space criteria. Here instead we take a real-space perspective by introducing the notion of vortexability. Vortexable Chern bands admit a fixed operator that introduces vortices into any band wavefunction while keeping the state entirely within the same band. Vortexable bands admit trial wavefunctions for FCI states, akin to Laughlin states. In the absence of dispersion and for sufficiently short ranged interactions, these FCI states are the ground state -- independent of the distribution of Berry curvature. Vortexable bands are much more general than the LLL, and we showcase a recipe for constructing them. We exhibit diverse examples in graphene-based systems with or without magnetic field, and with any Chern number. A special class of vortexable bands is shown to be equivalent to the momentum space "trace condition" or "ideal band condition". In addition, we also identify a more general form of vortexability that goes beyond this criterion. We introduce a modified measure that quantifies deviations from general vortexability which can be applied to generic Chern bands to identify promising FCI platforms.																																	2024-04-29	PPRN:19396741		
J	Liu, Kaibo; Liu, Yiyang; Chen, Zhenpeng; Zhang, Jie M.; Han, Yudong; Ma, Yun; Li, Ge; Huang, Gang				ma, yun/GQQ-1823-2022						LLM-Powered Test Case Generation for Detecting Tricky Bugs								Arxiv											1	1;2024-04-16;https://www.arxiv.org/abs/2404.10304v1	arXiv:2404.10304			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 16 2024	2024	Conventional automated test generation tools struggle to generate test oracles and tricky bug-revealing test inputs. Large Language Models (LLMs) can be prompted to produce test inputs and oracles for a program directly, but the precision of the tests can be very low for complex scenarios (only 6.3% based on our experiments). To fill this gap, this paper proposes AID, which combines LLMs with differential testing to generate fault-revealing test inputs and oracles targeting plausibly correct programs (i.e., programs that have passed all the existing tests). In particular, AID selects test inputs that yield diverse outputs on a set of program variants generated by LLMs, then constructs the test oracle based on the outputs. We evaluate AID on two large-scale datasets with tricky bugs: TrickyBugs and EvalPlus, and compare it with three state-of-the-art baselines. The evaluation results show that the recall, precision, and F1 score of AID outperform the state-of-the-art by up to 1.80x, 2.65x, and 1.66x, respectively.																																	2024-04-26	PPRN:88544169		
J	Zheng, Jianbin; Hu, Minghui; Fan, Zhongyi; Wang, Chaoyue; Ding, Changxing; Tao, Dacheng; Cham, Tat-Jen				Wang, Chaoyue/IWE-0324-2023; Hu, Minghui/KDP-1835-2024; Shen, Li/AEZ-9528-2022; 范, 忠义/JPX-9451-2023						Trajectory Consistency Distillation: Improved Latent Consistency Distillation by Semi-Linear Consistency Function with Trajectory Mapping								Arxiv											2	2;2024-04-15;https://www.arxiv.org/abs/2402.19159v2| 1;2024-02-29;https://www.arxiv.org/abs/2402.19159v1	arXiv:2402.19159			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 15 2024	2024	Latent Consistency Model (LCM) extends the Consistency Model to the latent space and leverages the guided consistency distillation technique to achieve impressive performance in accelerating text-to-image synthesis. However, we observed that LCM struggles to generate images with both clarity and detailed intricacy. Consequently, we introduce Trajectory Consistency Distillation (TCD), which encompasses trajectory consistency function and strategic stochastic sampling. The trajectory consistency function diminishes the parameterisation and distillation errors by broadening the scope of the self-consistency boundary condition with trajectory mapping and endowing the TCD with the ability to accurately trace the entire trajectory of the Probability Flow ODE in semi-linear form with an Exponential Integrator. Additionally, strategic stochastic sampling provides explicit control of stochastic and circumvents the accumulated errors inherent in multi-step consistency sampling. Experiments demonstrate that TCD not only significantly enhances image quality at low NFEs but also yields more detailed results compared to the teacher model at high NFEs.																																	2024-04-25	PPRN:88011198		
J	Haarnoja, Tuomas; Moran, Ben; Lever, Guy; Huang, Sandy H.; Tirumala, Dhruva; Humplik, Jan; Wulfmeier, Markus; Tunyasuvunakool, Saran; Siegel, Noah Y.; Hafner, Roland; Bloesch, Michael; Hartikainen, Kristian; Byravan, Arunkumar; Hasenclever, Leonard; Tassa, Yuval; Sadeghi, Fereshteh; Batchelor, Nathan; Casarini, Federico; Saliceti, Stefano; Game, Charles; Sreendra, Neil; Patel, Kushal; Gwira, Marlon; Huber, Andrea; Hurley, Nicole; Nori, Francesco; Hadsell, Raia; Heess, Nicolas				Patel, Kushal/KBA-0884-2024; Wulfmeier, Markus/HKM-5018-2023						Learning Agile Soccer Skills for a Bipedal Robot with Deep Reinforcement Learning								Arxiv											2	2;2024-04-11;https://www.arxiv.org/abs/2304.13653v2| 1;2023-04-26;https://www.arxiv.org/abs/2304.13653v1	arXiv:2304.13653			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 11 2024	2024	We investigate whether Deep Reinforcement Learning (Deep RL) is able to synthesize sophisticated and safe movement skills for a low-cost, miniature humanoid robot that can be composed into complex behavioral strategies in dynamic environments. We used Deep RL to train a humanoid robot with 20 actuated joints to play a simplified one-versus-one (1v1) soccer game. The resulting agent exhibits robust and dynamic movement skills such as rapid fall recovery, walking, turning, kicking and more; and it transitions between them in a smooth, stable, and efficient manner. The agent's locomotion and tactical behavior adapts to specific game contexts in a way that would be impractical to manually design. The agent also developed a basic strategic understanding of the game, and learned, for instance, to anticipate ball movements and to block opponent shots. Our agent was trained in simulation and transferred to real robots zero-shot. We found that a combination of sufficiently high-frequency control, targeted dynamics randomization, and perturbations during training in simulation enabled good-quality transfer. Although the robots are inherently fragile, basic regularization of the behavior during training led the robots to learn safe and effective movements while still performing in a dynamic and agile way -- well beyond what is intuitively expected from the robot. Indeed, in experiments, they walked 181% faster, turned 302% faster, took 63% less time to get up, and kicked a ball 34% faster than a scripted baseline, while efficiently combining the skills to achieve the longer term objectives.																																	2024-04-24	PPRN:65570501		
J	Luo, Zihan; Song, Xiran; Huang, Hong; Lian, Jianxun; Zhang, Chenhao; Jiang, Jinqi; Xie, Xing				Song, Xiran/OXB-9987-2025						GraphInstruct: Empowering Large Language Models with Graph Understanding and Reasoning Capability								Arxiv											2	2;2024-04-02;https://www.arxiv.org/abs/2403.04483v2| 1;2024-03-07;https://www.arxiv.org/abs/2403.04483v1	arXiv:2403.04483			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 02 2024	2024	Evaluating and enhancing the general capabilities of large language models (LLMs) has been an important research topic. Graph is a common data structure in the real world, and understanding graph datais a crucial part for advancing general intelligence. To evaluate and enhance the graph understanding abilities of LLMs, in this paper, we propose a benchmark named GraphInstruct, which comprehensively includes 21 classical graph reasoning tasks, providing diverse graph generation pipelines and detailed reasoning steps. Based on GraphInstruct, we further construct GraphLM through efficient instruction-tuning, which shows prominent graph understanding capability. In order to enhance the LLM with graph reasoning capability as well, we propose a step mask training strategy, and construct a model named GraphLM+. As one of the pioneering efforts to enhance the graph understanding and reasoning abilities of LLMs, extensive experiments have demonstrated the superiority of GraphLM and GraphLM+ over other LLMs. We look forward to more researchers exploring the potential of LLMs in the graph data mining domain through GraphInstruct. Our code for generating GraphInstruct is released publicly 																																	2024-04-18	PPRN:88061688		
J	Liang, Han; Zhang, Wenqian; Li, Wenxuan; Yu, Jingyi; Xu, Lan										InterGen: Diffusion-based Multi-human Motion Generation under Complex Interactions								Arxiv											3	3;2024-03-28;https://www.arxiv.org/abs/2304.05684v3| 2;2023-12-22;https://www.arxiv.org/abs/2304.05684v2| 1;2023-04-12;https://www.arxiv.org/abs/2304.05684v1	arXiv:2304.05684			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Mar 28 2024	2024	We have recently seen tremendous progress in diffusion advances for generating realistic human motions. Yet, they largely disregard the multi-human interactions. In this paper, we present InterGen, an effective diffusion-based approach that incorporates human-to-human interactions into the motion diffusion process, which enables layman users to customize high-quality two-person interaction motions, with only text guidance. We first contribute a multimodal dataset, named InterHuman. It consists of about 107M frames for diverse two-person interactions, with accurate skeletal motions and 23,337 natural language descriptions. For the algorithm side, we carefully tailor the motion diffusion model to our two-person interaction setting. To handle the symmetry of human identities during interactions, we propose two cooperative transformer-based denoisers that explicitly share weights, with a mutual attention mechanism to further connect the two denoising processes. Then, we propose a novel representation for motion input in our interaction diffusion model, which explicitly formulates the global relations between the two performers in the world frame. We further introduce two novel regularization terms to encode spatial relations, equipped with a corresponding damping scheme during the training of our interaction diffusion model. Extensive experiments validate the effectiveness and generalizability of InterGen. Notably, it can generate more diverse and compelling two-person motions than previous methods and enables various downstream applications for human interactions.																																	2024-04-15	PPRN:58898380		
J	Wen, Bowen; Yang, Wei; Kautz, Jan; Birchfield, Stan				Wen, Bowen/ACD-9179-2022						FoundationPose: Unified 6D Pose Estimation and Tracking of Novel Objects								Arxiv											2	2;2024-03-26;https://www.arxiv.org/abs/2312.08344v2| 1;2023-12-13;https://www.arxiv.org/abs/2312.08344v1	arXiv:2312.08344			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 26 2024	2024	We present FoundationPose, a unified foundation model for 6D object pose estimation and tracking, supporting both model-based and model-free setups. Our approach can be instantly applied at test-time to a novel object without fine-tuning, as long as its CAD model is given, or a small number of reference images are captured. We bridge the gap between these two setups with a neural implicit representation that allows for effective novel view synthesis, keeping the downstream pose estimation modules invariant under the same unified framework. Strong generalizability is achieved via large-scale synthetic training, aided by a large language model (LLM), a novel transformer-based architecture, and contrastive learning formulation. Extensive evaluation on multiple public datasets involving challenging scenarios and objects indicate our unified approach outperforms existing methods specialized for each task by a large margin. In addition, it even achieves comparable results to instance-level methods despite the reduced assumptions. 																																	2024-04-14	PPRN:86573986		
J	Wewer, Christopher; Raj, Kevin; Ilg, Eddy; Schiele, Bernt; Lenssen, Jan Eric										latentSplat: Autoencoding Variational Gaussians for Fast Generalizable 3D Reconstruction								Arxiv											2	2;2024-07-30;https://www.arxiv.org/abs/2403.16292v2| 1;2024-03-24;https://www.arxiv.org/abs/2403.16292v1	arXiv:2403.16292			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 24 2024	2024	We present latentSplat, a method to predict semantic Gaussians in a 3D latent space that can be splatted and decoded by a light-weight generative 2D architecture. Existing methods for generalizable 3D reconstruction either do not enable fast inference of high resolution novel views due to slow volume rendering, or are limited to interpolation of close input views, even in simpler settings with a single central object, where 360-degree generalization is possible. In this work, we combine a regression-based approach with a generative model, moving towards both of these capabilities within the same method, trained purely on readily available real video data. The core of our method are variational 3D Gaussians, a representation that efficiently encodes varying uncertainty within a latent space consisting of 3D feature Gaussians. From these Gaussians, specific instances can be sampled and rendered via efficient Gaussian splatting and a fast, generative decoder network. We show that latentSplat outperforms previous works in reconstruction quality and generalization, while being fast and scalable to high-resolution data.																																	2025-08-07	PPRN:88277971		
J	Wang, Zezhong; Yang, Fangkai; Wang, Lu; Zhao, Pu; Wang, Hongru; Chen, Liang; Lin, Qingwei; Wong, Kam-Fai				wang, zezhong/NTR-5831-2025; Lin, Qingwei/AAZ-3604-2021						Self-Guard: Empower the LLM to Safeguard Itself								Arxiv											2	2;2024-03-22;https://www.arxiv.org/abs/2310.15851v2| 1;2023-10-24;https://www.arxiv.org/abs/2310.15851v1	arXiv:2310.15851			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 22 2024	2024	  With the increasing risk posed by jailbreak attacks, recent studies have investigated various methods to improve the safety of large language models (LLMs), mainly falling into two strategies: safety training and safeguards. Safety training involves fine-tuning the LLM with adversarial samples, which activate the LLM’s capabilities against jailbreak. However, it is not always effective in countering new attacks and often leads to potential performance degradation. Safeguards, on the other hand, are methods using additional models to filter harmful content from the LLM’s response. Nevertheless, they can only reduce a limited amount of harmful output and introduce extra computational costs. Given the distinct strengths and weaknesses of both, we combine them to balance out their flaws and propose a more effective method called ELF-GUARD. Specifically, we train the LLM to review its responses for any harmful content and append a[harmful]or[harmless]tag to the end of the response. In this way, SELF-GUARD possesses the advantages of safety training, leveraging the powerful capabilities of the LLMs themselves to detect harmfulness. Besides that, it gains flexibility like safeguards, making the safety check tar-get the output side, which makes the system less vulnerable to attack updates. Experimental results indicate that our SELF-GUARD can effectively defend against jailbreak attacks and will not cause LLMs’ performance degradation.																																	2024-04-13	PPRN:85768126		
J	Liang, Yuxuan; Wen, Haomin; Nie, Yuqi; Jiang, Yushan; Jin, Ming; Song, Dongjin; Pan, Shirui; Wen, Qingsong				Han, Jindong/KFA-8486-2024; Jiang, Yushan/MEO-1281-2025; wen, Haomin/KLE-1789-2024						Foundation Models for Time Series Analysis: A Tutorial and Survey								Arxiv											3	3;2024-06-18;https://www.arxiv.org/abs/2403.14735v3| 2;2024-04-02;https://www.arxiv.org/abs/2403.14735v2| 1;2024-03-21;https://www.arxiv.org/abs/2403.14735v1	arXiv:2403.14735			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 21 2024	2024	Time series analysis stands as a focal point within the data mining community, serving as a cornerstone for extracting valuable insights crucial to a myriad of real-world applications. Recent advancements in Foundation Models (FMs) have fundamentally reshaped the paradigm of model design for time series analysis, boosting various downstream tasks in practice. These innovative approaches often leverage pre-trained or fine-tuned FMs to harness generalized knowledge tailored specifically for time series analysis. In this survey, we aim to furnish a comprehensive and up-to-date overview of FMs for time series analysis. While prior surveys have predominantly focused on either the application or the pipeline aspects of FMs in time series analysis, they have often lacked an in-depth understanding of the underlying mechanisms that elucidate why and how FMs benefit time series analysis. To address this gap, our survey adopts a model-centric classification, delineating various pivotal elements of time-series FMs, including model architectures, pre-training techniques, adaptation methods, and data modalities. Overall, this survey serves to consolidate the latest advancements in FMs pertinent to time series analysis, accentuating their theoretical underpinnings, recent strides in development, and avenues for future research exploration.																																	2025-08-07	PPRN:88263918		
J	Wang, Yuqing; Zhao, Yun				Wang, Yuqing/MCJ-1317-2025						Metacognitive Prompting Improves Understanding in Large Language Models								Arxiv											3	3;2024-03-20;https://www.arxiv.org/abs/2308.05342v4| 2;2023-08-17;https://www.arxiv.org/abs/2308.05342v3| 1;2023-08-10;https://www.arxiv.org/abs/2308.05342v1	arXiv:2308.05342			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 20 2024	2024	In Large Language Models (LLMs), there have been consistent advancements in taskspecific performance, largely influenced by effective prompt design. Recent advancements in prompting have enhanced reasoning in logicintensive tasks for LLMs, yet the nuanced understanding abilities of these models, crucial for processing and interpreting complex information, remain underexplored. In this study, we introduce Metacognitive Prompting (MP), a strategy inspired by human introspective reasoning processes. Using MP, LLMs undergo a systematic series of structured, selfaware evaluations, drawing on both their vast inherent knowledge and new insights. We conduct extensive experiments on four prevalent LLMs: Llama2, PaLM2, GPT-3.5, and GPT-4, across ten natural language understanding (NLU) datasets from GLUE, SuperGLUE, BLUE, and LexGLUE benchmarks. Additionally, we compare our method with chain -of thought prompting and its advanced versions. The results show that GPT-4 consistently excels across all tasks, while other models have shown significant progress in some tasks when used in conjunction with MP. Furthermore, MP consistently outperforms existing prompting methods in both general and domain -specific NLU tasks. This study underscores the potential to amplify the understanding abilities of LLMs and highlights the benefits of mirroring human introspective reasoning in NLU tasks. 																																	2024-04-13	PPRN:75280755		
J	Dai, Haixing; Ma, Chong; Yan, Zhiling; Liu, Zhengliang; Shi, Enze; Li, Yiwei; Shu, Peng; Wei, Xiaozheng; Zhao, Lin; Wu, Zihao; Zeng, Fang; Zhu, Dajiang; Liu, Wei; Li, Quanzheng; Sun, Lichao; Zhang, Shu; Liu, Tianming; Li, Xiang				Wei, Xiaozheng/JJD-3295-2023; Liu, Wei/JYQ-6082-2024; Ma, Chong/MIT-9373-2025; Zhao, Lin/ABM-7665-2022; Quanzheng, Li/OHU-0205-2025; SHU, PENG/LDF-4318-2024; wu, zihao/R-8745-2019; Shi, Enze/KFQ-3917-2024; Liu, Tianming/GLS-1211-2022; Li, Yiwei/JAX-1635-2023; Li, Xiang/J-6924-2019						SAMAUG: POINT PROMPT AUGMENTATION FOR SEGMENT ANYTHING MODEL								Arxiv											2	2;2024-03-19;https://www.arxiv.org/abs/2307.01187v4| 1;2023-10-31;https://www.arxiv.org/abs/2307.01187v2	arXiv:2307.01187			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 19 2024	2024	This paper introduces SAMAug, a novel visual point augmentation method for the Segment Anything Model (SAM) that enhances interactive image segmentation performance. SAMAug generates augmented point prompts to provide more information about the user's intention to SAM. Starting with an initial point prompt, SAM produces an initial mask, which is then fed into our proposed SAMAug to generate augmented point prompts. By incorporating these extra points, SAM can generate augmented segmentation masks based on both the augmented point prompts and the initial prompt, resulting in improved segmentation performance. We conducted evaluations using four different point augmentation strategies: random sampling, sampling based on maximum difference entropy, maximum distance, and saliency. Experiment results on the COCO, Fundus, COVID QU-Ex, and ISIC2018 datasets show that SAMAug can boost SAM's segmentation results, especially using the maximum distance and saliency. SAMAug demonstrates the potential of visual prompt augmentation for computer vision.																																	2024-04-12	PPRN:85906009		
J	Guo, Zhiyang; Zhou, Wengang; Li, Li; Wang, Min; Li, Houqiang										Motion-aware 3D Gaussian Splatting for Efficient Dynamic Scene Reconstruction								Arxiv											1	1;2024-03-18;https://www.arxiv.org/abs/2403.11447v1	arXiv:2403.11447			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 18 2024	2024	3D Gaussian Splatting (3DGS) has become an emerging tool for dynamic scene reconstruction. However, existing methods focus mainly on extending static 3DGS into a time-variant representation, while overlooking the rich motion information carried by 2D observations, thus suffering from performance degradation and model redundancy. To address the above problem, we propose a novel motion-aware enhancement framework for dynamic scene reconstruction, which mines useful motion cues from optical flow to improve different paradigms of dynamic 3DGS. Specifically, we first establish a correspondence between 3D Gaussian movements and pixel-level flow. Then a novel flow augmentation method is introduced with additional insights into uncertainty and loss collaboration. Moreover, for the prevalent deformation-based paradigm that presents a harder optimization problem, a transient-aware deformation auxiliary module is proposed. We conduct extensive experiments on both multi-view and monocular scenes to verify the merits of our work. Compared with the baselines, our method shows significant superiority in both rendering quality and efficiency.																																	2024-04-11	PPRN:88196497		
J	Zhang, Yaqi; Huang, Di; Liu, Bin; Tang, Shixiang; Lu, Yan; Chen, Lu; Bai, Lei; Chu, Qi; Yu, Nenghai; Ouyang, Wanli				shixiang, tang/JQX-3091-2023; Zhang, Yaqi/ABI-7921-2020; Lu, Yan/LSK-3159-2024; 黄, 笛/HPE-4754-2023; Chu, Qi/AAQ-5998-2020; Ouyang, Wanli/I-7135-2018						MotionGPT: Finetuned LLMs Are General-Purpose Motion Generators								Arxiv											2	2;2024-03-18;https://www.arxiv.org/abs/2306.10900v2| 1;2023-06-19;https://www.arxiv.org/abs/2306.10900v1	arXiv:2306.10900			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 18 2024	2024	Generating realistic human motion from given action descriptions has experienced significant advancements because of the emerging requirement of digital humans. While recent works have achieved impressive results in generating motion directly from textual action descriptions, they often support only a single modality of the control signal, which limits their application in the real digital human industry. This paper presents a Motion General-Purpose generaTor (MotionGPT) that can use multimodal control signals, e.g., text and single-frame poses, for generating consecutive human motions by treating multimodal signals as special input tokens in large language models (LLMs). Specifically, we first quantize multimodal control signals into discrete codes and then formulate them in a unified prompt instruction to ask the LLMs to generate the motion answer. Our MotionGPT demonstrates a unified human motion generation model with multimodal control signals by tuning a mere 0.4% of LLM parameters. To the best of our knowledge, MotionGPT is the first method to generate human motion by multimodal control signals, which we hope can shed light on this new direction. 																																	2024-04-11	PPRN:73434999		
J	Tian, Yuandong; Wang, Yiping; Zhang, Zhenyu; Chen, Beidi; Du, Simon				Wang, Wenjin/HSE-1306-2023						JoMA: Demystifying Multilayer Transformers via JOint Dynamics of MLP and Attention								Arxiv											2	2;2024-03-15;https://www.arxiv.org/abs/2310.00535v3| 1;2023-10-03;https://www.arxiv.org/abs/2310.00535v2	arXiv:2310.00535			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 15 2024	2024	We propose Joint MLP/Attention (JoMA) dynamics, a novel mathematical framework to understand the training procedure of multilayer Transformer architectures. This is achieved by integrating out the self -attention layer in Transformers, producing a modified dynamics of MLP layers only. JoMA removes unrealistic assumptions from previous analysis (e.g., lack of residual connection) and predicts that the attention first becomes sparse (to learn salient tokens), then dense (to learn less salient tokens) in the presence of nonlinear activations, while in the linear case, it is consistent with existing works that show attention becomes sparse over time. We leverage JoMA to qualitatively explains how tokens are combined to form hierarchies in multilayer Transformers, when the input tokens are generated by a latent hierarchical generative model. Experiments on models trained from real -world dataset (Wikitext2/Wikitext103) and various pre -trained models (OPT, Pythia) verify our theoretical findings. The code is at.																																	2024-04-11	PPRN:85375615		
J	Zhao, Jinman; Ding, Yitian; Jia, Chen; Wang, Yining; Qian, Zifan				jia, chen/KWU-2689-2024						Gender Bias in Large Language Models across Multiple Languages								Arxiv											1	1;2024-03-01;https://www.arxiv.org/abs/2403.00277v1	arXiv:2403.00277			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 01 2024	2024	With the growing deployment of large language models (LLMs) across various applications, assessing the influence of gender biases embedded in LLMs becomes crucial. The topic of gender bias within the realm of natural language processing (NLP) has gained considerable focus, particularly in the context of English. Nonetheless, the investigation of gender bias in languages other than English is still relatively under-explored and insufficiently analyzed. In this work, We examine gender bias in LLMs-generated outputs for different languages. We use three measurements: 1) gender bias in selecting descriptive words given the gender-related context. 2) gender bias in selecting gender-related pronouns (she/he) given the descriptive words. 3) gender bias in the topics of LLM-generated dialogues. We investigate the outputs of the GPT series of LLMs in various languages using our three measurement methods. Our findings revealed significant gender biases across all the languages we examined.																																	2024-03-28	PPRN:88003941		
J	Chen, Ziyi; Yang, Xiaocong; Lin, Jiacheng; Sun, Chenkai; Chang, Kevin Chen-Chuan; Huang, Jie				Chang, Kevin/ITR-8409-2023						Cascade Speculative Drafting for Even Faster LLM Inference								Arxiv											4	4;2024-02-27;https://www.arxiv.org/abs/2312.11462v4| 3;2024-02-16;https://www.arxiv.org/abs/2312.11462v3| 2;2023-12-21;https://www.arxiv.org/abs/2312.11462v2| 1;2023-12-18;https://www.arxiv.org/abs/2312.11462v1	arXiv:2312.11462			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 27 2024	2024	Introduced to enhance the efficiency of large language model (LLM) inference, speculative decoding operates by having a smaller model generate a draft. A larger target model then reviews this draft to align with its output, and any acceptance by the target model results in a reduction of the number of the target model runs, ultimately improving efficiency. However, the drafting process in speculative decoding includes slow autoregressive generation and allocates equal time to generating tokens, irrespective of their importance. These inefficiencies collectively contribute to the suboptimal performance of speculative decoding. To further improve LLM inference, we introduce Cascade Speculative Drafting (CS Drafting), a speculative execution algorithm that incorporates two types of cascades. The Vertical Cascade eliminates autoregressive generation from neural models, while the Horizontal Cascade optimizes time allocation in drafting for improved efficiency. Combining both cascades, CS Drafting achieves up to an 81 percent additional speedup over speculative decoding in our experiments, while maintaining the same output distribution as the target model.																																	2024-03-27	PPRN:86688860		
J	Hayase, Jonathan; Borevkovic, Ema; Carlini, Nicholas; Tramer, Florian; Nasr, Milad										Query-Based Adversarial Prompt Generation								Arxiv											1	1;2024-02-19;https://www.arxiv.org/abs/2402.12329v1	arXiv:2402.12329			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 19 2024	2024	Recent work has shown it is possible to construct adversarial examples that cause an aligned language model to emit harmful strings or perform harmful behavior. Existing attacks work either in the white-box setting (with full access to the model weights), or through transferability: the phenomenon that adversarial examples crafted on one model often remain effective on other models. We improve on prior work with a query-based attack that leverages API access to a remote language model to construct adversarial examples that cause the model to emit harmful strings with (much) higher probability than with transfer-only attacks. We validate our attack on GPT-3.5 and OpenAI's safety classifier; we can cause GPT-3.5 to emit harmful strings that current transfer attacks fail at, and we can evade the safety classifier with nearly 100% probability.																																	2024-03-16	PPRN:87760263		
J	Wang, Siyuan; Long, Zhuohan; Fan, Zhihao; Wei, Zhongyu; Huang, Xuanjing										Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation								Arxiv											1	1;2024-02-18;https://www.arxiv.org/abs/2402.11443v1	arXiv:2402.11443			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 18 2024	2024	This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations. We utilize a multi-agent system to manipulate the context or question of original instances, reframing new evolving instances with high confidence that dynamically extend existing benchmarks. Towards a more scalable, robust and fine-grained evaluation, we implement six reframing operations to construct evolving instances testing LLMs against diverse queries, data noise and probing their problem-solving sub-abilities. With this framework, we extend benchmark datasets of four tasks. Experimental results show a general performance decline in most LLMs against their original results. This decline under our scalable and robust evaluations, alongside our fine-grained evaluation, more accurately reflect models' capabilities. Besides, our framework widens performance discrepancies both between different models and within the same model across various tasks, facilitating more informed model selection for specific tasks 1.																																	2024-03-21	PPRN:87798690		
J	Dong, Xiangjue; Wang, Yibo; Yu, Philip S.; Caverlee, James				Wang, Yibo/KVB-3987-2024						Disclosure and Mitigation of Gender Bias in LLMs								Arxiv											1	1;2024-02-17;https://www.arxiv.org/abs/2402.11190v1	arXiv:2402.11190			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 17 2024	2024	Large Language Models (LLMs) can generate biased responses. Yet previous direct probing techniques contain either gender mentions or predefined gender stereotypes, which are challenging to comprehensively collect. Hence, we propose an indirect probing framework based on conditional generation. This approach aims to induce LLMs to disclose their gender bias even without explicit gender or stereotype mentions. We explore three distinct strategies to disclose explicit and implicit gender bias in LLMs. Our experiments demonstrate that all tested LLMs exhibit explicit and/or implicit gender bias, even when gender stereotypes are not present in the inputs. In addition, an increased model size or model alignment amplifies bias in most cases. Furthermore, we investigate three methods to mitigate bias in LLMs via Hyperparameter Tuning, Instruction Guiding, and Debias Tuning. Remarkably, these methods prove effective even in the absence of explicit genders or stereotypes.																																	2024-03-18	PPRN:87761382		
J	Wang, Wenxuan; Jiao, Wenxiang; Huang, Jingyuan; Dai, Ruyi; Huang, Jen-tse; Tu, Zhaopeng; Lyu, Michael R.				Huang, Jen-Tse/IRZ-7526-2023; Wang, Wenxuan/AAW-9073-2020; Tu, Zhaopeng/AAS-4259-2021; Huang, Jingyuan/KZU-9358-2024; dai, ruyi/HLW-1188-2023						Not All Countries Celebrate Thanksgiving: On the Cultural Dominance in Large Language Models								Arxiv											2	2;2024-02-16;https://www.arxiv.org/abs/2310.12481v2| 1;2023-10-19;https://www.arxiv.org/abs/2310.12481v1	arXiv:2310.12481			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 16 2024	2024	This paper identifies a cultural dominance issue within large language models (LLMs) due to the predominant use of English data in model training (e.g., ChatGPT). LLMs often provide inappropriate English-culture-related answers that are not relevant to the expected culture when users ask in non-English languages. To systematically evaluate the cultural dominance issue, we build a benchmark of concrete (e.g., holidays and songs) and abstract (e.g., values and opinions) cultural objects. Empirical results show that the representative GPT models suffer from the culture dominance problem, where GPT-4 is the most affected while text-davinci-003 suffers the least from this problem. Our study emphasizes the need to critically examine cultural dominance and ethical consideration in their development and deployment. We show that two straightforward methods in model development (i.e., pretraining on more diverse data) and deployment (e.g., culture-aware prompting) can significantly mitigate the cultural dominance issue in LLMs.																																	2024-05-04	PPRN:85724604		
J	Duan, Hanyu; Yang, Yi; Tam, Kar Yan				Duan, Hanyu/OGR-3102-2025						Do LLMs Know about Hallucination? An Empirical Investigation of LLM's Hidden States								Arxiv											1	1;2024-02-15;https://www.arxiv.org/abs/2402.09733v1	arXiv:2402.09733			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 15 2024	2024	Large Language Models (LLMs) can make up answers that are not real, and this is known as hallucination. This research aims to see if, how, and to what extent LLMs are aware of hallucination. More specifically, we check whether and how an LLM reacts differently in its hidden states when it answers a question right versus when it hallucinates. To do this, we introduce an experimental framework which allows examining LLM’s hidden states in different hallucination situations. Building upon this framework, we conduct a series of experiments with language models in the LLaMA family (Touvron et al., 2023). Our empirical findings suggest that LLMs react differently when processing a genuine response versus a fabricated one. We then apply various model interpretation techniques to help understand and explain the findings better. Moreover, informed by the empirical observations, we show great potential of using the guidance derived from LLM’s hidden representation space to mitigate hallucination. We believe this work provides insights into how LLMs produce hallucinated answers and how to make them occur less often.																																	2024-03-13	PPRN:87704218		
J	Kagaya, Tomoyuki; Yuan, Thong Jing; Lou, Yuxuan; Karlekar, Jayashree; Pranata, Sugiri; Kinose, Akira; Oguri, Koki; Wick, Felix; You, Yang										RAP: Retrieval-Augmented Planning with Contextual Memory for Multimodal LLM Agents								Arxiv											1	1;2024-02-06;https://www.arxiv.org/abs/2402.03610v1	arXiv:2402.03610			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 06 2024	2024	Owing to recent advancements, Large Language Models (LLMs) can now be deployed as agents for increasingly complex decision-making applications in areas including robotics, gaming, and API integration. However, reflecting past experiences in current decision-making processes, an innate human behavior, continues to pose significant challenges. Addressing this, we propose Retrieval-Augmented Planning (RAP) framework, designed to dynamically leverage past experiences corresponding to the current situation and context, thereby enhancing agents' planning capabilities. RAP distinguishes itself by being versatile: it excels in both text-only and multimodal environments, making it suitable for a wide range of tasks. Empirical evaluations demonstrate RAP's effectiveness, where it achieves SOTA performance in textual scenarios and notably enhances multimodal LLM agents' performance for embodied tasks. These results highlight RAP's potential in advancing the functionality and applicability of LLM agents in complex, real-world applications.																																	2024-02-21	PPRN:87533618		
J	Liusie, Adian; Manakul, Potsawee; Gales, Mark J.F.										LLM Comparative Assessment: Zero-shot NLG Evaluation through Pairwise Comparisons using Large Language Models								Arxiv											2	2;2024-02-06;https://www.arxiv.org/abs/2307.07889v3| 1;2023-07-15;https://www.arxiv.org/abs/2307.07889v1	arXiv:2307.07889			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 06 2024	2024	Current developments in large language models (LLMs) have enabled impressive zero -shot capabilities across various natural language tasks. An interesting application of these systems is in the automated assessment of natural language generation (NLG), a highly challenging area with great practical benefit. In this paper, we explore two options for exploiting the emergent abilities of LLMs for zero -shot NLG assessment: absolute score prediction, and comparative assessment which uses relative comparisons between pairs of candidates. Though comparative assessment has not been extensively studied in NLG assessment, we note that humans often find it more intuitive to compare two options rather than scoring each one independently. This work examines comparative assessment from multiple perspectives: performance compared to absolute grading; positional biases in the prompt; and efficient ranking in terms of the number of comparisons. We illustrate that LLM comparative assessment is a simple, general and effective approach for NLG assessment. For moderatesized open -source LLMs, such as FlanT5 and Llama2-chat, comparative assessment is superior to prompt scoring, and in many cases can achieve performance competitive with state-ofthe-art methods. Additionally, we demonstrate that LLMs often exhibit strong positional biases when making pairwise comparisons, and we propose debiasing methods that can further improve performance.																																	2024-05-25	PPRN:73945977		
J	Yang, Adam X.; Robeyns, Maxime; Wang, Xi; Aitchison, Laurence										Bayesian Low-rank Adaptation for Large Language Models								Arxiv											4	4;2024-02-05;https://www.arxiv.org/abs/2308.13111v5| 3;2024-01-28;https://www.arxiv.org/abs/2308.13111v4| 2;2023-10-04;https://www.arxiv.org/abs/2308.13111v3| 1;2023-08-28;https://www.arxiv.org/abs/2308.13111v2	arXiv:2308.13111			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 05 2024	2024	Low-rank adaptation (LoRA) has emerged as a new paradigm for cost-efficient fine-tuning of large language models (LLMs). However, fine-tuned LLMs often become overconfident especially when fine-tuned on small datasets. Bayesian methods, with their inherent ability to estimate uncertainty, serve as potent tools to mitigate overconfidence and enhance calibration. In this work, we introduce Laplace-LoRA, which applies a Bayesian approach to the LoRA parameters. Specifically, Laplace-LoRA applies a Laplace approximation to the posterior over the LoRA parameters, considerably improving the calibration of fine-tuned LLMs.																																	2024-05-25	PPRN:84289885		
J	Chan, Alex J.; Sun, Hao; Holt, Samuel; van der Schaar, Mihaela										Dense Reward for Free in Reinforcement Learning from Human Feedback								Arxiv											1	1;2024-02-01;https://www.arxiv.org/abs/2402.00782v1	arXiv:2402.00782			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 01 2024	2024	Reinforcement Learning from Human Feedback (RLHF) has been credited as the key advance that has allowed Large Language Models (LLMs) to effectively follow instructions and produce useful assistance. Classically, this involves generating completions from the LLM in response to a query before using a separate reward model to assign a score to the full completion. As an auto-regressive process, the LLM has to take many "actions" (selecting individual tokens) and only receives a single, sparse reward at the end of an episode, a setup that is known to be difficult to optimise in traditional reinforcement learning. In this work we leverage the fact that the reward model contains more information than just its scalar output, in particular, it calculates an attention map over tokens as part of the transformer architecture. We use these attention weights to redistribute the reward along the whole completion, effectively densifying the signal and highlighting the most important tokens, all without incurring extra computational cost or requiring any additional modelling. We demonstrate that, theoretically, this approach is equivalent to potential-based reward shaping, ensuring that the optimal policy remains unchanged. Empirically, we show that it stabilises training, accelerates the rate of learning, and, in practical cases, may lead to better local optima.																																	2024-05-25	PPRN:87456530		
J	Chakrabarty, Tuhin; Padmakumar, Vishakh; Brahman, Faeze; Muresan, Smaranda										Creativity Support in the Age of Large Language Models: An Empirical Study Involving Emerging Writers								Arxiv											2	2;2024-01-30;https://www.arxiv.org/abs/2309.12570v3| 1;2023-09-25;https://www.arxiv.org/abs/2309.12570v2	arXiv:2309.12570			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 30 2024	2024	The development of large language models (LLMs) capable of following instructions and engaging in conversational interactions sparked increased interest in their utilization across various support tools. We investigate the utility of modern LLMs in assisting professional writers via an empirical user study (n=30). The design of our collaborative writing interface is grounded in the cognitive process model of writing that views writing as a goal-oriented thinking process encompassing non-linear cognitive activities: planning, translating, and reviewing. Participants are asked to submit a post-completion survey to provide feedback on the potential and pitfalls of LLMs as writing collaborators. Upon analyzing the writer-LLM interactions, we find that while writers seek LLM's help across all three types of cognitive activities, they find LLMs more helpful in translation and reviewing. Our findings from analyzing both the interactions and the survey responses highlight future research directions in creative writing assistance using LLMs.																																	2024-02-15	PPRN:85187944		
J	Liu, Shengchao; Nie, Weili; Wang, Chengpeng; Lu, Jiarui; Qiao, Zhuoran; Liu, Ling; Tang, Jian; Xiao, Chaowei; Anandkumar, Anima				Xiao, Chaowei/AAT-8772-2021; Qiao, Zhuoran/IXX-1041-2023						Multi-modal Molecule Structure-text Model for Text-based Retrieval and Editing								Arxiv											3	3;2024-01-29;https://www.arxiv.org/abs/2212.10789v3| 2;2023-12-03;https://www.arxiv.org/abs/2212.10789v2| 1;2022-12-21;https://www.arxiv.org/abs/2212.10789v1	arXiv:2212.10789			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 29 2024	2024	There is increasing adoption of artificial intelligence in drug discovery. However, existing studies use machine learning to mainly utilize the chemical structures of molecules but ignore the vast textual knowledge available in chemistry. Incorporating textual knowledge enables us to realize new drug design objectives, adapt to text-based instructions and predict complex biological activities. Here we present a multi -modal molecule structure-text model, MoleculeSTM, by jointly learning molecules’ chemical structures and textual descriptions via a contrastive learning strategy. To train MoleculeSTM, we construct a large multi -modal dataset, namely, PubChemSTM, with over 280,000 chemical structure-text pairs. To demonstrate the effectiveness and utility of MoleculeSTM, we design two challenging zero-shot tasks based on text instructions, including structure-text retrieval and molecule editing. MoleculeSTM has two main properties: open vocabulary and compositionality via natural language. In experiments, MoleculeSTM obtains the state-of-the-art generalization ability to novel biochemical concepts across various benchmarks.																																	2024-02-16	PPRN:35893398		
J	Wei, Haoran; Kong, Lingyu; Chen, Jinyue; Zhao, Liang; Ge, Zheng; Yu, En; Sun, Jianjian; Han, Chunrui; Zhang, Xiangyu				Chen, Jinyue/LIH-3814-2024; wei, haoran/HGF-3374-2022						Small Language Model Meets with Reinforced Vision Vocabulary								Arxiv											1	1;2024-01-23;https://www.arxiv.org/abs/2401.12503v1	arXiv:2401.12503			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 23 2024	2024	Playing Large Vision Language Models (LVLMs) in 2023 is trendy among the AI community. However, the relatively large number of parameters (more than 7B) of popular LVLMs makes it difficult to train and deploy on consumer GPUs, discouraging many researchers with limited resources. Imagine how cool it would be to experience all the features of current LVLMs on an old GTX1080ti (our only game card). Accordingly, we present Vary-toy in this report, a small-size Vary along with Qwen-1.8B as the base ``large'' language model. In Vary-toy, we introduce an improved vision vocabulary, allowing the model to not only possess all features of Vary but also gather more generality. Specifically, we replace negative samples of natural images with positive sample data driven by object detection in the procedure of generating vision vocabulary, more sufficiently utilizing the capacity of the vocabulary network and enabling it to efficiently encode visual information corresponding to natural objects. For experiments, Vary-toy can achieve 65.6% ANLS on DocVQA, 59.1% accuracy on ChartQA, 88.1% accuracy on RefCOCO, and 29% on MMVet. The code will be publicly available on the homepage.																																	2024-05-25	PPRN:87297567		
J	Liu, Shikun; Fan, Linxi; Johns, Edward; Yu, Zhiding; Xiao, Chaowei; Anandkumar, Anima				Liu, Shikun/LGY-0616-2024; Xiao, Chaowei/AAT-8772-2021						Prismer: A Vision-Language Model with Multi-Task Experts								Arxiv											2	2;2024-01-18;https://www.arxiv.org/abs/2303.02506v3| 1;2023-03-12;https://www.arxiv.org/abs/2303.02506v1	arXiv:2303.02506			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 18 2024	2024	Recent vision-language models have shown impressive multi-modal generation capabilities. However, typically they require training huge models on massive datasets. As a more scalable alternative, we introduce Prismer, a data- and parameter-efficient vision-language model that leverages an ensemble of task-specific experts. Prismer only requires training of a small number of components, with the majority of network weights inherited from multiple readily-available, pre-trained experts, and kept frozen during training. By leveraging experts from a wide range of domains, we show Prismer can efficiently pool this expert knowledge and adapt it to various vision-language reasoning tasks. In our experiments, we show that Prismer achieves fine-tuned and few-shot learning performance which is competitive with current state-of-the-arts, whilst requiring up to two orders of magnitude less training data. Code is available at https://github.com/NVlabs/prismer.																																	2024-05-25	PPRN:43532167		
J	Hosking, Tom; Blunsom, Phil; Bartolo, Max										Human Feedback is not Gold Standard								Arxiv											2	2;2024-01-16;https://www.arxiv.org/abs/2309.16349v2| 1;2023-09-28;https://www.arxiv.org/abs/2309.16349v1	arXiv:2309.16349			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 16 2024	2024	Human feedback has become the de facto standard for evaluating the performance of Large Language Models, and is increasingly being used as a training objective. However, it is not clear which properties of a generated output this single ‘preference’ score captures. We hypothesise that preference scores are subjective and open to undesirable biases. We critically analyse the use of human feedback for both training and evaluation, to verify whether it fully captures a range of crucial error criteria. We find that while preference scores have fairly good coverage, they under-represent important aspects like factuality. We further hypothesise that both preference scores and error annotation may be affected by confounders, and leverage instruction-tuned models to generate outputs that vary along two possible confounding dimensions: assertiveness and complexity. We find that the assertiveness of an output skews the perceived rate of factuality errors, indicating that human annotations are not a fully reliable evaluation metric or training objective. Finally, we offer preliminary evidence that using human feedback as a training objective disproportionately increases the assertiveness of model outputs. We encourage future work to carefully consider whether preference scores are well aligned with the desired objective.																																	2024-05-25	PPRN:85322736		
J	Perez-Gonzalez, Pablo G.; Barro, Guillermo; Rieke, George H.; Lyu, Jianwei; Rieke, Marcia; Alberts, Stacey; Williams, Christina C; Hainline, Kevin; Sun, Fengwu; Puskas, David; Annunziatella, Marianna; Baker, William M.; Bunker, Andrew J.; Egami, Eiichi; Ji, Zhiyuan; Johnson, Benjamin D.; Robertson, Brant; Del Pino, Bruno Rodriguez; Rujopakarn, Wiphu; Shivaei, Irene; Tacchella, Sandro; Willmer, Christopher N.A.; Willott, Chris				Tacchella, Sandro/AAT-1602-2021; Annunziatella, Marianna/GRR-8306-2022; Del Pino, Bruno/C-3326-2017; BOEKER, TORSTEN/KVC-3022-2024; ji, zhiyuan/HGC-6180-2022; Perez-Gonzalez, Pablo G./IVH-0781-2023; Puskás, Dávid/NZO-4934-2025; Robertson, Brant/AAA-6124-2022; Lyu, Jianwei/KGL-5057-2024; Rujopakarn, Wiphu/AAV-2176-2021; Baker, William/KUD-6412-2024						What is the nature of Little Red Dots and what is not, MIRI SMILES edition								Arxiv											1	1;2024-01-16;https://www.arxiv.org/abs/2401.08782v1	arXiv:2401.08782			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 16 2024	2024	We study little red dots (LRD) detected by JADES and covered by the SMILES MIRI survey. Our sample contains 31 sources, ∼ 70% detected in the two bluest MIRI bands, 40% in redder filters. The median/quartiles redshifts are z = 6.97.7 5.9 (55% spectroscopic). We analyze the rest-frame ultraviolet through near/mid-infrared spectral energy distributions of LRDs combining NIRCam and MIRI obser-vations, using a variety of modeling techniques that include emission from stars, dust, and (un)obscured active galactic nuclei (AGN). The NIRCam−MIRI colors, for ≥ 10 µm, are bluer than direct pure emis-sion from AGN tori; the spectral slope flattens in the rest-frame near-infrared, consistent with a 1.6 µm stellar bump. Both observations imply that stellar emission makes the dominant contribution at these wavelengths, expediting a stellar mass estimation: the median/quartiles are log M⋆/M⊙ = 9.49.7 9.1. The number density of LRDs is 10 -4.0±0.1 Mpc -3, accounting for 14 ± 3% of the global population of galaxies with similar redshifts and masses. The flat ultraviolet spectral range is dominated by young stars. The rest-frame near/mid-infrared (2–4 µm) spectral slope reveals significant amounts of dust (bolometric stellar attenuation ∼ 3 − 4 mag) heated by strong radiation fields arising from highly embedded compact sources. Our models imply < 0.4 kpc heating knots, containing dust-enshrouded OB stars or an AGN producing a similar radiation field, obscured by A(V) > 10 mag. We conclude that LRDs are extremely intense and compact starburst galaxies with mass-weighted ages 5–10 Myr, very efficient in producing dust, their global energy output dominated by the direct and dust-recycled emission from OB stars, with some contribution from obscured AGN in the mid-infrared.																																	2024-02-03	PPRN:87209285		
J	Wurtz, Jonathan; Lopes, Pedro; Gorgulla, Christoph; Gemelke, Nathan; Keesling, Alexander; Wang, Sheng-Tao				Wang, Shengtao/OJU-0401-2025; Gorgulla, Christoph/HGU-9277-2022						Industry applications of neutral-atom quantum computing solving independent set problems								Arxiv											2	2;2024-01-16;https://www.arxiv.org/abs/2205.08500v2| 1;2022-05-17;https://www.arxiv.org/abs/2205.08500v1	arXiv:2205.08500			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 16 2024	2024	Architectures for quantum computing based on neutral atoms have risen to prominence as candidates for both near and long-term applications. These devices are particularly well suited to solve independent set problems, as the combinatorial constraints can be naturally encoded in the low-energy Hilbert space due to the Rydberg blockade mechanism. Here, we approach this connection with a focus on a particular device architecture and explore the ubiquity and utility of independent set problems by providing examples of real-world applications. After a pedagogical introduction of basic graph theory concepts of relevance, we briefly discuss how to encode independent set problems in Rydberg Hamiltonians. We then outline the major classes of independent set problems and include associated example applications with industry and social relevance. We determine a wide range of sectors that could benefit from efficient solutions of independent set problems -- from telecommunications and logistics to finance and strategic planning -- and display some general strategies for efficient problem encoding and implementation on neutral-atom platforms.																																	2024-05-25	PPRN:15639902		
J	Ellis, John; Malcolm, Fairbairn; Hutsi, Gert; Raidal, Juhan; Urrutia, Juan; Vaskonen, Ville; Veermae, Hardi				Veermäe, Hardi/GRO-1462-2022; Vaskonen, Ville/AAL-9788-2020; Hutsi, Gert/OIT-8415-2025						Gravitational Waves from SMBH Binaries in Light of the NANOGrav 15-Year Data								Arxiv											3	3;2024-01-12;https://www.arxiv.org/abs/2306.17021v4| 2;2023-10-09;https://www.arxiv.org/abs/2306.17021v3| 1;2023-06-29;https://www.arxiv.org/abs/2306.17021v1	arXiv:2306.17021			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 12 2024	2024	The NANOGrav and other Pulsar Timing Arrays (PTAs) have recently announced evidence for nHz gravitational waves (GWs) that may originate from supermassive black holes (SMBH) binaries. The spectral index of the GW signal differs from that predicted for binary evolution by GW emission alone, and we show that environmental effects such as dynamical friction with gas, stars and dark matter improve the consistency of the SMBH binary model with the PTA data. We comment on the possible implications of environmental effects for PTA observations of fluctuations in the GW frequency spectrum and measurements of GWs at higher frequencies.																																	2024-05-25	PPRN:73644136		
J	Struppek, Lukas; Hintersdorf, Dominik; Friedrich, Felix; Brack, Manuel; Schramowski, Patrick; Kersting, Kristian				Friedrich, Felix/LKM-6617-2024						Exploiting Cultural Biases via Homoglyphs in Text-to-Image Synthesis								Arxiv											2	2;2024-01-09;https://www.arxiv.org/abs/2209.08891v3| 1;2022-09-19;https://www.arxiv.org/abs/2209.08891v1	arXiv:2209.08891			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 09 2024	2024	Models for text-to-image synthesis, such as DALL-E 2 and Stable Diffusion, have recently drawn a lot of interest from academia and the general public. These models are capable of producing high-quality images that depict a variety of concepts and styles when conditioned on textual descriptions. However, these models adopt cultural characteristics associated with specific Unicode scripts from their vast amount of training data, which may not be immediately apparent. We show that by simply inserting single non-Latin characters in a textual description, common models reflect cultural stereotypes and biases in their generated images. We analyze this behavior both qualitatively and quantitatively, and identify a model's text encoder as the root cause of the phenomenon. Additionally, malicious users or service providers may try to intentionally bias the image generation to create racist stereotypes by replacing Latin characters with similarly-looking characters from non-Latin scripts, so-called homoglyphs. To mitigate such unnoticed script attacks, we propose a novel homoglyph unlearning method to fine-tune a text encoder, making it robust against homoglyph manipulations.																																	2024-01-26	PPRN:15669631		
J	Lu, Haihao; Yang, Jinwen; Hu, Haodong; Huangfu, Qi; Liu, Jinsong; Liu, Tianhao; Ye, Yinyu; Zhang, Chuwen; Ge, Dongdong				Ge, Dongdong/P-3745-2019; Zhang, Chuwen/NRZ-1343-2025						cuPDLP-C: A Strengthened Implementation of cuPDLP for Linear Programming by C language								Arxiv											2	2;2024-01-07;https://www.arxiv.org/abs/2312.14832v2| 1;2023-12-22;https://www.arxiv.org/abs/2312.14832v1	arXiv:2312.14832			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 07 2024	2024	A recent GPU implementation of the Restarted Primal-Dual Hybrid Gradient Method for Linear Programming (cuPDLP.jl) was proposed in [10]. Its computational results demonstrate the significant computational advantages of the GPU-based first-order algorithm on certain large-scale problems. The average performance also achieves a level close to commercial solvers for the first time in history. However, due to limitations in experimental hardware and the disadvantage of implementing the algorithm in Julia compared to C language, neither the commercial solver nor cuPDLP reached their maximum efficiency. Therefore, in this report, we have re-implemented and optimized cuPDLP in C language. Utilizing state-of-the-art CPU and GPU hardware, we extensively compare cuPDLP with the best commercial solvers. The experiments further highlight its substantial computational advantages and potential for solving large-scale linear programming problems. We also discuss the profound impact this breakthrough may have on mathematical programming research and the entire operations research community.																																	2024-05-25	PPRN:86783992		
J	Zhou, Guangdi; Lv, Wei; Wang, Heng; Nie, Zihao; Chen, Yaqi; Li, Yueying; Huang, Haoliang; Chen, Weiqiang; Sun, Yujie; Xue, Qi-Kun; Chen, Zhuoyu				Huang, Haoliang/A-4235-2019; Sun, Yujie/JVZ-2932-2024						Ambient-pressure superconductivity onset above 40 K in bilayer nickelate ultrathin films								Arxiv											1	1;2024-12-21;https://www.arxiv.org/abs/2412.16622v1	arXiv:2412.16622			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 21 2024	2024	The discovery of bilayer nickelate superconductors under high pressure has opened a new chapter in high-transition temperature (high-TC) superconductivity. Here, we report ambient-pressure superconductivity onset above the McMillan limit (40 K) in bilayer nickelate epitaxial ultrathin films. Three-unit-cell (3UC) thick La2.85Pr0.15Ni2O7 single-phase-crystalline films are grown using the gigantic-oxidative atomic-layer-by-layer epitaxy (GOALL-Epitaxy) on SrLaAlO4 substrates9. Resistivity measurements and magnetic-field responses indicate onset TC = 45 K. The transition to zero resistance exhibits characteristics consistent with a Berezinskii-Kosterlitz-Thouless (BKT)-like behavior, with TBKT=9 K. Meissner diamagnetic effect is observed at TM=8.5 K via a mutual inductance setup, in agreement with the BKT-like transition. In-plane and out-of-plane critical magnetic fields exhibit anisotropy. Scanning transmission electron microscopy (STEM) images and X-ray reciprocal space mappings (RSMs) show that the films maintain a tetragonal phase with coherent epitaxial compressive strain ~2% in the NiO2 planes relative to the bulk. Our findings pave the way for comprehensive investigations of nickelate superconductors under ambient pressure conditions and for exploring superconductivity at higher transition temperature through strain engineering in heterostructures.																																	2025-01-31	PPRN:120128448		
J	Rodriguez, Pedro Sales; Robinson, John M.; Jepsen, Paul Niklas; He, Zhiyang; Duckering, Casey; Zhao, Chen; Wu, Kai-Hsin; Campo, Joseph; Bagnall, Kevin; Kwon, Minho; Karolyshyn, Thomas; Weinberg, Phillip; Cain, Madelyn; Evered, Simon J.; Geim, Alexandra A.; Kalinowski, Marcin; Li, Sophie H.; Manovitz, Tom; Amato-Grill, Jesse; Basham, James I.; Bernstein, Liane; Braverman, Boris; Bylinskii, Alexei; Choukri, Adam; Deangelo, Robert; Fang, Fang; Fieweger, Connor; Frederick, Paige; Haines, David; Hamdan, Majd; Hammett, Julian; Hsu, Ning; Hu, Ming-Guang; Huber, Florian; Jia, Ningyuan; Kedar, Dhruv; Kornjača, Milan; Liu, Fangli; Long, John; Lopatin, Jonathan; Lopes, Pedro L.S.; Luo, Xiu-Zhe; Macri, Tommaso; Markovic, Ognjen; Martinez-Martinez, Luis A.; Meng, Xianmei; Ostermann, Stefan; Ostroumov, Evgeny; Paquette, David; Qiang, Zexuan; Shofman, Vadim; Singh, Anshuman; Singh, Manuj; Sinha, Nandan; Thoreen, Henry; Wan, Noel; Wang, Yiping; Waxman-Lenz, Daniel; Wong, Tak; Wurtz, Jonathan; Zhdanov, Andrii; Zheng, Laurent; Greiner, Markus; Keesling, Alexander; Gemelke, Nathan; Vuletic, Vladan; Kitagawa, Takuya; Wang, Sheng-Tao; Bluvstein, Dolev; Lukin, Mikhail D.; Lukin, Alexander; Zhou, Hengyun; Cantu, Sergio H.				Zhao, Chen/CAH-3094-2022; Hu, MingGuang/J-8379-2017; Geim, Andre/J-7888-2012; He, Zhiyang/KBA-6468-2024; Kedar, Dhruv/JQV-5145-2023; Wang, Shengtao/HMW-0150-2023; Liu, Fangli/AFZ-9352-2022; Macrì, Tommaso/S-9634-2017; Bylinskii, Alexei/I-7969-2015						Experimental Demonstration of Logical Magic State Distillation								Arxiv											1	1;2024-12-19;https://www.arxiv.org/abs/2412.15165v1	arXiv:2412.15165			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 19 2024	2024	Realizing universal fault-tolerant quantum computation is a key goal in quantum information science. By encoding quantum information into logical qubits utilizing quantum error correcting codes, physical errors can be detected and corrected, enabling substantial reduction in logical error rates. However, the set of logical operations that can be easily implemented on such encoded qubits is often constrained, necessitating the use of special resource states known as 'magic states' to implement universal, classically hard circuits. A key method to prepare high-fidelity magic states is to perform 'distillation', creating them from multiple lower fidelity inputs. Here we present the experimental realization of magic state distillation with logical qubits on a neutral-atom quantum computer. Our approach makes use of a dynamically reconfigurable architecture to encode and perform quantum operations on many logical qubits in parallel. We demonstrate the distillation of magic states encoded in d=3 and d=5 color codes, observing improvements of the logical fidelity of the output magic states compared to the input logical magic states. These experiments demonstrate a key building block of universal fault-tolerant quantum computation, and represent an important step towards large-scale logical quantum processors.																																	2025-01-24	PPRN:120064569		
J	Tamkin, Alex; Mccain, Miles; Handa, Kunal; Durmus, Esin; Lovitt, Liane; Rathi, Ankur; Huang, Saffron; Mountfield, Alfred; Hong, Jerry; Ritchie, Stuart; Stern, Michael; Clarke, Brian; Goldberg, Landon; Sumers, Theodore R.; Mueller, Jared; Mceachen, William; Mitchell, Wes; Carter, Shan; Clark, Jack; Kaplan, Jared; Ganguli, Deep										Clio: Privacy-Preserving Insights into Real-World AI Use								Arxiv											1	1;2024-12-18;https://www.arxiv.org/abs/2412.13678v1	arXiv:2412.13678			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 18 2024	2024	How are AI assistants being used in the real world? While model providers in theory have a window into this impact via their users' data, both privacy concerns and practical challenges have made analyzing this data difficult. To address these issues, we present Clio (Claude insights and observations), a privacy-preserving platform that uses AI assistants themselves to analyze and surface aggregated usage patterns across millions of conversations, without the need for human reviewers to read raw conversations. We validate this can be done with a high degree of accuracy and privacy by conducting extensive evaluations. We demonstrate Clio's usefulness in two broad ways. First, we share insights about how models are being used in the real world from one million Claude.ai Free and Pro conversations, ranging from providing advice on hairstyles to providing guidance on Git operations and concepts. We also identify the most common high-level use cases on Claude.ai (coding, writing, and research tasks) as well as patterns that differ across languages (e.g., conversations in Japanese discuss elder care and aging populations at higher-than-typical rates). Second, we use Clio to make our systems safer by identifying coordinated attempts to abuse our systems, monitoring for unknown unknowns during critical periods like launches of new capabilities or major world events, and improving our existing monitoring systems. We also discuss the limitations of our approach, as well as risks and ethical concerns. By enabling analysis of real-world AI usage, Clio provides a scalable platform for empirically grounded AI safety and governance.																																	2025-01-24	PPRN:120040966		
J	Zeng, Zhiyuan; Cheng, Qinyuan; Yin, Zhangyue; Wang, Bo; Li, Shimin; Zhou, Yunhua; Guo, Qipeng; Huang, Xuanjing; Qiu, Xipeng				ZHOU, YUN/ISA-9160-2023; Qiu, Xipeng/G-4071-2011; Cheng, Qinyuan/LDN-9770-2024; Zeng, Zhiyuan/JAC-2446-2023						Scaling of Search and Learning: A Roadmap to Reproduce o1 from Reinforcement Learning Perspective								Arxiv											1	1;2024-12-18;https://www.arxiv.org/abs/2412.14135v1	arXiv:2412.14135			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 18 2024	2024	OpenAI o1 represents a significant milestone in Artificial Inteiligence, which achieves expert-level performances on many challanging tasks that require strong reasoning ability.OpenAI has claimed that the main techinique behinds o1 is the reinforcement learining. Recent works use alternative approaches like knowledge distillation to imitate o1's reasoning style, but their effectiveness is limited by the capability ceiling of the teacher model. Therefore, this paper analyzes the roadmap to achieving o1 from the perspective of reinforcement learning, focusing on four key components: policy initialization, reward design, search, and learning. Policy initialization enables models to develop human-like reasoning behaviors, equipping them with the ability to effectively explore solution spaces for complex problems. Reward design provides dense and effective signals via reward shaping or reward modeling, which is the guidance for both search and learning. Search plays a crucial role in generating high-quality solutions during both training and testing phases, which can produce better solutions with more computation. Learning utilizes the data generated by search for improving policy, which can achieve the better performance with more parameters and more searched data. Existing open-source projects that attempt to reproduce o1 can be seem as a part or a variant of our roadmap. Collectively, these components underscore how learning and search drive o1's advancement, making meaningful contributions to the development of LLM. [GRAPHICS].																																	2025-01-24	PPRN:120040081		
J	Liu, Ming-Zhu; Pan, Ya-Wen; Liu, Zhi-Wei; Wu, Tian-Wei; Lu, Jun-Xu; Geng, Li-Sheng				Liu, Mingzhu/HTP-3779-2023; Geng, Li-Sheng/C-6441-2009; Lu, Junxu/JDD-4198-2023						Three ways to decipher the nature of exotic hadrons: multiplets, three-body hadronic molecules, and correlation functions								Arxiv											2	2;2024-12-16;https://www.arxiv.org/abs/2404.06399v2| 1;2024-04-09;https://www.arxiv.org/abs/2404.06399v1	arXiv:2404.06399			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 16 2024	2024	In the past two decades, a plethora of hadronic states beyond the conventional quark model of $qbar{q}$ mesons and $qqq$ baryons have been observed experimentally, which motivated extensive studies to understand their nature and the non-perturbative strong interaction. Since most of these exotic states are near the mass thresholds of a pair of conventional hadrons, the prevailing picture is that they are primarily hadronic molecules. In principle, one can verify the molecular nature of these states by thoroughly comparing their masses, decay widths, and production rates in a particular picture with experimental data. However, this is difficult or impossible. First, quantum mechanics allows for the mixing of configurations allowed by symmetries and quantum numbers. Second, data are relatively scarce because of their small production rates and the many difficulties in the experimental measurements. As a result, other alternatives need to be explored. This review summarizes three such approaches that can help disentangle the nature of the many exotic hadrons discovered. In the first approach, based on the molecular interpretations for some exotic states, we study the likely existence of multiplets of hadronic molecules related by various symmetries, such as isospin symmetry, SU(3)-flavor symmetry, heavy quark spin/flavor symmetry, and heavy antiquark diquark symmetry. In the second approach, starting from some hadronic molecular candidates, one can derive the underlying hadron-hadron interactions. With these interactions, one can study related three-body systems and check whether three-body bound states/resonances exist. In the third approach, one can turn to the femtoscopy technique to derive the hadron-hadron interactions, hence inaccessible. This technique provided an unprecedented opportunity to understand the interactions between unstable hadrons.																																	2025-01-31	PPRN:88468311		
J	Zohar, Orr; Wang, Xiaohan; Dubois, Yann; Mehta, Nikhil; Xiao, Tong; Hansen-Estruch, Philippe; Yu, Licheng; Wang, Xiaofang; Juefei-Xu, Felix; Zhang, Ning; Yeung-Levy, Serena; Xia, Xide										Apollo: An Exploration of Video Understanding in Large Multimodal Models								Arxiv											1	1;2024-12-13;https://www.arxiv.org/abs/2412.10360v1	arXiv:2412.10360			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 13 2024	2024	Despite the rapid integration of video perception capabilities into Large Multimodal Models (LMMs), the underlying mechanisms driving their video understanding remain poorly understood. Consequently, many design decisions in this domain are made without proper justification or analysis. The high computational cost of training and evaluating such models, coupled with limited open research, hinders the development of video-LMMs. To address this, we present a comprehensive study that helps uncover what effectively drives video understanding in LMMs. We begin by critically examining the primary contributors to the high computational requirements associated with video-LMM research and discover Scaling Consistency, wherein design and training decisions made on smaller models and datasets (up to a critical size) effectively transfer to larger models. Leveraging these insights, we explored many video-specific aspects of video-LMMs, including video sampling, architectures, data composition, training schedules, and more. For example, we demonstrated that fps sampling during training is vastly preferable to uniform frame sampling and which vision encoders are the best for video representation. Guided by these findings, we introduce Apollo, a state-of-the-art family of LMMs that achieve superior performance across different model sizes. Our models can perceive hour-long videos efficiently, with Apollo-3B outperforming most existing 7 B models with an impressive 55.1 on LongVideoBench. Apollo-7B is state-of-the-art compared to 7B LMMs with a 70.9 on MLVU, and 63.3 on Video-MME.																																	2025-01-22	PPRN:119938582		
J	Li, Zongjie; Wang, Chaozheng; Ma, Pingchuan; Wu, Daoyuan; Wang, Shuai; Gao, Cuiyun; Liu, Yang				Li, Zongjie/KMX-3522-2024; Ma, Pingchuan/AFR-0634-2022; Wu, Daoyuan/Y-3128-2018; Liu, Yang/D-2306-2013; Wang, Chaozheng/KHT-6430-2024; Gao, Cuiyun/LDF-8707-2024						Split and Merge: Aligning Position Biases in LLM-based Evaluators								Arxiv											3	3;2024-12-09;https://www.arxiv.org/abs/2310.01432v3| 2;2023-10-09;https://www.arxiv.org/abs/2310.01432v2| 1;2023-09-29;https://www.arxiv.org/abs/2310.01432v1	arXiv:2310.01432			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 09 2024	2024	Large language models (LLMs) have shown promise as automated evaluators for assessing the quality of answers generated by AI systems. However, these LLM-based evaluators exhibit position bias, or inconsistency, when used to evaluate candidate answers in pairwise comparisons, favoring either the first or second answer regardless of content. To address this limitation, we propose PORTIA, an alignment-based system designed to mimic human comparison strategies to calibrate position bias in a lightweight yet effective manner. Specifically, PORTIA splits the answers into multiple segments, aligns similar content across candidate answers, and then merges them back into a single prompt for evaluation by LLMs. We conducted extensive experiments with six diverse LLMs to evaluate 11,520 answer pairs. Our results show that PORTIA markedly enhances the consistency rates for all the models and comparison forms tested, achieving an average relative improvement of 47.46%. Remarkably, PORTIA enables less advanced GPT models to achieve 88% agreement with the state-of-the-art GPT-4 model at just 10% of the cost. Furthermore, it rectifies around 80% of the position bias instances within the GPT-4 model, elevating its consistency rate up to 98%. Subsequent human evaluations indicate that the PORTIA-enhanced GPT-3.5 model can even surpass the standalone GPT-4 in terms of alignment with human evaluators. These findings highlight PORTIA's ability to correct position bias, improve LLM consistency, and boost performance while keeping cost-efficiency. This represents a valuable step toward a more reliable and scalable use of LLMs for automated evaluations across diverse applications.																																	2025-01-16	PPRN:85378273		
J	Baggen, Josephine F.W.; Dokkum, Pieter van; Brammer, Gabriel; Graaff, Anna de; Franx, Marijn; Greene, Jenny; Labbe, Ivo; Leja, Joel; Maseda, Michael V.; Nelson, Erica J.; Rix, Hans-Walter; Wang, Bingjie; Weibel, Andrea				Brammer, Gabriel/AAB-4859-2020; Nelson, Erica/OUI-1817-2025; Wang, Bingjie/AAD-6128-2022; Leja, Joel/JPL-7942-2023; Labbe, Ivo/B-1408-2016						The Small Sizes and High Implied Densities of 'Little Red Dots' with Balmer Breaks Could Explain Their Broad Emission Lines Without an AGN								Arxiv											2	2;2024-12-06;https://www.arxiv.org/abs/2408.07745v2| 1;2024-08-14;https://www.arxiv.org/abs/2408.07745v1	arXiv:2408.07745			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Dec 06 2024	2024	Early JWST studies found an apparent population of massive, compact galaxies at redshifts z≳7. Recently three of these galaxies were shown to have prominent Balmer breaks, demonstrating that their light at λrest∼3500 Å is dominated by a stellar population that is relatively old (∼200 Myr). All three also have broad Hβ emission with σ >1000⁢km⁢s−1, a common feature of such ‘little red dots’. From Sersic profile fits to the NIRCam images in F200W we find that the stellar light of galaxies is extremely compact: the galaxies have half-light radii of re∼ 100 pc, in the regime of ultra compact dwarfs in the nearby Universe. Their masses are uncertain, as they depend on the contribution of possible light from an AGN to the flux at λrest>5000 Å. If the AGN contribution is low beyond the Balmer break region, the masses are M∗∼1010−1011⁢M☉, and the central densities are higher than those of any other known galaxy population by an order of magnitude. Interestingly, the implied velocity dispersions of ∼1500 km s-1 are in very good agreement with the measured Hβ line widths. We suggest that some of the broad lines in ‘little red dots’ are not due to AGNs but simply reflect the kinematics of the galaxies, and speculate that the galaxies are observed in a short-lived phase where the central densities are much higher than at later times. We stress, however, that the canonical interpretation of AGNs causing the broad Hβ lines also remains viable.																																	2025-01-17	PPRN:91413556		
J	Zhang, Jie; Bu, Haoyu; Wen, Hui; Liu, Yongji; Fei, Haiqiang; Xi, Rongrong; Li, Lun; Yang, Yun; Zhu, Hongsong; Meng, Dan				Liu, Yongji/JWP-6795-2024; Bu, Haoyu/GRY-2060-2022						When LLMs Meet Cybersecurity: A Systematic Literature Review								Arxiv											1	1;2024-12-04;https://www.arxiv.org/abs/2405.03644v2	arXiv:2405.03644			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 04 2024	2024	The rapid development of large language models (LLMs) has opened new avenues across various fields, including cybersecurity, which faces an evolving threat landscape and demand for innovative technologies. Despite initial explorations into the application of LLMs in cybersecurity, there is a lack of a comprehensive overview of this research area. This paper addresses this gap by providing a systematic literature review, covering the analysis of over 300 works, encompassing 25 LLMs and more than 10 downstream scenarios. Our comprehensive overview addresses three key research questions: the construction of cybersecurity-oriented LLMs, the application of LLMs to various cybersecurity tasks, the challenges and further research in this area. This study aims to shed light on the extensive potential of LLMs in enhancing cybersecurity practices and serve as a valuable resource for applying LLMs in this field. We also maintain and regularly update a list of practical guides on LLMs for cybersecurity at 																																	2025-01-15	PPRN:119699506		
J	Wang, Shuzhe; Leroy, Vincent; Cabon, Yohann; Chidlovskii, Boris; Revaud, Jerome										DUSt3R: Geometric 3D Vision Made Easy								Arxiv											3	3;2024-12-02;https://www.arxiv.org/abs/2312.14132v3| 2;2024-10-26;https://www.arxiv.org/abs/2312.14132v2| 1;2023-12-21;https://www.arxiv.org/abs/2312.14132v1	arXiv:2312.14132			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 02 2024	2024	Multi-view stereo reconstruction (MVS) in the wild requires to first estimate the camera parameters e.g. intrinsic and extrinsic parameters. These are usually tedious and cumbersome to obtain, yet they are mandatory to triangulate corresponding pixels in 3D space, which is the core of all best performing MVS algorithms. In this work, we take an opposite stance and introduce DUSt3R, a radically novel paradigm for Dense and Unconstrained Stereo 3D Reconstruction of arbitrary image collections, i.e. operating without prior information about camera calibration nor viewpoint poses. We cast the pairwise reconstruction problem as a regression of pointmaps, relaxing the hard constraints of usual projective camera models. We show that this formulation smoothly unifies the monocular and binocular reconstruction cases. In the case where more than two images are provided, we further propose a simple yet effective global alignment strategy that expresses all pairwise pointmaps in a common reference frame. We base our network architecture on standard Transformer encoders and decoders, allowing us to leverage powerful pretrained models. Our formulation directly provides a 3D model of the scene as well as depth information, but interestingly, we can seamlessly recover from it, pixel matches, relative and absolute camera. Exhaustive experiments on all these tasks showcase that the proposed DUSt3R can unify various 3D vision tasks and set new SoTAs on monocular/multi-view depth estimation as well as relative pose estimation. In summary, DUSt3R makes many geometric 3D vision tasks easy.																																	2025-01-11	PPRN:86786957		
J	Lessa, Leonardo A.; Cheng, Meng; Wang, Chong										Mixed-state quantum anomaly and multipartite entanglement								Arxiv											4	4;2024-11-29;https://www.arxiv.org/abs/2401.17357v4| 3;2024-06-26;https://www.arxiv.org/abs/2401.17357v3| 2;2024-02-08;https://www.arxiv.org/abs/2401.17357v2| 1;2024-01-30;https://www.arxiv.org/abs/2401.17357v1	arXiv:2401.17357			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 29 2024	2024	Quantum entanglement measures of many-body states have been increasingly useful to characterize phases of matter. Here we explore a surprising connection between mixed state entanglement and ’t Ho oft anomaly. More specifically, we consider lattice systems in d space dimensions with anomalous symmetry G where the anomaly is characterized by an invariant in the group cohomology Hd+2(G,U(1)). We show that any mixed state ρ that is strongly symmetric under G , in the sense that Gρ∝ρ , is necessarily (d+2)-nonseparable, i.e. is not the mixture of tensor products of d+2 states in the Hilbert space. Furthermore, such states cannot be prepared from any (d+2)-separable states using finite-depth local quantum channels, so the nonseparability is long-ranged in nature. We provide proof of these results in d ≤1, and plausibility arguments in d >1. The anomaly-nonseparability connection thus allows us to generate simple examples of mixed states with nontrivial long-ranged multipartite entanglement. In particular, in d=1 we found an example of intrinsically mixed quantum phase, in the sense that states in this phase cannot be two-way connected to any pure state through finite-depth local quantum channels. We also analyze mixed anomaly involving both strong and weak symmetries, including systems constrained by the Lieb-Schultz-Mattis type of anomaly. We find that, while strong-weak mixed anomaly in general does not constrain quantum entanglement, it does constrain long-range correlations of mixed states in nontrivial ways. Namely, such states are not symmetrically invertible and not gapped Markovian, generalizing familiar properties of anomalous pure states.																																	2025-01-11	PPRN:87436602		
J	Li, Lei; Wei, Yuancheng; Xie, Zhihui; Yang, Xuqing; Song, Yifan; Wang, Peiyi; An, Chenxin; Liu, Tianyu; Li, Sujian; Lin, Bill Yuchen; Kong, Lingpeng; Liu, Qi				kong, lingpeng/NHQ-3170-2025; Liu, Jiumeng/G-3719-2019; wang, peiyi/LNR-6224-2024; Liu, Tianyu/JXN-8107-2024; Li, Lei/LMN-0940-2024; Song, Yifan/LGY-4372-2024						VLRewardBench: A Challenging Benchmark for Vision-Language Generative Reward Models								Arxiv											1	1;2024-11-26;https://www.arxiv.org/abs/2411.17451v1	arXiv:2411.17451			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 26 2024	2024	Vision-language generative reward models (VL-GenRMs) play a crucial role in aligning and evaluating multimodal AI systems, yet their own evaluation remains under-explored. Current assessment methods primarily rely on AI-annotated preference labels from traditional VL tasks, which can introduce biases and often fail to effectively challenge state-of-the-art models. To address these limitations, we introduce VL-RewardBench, a comprehensive benchmark spanning general multimodal queries, visual hallucination detection, and complex reasoning tasks. Through our AI-assisted annotation pipeline combining sample selection with human verification, we curate 1,250 high-quality examples specifically designed to probe model limitations. Comprehensive evaluation across 16 leading large vision-language models, demonstrates VL-RewardBench's effectiveness as a challenging testbed, where even GPT-4o achieves only 65.4% accuracy, and state-of-the-art open-source models such as Qwen2-VL-72B, struggle to surpass random-guessing. Importantly, performance on VL-RewardBench strongly correlates (Pearson's r > 0.9) with MMMU-Pro accuracy using Best-of-N sampling with VL-GenRMs. Analysis experiments uncover three critical insights for improving VL-GenRMs: (i) models predominantly fail at basic visual perception tasks rather than reasoning tasks; (ii) inference-time scaling benefits vary dramatically by model capacity; and (iii) training VL-GenRMs to learn to judge substantially boosts judgment capability (+14.7% accuracy for a 7B VL-GenRM). We believe VL-RewardBench along with the experimental insights will become a valuable resource for advancing VL-GenRMs.																																	2025-01-08	PPRN:119437565		
J	Asai, Akari; He, Jacqueline; Shao, Rulin; Shi, Weijia; Singh, Amanpreet; Chang, Joseph Chee; Lo, Kyle; Soldaini, Luca; Feldman, Sergey; D'arcy, Mike; Wadden, David; Latzke, Matt; Tian, Minyang; Ji, Pan; Liu, Shengyan; Tong, Hao; Wu, Bohao; Xiong, Yanyu; Zettlemoyer, Luke; Neubig, Graham; Weld, Dan; Downey, Doug; Yih, Wen-tau; Koh, Pang Wei; Hajishirzi, Hannaneh				Xiong, Yanyu/HOF-8362-2023; Tong, Hao/JCE-7052-2023; Liu, Shengyan/GPX-4540-2022; Wu, Bohao/KHO-6692-2024						OpenScholar: Synthesizing Scientific Literature with Retrieval-augmented LMs								Arxiv											1	1;2024-11-21;https://www.arxiv.org/abs/2411.14199v1	arXiv:2411.14199			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 21 2024	2024	Scientific progress depends on researchers’ ability to synthesize the growing body of literature. Can large language models (LMs) assist scientists in this task? We introduce OPEN SCHOLAR , a specialized retrieval-augmented LM that answers scientific queries by identifying relevant passages from 45 million open-access papers and synthesizing citation-backed responses. To evaluate OPEN SCHOLAR , we develop SCHOLAR QABENCH , the first large-scale multi-domain benchmark for literature search, comprising 2,967 expert-written queries and 208 long-form answers across computer science, physics, neuroscience, and biomedicine. On SCHOLAR QAB ENCH , OPEN SCHOLAR-8B outperforms GPT-4o by 5% and PaperQA2 by 7% in correctness, despite being a smaller, open model. While GPT4o hallucinates citations 78–90% of the time, OPEN SCHOLAR achieves citation accuracy on par with human experts. OPEN SCHOLAR ’s datastore, retriever, and self-feedback inference loop also improves off-the-shelf LMs: for instance, OPEN- SCHOLAR-GPT4o improves GPT-4o’s correctness by 12%. In human evaluations, experts preferred OPEN SCHOLAR-8B and OPEN SCHOLAR-GPT4o responses over expert-written ones 51% and 70% of the time, respectively, compared to GPT4o’s 32%. We open-source all of our code, models, datastore, data and a public demo.																																	2024-12-31	PPRN:119316547		
J	Jung, Tae Hyun; Okui, Takemichi										Primordial black holes from bubble collisions during a first-order phase transition								Arxiv											3	3;2024-11-19;https://www.arxiv.org/abs/2110.04271v4| 2;2023-12-26;https://www.arxiv.org/abs/2110.04271v3| 1;2021-11-12;https://www.arxiv.org/abs/2110.04271v2	arXiv:2110.04271			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 19 2024	2024	We study the possibility of production of primordial black holes (PBHs) from bubble collisions during a first-order phase transition. While typical colliding bubbles are small and irrelevant for PBH production, we find that those that can produce PBHs must have a macroscopically thick fluid shell and have been born much before the typical nucleation time. Particularly large uncertainties arise from an exponential sensitivity of the nucleation rate on the required duration of bubble growth which depends on the details of the collisions and the evolution of the spacetime metric toward the end of the phase transition. We introduce a few parameters to be obtained from future numerical simulation to represent those unknowns, and estimate the PBH abundance in an Abelian Higgs benchmark model and show that it can be significant. We predict an approximately monochromatic PBH mass spectrum, and find regions in the parameter space where the PBHs can constitute entire dark matter or even over-close the universe. Our result thus shows that models with a first-order phase transition can be constrained by over-abundant PBHs or null results of other PBH searches.																																	2024-12-28	PPRN:11954488		
J	Weber, Maurice; Fu, Daniel; Anthony, Quentin; Oren, Yonatan; Adams, Shane; Alexandrov, Anton; Lyu, Xiaozhong; Nguyen, Huu; Yao, Xiaozhe; Adams, Virginia; Athiwaratkun, Ben; Chalamala, Rahul; Chen, Kezhen; Ryabinin, Max; Dao, Tri; Liang, Percy; Re, Christopher; Rish, Irina; Zhang, Ce				Fu, Daniel/KLC-3860-2024						RedPajama: an Open Dataset for Training Large Language Models								Arxiv											1	1;2024-11-19;https://www.arxiv.org/abs/2411.12372v1	arXiv:2411.12372			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 19 2024	2024	Large language models are increasingly becoming a cornerstone technology in artificial intelligence, the sciences, and society as a whole, yet the optimal strategies for dataset composition and filtering remain largely elusive. Many of the top-performing models lack transparency in their dataset curation and model development processes, posing an obstacle to the development of fully open language models. In this paper, we identify three core data-related challenges that must be addressed to advance open-source language models. These include (1) transparency in model development, including the data curation process, (2) access to large quantities of high-quality data, and (3) availability of artifacts and meta- data for dataset curation and analysis. To address these challenges, we release RedPajama-V1, an open reproduction of the LLaMA training dataset. In addition, we release RedPajama-V2, a massive web-only dataset consisting of raw, unfiltered text data together with quality signals and metadata. Together, the RedPajama datasets comprise over 100 trillion tokens spanning multiple domains and with their quality signals facilitate the filtering of data, aiming to inspire the development of numerous new datasets. To date, these datasets have already been used in the training of strong language models used in production, such as Snowflake Arctic, Salesforce’s XGen and AI2’s OLMo. To provide insight into the quality of RedPajama, we present a series of analyses and ablation studies with decoder-only language models with up to 1.6B parameters. Our findings demonstrate how quality signals for web data can be effectively leveraged to curate high-quality subsets of the dataset, underscoring the potential of RedPajama to advance the development of transparent and high-performing language models at scale.																																	2025-01-24	PPRN:119280090		
J	Xu, Rui; Wang, Xintao; Chen, Jiangjie; Yuan, Siyu; Yuan, Xinfeng; Liang, Jiaqing; Chen, Zulong; Dong, Xiaoqing; Xiao, Yanghua				Chen, Jiangjie/JCE-5486-2023; Xu, Rui/LRV-2470-2024						Character is Destiny: Can Role-Playing Language Agents Make Persona-Driven Decisions?								Arxiv											2	2;2024-11-18;https://www.arxiv.org/abs/2404.12138v2| 1;2024-04-18;https://www.arxiv.org/abs/2404.12138v1	arXiv:2404.12138			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 18 2024	2024	Can Large Language Models (LLMs) simulate humans in making important decisions? Recent research has unveiled the potential of using LLMs to develop role-playing language agents (RPLAs), mimicking mainly the knowledge and tones of various characters. However, imitative decision-making necessitates a more nuanced understanding of personas. In this paper, we benchmark the ability of LLMs in persona-driven decision-making. Specifically, we investigate whether LLMs can predict characters' decisions provided by the preceding stories in high-quality novels. Leveraging character analyses written by literary experts, we construct a dataset LIFECHOICE comprising 1,462 characters' decision points from 388 books. Then, we conduct comprehensive experiments on LIFECHOICE, with various LLMs and RPLA methodologies. The results demonstrate that state-of-the-art LLMs exhibit promising capabilities in this task, yet substantial room for improvement remains. Hence, we further propose the CHARMAP method, which adopts persona-based memory retrieval and significantly advances RPLAs on this task, achieving 5.03% increase in accuracy.																																	2024-12-28	PPRN:88565295		
J	Zhang, Jianguo; Lan, Tian; Murthy, Rithesh; Liu, Zhiwei; Yao, Weiran; Zhu, Ming; Tan, Juntao; Hoang, Thai; Liu, Zuxin; Yang, Liangwei; Feng, Yihao; Kokane, Shirley; Awalgaonkar, Tulika; Niebles, Juan Carlos; Savarese, Silvio; Heinecke, Shelby; Wang, Huan; Xiong, Caiming				Niebles, Juan/AAT-5882-2021; Yang, Lingwei/AHC-6477-2022; Liu, Zhi-Wei/G-6187-2011; Zhang, Junying/C-2036-2013						AgentOhana: Design Unified Data and Training Pipeline for Effective Agent Learning								Arxiv											3	3;2024-11-09;https://www.arxiv.org/abs/2402.15506v4| 2;2024-03-20;https://www.arxiv.org/abs/2402.15506v3| 1;2024-02-26;https://www.arxiv.org/abs/2402.15506v2	arXiv:2402.15506			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Nov 09 2024	2024	Autonomous agents powered by large language models (LLMs) have garnered significant research attention. However, fully harnessing the potential of LLMs for agent-based tasks presents inherent challenges due to the heterogeneous nature of diverse data sources featuring multi-turn trajectories. In this paper, we introduce AgentOhana as a comprehensive solution to address these challenges. AgentOhana aggregates agent trajectories from distinct environments, spanning a wide array of scenarios. It meticulously standardizes and unifies these trajectories into a consistent format, streamlining the creation of a generic data loader optimized for agent training. Leveraging the data unification, our training pipeline maintains equilibrium across different data sources and preserves independent randomness across devices during dataset partitioning and model training. Additionally, we present xLAM-v0.1, a large action model tailored for AI agents, which demonstrates exceptional performance across various benchmarks. 																																	2024-12-19	PPRN:87871266		
J	Wozniak, Stanislaw; Koptyra, Bartlomiej; Janz, Arkadiusz; Kazienko, Przemyslaw; Kocon, Jan				Kazienko, Przemysław/F-1849-2014; Koptyra, Bartlomiej/LDF-8467-2024; Kocon, Jan/IXN-3388-2023; Woźniak, Stanisław/LIH-4606-2024						Personalized Large Language Models								Arxiv											2	2;2024-11-07;https://www.arxiv.org/abs/2402.09269v2| 1;2024-02-14;https://www.arxiv.org/abs/2402.09269v1	arXiv:2402.09269			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 07 2024	2024	Large language models (LLMs) have significantly advanced Natural Language Processing (NLP) tasks in recent years. However, their universal nature poses limitations in scenarios requiring personalized responses, such as recommendation systems and chatbots. This paper investigates methods to personalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on subjective tasks. Results demonstrate that personalized fine-tuning improves model reasoning compared to non-personalized models. Experiments on datasets for emotion recognition and hate speech detection show consistent performance gains with personalized methods across different LLM architectures. These findings underscore the importance of personalization for enhancing LLM capabilities in subjective text perception tasks.																																	2024-12-16	PPRN:87688712		
J	Lee, Seongyun; Park, Sue Hyun; Kim, Seungone; Seo, Minjoon										Aligning to Thousands of Preferences via System Message Generalization								Arxiv											2	2;2024-11-05;https://www.arxiv.org/abs/2405.17977v2| 1;2024-05-28;https://www.arxiv.org/abs/2405.17977v1	arXiv:2405.17977			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 05 2024	2024	Although humans inherently have diverse values, current large language model (LLM) alignment methods often assume that aligning LLMs with the general public's preferences is optimal. A major challenge in adopting a more individualized approach to LLM alignment is its lack of scalability, as it involves repeatedly acquiring preference data and training new reward models and LLMs for each individual's preferences. To address these challenges, we propose a new paradigm where users specify what they value most within the system message, steering the LLM's generation behavior to better align with the user's intentions. However, a naive application of such an approach is non-trivial since LLMs are typically trained on a uniform system message (e.g., "You are a helpful assistant") which limits their ability to generalize to diverse, unseen system messages. To improve this generalization, we create the Multifaceted Collection, a preference dataset with 192k combinations of values beyond generic helpfulness and harmlessness, spanning 65k user instructions. Using this dataset, we train a 7B LLM called Janus and test it on 921 prompts from 5 benchmarks (AlpacaEval 2.0, FLASK, Koala, MT-Bench, and Self-Instruct) by adding various unseen system messages that reflect user preferences. Janus achieves tie+win rate of 75.2%, 72.4%, and 66.4% against Mistral 7B Instruct v0.2, GPT-3.5 Turbo, and GPT-4, respectively. Unexpectedly, on three benchmarks focused on response helpfulness (AlpacaEval 2.0, MT-Bench, Arena Hard Auto v0.1), Janus also outperforms LLaMA 3 8B Instruct by a +4.0%, +0.1%, +3.0% margin, underscoring that training with a vast array of system messages could also enhance alignment to the general public's preference as well. 																																	2024-12-10	PPRN:89086662		
J	Chen, Kai; Li, Yanze; Zhang, Wenhua; Liu, Yanxin; Li, Pengxiang; Gao, Ruiyuan; Hong, Lanqing; Tian, Meng; Zhao, Xinhai; Li, Zhenguo; Yeung, Dit-Yan; Lu, Huchuan; Jia, Xu				Chen, Xiangyu/P-7839-2018; Gao, Ruiyuan/LIC-0347-2024; Lv, Zhengtong/AAW-9611-2020; zhang, Shifeng/HPH-0217-2023; Liu, YanXin/OSI-2982-2025; li, pengxiang/GQZ-5777-2022; Li, Jiaqi/HHN-8236-2022						Automated Evaluation of Large Vision-Language Models on Self-driving Corner Cases								Arxiv											4	4;2024-11-03;https://www.arxiv.org/abs/2404.10595v4| 3;2024-06-27;https://www.arxiv.org/abs/2404.10595v3| 2;2024-06-20;https://www.arxiv.org/abs/2404.10595v2| 1;2024-04-16;https://www.arxiv.org/abs/2404.10595v1	arXiv:2404.10595			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 03 2024	2024	Large Vision-Language Models (LVLMs) have received widespread attention for advancing the interpretable self-driving. Existing evaluations of LVLMs primarily focus on multi-faceted capabilities in natural circumstances, lacking automated and quantifiable assessment for self-driving, let alone the severe road corner cases. In this work, we propose CODA-LM, the very first benchmark for the automatic evaluation of LVLMs for self-driving corner cases. We adopt a hierarchical data structure and prompt powerful LVLMs to analyze complex driving scenes and generate high-quality pre-annotations for the human annotators, while for LVLM evaluation, we show that using the text-only large language models (LLMs) as judges reveals even better alignment with human preferences than the LVLM judges. Moreover, with our CODA-LM, we build CODA-VLM, a new driving LVLM surpassing all open-sourced counterparts on CODA-LM. Our CODA-VLM performs comparably with GPT-4V, even surpassing GPT-4V by +21.42% on the regional perception task. We hope CODA-LM can become the catalyst to promote interpretable self-driving empowered by LVLMs.																																	2024-12-16	PPRN:88544257		
J	Chernozhukov, Victor; Chetverikov, Denis; Demirer, Mert; Duflo, Esther; Hansen, Christian; Newey, Whitney; Robins, James				Hansen, Christian/KHE-4355-2024						Double/Debiased Machine Learning for Treatment and Causal Parameters								Arxiv											2	2;2024-11-03;https://www.arxiv.org/abs/1608.00060v7| 1;2017-12-12;https://www.arxiv.org/abs/1608.00060v6	arXiv:1608.00060			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 03 2024	2024	We revisit the classic semiparametric problem of inference on a low dimensional parameter 00 in the presence of high-dimensional nuisance parameters η0. We depart from the classical setting by allowing for η0 to be so high-dimensional that the traditional assumptions, such as Donsker properties, that limit complexity of the parameter space for this object break down. To estimate η0 , we consider the use of statistical or machine learning (ML) methods which are particularly well-suited to estimation in modern, very high-dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating η0 cause a heavy bias in estimators of 00 that are obtained by naively plugging ML estimators of η0 into estimating equations for 00. This bias results in the naive estimator failing to be N−1/2 consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest 00 can be removed by using two simple, yet critical, ingredients: (1) using Neyman-orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate θ0, and (2) making use of cross-fitting which provides an efficient form of data-splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in a N−1/2-neighborhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of DML applied to learn the main regression parameter in a partially linear regression model, DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model, DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness, and DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.																																	2024-12-09	PPRN:12826175		
J	Jin, Can; Che, Tong; Peng, Hongwu; Li, Yiyuan; Metaxas, Dimitris N.; Pavone, Marco				Li, Yiyuan/JPX-6400-2023						Learning from Teaching Regularization: Generalizable Correlations Should be Easy to Imitate								Arxiv											3	3;2024-10-31;https://www.arxiv.org/abs/2402.02769v3| 2;2024-07-19;https://www.arxiv.org/abs/2402.02769v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.02769v1	arXiv:2402.02769			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 31 2024	2024	Generalization remains a central challenge in machine learning. In this work, we propose Learning from Teaching ( L O T ), a novel regularization technique for deep neural networks to enhance generalization. Inspired by the human ability to capture concise and abstract patterns, we hypothesize that generalizable correlations are expected to be easier to imitate. LOT operationalizes this concept to improve the generalization of the main model with auxiliary student learners. The student learners are trained by the main model and, in turn, provide feedback to help the main model capture more generalizable and imitable correlations. Our experimental results across several domains, including Computer Vision, Natural Language Processing, and methodologies like Reinforcement Learning, demonstrate that the introduction of LOT brings significant benefits compared to training models on the original dataset. The results suggest the effectiveness and efficiency of LOT in identifying generalizable information at the right scales while discarding spurious data correlations, thus making LOT a valuable addition to current machine learning. Code is available at https://github.com/jincan333/LoT.																																	2024-12-10	PPRN:87522228		
J	Salmi, Tuomo; Choudhury, Devarshi; Kini, Yves; Riley, Thomas E.; Vinciguerra, Serena; Watts, Anna L.; Wolff, Michael T.; Arzoumanian, Zaven; Bogdanov, Slavko; Chakrabarty, Deepto; Gendreau, Keith; Guillot, Sebastien; Ho, Wynn C.G.; Huppenkothen, Daniela; Ludlam, Renee M.; Morsink, Sharon M.; Ray, Paul S.				Ray, Paul/LVS-1508-2024						The Radius of the High-mass Pulsar PSR J0740+6620 with 3.6 yr of NICER Data								Arxiv											2	2;2024-10-25;https://www.arxiv.org/abs/2406.14466v2| 1;2024-06-20;https://www.arxiv.org/abs/2406.14466v1	arXiv:2406.14466			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 25 2024	2024	We report an updated analysis of the radius, mass, and heated surface regions of the massive pulsar PSR J0740+6620 using Neutron Star Interior Composition Explorer (NICER) data from 2018 September 21 to 2022 April 21, a substantial increase in data set size compared to previous analyses. Using a tight mass prior from radio timing measurements and jointly modeling the new NICER data with XMM-Newton data, the inferred equatorial radius and gravitational mass are 12 . 49 −0.88 +1.28km and 2 . 073 −0.069 +0.069 M⊙ respectively, each reported as the posterior credible interval bounded by the 16 % and 84 % quantiles, with an estimated systematic error ≲ 0 . 1 km. This result was obtained using the best computationally feasible sampler settings providing a strong radius lower limit but a slightly more uncertain radius upper limit. The inferred radius interval is also close to the R = 12 . 76 −1.02+1.49 km obtained by Dittmann et al., when they require the radius to be less than 16 km as we do. The results continue to disfavor very soft equations of state for dense matter, with R < 11 . 15 km for this high-mass pulsar excluded at the 95% probability. The results do not depend significantly on the assumed cross-calibration uncertainty between NICER and XMM-Newton. Using simulated data that resemble the actual observations, we also show that our pipeline is capable of recovering parameters for the inferred models reported in this paper.																																	2024-11-30	PPRN:89378241		
J	Kumar, Saurabh; Marklund, Henrik; Van Roy, Benjamin										Maintaining Plasticity in Continual Learning via Regenerative Regularization								Arxiv											3	3;2024-10-24;https://www.arxiv.org/abs/2308.11958v3| 2;2023-10-03;https://www.arxiv.org/abs/2308.11958v2| 1;2023-08-23;https://www.arxiv.org/abs/2308.11958v1	arXiv:2308.11958			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 24 2024	2024	In continual learning, plasticity refers to the ability of an agent to quickly adapt to new information. Neural networks are known to lose plasticity when processing non-stationary data streams. In this paper, we propose L2 Init, a simple approach for maintaining plasticity by incorporating in the loss function L2 regularization toward initial parameters. This is very similar to standard L2 regularization (L2), the only difference being that L2 regularizes toward the origin. L2 Init is simple to implement and requires selecting only a single hyper-parameter. The motivation for this method is the same as that of methods that reset neurons or parameter values. Intuitively, when recent losses are insensitive to particular parameters, these parameters should drift toward their initial values. This prepares parameters to adapt quickly to new tasks. On problems representative of different types of nonstationarity in continual supervised learning, we demonstrate that L2 Init most consistently mitigates plasticity loss compared to previously proposed approaches.																																	2024-11-30	PPRN:83086648		
J	Tan, Hanzhuo; Luo, Qi; Li, Jing; Zhang, Yuqun				Li, Jing/IQU-9459-2023						LLM4Decompile: Decompiling Binary Code with Large Language Models								Arxiv											3	3;2024-10-22;https://www.arxiv.org/abs/2403.05286v3| 2;2024-06-19;https://www.arxiv.org/abs/2403.05286v2| 1;2024-03-08;https://www.arxiv.org/abs/2403.05286v1	arXiv:2403.05286			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 22 2024	2024	Decompilation aims to convert binary code to high-level source code, but traditional tools like Ghidra often produce results that are difficult to read and execute. Motivated by the advancements in Large Language Models (LLMs), we propose LLM4Decompile, the first and largest open-source LLM series (1.3B to 33B) trained to decompile binary code. We optimize the LLM training process and introduce the LLM4Decompile-End models to decompile binary directly. The resulting models significantly outperform GPT-4o and Ghidra on the HumanEval and ExeBench benchmarks by over 100% in terms of re-executability rate. Additionally, we improve the standard refinement approach to fine-tune the LLM4Decompile-Ref models, enabling them to effectively refine the decompiled code from Ghidra and achieve a further 16.2% improvement over the LLM4Decompile-End. LLM4Decompile demonstrates the potential of LLMs to revolutionize binary code decompilation, delivering remarkable improvements in readability and executability while complementing conventional tools for optimal results. 																																	2024-11-22	PPRN:88082379		
J	Yuan, Xinyu; Qiao, Yan										Diffusion-TS: Interpretable Diffusion for General Time Series Generation								Arxiv											3	3;2024-10-21;https://www.arxiv.org/abs/2403.01742v3| 2;2024-03-14;https://www.arxiv.org/abs/2403.01742v2| 1;2024-03-04;https://www.arxiv.org/abs/2403.01742v1	arXiv:2403.01742			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 21 2024	2024	Denoising diffusion probabilistic models (DDPMs) are becoming the leading paradigm for generative models. It has recently shown breakthroughs in audio synthesis, time series imputation and forecasting. In this paper, we propose Diffusion-TS, a novel diffusion-based framework that generates multivariate time series samples of high quality by using an encoder-decoder transformer with disentangled temporal representations, in which the decomposition technique guides Diffusion-TS to capture the semantic meaning of time series while transformers mine detailed sequential information from the noisy model input. Different from existing diffusion-based approaches, we train the model to directly reconstruct the sample instead of the noise in each diffusion step, combining a Fourier-based loss term. Diffusion-TS is expected to generate time series satisfying both interpretablity and realness. In addition, it is shown that the proposed Diffusion-TS can be easily extended to conditional generation tasks, such as forecasting and imputation, without any model changes. This also motivates us to further explore the performance of Diffusion-TS under irregular settings. Finally, through qualitative and quantitative experiments, results show that Diffusion-TS achieves the state-of-the-art results on various realistic analyses of time series.																																	2024-11-20	PPRN:88024375		
J	Meng, Xiangming; Kabashima, Yoshiyuki				Kabashima, Yoshiyuki/F-4719-2015						Diffusion Model Based Posterior Sampling for Noisy Linear Inverse Problems								Arxiv											3	3;2024-10-20;https://www.arxiv.org/abs/2211.12343v4| 2;2024-01-24;https://www.arxiv.org/abs/2211.12343v3| 1;2022-11-20;https://www.arxiv.org/abs/2211.12343v1	arXiv:2211.12343			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 20 2024	2024	With the rapid development of diffusion models and flow-based generative models, there has been a surge of interests in solving noisy linear inverse problems, e.g., super-resolution, deblurring, denoising, colorization, etc, with generative models. However, while remarkable reconstruction performances have been achieved, their inference time is typically too slow since most of them rely on the seminal diffusion posterior sampling (DPS) framework and thus to approximate the intractable likelihood score, time-consuming gradient calculation through back-propagation is needed. To address this issue, this paper provides a fast and effective solution by proposing a simple closed-form approximation to the likelihood score. For both diffusion and flow-based models, extensive experiments are conducted on various noisy linear inverse problems such as noisy super-resolution, denoising, deblurring, and colorization. In all these tasks, our method (namely DMPS) demonstrates highly competitive or even better reconstruction performances while being significantly faster than all the baseline methods.																																	2024-11-20	PPRN:23120643		
J	Felkner, Virginia K.; Chang, Ho-Chun Herbert; Jang, Eugene; May, Jonathan										WinoQueer: A Community-in-the-Loop Benchmark for Anti-LGBTQ+ Bias in Large Language Models								Arxiv											2	2;2024-10-17;https://www.arxiv.org/abs/2306.15087v2| 1;2023-06-26;https://www.arxiv.org/abs/2306.15087v1	arXiv:2306.15087			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 17 2024	2024	We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community. The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias. Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members. Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities. 																																	2024-11-15	PPRN:73567580		
J	Cai, Mu; Tan, Reuben; Zhang, Jianrui; Zou, Bocheng; Zhang, Kai; Yao, Feng; Zhu, Fangrui; Gu, Jing; Zhong, Yiwu; Shang, Yuzhang; Dou, Yao; Park, Jaden; Gao, Jianfeng; Lee, Yong Jae; Yang, Jianwei				Gao, Jianfeng/AAP-8200-2021; Zhang, Jianrui/AAK-7546-2021; Shang, Yuzhang/HTO-5198-2023; Zhong, Yiwu/OAJ-2011-2025; Zhu, Fangrui/LXB-3116-2024						<italic>TemporalBench</italic>: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models								Arxiv											1	1;2024-10-15;https://www.arxiv.org/abs/2410.10818v2	arXiv:2410.10818			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 15 2024	2024	Understanding fine-grained temporal dynamics is crucial for multimodal video comprehension and generation. Due to the lack of fine-grained temporal annotations, existing video benchmarks mostly resemble static image benchmarks and are incompetent at evaluating models for temporal understanding. In this paper, we introduce TemporalBench, , a new benchmark dedicated to evaluating fine-grained temporal understanding in videos. TemporalBench consists of- 10K video question-answer pairs, derived from- 2K high-quality human annotations detailing the temporal dynamics in video clips. As a result, our benchmark provides a unique testbed for evaluating various temporal understanding and reasoning abilities such as action frequency, motion magnitude, event order, etc. Moreover, it enables evaluations on various tasks like both video question answering and captioning, both short and long video understanding, as well as different models such as multimodal video embedding models and text generation models. Results show that state-of-the-art models like GPT-4o achieve only 38.5% question answering accuracy on TemporalBench, , demonstrating a significant gap (-- 30%) between humans and AI in temporal understanding. Furthermore, we notice a critical pitfall for multi-choice QA where LLMs can detect the subtle changes in negative captions and find a “centralized” description as a cue for its prediction, where we propose Multiple Binary Accuracy (MBA) to correct such bias. We hope that TemporalBench can foster research on improving models’ temporal reasoning capabilities. 																																	2025-01-24	PPRN:112888898		
J	Yang, Ling; Yu, Zhaochen; Zhang, Tianjun; Cao, Shiyi; Xu, Minkai; Zhang, Wentao; Gonzalez, Joseph E.; Cui, Bin				Xu, Minkai/JXL-2266-2024						Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models								Arxiv											2	2;2024-10-14;https://www.arxiv.org/abs/2406.04271v2| 1;2024-06-06;https://www.arxiv.org/abs/2406.04271v1	arXiv:2406.04271			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 14 2024	2024	We introduce Buffer of Thoughts (BoT), a novel and versatile thought-augmented reasoning approach for enhancing accuracy, efficiency and robustness of large language models (LLMs). Specifically, we propose meta-buffer to store a series of informative high-level thoughts, namely thought-template , distilled from the problem-solving processes across various tasks. Then for each problem, we retrieve a relevant thought-template and adaptively instantiate it with specific reasoning structures to conduct efficient reasoning. To guarantee the scalability and stability, we further propose buffer-manager to dynamically update the meta-buffer, thus enhancing the capacity of meta-buffer as more tasks are solved. We conduct extensive experiments on 10 challenging reasoning-intensive tasks, and achieve significant performance improvements over previous SOTA methods: 11% on Game of 24, 20% on Geometric Shapes and 51% on Checkmate-in-One. Further analysis demonstrate the superior generalization ability and model robustness of our BoT, while requiring only 12% of the cost of multi-query prompting methods (e.g., tree/graph of thoughts) on average. Notably, we find that our Llama3-8B + BoT has the potential to surpass Llama3-70B model. Our project is available at https://github.com/YangLing0818/buffer-of-thought-llm																																	2024-11-11	PPRN:89262061		
J	Wu, Minghao; Vu, Thuy-Trang; Qu, Lizhen; Foster, George; Haffari, Gholamreza				Vu, Thuy-Trang/MBW-2710-2025						Adapting Large Language Models for Document-Level Machine Translation								Arxiv											4	4;2024-10-11;https://www.arxiv.org/abs/2401.06468v4| 3;2024-06-09;https://www.arxiv.org/abs/2401.06468v3| 2;2024-02-15;https://www.arxiv.org/abs/2401.06468v2| 1;2024-01-12;https://www.arxiv.org/abs/2401.06468v1	arXiv:2401.06468			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 11 2024	2024	Large language models (LLMs) have significantly advanced various natural language processing (NLP) tasks. Recent research indicates that moderately-sized LLMs often outperform larger ones after task-specific fine-tuning. This study focuses on adapting LLMs for document-level machine translation (DocMT) for specific language pairs. We first investigate the impact of prompt strategies on translation performance and then conduct extensive experiments using two fine-tuning methods, three LLM backbones, and 18 translation tasks across nine language pairs. Our results show that specialized models can sometimes surpass GPT-4 in translation performance but still face issues like off-target translation due to error propagation in decoding. We provide an in-depth analysis of these LLMs tailored for DocMT, examining translation errors, discourse phenomena, strategies for training and inference, the data efficiency of parallel documents, recent test set evaluations, and zero-shot crosslingual transfer. Our findings highlight the strengths and limitations of LLM-based DocMT models and provide a foundation for future research.																																	2024-11-06	PPRN:87157216		
J	Chiu, Yu Ying; Jiang, Liwei; Lin, Bill Yuchen; Park, Chan Young; Li, Shuyue Stella; Ravi, Sahithya; Bhatia, Mehar; Antoniak, Maria; Tsvetkov, Yulia; Shwartz, Vered; Choi, Yejin				Park, Chan Young/GPG-0558-2022; Jiang, Alicia/X-3945-2019						CulturalBench: a Robust, Diverse and Challenging Benchmark on Measuring the (Lack of) Cultural Knowledge of LLMs								Arxiv											1	1;2024-10-03;https://www.arxiv.org/abs/2410.02677v1	arXiv:2410.02677			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 03 2024	2024	To make large language models (LLMs) more helpful across diverse cultures, it is essential to have effective cultural knowledge benchmarks to measure and track our progress. Effective benchmarks need to be robust, diverse, and challenging. We introduce CulturalBench: a set of 1,227 human-written and human-verified questions for effectively assessing LLMs' cultural knowledge, covering 45 global regions including the underrepresented ones like Bangladesh, Zimbabwe, and Peru. Questions - each verified by five independent annotators - span 17 diverse topics ranging from food preferences to greeting etiquettes. We evaluate models on two setups: CulturalBench-Easy and CulturalBench-Hard which share the same questions but asked differently. We find that LLMs are sensitive to such difference in setups (e.g., GPT-4o with 27.3% difference). Compared to human performance (92.6% accuracy), CulturalBench-Hard is more challenging for frontier LLMs with the best performing model (GPT-4o) at only 61.5% and the worst (Llama3-8b) at 21.4%. Moreover, we find that LLMs often struggle with tricky questions that have multiple correct answers (e.g., What utensils do the Chinese usually use?), revealing a tendency to converge to a single answer. Our results also indicate that OpenAI GPT-4o substantially outperform other proprietary and open source models in questions related to all but one region (Oceania). Nonetheless, all models consistently underperform on questions related to South America and the Middle East.																																	2024-10-21	PPRN:102575718		
J	Martin, Nicolas F.; Starkenburg, Else; Yuan, Zhen; Fouesneau, Morgan; Ardern-Arentsen, Anke; Angeli, Francesca De; Gran, Felipe; Montelius, Martin; Rusterucci, Samuel; Andrae, Rene; Bellazzini, Michele; Montegriffo, Paolo; Esselink, Anna F.; Zhang, Hanyuan; Venn, Kim A.; Viswanathan, Akshara; Aguado, David S.; Battaglia, Giuseppina; Bayer, Manuel; Bonifacio, Piercarlo; Caffau, Elisabetta; Cote, Patrick; Carlberg, Raymond; Fabbro, Sebastien; Alvar, Emma Fernandez; Gonzalez Hernandez, Jonay I.; Vernhe, Isaure Gonzalez Rivera de La; Hill, Vanessa; Ibata, Rodrigo A.; Jablonka, Pascale; Kordopatis, Georges; Lardo, Carmela; Mcconnachie, Alan W.; Navarrete, Camila; Navarro, Julio; Recio-Blanco, Alejandra; Janssen, Ruben Sanchez; Sestito, Federico; Thomas, Guillaume F.; Vitali, Sara; Youakim, Kristopher				Hill, Vanessa/HRA-5121-2023; Navarrete, Camila/LJK-7033-2024; Fernández-Alvar, Emma/AAW-8358-2021; Martin, Nicolas/N-9557-2014; Sanchez-Janssen, Ruben/LTE-2549-2024; Carlberg, Raymond/I-6947-2012; Aguado, David/L-9186-2013						The Pristine survey -- XXIII. Data Release 1 and an all-sky metallicity catalogue based on Gaia DR3 BP/RP spectro-photometry								Arxiv											2	2;2024-10-01;https://www.arxiv.org/abs/2308.01344v2| 1;2023-08-02;https://www.arxiv.org/abs/2308.01344v1	arXiv:2308.01344			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 01 2024	2024	We used the spectro-photometric information of ∼ 219 million stars from Gaia ’s Data Release 3 (DR3) to calculate synthetic, narrowband, metallicity-sensitive CaHK magnitudes that mimic the observations of the Pristine survey, a survey of photometric metallicities of Milky Way stars that has been mapping more than 6,500 deg 2 of the northern sky with the Canada-France-Hawaii Telescope since 2015. These synthetic magnitudes were used for an absolute recalibration of the deeper Pristine photometry and, combined with broadband Gaia information, synthetic and Pristine CaHK magnitudes were used to estimate photometric metallicities over the whole sky. The resulting metallicity catalogue is accurate down to [Fe / H] ∼ − 3 . 5 and is particularly suited for the exploration of the metalpoor Milky Way ([Fe / H] < − 1 . 0). We make available here the catalogue of synthetic CaHK syn magnitudes for all stars with BP / RP information in Gaia DR3, as well as an associated catalogue of more than ∼ 30 million photometric metallicities for high signalto-noise FGK stars. This paper further provides the first public data release of the Pristine catalogue in the form of higher quality recalibrated Pristine CaHK magnitudes and photometric metallicities for all stars in common with the BP / RP spectro-photometric information in Gaia DR3. We demonstrate that, when available, the much deeper Pristine data greatly enhance the quality of the derived metallicities, in particular at the faint end of the catalogue ( G BP ≳ 16). Combined, both photometric metallicity catalogues include more than two million metal-poor star candidates ([Fe / H] phot < − 1 . 0) as well as more than 200,000 and ∼ 8,000 very and extremely metal-poor candidates ([Fe / H] phot < − 2 . 0 and < − 3 . 0, respectively). Finally, we show that these metallicity catalogues can be used e ffi ciently, among other applications, for Galactic archaeology, to hunt for the most metal-poor stars, and to study how the structure of the Milky Way varies with metallicity, from the flat distribution of disk stars to the spheroid-shaped metal-poor halo.																																	2025-04-19	PPRN:74243796		
J	Zhang, Tao; Li, Xiangtai; Fei, Hao; Yuan, Haobo; Wu, Shengqiong; Ji, Shunping; Loy, Chen Change; Yan, Shuicheng				yan, shuicheng/HCH-9860-2022; Yuan, Haobo/JNF-0317-2023; Fei, Hao/IZD-5292-2023						OMG-LLaVA: Bridging Image-level, Object-level, Pixel-level Reasoning and Understanding								Arxiv											2	2;2024-10-01;https://www.arxiv.org/abs/2406.19389v2| 1;2024-06-27;https://www.arxiv.org/abs/2406.19389v1	arXiv:2406.19389			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 01 2024	2024	Current universal segmentation methods demonstrate strong capabilities in pixel-level image and video understanding. However, they lack reasoning abilities and cannot be controlled via text instructions. In contrast, large vision-language multimodal models exhibit powerful vision-based conversation and reasoning capabilities but lack pixel-level understanding and have difficulty accepting visual prompts for flexible user interaction. This paper proposes OMG-LLaVA, a new and elegant framework combining powerful pixel-level vision understanding with reasoning abilities. It can accept various visual and text prompts for flexible user interaction. Specifically, we use a universal segmentation method as the visual encoder, integrating image information, perception priors, and visual prompts into visual tokens provided to the LLM. The LLM is responsible for understanding the user's text instructions and providing text responses and pixel-level segmentation results based on the visual information. We propose perception prior embedding to better integrate perception priors with image features. OMG-LLaVA achieves image-level, object-level, and pixel-level reasoning and understanding in a single model, matching or surpassing the performance of specialized methods on multiple benchmarks. Rather than using LLM to connect each specialist, our work aims at end-to-end training on one encoder, one decoder, and one LLM. The code and model have been released for further research.																																	2024-10-12	PPRN:90150467		
J	Arkani-Hamed, Nima; Frost, Hadleigh; Salvatori, Giulio; Plamondon, Pierre-Guy; Thomas, Hugh										All Loop Scattering For All Multiplicity								Arxiv											2	2;2024-09-27;https://www.arxiv.org/abs/2311.09284v2| 1;2023-11-15;https://www.arxiv.org/abs/2311.09284v1	arXiv:2311.09284			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 27 2024	2024	This is part of a series of papers describing the new curve integral formalism for scattering amplitudes of the colored scalar trϕ3 theory. We show that the curve integral manifests a very surprising fact about these amplitudes: the dependence on the number of particles, n, and the loop order, L, is effectively decoupled. We derive the curve integrals at tree-level for all n. We then show that, for higher loop-order, it suffices to study the curve integrals for L-loop tadpole-like amplitudes, which have just one particle per color trace-factor. By combining these tadpole-like formulas with the the tree-level result, we find formulas for the all n amplitudes at L loops. We illustrate this result by giving explicit curve integrals for all the amplitudes in the theory, including the non-planar amplitudes, through to two loops, for all n.																																	2025-01-08	PPRN:86177901		
J	Lu, Zimu; Zhou, Aojun; Ren, Houxing; Wang, Ke; Shi, Weikang; Pan, Junting; Zhan, Mingjie; Li, Hongsheng				Li, Hongsheng/AES-5328-2022; Shi, WeiKang/LIG-8896-2024; Zhan, Mingjie/MGW-5518-2025						MathGenie: Generating Synthetic Data with Question Back-translation for Enhancing Mathematical Reasoning of LLMs								Arxiv											2	2;2024-09-11;https://www.arxiv.org/abs/2402.16352v2| 1;2024-02-26;https://www.arxiv.org/abs/2402.16352v1	arXiv:2402.16352			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 11 2024	2024	Large language models (LLMs) have exhibited great potential in mathematical reasoning. However, there remains a performance gap in this area between existing open-source models and closed-source models such as GPT-4. In this paper, we introduce MathGenie, a novel method for generating diverse and reliable math problems from a small-scale problem-solution dataset (denoted as seed data). We augment the ground-truth solutions of our seed data and train a back-translation model to translate the augmented solutions back into new questions. Subsequently, we generate code-integrated solutions for the new questions. To ensure the correctness of the code-integrated solutions, we employ rationale-based strategy for solution verification. Various pretrained models, ranging from 7B to 70B, are trained on the newly curated data to test the effectiveness of the proposed augmentation technique, resulting in a family of models known as MathGenieLM. These models consistently outperform previous open-source models across five representative mathematical reasoning datasets, achieving state-of-the-art performance. In particular, MathGenieLM-InternLM2 achieves an accuracy of 87.7% on GSM8K and 55.7% on MATH, securing the best overall score among open-source language models.																																	2024-09-26	PPRN:87890747		
J	Wang, Hao; Peng, Ze-Yu; Piao, Yun-Song										Can recent DESI BAO measurements accommodate a negative cosmological constant?								Arxiv											2	2;2024-09-11;https://www.arxiv.org/abs/2406.03395v2| 1;2024-06-05;https://www.arxiv.org/abs/2406.03395v1	arXiv:2406.03395			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 11 2024	2024	Anti-de Sitter vacuum, which correspond to a negative cosmological constant (CC), is theoretically important and well-motivated. However, whether it exists in reality or not has always been a controversial issue. In this paper, we perform the search for the negative CC using recent Dark Energy Spectroscopic Instrument (DESI) baryon acoustic oscillation measurements combined with Planck cosmic microwave background and Pantheon Plus supernova data. Though we did not find the evidence for negative CC, we observed the indication for it, the negative CC is preferred at > 68% significance level, while such a negative CC can make the state equation of evolving dark energy component (coexisting with negative CC) w ⩾ −1. Our work highlights the potential of upcoming cosmological surveys to search for the negative CC.																																	2024-09-27	PPRN:89258450		
J	Munoz, Julian B.; Mirocha, Jordan; Chisholm, John; Furlanetto, Steven R.; Mason, Charlotte				Mason, Charlotte/IYJ-2820-2023						Reionization after JWST: a photon budget crisis?								Arxiv											2	2;2024-09-05;https://www.arxiv.org/abs/2404.07250v2| 1;2024-04-10;https://www.arxiv.org/abs/2404.07250v1	arXiv:2404.07250			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 05 2024	2024	New James Webb Space Telescope (JWST) observations are revealing the first galaxies to be prolific producers of ionizing photons, which we argue gives rise to a tension between different probes of reionization. Over the last two decades a consensus has emerged where star-forming galaxies are able to generate enough photons to drive reionization, given reasonable values for their number densities, ionizing efficiencies ξion (per unit UV luminosity), and escape fractions fesc . However, some new JWST observations infer high values of ξion during reionization and an enhanced abundance of earlier (z≳ 9) galaxies, dramatically increasing the number of ionizing photons produced at high z . Simultaneously, recent low-z  studies predict significant escape fractions for faint reionization-era galaxies. Put together, we show that the galaxies we have directly observed (MUV < − 15) not only can drive reionization, but would end it too early. That is, our current galaxy observations, taken at face value, imply an excess of ionizing photons and thus a process of reionization in tension with the cosmic microwave background (CMB) and Lyman-a a forest. Considering galaxies down to MUV ≈ − 11, below current observational limits, only worsens this tension. We discuss possible avenues to resolve this photon budget crisis, including systematics in either theory or observations.																																	2024-09-16	PPRN:88501349		
J	Chen, Liguo; Guo, Qi; Jia, Hongrui; Zeng, Zhengran; Wang, Xin; Xu, Yijiang; Wu, Jian; Wang, Yidong; Gao, Qing; Wang, Jindong; Ye, Wei; Zhang, Shikun				Zhang, Shikun/ITU-3545-2023; wang, jindong/ACD-8485-2022; liguo, chen/MGB-3914-2025						A Survey on Evaluating Large Language Models in Code Generation Tasks								Arxiv											1	1;2024-08-29;https://www.arxiv.org/abs/2408.16498v1	arXiv:2408.16498			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 29 2024	2024	This paper provides a comprehensive review of the current methods and metrics used to evaluate the performance of Large Language Models (LLMs) in code generation tasks. With the rapid growth in demand for automated software development, LLMs have demonstrated significant potential in the field of code generation. The paper begins by reviewing the historical development of LLMs and their applications in code generation. Next, it details various methods and metrics for assessing the code generation capabilities of LLMs, including code correctness, efficiency, readability, and evaluation methods based on expert review and user experience. The paper also evaluates the widely used benchmark datasets, identifying their limitations and proposing directions for future improvements. Specifically, the paper analyzes the performance of code generation models across different tasks by combining multiple evaluation metrics, such as code compilation/interpretation success rates, unit test pass rates, and performance and efficiency metrics, to comprehensively assess the practical application of LLMs in code generation. Finally, the paper discusses the challenges faced in evaluating LLMs in code generation, particularly how to ensure the comprehensiveness and accuracy of evaluation methods and how to adapt to the evolving practices of software development. These analyses and discussions provide valuable insights for further optimizing and improving the application of LLMs in code generation tasks.																																	2024-09-23	PPRN:91782539		
J	Griffin; Botev, Aleksandar; De, Soham; Smith, Samuel L; Fernando, Anushan; Muraru, George-Cristian; Haroun, Ruba; Berrada, Leonard; Pascanu, Razvan; Sessa, Pier Giuseppe; Dadashi, Robert; Hussenot, Leonard; Ferret, Johan; Girgin, Sertan; Bachem, Olivier; Andreev, Alek; Kenealy, Kathleen; Mesnard, Thomas; Hardin, Cassidy; Bhupatiraju, Surya; Pathak, Shreya; Sifre, Laurent; Riviere, Morgane; Kale, Mihir Sanjay; Love, Juliette; Tafti, Pouya; Joulin, Armand; Fiedel, Noah; Senter, Evan; Chen, Yutian; Srinivasan, Srivatsan; Desjardins, Guillaume; Budden, David; Doucet, Arnaud; Vikram, Sharad; Paszke, Adam; Gale, Trevor; Borgeaud, Sebastian; Chen, Charlie; Brock, Andy; Paterson, Antonia; Brennan, Jenny; Risdal, Meg; Gundluru, Raj; Devanathan, Nesh; Mooney, Paul; Chauhan, Nilay; Culliton, Phil; Martins, Luiz Gustavo; Bandy, Elisa; Huntsperger, David; Cameron, Glenn; Zucker, Arthur; Warkentin, Tris; Peran, Ludovic; Giang, Minh; Ghahramani, Zoubin; Farabet, Clement; Kavukcuoglu, Koray; Hassabis, Demis; Hadsell, Raia; Teh, Yee Whye; de Frietas, Nando		RLHF; Gemma Teams		Desjardins, Guillaume/AFM-0561-2022; Teh, Yee/C-3400-2008						RecurrentGemma: Moving Past Transformers for Efficient Open Language Models								Arxiv											2	2;2024-08-28;https://www.arxiv.org/abs/2404.07839v2| 1;2024-04-11;https://www.arxiv.org/abs/2404.07839v1	arXiv:2404.07839			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 28 2024	2024	We introduce RecurrentGemma, a family of open language models which uses Google's novel Griffin architecture. Griffin combines linear recurrences with local attention to achieve excellent performance on language. It has a fixed-sized state, which reduces memory use and enables efficient inference on long sequences. We provide two sizes of models, containing 2B and 9B parameters, and provide pre-trained and instruction tuned variants for both. Our models achieve comparable performance to similarly-sized Gemma baselines despite being trained on fewer tokens.																																	2024-09-06	PPRN:88500319		
J	Zhang, Jielu; Zhou, Zhongliang; Mai, Gengchen; Hu, Mengxuan; Guan, Zihan; Li, Sheng; Mu, Lan				Mai, Gengchen/ABF-8620-2020; Zhou, Zhongliang/IEY-6519-2023						Text2Seg: Remote Sensing Image Semantic Segmentation via Text-Guided Visual Foundation Models								Arxiv											2	2;2024-08-25;https://www.arxiv.org/abs/2304.10597v2| 1;2023-04-20;https://www.arxiv.org/abs/2304.10597v1	arXiv:2304.10597			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 25 2024	2024	Remote sensing imagery has attracted significant attention in recent years due to its instrumental role in global environmental monitoring, land usage monitoring, and more. As image databases grow each year, performing automatic segmentation with deep learning models has gradually become the standard approach for processing the data. Despite the improved performance of current models, certain limitations remain unresolved. Firstly, training deep learning models for segmentation requires per-pixel annotations. Given the large size of datasets, only a small portion is fully annotated and ready for training. Additionally, the high intra-dataset variance in remote sensing data limits the transfer learning ability of such models. Although recently proposed generic segmentation models like SAM have shown promising results in zero-shot instance-level segmentation, adapting them to semantic segmentation is a non-trivial task. To tackle these challenges, we propose a novel method named Text2Seg for remote sensing semantic segmentation. Text2Seg overcomes the dependency on extensive annotations by employing an automatic prompt generation process using different visual foundation models (VFMs), which are trained to understand semantic information in various ways. This approach not only reduces the need for fully annotated datasets but also enhances the model's ability to generalize across diverse datasets. Evaluations on four widely adopted remote sensing datasets demonstrate that Text2Seg significantly improves zero-shot prediction performance compared to the vanilla SAM model, with relative improvements ranging from 31% to 225%. 																																	2024-09-06	PPRN:65041021		
J	Huang, Jie; Ping, Wei; Xu, Peng; Shoeybi, Mohammad; Chang, Kevin Chen-Chuan; Catanzaro, Bryan				Chang, Kevin/ITR-8409-2023						RAVEN: In-Context Learning with Retrieval-Augmented Encoder-Decoder Language Models								Arxiv											3	3;2024-08-19;https://www.arxiv.org/abs/2308.07922v3| 2;2024-04-01;https://www.arxiv.org/abs/2308.07922v2| 1;2023-08-15;https://www.arxiv.org/abs/2308.07922v1	arXiv:2308.07922			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 19 2024	2024	In this paper, we investigate the in-context learning ability of retrieval-augmented encoder-decoder language models. We first conduct a comprehensive analysis of existing models and identify their limitations in in-context learning, primarily due to a mismatch between pretraining and inference, as well as a restricted context length. To address these issues, we propose RAVEN, a model that combines retrieval-augmented masked language modeling and prefix language modeling. We further introduce Fusion-in-Context Learning to enhance the few-shot performance by enabling the model to leverage more in-context examples without requiring additional training. Through extensive experiments, we demonstrate that our simple yet effective design significantly improves performance, achieving results comparable to the most advanced language models in certain scenarios, despite having substantially fewer parameters. Our work underscores the potential of retrieval-augmented encoder-decoder language models for in-context learning and encourages further research in this direction.																																	2024-08-30	PPRN:77962738		
J	Xiong, Xinyu; Wu, Zihuang; Tan, Shuangyi; Li, Wenxue; Tang, Feilong; Chen, Ying; Li, Siying; Ma, Jie; Li, Guanbin				Xiong, Xinyu/JJE-7134-2023; Li, Wenxue/HOC-1720-2023; Tang, Feilong/LPR-1018-2024						SAM2-UNet: Segment Anything 2 Makes Strong Encoder for Natural and Medical Image Segmentation								Arxiv											1	1;2024-08-16;https://www.arxiv.org/abs/2408.08870v1	arXiv:2408.08870			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 16 2024	2024	Image segmentation plays an important role in vision understanding. Recently, the emerging vision foundation models continuously achieved superior performance on various tasks. Following such success, in this paper, we prove that the Segment Anything Model 2 (SAM2) can be a strong encoder for U-shaped segmentation models. We propose a simple but effective framework, termed SAM2-UNet, for versatile image segmentation. Specifically, SAM2-UNet adopts the Hiera backbone of SAM2 as the encoder, while the decoder uses the classic U-shaped design. Additionally, adapters are inserted into the encoder to allow parameter-efficient fine-tuning. Preliminary experiments on various downstream tasks, such as camouflaged object detection, salient object detection, marine animal segmentation, mirror detection, and polyp segmentation, demonstrate that our SAM2-UNet can simply beat existing specialized state-of-the-art methods without bells and whistles. 																																	2024-08-25	PPRN:91462387		
J	Christophe, Clement; Kanithi, Praveen K; Raha, Tathagata; Khan, Shadab; Pimentel, Marco A.F.										Med42-v2: A Suite of Clinical LLMs								Arxiv											1	1;2024-08-12;https://www.arxiv.org/abs/2408.06142v1	arXiv:2408.06142			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 12 2024	2024	Med42-v2 introduces a suite of clinical large language models (LLMs) designed to address the limitations of generic models in healthcare settings. These models are built on Llama3 architecture and fine-tuned using specialized clinical data. They underwent multi-stage preference alignment to effectively respond to natural prompts. While generic models are often preference-aligned to avoid answering clinical queries as a precaution, Med42-v2 is specifically trained to overcome this limitation, enabling its use in clinical settings. Med42-v2 models demonstrate superior performance compared to the original Llama3 models in both 8B and 70B parameter configurations and GPT-4 across various medical benchmarks. These LLMs are developed to understand clinical queries, perform reasoning tasks, and provide valuable assistance in clinical environments. 																																	2024-08-21	PPRN:91348287		
J	Bharadhwaj, Homanga; Mottaghi, Roozbeh; Gupta, Abhinav; Tulsiani, Shubham				Bharadhwaj, Homanga/LQK-7079-2024						Track2Act: Predicting Point Tracks from Internet Videos enables Generalizable Robot Manipulation								Arxiv											2	2;2024-08-08;https://www.arxiv.org/abs/2405.01527v2| 1;2024-05-02;https://www.arxiv.org/abs/2405.01527v1	arXiv:2405.01527			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 08 2024	2024	We seek to learn a generalizable goal-conditioned policy that enables zero-shot robot manipulation: interacting with unseen objects in novel scenes without test-time adaptation. While typical approaches rely on a large amount of demonstration data for such generalization, we propose an approach that leverages web videos to predict plausible interaction plans and learns a task-agnostic transformation to obtain robot actions in the real world. Our framework,Track2Act predicts tracks of how points in an image should move in future time-steps based on a goal, and can be trained with diverse videos on the web including those of humans and robots manipulating everyday objects. We use these 2D track predictions to infer a sequence of rigid transforms of the object to be manipulated, and obtain robot end-effector poses that can be executed in an open-loop manner. We then refine this open-loop plan by predicting residual actions through a closed loop policy trained with a few embodiment-specific demonstrations. We show that this approach of combining scalably learned track prediction with a residual policy requiring minimal in-domain robot-specific data enables diverse generalizable robot manipulation, and present a wide array of real-world robot manipulation results across unseen tasks, objects, and scenes.																																	2024-08-21	PPRN:88726004		
J	Ma, Ziyang; Song, Yakun; Du, Chenpeng; Cong, Jian; Chen, Zhuo; Wang, Yuping; Wang, Yuxuan; Chen, Xie				song, yakun/IUO-2479-2023; Du, Chenpeng/LVS-2383-2024						Language Model Can Listen While Speaking								Arxiv											1	1;2024-08-05;https://www.arxiv.org/abs/2408.02622v1	arXiv:2408.02622			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 05 2024	2024	Dialogue serves as the most natural manner of human-computer interaction (HCI). Recent advancements in speech language models (SLM) have significantly enhanced speech-based conversational AI. However, these models are limited to turn-based conversation, lacking the ability to interact with humans in real-time spoken scenarios, for example, being interrupted when the generated content is not satisfactory. To address these limitations, we explore full duplex modeling (FDM) in interactive speech language models (iSLM), focusing on enhancing real-time interaction and, more explicitly, exploring the quintessential ability of interruption. We introduce a novel model design, namely listening-while-speaking language model (LSLM), an end-to-end system equipped with both listening and speaking channels. Our LSLM employs a token-based decoder-only TTS for speech generation and a streaming self-supervised learning (SSL) encoder for real-time audio input. LSLM fuses both channels for autoregressive generation and detects turn-taking in real time. Three fusion strategies -- early fusion, middle fusion, and late fusion -- are explored, with middle fusion achieving an optimal balance between speech generation and real-time interaction. Two experimental settings, command-based FDM and voice-based FDM, demonstrate LSLM's robustness to noise and sensitivity to diverse instructions. Our results highlight LSLM's capability to achieve duplex communication with minimal impact on existing systems. This study aims to advance the development of interactive speech dialogue systems, enhancing their applicability in real-world contexts.																																	2024-08-09	PPRN:91246157		
J	Serfaty, Sylvia										Lectures on Coulomb and Riesz gases								Arxiv											1	1;2024-07-30;https://www.arxiv.org/abs/2407.21194v1	arXiv:2407.21194			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 30 2024	2024	This is the preliminary version of a book on Coulomb and Riesz gases that grew out of a set of notes written for graduate courses taught at the Courant Institute, at the Ecole Normale Supérieure, and at the 2024 Saint-Flour Probability summer school.																																	2024-12-06	PPRN:91177881		
J	Malach, Eran										Auto-Regressive Next-Token Predictors are Universal Learners								Arxiv											3	3;2024-07-29;https://www.arxiv.org/abs/2309.06979v3| 2;2024-07-17;https://www.arxiv.org/abs/2309.06979v2| 1;2023-09-13;https://www.arxiv.org/abs/2309.06979v1	arXiv:2309.06979			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 29 2024	2024	Large language models display remarkable capabilities in logical and mathematical reasoning, allowing them to solve complex tasks. Interestingly, these abilities emerge in networks trained on the simple task of next-token prediction. In this work, we present a theoretical framework for studying auto-regressive next-token predictors. We demonstrate that even simple models such as linear next-token predictors, trained on Chain-of-Thought (CoT) data, can approximate any function efficiently computed by a Turing machine. We introduce a new complexity measure -- length complexity -- which measures the number of intermediate tokens in a CoT sequence required to approximate some target function, and analyze the interplay between length complexity and other notions of complexity. Finally, we show experimentally that simple next-token predictors, such as linear networks and shallow Multi-Layer Perceptrons (MLPs), display non-trivial performance on text generation and arithmetic tasks. Our results demonstrate that the power of today's LLMs can be attributed, to a great extent, to the auto-regressive next-token training scheme, and not necessarily to a particular choice of architecture.																																	2024-08-06	PPRN:84998925		
J	Wang, Yanlin; Wang, Yanli; Guo, Daya; Chen, Jiachi; Zhang, Ruikai; Ma, Yuchi; Zheng, Zibin				Zhang, Ruikai/W-9848-2019; Guo, Daya/HPG-8192-2023; Chen, Jiachi/HOC-4256-2023; Ma, Yuchi/C-8792-2018						RLCoder: Reinforcement Learning for Repository-Level Code Completion								Arxiv											1	1;2024-07-28;https://www.arxiv.org/abs/2407.19487v1	arXiv:2407.19487			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 28 2024	2024	Repository-level code completion aims to generate code for unfinished code snippets within the context of a specified repository. Existing approaches mainly rely on retrieval-augmented generation strategies due to limitations in input sequence length. However, traditional lexical-based retrieval methods like BM25 struggle to capture code semantics, while model-based retrieval methods face challenges due to the lack of labeled data for training. Therefore, we propose RLCoder, a novel reinforcement learning framework, which can enable the retriever to learn to retrieve useful content for code completion without the need for labeled data. Specifically, we iteratively evaluate the usefulness of retrieved content based on the perplexity of the target code when provided with the retrieved content as additional context, and provide feedback to update the retriever parameters. This iterative process enables the retriever to learn from its successes and failures, gradually improving its ability to retrieve relevant and high-quality content. Considering that not all situations require information beyond code files and not all retrieved context is helpful for generation, we also introduce a stop signal mechanism, allowing the retriever to decide when to retrieve and which candidates to retain autonomously. Extensive experimental results demonstrate that RLCoder consistently outperforms state-of-the-art methods on CrossCodeEval and RepoEval, achieving 12.2% EM improvement over previous methods. Moreover, experiments show that our framework can generalize across different programming languages and further improve previous methods like RepoCoder. 																																	2024-08-06	PPRN:91156810		
J	Yuan, Zhuowen; Xiong, Zidi; Zeng, Yi; Yu, Ning; Jia, Ruoxi; Song, Dawn; Li, Bo				Yuan, Zhuowen/JHT-5579-2023; Xiong, Zidi/KBB-8747-2024						RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content								Arxiv											2	2;2024-07-23;https://www.arxiv.org/abs/2403.13031v2| 1;2024-03-19;https://www.arxiv.org/abs/2403.13031v1	arXiv:2403.13031			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 23 2024	2024	Recent advancements in Large Language Models (LLMs) have showcased remarkable capabilities across various tasks in different domains. However, the emergence of biases and the potential for generating harmful content in LLMs, particularly under malicious inputs, pose significant challenges. Current mitigation strategies, while effective, are not resilient under adversarial attacks. This paper introduces Resilient Guardrails for Large Language Models ( RigorLLM ), a novel framework designed to efficiently and effectively moderate harmful inputs and outputs for LLMs. By employing a multifaceted approach that includes energy-based training data generation through Langevin dynamics, optimizing a safe suffix for inputs via minimax optimization, and integrating a fusion-based model combining robust KNN with LLMs based on our prompt augmentation, RigorLLM offers a robust solution to harmful content moderation. Our experimental evaluations demonstrate that RigorLLM not only outperforms existing baselines like OpenAI API and Perspective API in detecting harmful content but also exhibits unparalleled resilience to jailbreaking attacks. The innovative use of constrained optimization and a fusionbased guardrail approach represents a significant step forward in developing more secure and reliable LLMs, setting a new standard for content moderation frameworks in the face of evolving digital threats. 																																	2024-07-31	PPRN:88221007		
J	Tang, Hanlin; Lin, Yang; Lin, Jing; Han, Qingsen; Hong, Shikuan; Yao, Yiwu; Wang, Gongyi				Han, Qingsen/V-9909-2018; yao, yw/OTH-7724-2025						RazorAttention: Efficient KV Cache Compression Through Retrieval Heads								Arxiv											1	1;2024-07-22;https://www.arxiv.org/abs/2407.15891v1	arXiv:2407.15891			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 22 2024	2024	The memory and computational demands of Key-Value (KV) cache present significant challenges for deploying long-context language models. Previous approaches attempt to mitigate this issue by selectively dropping tokens, which irreversibly erases critical information that might be needed for future queries. In this paper, we propose a novel compression technique for KV cache that preserves all token information. Our investigation reveals that: i) Most attention heads primarily focus on the local context; ii) Only a few heads, denoted as retrieval heads, can essentially pay attention to all input tokens. These key observations motivate us to use separate caching strategy for attention heads. Therefore, we propose RazorAttention, a training-free KV cache compression algorithm, which maintains a full cache for these crucial retrieval heads and discards the remote tokens in non-retrieval heads. Furthermore, we introduce a novel mechanism involving a "compensation token" to further recover the information in the dropped tokens. Extensive evaluations across a diverse set of large language models (LLMs) demonstrate that RazorAttention achieves a reduction in KV cache size by over 70% without noticeable impacts on performance. Additionally, RazorAttention is compatible with FlashAttention, rendering it an efficient and plug-and-play solution that enhances LLM inference efficiency without overhead or retraining of the original model.																																	2024-07-30	PPRN:91044147		
J	Jiralerspong, Thomas; Chen, Xiaoyin; More, Yash; Shah, Vedant; Bengio, Yoshua				Chen, Xiaoyin/GFA-4264-2022						Efficient Causal Graph Discovery Using Large Language Models								Arxiv											3	3;2024-07-20;https://www.arxiv.org/abs/2402.01207v4| 2;2024-02-13;https://www.arxiv.org/abs/2402.01207v3| 1;2024-02-05;https://www.arxiv.org/abs/2402.01207v2	arXiv:2402.01207			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 20 2024	2024	We propose a novel framework that leverages LLMs for full causal graph discovery. While previous LLM-based methods have used a pairwise query approach, this requires a quadratic number of queries which quickly becomes impractical for larger causal graphs. In contrast, the proposed framework uses a breadth-first search (BFS) approach which allows it to use only a linear number of queries. We also show that the proposed method can easily incorporate observational data when available, to improve performance. In addition to being more time and data-efficient, the proposed framework achieves state-of-the-art results on real-world causal graphs of varying sizes. The results demonstrate the effectiveness and efficiency of the proposed method in discovering causal relationships, showcasing its potential for broad applicability in causal graph discovery tasks across different domains.																																	2024-07-28	PPRN:87521436		
J	Liu, Yixin; Shi, Kejian; He, Katherine S; Ye, Longtian; Fabbri, Alexander R.; Liu, Pengfei; Radev, Dragomir; Cohan, Arman				Radev, Dragomir/E-9641-2012; Liu, Pengfei/JUV-0307-2023; Liu, Yixin/ABC-7725-2021						On Learning to Summarize with Large Language Models as References								Arxiv											3	3;2024-07-18;https://www.arxiv.org/abs/2305.14239v3| 2;2023-11-16;https://www.arxiv.org/abs/2305.14239v2| 1;2023-05-23;https://www.arxiv.org/abs/2305.14239v1	arXiv:2305.14239			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 18 2024	2024	Recent studies have found that summaries generated by large language models (LLMs) are favored by human annotators over the original reference summaries in commonly used summarization datasets. Therefore, we study an LLM-as-reference learning setting for smaller text summarization models to investigate whether their performance can be substantially improved. To this end, we use LLMs as both oracle summary generators for standard supervised fine-tuning and oracle summary evaluators for efficient contrastive learning that leverages the LLMs' supervision signals. We conduct comprehensive experiments with source news articles and find that (1) summarization models trained under the LLM-as-reference setting achieve significant performance improvement in both LLM and human evaluations; (2) contrastive learning outperforms standard supervised fine-tuning under both low and high resource settings. Our experimental results also enable a meta-analysis of LLMs' summary evaluation capacities under a challenging setting, showing that LLMs are not well-aligned with human evaluators. Particularly, our expert human evaluation reveals remaining nuanced performance gaps between LLMs and our fine-tuned models, which LLMs fail to capture. Thus, we call for further studies into both the potential and challenges of using LLMs in summarization model development.																																	2024-07-26	PPRN:71601633		
J	Tsoukalas, George; Lee, Jasper; Jennings, John; Xin, Jimmy; Ding, Michelle; Jennings, Michael; Thakur, Amitayush; Chaudhuri, Swarat										PutnamBench: Evaluating Neural Theorem-Provers on the Putnam Mathematical Competition								Arxiv											1	1;2024-07-15;https://www.arxiv.org/abs/2407.11214v1	arXiv:2407.11214			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 15 2024	2024	We present PutnamBench, a new multilingual benchmark for evaluating the ability of neural theorem-provers to solve competition mathematics problems. PutnamBench consists of 1697 hand-constructed formalizations of 640 theorems sourced from the William Lowell Putnam Mathematical Competition, the premier undergraduate-level mathematics competition in North America. All the theorems have formalizations in Lean 4 and Isabelle; a substantial subset also has Coq formalizations. Proving the theorems requires significant problem-solving ability and proficiency in a broad range of topics taught in undergraduate mathematics courses. We use PutnamBench to evaluate several established neural and symbolic theorem-provers. These approaches can only solve a handful of the PutnamBench problems, establishing the benchmark as a difficult open challenge for research on neural theorem-proving. 																																	2024-07-25	PPRN:90851487		
J	Chen, Weize; You, Ziming; Li, Ran; Guan, Yitong; Qian, Chen; Zhao, Chenyang; Yang, Cheng; Xie, Ruobing; Liu, Zhiyuan; Sun, Maosong				Liu, Zhiyuan/I-2233-2014						Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence								Arxiv											1	1;2024-07-10;https://www.arxiv.org/abs/2407.07061v2	arXiv:2407.07061			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 10 2024	2024	The rapid advancement of large language models (LLMs) has paved the way for the development of highly capable autonomous agents. However, existing multi-agent frameworks often struggle with integrating diverse capable third-party agents due to reliance on agents defined within their own ecosystems. They also face challenges in simulating distributed environments, as most frameworks are limited to single-device setups. Furthermore, these frameworks often rely on hard-coded communication pipelines, limiting their adaptability to dynamic task requirements. Inspired by the concept of the Internet, we propose the Internet of Agents (IoA), a novel framework that addresses these limitations by providing a flexible and scalable platform for LLM-based multi-agent collaboration. IoA introduces an agent integration protocol, an instant-messaging-like architecture design, and dynamic mechanisms for agent teaming and conversation flow control. Through extensive experiments on general assistant tasks, embodied AI tasks, and retrieval-augmented generation benchmarks, we demonstrate that IoA consistently outperforms state-of-the-art baselines, showcasing its ability to facilitate effective collaboration among heterogeneous agents. IoA represents a step towards linking diverse agents in an Internet-like environment, where agents can seamlessly collaborate to achieve greater intelligence and capabilities. 																																	2024-07-21	PPRN:90760343		
J	Yao, Zijun; Qi, Weijian; Pan, Liangming; Cao, Shulin; Hu, Linmei; Liu, Weichuan; Hou, Lei; Li, Juanzi				Pan, Liangming/LIF-2753-2024						SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation								Arxiv											1	1;2024-06-27;https://www.arxiv.org/abs/2406.19215v1	arXiv:2406.19215			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 27 2024	2024	Adaptive Retrieval-Augmented Generation (RAG) is an effective strategy to alleviate hallucination of large language models (LLMs). It dynamically determines whether LLMs need external knowledge for generation and invokes retrieval accordingly. This paper introduces Self-aware Knowledge Retrieval (S EA KR), a novel adaptive RAG model that extracts self-aware uncertainty of LLMs from their internal states. S EA KR activates retrieval when the LLMs present high self-aware uncertainty for generation. To effectively integrate retrieved knowledge snippets, S EA KR re-ranks them based on LLM’s self-aware uncertainty to preserve the snippet that reduces their uncertainty to the utmost. To facilitate solving complex tasks that require multiple retrievals, S EA KR utilizes their self-aware uncertainty to choose among different reasoning strategies. Our experiments on both complex and simple Question Answering datasets show that S EA KR outperforms existing adaptive RAG methods. We release our code in our Github repository.																																	2024-07-17	PPRN:90141175		
J	Li, Linhao; Oshikawa, Masaki; Zheng, Yunqin				Oshikawa, Masaki/F-4992-2011						Decorated Defect Construction of Gapless-SPT States								Arxiv											2	2;2024-06-12;https://www.arxiv.org/abs/2204.03131v3| 1;2023-07-12;https://www.arxiv.org/abs/2204.03131v2	arXiv:2204.03131			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 12 2024	2024	Symmetry protected topological (SPT) phases are one of the simplest, yet nontrivial, gapped systems that go beyond the Landau paradigm. In this work, we study an extension of the notion of SPT for gapless systems, namely, gapless symmetry protected topological states. We construct several simple gapless-SPT models using the decorated defect construction, which allow analytical understanding of non-trivial topological features including the symmetry charge under twisted boundary conditions, and boundary (quasi)-degeneracy under open boundary conditions. We also comment on the stability of the gapless-SPT models under symmetric perturbations, and apply small-scale exact diagonalization when direct analytic understanding is not available.																																	2024-07-10	PPRN:73887510		
J	Chen, Yi; Ge, Yuying; Ge, Yixiao; Ding, Mingyu; Li, Bohao; Wang, Rui; Xu, Ruifeng; Shan, Ying; Liu, Xihui				Li, Bohao/KGL-4634-2024; Xu, Ruifeng/LWJ-4793-2024; Liu, Xihui/LHA-5141-2024						EgoPlan-Bench: Benchmarking Multimodal Large Language Models for Human-Level Planning								Arxiv											3	3;2024-06-11;https://www.arxiv.org/abs/2312.06722v3| 2;2024-04-17;https://www.arxiv.org/abs/2312.06722v2| 1;2023-12-11;https://www.arxiv.org/abs/2312.06722v1	arXiv:2312.06722			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 11 2024	2024	The pursuit of artificial general intelligence (AGI) has been accelerated by Multimodal Large Language Models (MLLMs), which exhibit superior reasoning, generalization capabilities, and proficiency in processing multimodal inputs. A crucial milestone in the evolution of AGI is the attainment of human-level planning, a fundamental ability for making informed decisions in complex environments, and solving a wide range of real-world problems. Despite the impressive advancements in MLLMs, a question remains: How far are current MLLMs from achieving human-level planning? To shed light on this question, we introduce EgoPlan-Bench, a comprehensive benchmark to evaluate the planning abilities of MLLMs in real-world scenarios from an egocentric perspective, mirroring human perception. EgoPlan-Bench emphasizes the evaluation of planning capabilities of MLLMs, featuring realistic tasks, diverse action plans, and intricate visual observations. Our rigorous evaluation of a wide range of MLLMs reveals that EgoPlan-Bench poses significant challenges, highlighting a substantial scope for improvement in MLLMs to achieve human-level task planning. To facilitate this advancement, we further present EgoPlan-IT, a specialized instruction-tuning dataset that effectively enhances model performance on EgoPlan-Bench. We have made all codes, data, and a maintained benchmark leaderboard available to advance future research.																																	2024-07-04	PPRN:86554547		
J	Zhang, Xiaoying; Peng, Baolin; Tian, Ye; Zhou, Jingyan; Jin, Lifeng; Song, Linfeng; Mi, Haitao; Meng, Helen				Peng, Baolin/F-2278-2019; Song, Linfeng/JOH-3221-2023						Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation								Arxiv											2	2;2024-06-11;https://www.arxiv.org/abs/2402.09267v2| 1;2024-02-14;https://www.arxiv.org/abs/2402.09267v1	arXiv:2402.09267			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 11 2024	2024	Despite showing impressive abilities, large language models (LLMs) often struggle with factual inaccuracies, i.e., “hallucinations”, even when they hold relevant knowledge. To mitigate these hallucinations, current approaches typically necessitate high-quality human factuality annotations. In this work, we explore Self-Alignment for Factuality , where we leverage the self-evaluation capability of an LLM to provide training signals that steer the model towards factuality. Specifically, we incorporate S ELF -E VAL , a self-evaluation component, to prompt an LLM to validate the factuality of its own generated responses solely based on its internal knowledge. Additionally, we design S ¯ elf- K ¯ nowledge Tuning (SK-T UNING ) to augment the LLM’s self-evaluation ability by improving the model’s confidence estimation and calibration. We then utilize these self-annotated responses to fine -tune the model via Direct Preference Optimization algorithm. We show that the proposed self-alignment approach substantially enhances factual accuracy over L LAMA family models across three key knowledge-intensive tasks on TruthfulQA and BioGEN. 1																																	2024-07-11	PPRN:87684232		
J	Wang, Haoxiang; Vasu, Pavan Kumar Anasosalu; Faghri, Fartash; Vemulapalli, Raviteja; Farajtabar, Mehrdad; Mehta, Sachin; Rastegari, Mohammad; Tuzel, Oncel; Pouransari, Hadi										SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding								Arxiv											4	4;2024-06-10;https://www.arxiv.org/abs/2310.15308v4| 3;2024-05-22;https://www.arxiv.org/abs/2310.15308v3| 2;2023-11-20;https://www.arxiv.org/abs/2310.15308v2| 1;2023-10-23;https://www.arxiv.org/abs/2310.15308v1	arXiv:2310.15308			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 10 2024	2024	The landscape of publicly available vision foundation models (VFMs), such as CLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed with distinct capabilities stemming from their pre-training objectives. For instance, CLIP excels in semantic understanding, while SAM specializes in spatial understanding for segmentation. In this work, we introduce a simple recipe to efficiently merge VFMs into a unified model that absorbs their expertise. Our method integrates techniques of multi-task learning, continual learning, and distillation. Further, it demands significantly less computational cost compared to traditional multi-task training from scratch, and it only needs a small fraction of the pre-training datasets that were initially used to train individual models. By applying our method to SAM and CLIP, we obtain SAM-CLIP: a unified model that combines the capabilities of SAM and CLIP into a single vision transformer. Compared with deploying SAM and CLIP independently, our merged model, SAM-CLIP, reduces storage and compute costs for inference, making it well-suited for edge device applications. We show that SAM-CLIP not only retains the foundational strengths of SAM and CLIP, but also introduces synergistic functionalities, notably in zero-shot semantic segmentation, where SAM-CLIP establishes new state-of-the-art results on 5 benchmarks. It outperforms previous models that are specifically designed for this task by a large margin, including +6.8% and +5.9% mean IoU improvement on Pascal-VOC and COCO-Stuff datasets, respectively.																																	2024-07-02	PPRN:85762965		
J	Gema, Aryo Pradipta; Minervini, Pasquale; Daines, Luke; Hope, Tom; Alex, Beatrice				Daines, Luke/AAH-3707-2019						Parameter-Efficient Fine-Tuning of LLaMA for the Clinical Domain								Arxiv											2	2;2024-06-09;https://www.arxiv.org/abs/2307.03042v3| 1;2023-07-06;https://www.arxiv.org/abs/2307.03042v1	arXiv:2307.03042			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 09 2024	2024	Adapting pretrained language models to novel domains, such as clinical applications, traditionally involves retraining their entire set of parameters. Parameter-Efficient Fine-Tuning (PEFT) techniques for fine-tuning language models significantly reduce computational requirements by selectively fine-tuning small subsets of parameters. In this study, we propose a two-step PEFT framework and evaluate it in the clinical domain. Our approach combines a specialised PEFT adapter layer designed for clinical domain adaptation with another adapter specialised for downstream tasks. We evaluate the framework on multiple clinical outcome prediction datasets, comparing it to clinically trained language models. Our framework achieves a better AUROC score averaged across all clinical downstream tasks compared to clinical language models. In particular, we observe large improvements of 4-5% AUROC in large-scale multilabel classification tasks, such as diagnoses and procedures classification. To our knowledge, this study is the first to provide an extensive empirical analysis of the interplay between PEFT techniques and domain adaptation in an important real-world domain of clinical applications.1 1																																	2024-07-04	PPRN:73805492		
J	Cho, Joseph; Puspitasari, Fachrina Dewi; Zheng, Sheng; Zheng, Jingyao; Lee, Lik-Hang; Kim, Tae-Ho; Hong, Choong Seon; Zhang, Chaoning				Lee, PhD, Lik-Hang (Paul)/IST-7358-2023; Hong, Choong Seon/ABF-5527-2020; Zhang, Chaoning/ABG-1572-2022						Sora as an AGI World Model? A Complete Survey on Text-to-Video Generation								Arxiv											2	2;2024-06-07;https://www.arxiv.org/abs/2403.05131v2| 1;2024-03-08;https://www.arxiv.org/abs/2403.05131v1	arXiv:2403.05131			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jun 07 2024	2024	The evolution of video generation from text, starting with animating MNIST numbers to simulating the physical world with Sora, has progressed at a breakneck speed over the past seven years. While often seen as a superficial expansion of the predecessor text-to-image generation model, text-to-video generation models are developed upon carefully engineered constituents. Here, we systematically discuss these elements consisting of but not limited to core building blocks (vision, language, and temporal) and supporting features from the perspective of their contributions to achieving a world model. We employ the PRISMA framework to curate 97 impactful research articles from renowned scientific databases primarily studying video synthesis using text conditions. Upon minute exploration of these manuscripts, we observe that text-to-video generation involves more intricate technologies beyond the plain extension of text-to-image generation. Our additional review into the shortcomings of Sora-generated videos pinpoints the call for more in-depth studies in various enabling aspects of video generation such as dataset, evaluation metric, efficient architecture, and human-controlled generation. Finally, we conclude that the study of the text-to-video generation may still be in its infancy, requiring contribution from the cross-discipline research community towards its advancement as the first step to realize artificial general intelligence (AGI).																																	2024-06-22	PPRN:88086434		
J	Long, Yuxing; Cai, Wenzhe; Wang, Hongcheng; Zhan, Guanqi; Dong, Hao										InstructNav: Zero-shot System for Generic Instruction Navigation in Unexplored Environment								Arxiv											1	1;2024-06-07;https://www.arxiv.org/abs/2406.04882v1	arXiv:2406.04882			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 07 2024	2024	Enabling robots to navigate following diverse language instructions in unexplored environments is an attractive goal for human-robot interaction. However, this goal is challenging because different navigation tasks require different strategies. The scarcity of instruction navigation data hinders training an instruction navigation model with varied strategies. Therefore, previous methods are all constrained to one specific type of navigation instruction. In this work, we propose InstructNav, a generic instruction navigation system. InstructNav makes the first endeavor to handle various instruction navigation tasks without any navigation training or pre-built maps. To reach this goal, we introduce Dynamic Chain-ofNavigation (DCoN) to unify the planning process for different types of navigation instructions. Furthermore, we propose Multi-sourced Value Maps to model key elements in instruction navigation so that linguistic DCoN planning can be converted into robot actionable trajectories. With InstructNav, we complete the R2R-CE task in a zero-shot way for the first time and outperform many task-training methods. Besides, InstructNav also surpasses the previous SOTA method by 10.48% on the zero-shot Habitat ObjNav and by 86.34% on demand-driven navigation DDN. Real robot experiments on diverse indoor scenes further demonstrate our method’s robustness in coping with the environment and instruction variations. The project webpage is https://sites.google.com/view/instructnav .																																	2024-07-04	PPRN:89230357		
J	Fadeeva, Ekaterina; Rubashevskii, Aleksandr; Shelmanov, Artem; Petrakov, Sergey; Li, Haonan; Mubarak, Hamdy; Tsymbalov, Evgenii; Kuzmin, Gleb; Panchenko, Alexander; Baldwin, Timothy; Nakov, Preslav; Panov, Maxim				Kuzmin, Gleb/KUC-6084-2024; Panchenko, Alexander/AAQ-7808-2021; Li, Haonan/IAQ-4402-2023; Shelmanov, Artem/AAE-2008-2019						Fact-Checking the Output of Large Language Models via Token-Level Uncertainty Quantification								Arxiv											2	2;2024-06-06;https://www.arxiv.org/abs/2403.04696v2| 1;2024-03-07;https://www.arxiv.org/abs/2403.04696v1	arXiv:2403.04696			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 06 2024	2024	Large language models (LLMs) are notorious for hallucinating, i.e., producing erroneous claims in their output. Such hallucinations can be dangerous, as occasional factual inaccuracies in the generated text might be obscured by the rest of the output being generally factually correct, making it extremely hard for the users to spot them. Current services that leverage LLMs usually do not provide any means for detecting unreliable generations. Here, we aim to bridge this gap. In particular, we propose a novel fact-checking and hallucination detection pipeline based on token-level uncertainty quantification. Uncertainty scores leverage information encapsulated in the output of a neural network or its layers to detect unreliable predictions, and we show that they can be used to fact-check the atomic claims in the LLM output. Moreover, we present a novel token-level uncertainty quantification method that removes the impact of uncertainty about what claim to generate on the current step and what surface form to use. Our method Claim Conditioned Probability (CCP) measures only the uncertainty of a particular claim value expressed by the model. Experiments on the task of biography generation demonstrate strong improvements for CCP compared to the baselines for seven LLMs and four languages. Human evaluation reveals that the fact-checking pipeline based on uncertainty quantification is competitive with a fact-checking tool that leverages external knowledge.																																	2024-06-22	PPRN:88062435		
J	Li, Panfeng; Lin, Youzuo; Schultz-Fellenz, Emily				Li, Panfeng/LBG-9988-2024						Contextual Hourglass Network for Semantic Segmentation of High Resolution Aerial Imagery								Arxiv											3	3;2024-06-05;https://www.arxiv.org/abs/1810.12813v4| 2;2023-11-21;https://www.arxiv.org/abs/1810.12813v3| 1;2019-02-09;https://www.arxiv.org/abs/1810.12813v2	arXiv:1810.12813			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 05 2024	2024	Semantic segmentation for aerial imagery is a challenging and important problem in remotely sensed imagery analysis. In recent years, with the success of deep learning, various convolutional neural network (CNN) based models have been developed. However, due to the varying sizes of the objects and imbalanced class labels, it can be challenging to obtain accurate pixel-wise semantic segmentation results. To address those challenges, we develop a novel semantic segmentation method and call it Contextual Hourglass Network. In our method, in order to improve the robustness of the prediction, we design a new contextual hourglass module which incorporates attention mechanism on processed low-resolution featuremaps to exploit the contextual semantics. We further exploit the stacked encoder-decoder structure by connecting multiple contextual hourglass modules from end to end. This architecture can effectively extract rich multi-scale features and add more feedback loops for better learning contextual semantics through intermediate supervision. To demonstrate the efficacy of our semantic segmentation method, we test it on Potsdam and Vaihingen datasets. Through the comparisons to other baseline methods, our method yields the best results on overall performance.																																	2024-10-08	PPRN:12896569		
J	Qiu, Pengcheng; Wu, Chaoyi; Zhang, Xiaoman; Lin, Weixiong; Wang, Haicheng; Zhang, Ya; Wang, Yanfeng; Xie, Weidi				Wang, Yanfeng/AAT-4268-2021; Zhang, Xiaoman/KLC-3306-2024; Qiu, Pengcheng/HPH-0178-2023; 林, 伟雄/HNJ-1424-2023; Wu, Chaoyi/HNQ-7762-2023						Towards Building Multilingual Language Model for Medicine								Arxiv											4	4;2024-06-02;https://www.arxiv.org/abs/2402.13963v4| 3;2024-05-29;https://www.arxiv.org/abs/2402.13963v3| 2;2024-02-26;https://www.arxiv.org/abs/2402.13963v2| 1;2024-02-21;https://www.arxiv.org/abs/2402.13963v1	arXiv:2402.13963			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 02 2024	2024	The development of open-source, multilingual medical language models can benefit a wide, linguistically diverse audience from different regions. To promote this domain, we present contributions from the following: First, we construct a multilingual medical corpus, containing approximately 25.5B tokens encompassing 6 main languages, termed as MMedC, enabling auto-regressive domain adaptation for general LLMs; Second, to monitor the development of multilingual medical LLMs, we propose a multilingual medical multi-choice question-answering benchmark with rationale, termed as MMedBench; Third, we have assessed a number of open-source large language models (LLMs) on our benchmark, along with those further auto-regressive trained on MMedC. Our final model, MMed-Llama 3, with only 8B parameters, achieves superior performance compared to all other open-source models on both MMedBench and English benchmarks, even rivaling GPT-4. In conclusion, in this work, we present a large-scale corpus, a benchmark and a series of models to support the development of multilingual medical LLMs.																																	2024-06-22	PPRN:87788160		
J	Dohmatob, Elvis; Feng, Yunzhen; Yang, Pu; Charton, Francois; Kempe, Julia										A Tale of Tails: Model Collapse as a Change of Scaling Laws								Arxiv											3	3;2024-05-31;https://www.arxiv.org/abs/2402.07043v2| 2;2024-02-10;https://www.arxiv.org/abs/2402.07043v1| 1;2024-02-10;https://www.arxiv.org/abs/2402.07043v1	arXiv:2402.07043			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 31 2024	2024	As AI model size grows, neural scaling laws have become an important tool to predict the improvements of large models when increasing capacity and the size of original (human or natural) training data. Yet, the widespread use of popular models means that the ecosystem of online data and text will co -evolve to progressively contain increased amounts of synthesized data. In this paper we ask: How will the scaling laws change in the inevitable regime where synthetic data makes its way into the training corpus? Will future models, still improve, or be doomed to degenerate up to total (model) collapse? ? We develop a theoretical framework of model collapse through the lens of scaling laws. We discover a wide range of decay phenomena, analyzing loss of scaling, shifted scaling with number of generations, the “un-learning” of skills, and grokking when mixing human and synthesized data. Our theory is validated by large-scale experiments with a transformer on an arithmetic task and text generation using the large language model Llama2. .																																	2024-06-19	PPRN:87638223		
J	Ye, Hanrong; Huang, De-An; Lu, Yao; Yu, Zhiding; Ping, Wei; Tao, Andrew; Kautz, Jan; Han, Song; Xu, Dan; Molchanov, Pavlo; Yin, Hongxu				Xu, Dan/OML-8012-2025; Yin, Hongxu/AAZ-3328-2020						X-VILA: Cross-Modality Alignment for Large Language Model								Arxiv											1	1;2024-05-29;https://www.arxiv.org/abs/2405.19335v1	arXiv:2405.19335			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 29 2024	2024	We introduce X-VILA, an omni-modality model designed to extend the capabilities of large language models (LLMs) by incorporating image, video, and audio modalities. By aligning modality-specific encoders with LLM inputs and diffusion decoders with LLM outputs, X-VILA achieves cross-modality understanding, reasoning, and generation. To facilitate this cross-modality alignment, we curate an effective interleaved any-to-any modality instruction-following dataset. Furthermore, we identify a significant problem with the current cross-modality alignment method, which results in visual information loss. To address the issue, we propose a visual alignment mechanism with a visual embedding highway module. We then introduce a resource-efficient recipe for training X-VILA, that exhibits proficiency in any-to-any modality conversation, surpassing previous approaches by large margins. X-VILA also showcases emergent properties across modalities even in the absence of similar training data. The project will be made open-source.																																	2024-11-10	PPRN:89100457		
J	Zhang, He; Wu, Chuhao; Xie, Jingyi; Lyu, Yao; Cai, Jie; Carroll, John M.				Zhang, He/GXN-0028-2022; Wu, Chuhao/HNJ-1220-2023; Carroll, John/A-8718-2009; Cai, Jie/ABB-4771-2020; xie, jingyi/HTN-4792-2023						Redefining Qualitative Analysis in the AI Era: Utilizing ChatGPT for Efficient Thematic Analysis								Arxiv											3	3;2024-05-28;https://www.arxiv.org/abs/2309.10771v3| 2;2024-05-16;https://www.arxiv.org/abs/2309.10771v2| 1;2023-09-19;https://www.arxiv.org/abs/2309.10771v1	arXiv:2309.10771			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 28 2024	2024	AI tools, particularly large-scale language model (LLM) based applications such as ChatGPT, have the potential to simplify qualitative research. Through semi-structured interviews with seventeen participants, we identified challenges and concerns in integrating ChatGPT into the qualitative analysis process. Collaborating with thirteen qualitative researchers, we developed a framework for designing prompts to enhance the effectiveness of ChatGPT in thematic analysis. Our findings indicate that improving transparency, providing guidance on prompts, and strengthening users' understanding of LLMs' capabilities significantly enhance the users' ability to interact with ChatGPT. We also discovered and revealed the reasons behind researchers' shift in attitude towards ChatGPT from negative to positive. This research not only highlights the importance of well-designed prompts in LLM applications but also offers reflections for qualitative researchers on the perception of AI's role. Finally, we emphasize the potential ethical risks and the impact of constructing AI ethical expectations by researchers, particularly those who are novices, on future research and AI development.																																	2024-06-12	PPRN:85053963		
J	Huang, Jianheng; Cui, Leyang; Wang, Ante; Yang, Chengyi; Liao, Xinting; Song, Linfeng; Yao, Junfeng; Su, Jinsong				Wang, Ante/KLZ-2175-2024; Yao, Junfeng/ABE-6440-2020; Su, Jinsong/JXM-6940-2024; Song, Linfeng/JQJ-0047-2023						Mitigating Catastrophic Forgetting in Large Language Models with Self-Synthesized Rehearsal								Arxiv											2	2;2024-05-25;https://www.arxiv.org/abs/2403.01244v2| 1;1800-01-01;https://www.arxiv.org/abs/2403.01244v1	arXiv:2403.01244			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 25 2024	2024	Large language models (LLMs) suffer from catastrophic forgetting during continual learning. Conventional rehearsal -based methods rely on previous training data to retain the model’s ability, which may not be feasible in real -world applications. When conducting continual learning based on a publicly -released LLM checkpoint, the availability of the original training data may be non-existent. To address this challenge, we propose a framework called Self -Synthesized Rehearsal (SSR) that uses the LLM to generate synthetic instances for rehearsal. Concretely, we first employ the base LLM for in -context learning to generate synthetic instances. Subsequently, we utilize the latest LLM to refine the instance outputs based on the synthetic inputs, preserving its acquired ability. Finally, we select diverse high -quality synthetic instances for rehearsal in future stages. Experimental results demonstrate that SSR achieves superior or comparable performance compared to conventional rehearsal -based approaches while being more data -efficient. Besides, SSR effectively preserves the generalization capabilities of LLMs in general domains.																																	2024-06-08	PPRN:88014053		
J	Liu, Peiyuan; Guo, Hang; Dai, Tao; Li, Naiqi; Bao, Jigang; Ren, Xudong; Jiang, Yong; Xia, Shu-Tao				Li, Naiqi/LGY-9146-2024; Guo, Hang/KWT-3703-2024; Liu, Peiyuan/JQW-6160-2023						CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning								Arxiv											2	2;2024-05-23;https://www.arxiv.org/abs/2403.07300v2| 1;2024-03-12;https://www.arxiv.org/abs/2403.07300v1	arXiv:2403.07300			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 23 2024	2024	Deep learning (e.g., Transformer) has been widely and successfully used in multivariate time series forecasting (MTSF). Unlike existing methods that focus on training models from a single modal of time series input, large language models (LLMs) based MTSF methods with cross-modal text and time series input have recently shown great superiority, especially with limited temporal data. However, current LLM-based MTSF methods usually focus on adapting and fine-tuning LLMs, while neglecting the distribution discrepancy between textual and temporal input tokens, thus leading to sub-optimal performance. To address this issue, we propose a novel Cross-Modal LLM Fine-Tuning (CALF) framework for MTSF by reducing the distribution discrepancy between textual and temporal data, which mainly consists of the temporal target branch with temporal input and the textual source branch with aligned textual input. To reduce the distribution discrepancy, we develop the cross-modal match module to first align cross-modal input distributions. Additionally, to minimize the modality distribution gap in both feature and output spaces, feature regularization loss is developed to align the intermediate features between the two branches for better weight updates, while output consistency loss is introduced to allow the output representations of both branches to correspond effectively. Thanks to the modality alignment, CALF establishes state-of-the-art performance for both long-term and short-term forecasting tasks with low computational complexity, and exhibiting favorable few-shot and zero-shot abilities similar to that in LLMs. Code is available at url{https://github.com/Hank0626/LLaTA}.																																	2024-06-05	PPRN:88112845		
J	Kim, Minsu; Choi, Sanghyeok; Kim, Hyeonah; Son, Jiwoo; Park, Jinkyoo; Bengio, Yoshua										Ant Colony Sampling with GFlowNets for Combinatorial Optimization								Arxiv											2	2;2024-05-22;https://www.arxiv.org/abs/2403.07041v2| 1;2024-03-11;https://www.arxiv.org/abs/2403.07041v1	arXiv:2403.07041			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 22 2024	2024	This paper introduces the Generative Flow Ant Colony Sampler (GFACS), a neural-guided probabilistic search algorithm for solving combinatorial optimization (CO). GFACS integrates generative flow networks (GFlowNets), an emerging amortized inference method, with ant colony optimization (ACO), a promising probabilistic search algorithm. Specifically, we use GFlowNets to learn a constructive policy in combinatorial spaces for enhancing ACO by providing an informed prior distribution over decision variables conditioned on input graph instances. Furthermore, we introduce a novel off-policy training algorithm for scaling conditional GFlowNets into large-scale combinatorial spaces by leveraging local search and shared energy normalization. Our experimental results demonstrate that GFACS outperforms baseline ACO algorithms in seven CO tasks and is competitive with problem-specific heuristics for vehicle routing problems.																																	2024-06-06	PPRN:88113410		
J	Li, Yunxin; Jiang, Shenyuan; Hu, Baotian; Wang, Longyue; Zhong, Wanqi; Luo, Wenhan; Ma, Lin; Zhang, Min				Hu, Baotian/AAA-4102-2022; Luo, Wenhan/KXR-1375-2024						Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts								Arxiv											1	1;2024-05-18;https://www.arxiv.org/abs/2405.11273v1	arXiv:2405.11273			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	May 18 2024	2024	Recent advancements in Multimodal Large Language Models (MLLMs) underscore the significance of scalable models and data to boost performance, yet this often incurs substantial computational costs. Although the Mixture of Experts (MoE) architecture has been employed to efficiently scale large language and image-text models, these efforts typically involve fewer experts and limited modalities. To address this, our work presents the pioneering attempt to develop a unified MLLM with the MoE architecture, named Uni-MoE that can handle a wide array of modalities. Specifically, it features modality-specific encoders with connectors for a unified multimodal representation. We also implement a sparse MoE architecture within the LLMs to enable efficient training and inference through modality-level data parallelism and expert-level model parallelism. To enhance the multi-expert collaboration and generalization, we present a progressive training strategy: 1) Cross-modality alignment using various connectors with different cross-modality data, 2) Training modality-specific experts with cross-modality instruction data to activate experts' preferences, and 3) Tuning the Uni-MoE framework utilizing Low-Rank Adaptation (LoRA) on mixed multimodal instruction data. We evaluate the instruction-tuned Uni-MoE on a comprehensive set of multimodal datasets. The extensive experimental results demonstrate Uni-MoE's principal advantage of significantly reducing performance bias in handling mixed multimodal datasets, alongside improved multi-expert collaboration and generalization. 																																	2024-06-15	PPRN:89097944		
J	Maulik, Davesh; Shen, Junliang										THE P=W CONJECTURE FOR GL<italic>n</italic>								Arxiv											2	2;2024-05-17;https://www.arxiv.org/abs/2209.02568v2| 1;2022-09-06;https://www.arxiv.org/abs/2209.02568v1	arXiv:2209.02568			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 17 2024	2024	We prove the P=W conjecture for GL n for all ranks n and curves of arbitrary genus g ≥ 2. The proof combines a strong perversity result on tautological classes with the curious Hard Lefschetz theorem of Mellit. For the perversity statement, we apply the vanishing cycles constructions in our earlier work to global Springer theory in the sense of Yun, and prove a parabolic support theorem.																																	2024-06-01	PPRN:13416412		
J	Xiang, Ao; Zhang, Jingyu; Yang, Qin; Wang, Liyang; Cheng, Yu				Zhang, Jingyu/IUQ-7500-2023; Ao, Xiang/JYO-6512-2024; Yan, Qin/E-8893-2012						Research on Splicing Image Detection Algorithms Based on Natural Image Statistical Characteristics								Arxiv											3	3;2024-05-17;https://www.arxiv.org/abs/2404.16296v3| 2;2024-04-26;https://www.arxiv.org/abs/2404.16296v2| 1;2024-04-25;https://www.arxiv.org/abs/2404.16296v1	arXiv:2404.16296			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 17 2024	2024	With the development and widespread application of digital image processing technology, image splicing has become a common method of image manipulation, raising numerous security and legal issues. This paper introduces a new splicing image detection algorithm based on the statistical characteristics of natural images, aimed at improving the accuracy and efficiency of splicing image detection. By analyzing the limitations of traditional methods, we have developed a detection framework that integrates advanced statistical analysis techniques and machine learning methods. The algorithm has been validated using multiple public datasets, showing high accuracy in detecting spliced edges and locating tampered areas, as well as good robustness. Additionally, we explore the potential applications and challenges faced by the algorithm in real -world scenarios. This research not only provides an effective technological means for the field of image tampering detection but also offers new ideas and methods for future related research.																																	2024-06-14	PPRN:88650744		
J	Sala, Pablo; Gopalakrishnan, Sarang; Oshikawa, Masaki; You, Yizhi				Sala, Pablo/ODK-1670-2025; Oshikawa, Masaki/F-4992-2011						Spontaneous Strong Symmetry Breaking in Open Systems: Purification Perspective								Arxiv											1	1;2024-05-03;https://www.arxiv.org/abs/2405.02402v1	arXiv:2405.02402			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 03 2024	2024	We explore the landscape of the decoherence effect in mixed-state ensembles from a purification perspective. We analyze the spontaneous strong-to-weak symmetry breaking (SSSB) in mixed states triggered by local quantum channels by mapping this decoherence process to unitary operations in the purified state within an extended Hilbert space. Our key finding is that mixed-state long-range order and SSSB can be mapped into symmetry-protected topological (SPT) order in the purified state. Notably, the measurement-induced long-range order in the purified SPT state mirrors the long-range order in the mixed state due to SSSB, characterized by the Renyi-2 correlator. We establish a correspondence between fidelity correlators in the mixed state, which serve as a measure of SSSB, and strange correlators in the purification, which signify the SPT order. This purification perspective is further extended to explore intrinsic mixed-state topological order and decoherent symmetry-protected topological phases.																																	2024-05-24	PPRN:88789587		
J	Zhang, Liang; Hu, Anwen; Xu, Haiyang; Yan, Ming; Xu, Yichen; Jin, Qin; Zhang, Ji; Huang, Fei				xu, yichen/KYR-0603-2024; Yan, Ming/LDT-2692-2024						TinyChart: Efficient Chart Understanding with Visual Token Merging and Program-of-Thoughts Learning								Arxiv											1	1;2024-04-25;https://www.arxiv.org/abs/2404.16635v1	arXiv:2404.16635			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 25 2024	2024	Charts are important for presenting and explaining complex data relationships. Recently, multimodal large language models (MLLMs) have shown remarkable capabilities in various chart understanding tasks. However, the sheer size of these models in terms of parameters and computational requirements limits their use in resource-constrained environments. In this paper, we present TinyChart, an efficient MLLM for chart understanding with only 3B parameters. TinyChart overcomes two key challenges in efficient chart understanding: (1) reduce the burden of learning numerical computations through a Program-of-Thoughts (PoT) learning strategy, which trains the model to generate Python programs for numerical calculations, and (2) reduce lengthy vision feature sequences produced by the vision transformer for high-resolution images through a Vision Token Merging module, which gradually merges most similar vision tokens. Extensive experiments demonstrate that our 3B TinyChart achieves SOTA performance on a variety of chart understanding benchmarks including ChartQA, Chart-to-Text, Chart-to-Table, OpenCQA, and ChartX. It outperforms several chart understanding MLLM with up to 13B parameters such as ChartLlama and ChartAst, and close-sourced general-purpose MLLM GPT-4V on ChartQA. It also demonstrates its superior efficiency with higher throughput during inference due to a smaller model scale and more efficient vision encoding. 																																	2024-05-04	PPRN:88651270		
J	Deng, Ailin; Chen, Zhirui; Hooi, Bryan				Hooi, Bryan/AAU-5707-2020						Seeing is Believing: Mitigating Hallucination in Large Vision-Language Models via CLIP-Guided Decoding								Arxiv											2	2;2024-04-23;https://www.arxiv.org/abs/2402.15300v2| 1;2024-02-23;https://www.arxiv.org/abs/2402.15300v1	arXiv:2402.15300			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 23 2024	2024	Large Vision -Language Models (LVLMs) are susceptible to object hallucinations, an issue in which their generated text contains non-existent objects, greatly limiting their reliability and practicality. Current approaches often rely on the model’s token likelihoods or other internal information, instruction tuning on additional datasets, or incorporating complex external tools. We first perform empirical analysis on sentence -level LVLM hallucination, finding that CLIP similarity to the image acts as a stronger and more robust indicator of hallucination compared to token likelihoods. Motivated by this, we introduce our CLIP -Guided Decoding (CGD) approach, a straightforward but effective training -free approach to reduce object hallucination at decoding time. CGD uses CLIP to guide the model’s decoding process by enhancing visual grounding of generated text with the image. Experiments demonstrate that CGD effectively mitigates object hallucination across multiple LVLM families while preserving the utility of text generation. Codes are available1.																																	2024-05-01	PPRN:87908400		
J	Shi, Weiyan; Li, Ryan; Zhang, Yutong; Ziems, Caleb; Yu, Chunhua; Horesh, Raya; de Paula, Rogerio Abreu; Yang, Diyi				Shi, Weiyan/JOK-7836-2023; zhang, yutong/GXV-2287-2022						CultureBank: An Online Community-Driven Knowledge Base Towards Culturally Aware Language Technologies								Arxiv											1	1;2024-04-23;https://www.arxiv.org/abs/2404.15238v1	arXiv:2404.15238			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 23 2024	2024	To enhance language models’ cultural awareness, we design a generalizable pipeline to construct cultural knowledge bases from different online communities on a massive scale. With the pipeline, we construct Culture - Bank, a knowledge base built upon users’ self -narratives with 12K cultural descriptors sourced from TikTok and 11K from Reddit. Unlike previous cultural knowledge resources, CultureBank contains diverse views on cultural descriptors to allow flexible interpretation of cultural knowledge, and contextualized cultural scenarios to help grounded evaluation. With CultureBank, we evaluate different LLMs’ cultural awareness, and identify areas for improvement. We also fine-tune a language model on CultureBank: experiments show that it achieves better performances on two downstream cultural tasks in a zero -shot setting. Finally, we offer recommendations based on our findings for future culturally aware language technologies.1 2																																	2024-05-01	PPRN:88621380		
J	Tang, Raphael; Zhang, Xinyu; Ma, Xueguang; Lin, Jimmy; Ture, Ferhan				Ma, Xueguang/GPF-7396-2022						Found in the Middle: Permutation Self-Consistency Improves Listwise Ranking in Large Language Models								Arxiv											2	2;2024-04-22;https://www.arxiv.org/abs/2310.07712v2| 1;2023-10-11;https://www.arxiv.org/abs/2310.07712v1	arXiv:2310.07712			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 22 2024	2024	Large language models (LLMs) exhibit positional bias in how they use context, which especially complicates listwise ranking. To address this, we propose permutation self-consistency, a form of self-consistency over ranking list outputs of black-box LLMs. Our key idea is to marginalize out different list orders in the prompt to produce an order-independent ranking with less positional bias. First, given some input prompt, we repeatedly shuffle the list in the prompt and pass it through the LLM while holding the instructions the same. Next, we aggregate the resulting sample of rankings by computing the central ranking closest in distance to all of them, marginalizing out prompt order biases in the process. Theoretically, we prove the robustness of our method, showing convergence to the true ranking in the presence of random perturbations. Empirically, on five list-ranking datasets in sorting and passage reranking, our approach improves scores from conventional inference by up to 7-18% for GPT-3.5 and 8-16% for LLaMA v2 (70B), surpassing the previous state of the art in passage reranking.																																	2024-05-01	PPRN:85568808		
J	Chen, Wei; Li, Zhiyuan				li, zhiyuan/ACF-5587-2022						Octopus v2: On-device language model for super agent								Arxiv											3	3;2024-04-16;https://www.arxiv.org/abs/2404.01744v5| 2;2024-04-05;https://www.arxiv.org/abs/2404.01744v3| 1;2024-04-03;https://www.arxiv.org/abs/2404.01744v2	arXiv:2404.01744			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Apr 16 2024	2024	Language models have shown effectiveness in a variety of software applications, particularly in tasks related to automatic workflow. These models possess the crucial ability to call functions, which is essential in creating AI agents. Despite the high performance of large-scale language models in cloud environments, they are often associated with concerns over privacy and cost. Current on-device models for function calling face issues with latency and accuracy. Our research presents a new method that empowers an on-device model with 2 billion parameters to surpass the performance of GPT-4 in both accuracy and latency, and decrease the context length by 95%. When compared to Llama-7B with a RAG-based function calling mechanism, our method enhances latency by 35-fold. This method reduces the latency to levels deemed suitable for deployment across a variety of edge devices in production environments, aligning with the performance requisites for real-world applications.																																	2024-04-26	PPRN:88389190		
J	Niroula, Pradeep; White, Christopher David; Wang, Qingfeng; Johri, Sonika; Zhu, Daiwei; Monroe, Christopher; Noel, Crystal; Gullans, Michael J.				Monroe, Christopher/G-8105-2011						Phase transition in magic with random quantum circuits								Arxiv											2	2;2024-04-11;https://www.arxiv.org/abs/2304.10481v2| 1;2023-04-20;https://www.arxiv.org/abs/2304.10481v1	arXiv:2304.10481			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 11 2024	2024	Magic is a property of quantum states that enables universal fault-tolerant quantum computing using simple sets of gate operations. Understanding the mechanisms by which magic is created or destroyed is, therefore, a crucial step towards efficient and practical fault-tolerant computation. We observe that a random stabilizer code subject to coherent errors exhibits a phase transition in magic, which we characterize through analytic, numeric and experimental probes. Below a critical error rate, stabilizer syndrome measurements remove the accumulated magic in the circuit, effectively protecting against coherent errors; above the critical error rate syndrome measurements concentrate magic. A better understanding of such rich behavior in the resource theory of magic could shed more light on origins of quantum speedup and pave pathways for more efficient magic state generation.																																	2024-04-24	PPRN:64603561		
J	Patel, Maitreya; Jung, Sangmin; Baral, Chitta; Yang, Yezhou										<italic>λ-ECLIPSE:</italic> Multi-Concept Personalized Text-to-Image Diffusion Models by Leveraging CLIP Latent Space								Arxiv											2	2;2024-04-09;https://www.arxiv.org/abs/2402.05195v2| 1;2024-02-07;https://www.arxiv.org/abs/2402.05195v1	arXiv:2402.05195			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 09 2024	2024	Despite the recent advances in personalized text-to-image (P-T2I) generative models, it remains challenging to perform finetuning-free multi-subject-driven T2I in a resource-efficient manner. Predominantly, contemporary approaches, involving the training of Hypernetworks and Multimodal Large Language Models (MLLMs), require heavy computing resources that range from 600 to 12300 GPU hours of training. These subject-driven T2I methods hinge on Latent Diffusion Models (LDMs), which facilitate T2I mapping through cross-attention layers. While LDMs offer distinct advantages, P-T2I methods’ reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image. In this paper, we present λ-ECLIPSE, an alternative prior-training strategy that works in the latent space of a pre-trained CLIP model without relying on the diffusion UNet models. λ-ECLIPSE leverages the image-text interleaved pre-training for fast and effective multi-subject-driven P-T2I. Through extensive experiments, we establish that A -ECLIPSE surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization. A -ECLIPSE performs multi -subject driven P-T2I with just 34M parameters and is trained on a mere 74 GPU hours. Additionally, A -ECLIPSE demonstrates the unique ability to perform multi -concept interpolations.																																	2024-04-24	PPRN:87572960		
J	Ma, Wan-Duo Kurt; Lewis, J.P.; W. Bastiaan, Kleijn										TrailBlazer: Trajectory Control for Diffusion-Based Video Generation								Arxiv											2	2;2024-04-08;https://www.arxiv.org/abs/2401.00896v2| 1;2023-12-31;https://www.arxiv.org/abs/2401.00896v1	arXiv:2401.00896			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 08 2024	2024	Within recent approaches to text-to-video (T2V) generation, achieving controllability in the synthesized video is often a challenge. Typically, this issue is addressed by providing low-level per-frame guidance in the form of edge maps, depth maps, or an existing video to be altered. However, the process of obtaining such guidance can be labor-intensive. This paper focuses on enhancing controllability in video synthesis by employing straightforward bounding boxes to guide the subject in various ways, all without the need for neural network training, finetuning, optimization at inference time, or the use of pre-existing videos. Our algorithm, TrailBlazer, is constructed upon a pre-trained (T2V) model, and easy to implement. The subject is directed by a bounding box through the proposed spatial and temporal attention map editing. Moreover, we introduce the concept of keyframing, allowing the subject trajectory and overall appearance to be guided by both a moving bounding box and corresponding prompts, without the need to provide a detailed mask. The method is efficient, with negligible additional computation relative to the underlying pre-trained model. Despite the simplicity of the bounding box guidance, the resulting motion is surprisingly natural, with emergent effects including perspective and movement toward the virtual camera as the box size increases.																																	2024-04-24	PPRN:86916293		
J	Seddik, Mohamed El Amine; Chen, Suei-Wen; Hayou, Soufiane; Youssef, Pierre; Debbah, Merouane				Debbah, Merouane/LSL-4090-2024; Hayou, Soufiane/JJD-9155-2023						How Bad is Training on Synthetic Data? A Statistical Analysis of Language Model Collapse								Arxiv											1	1;2024-04-07;https://www.arxiv.org/abs/2404.05090v1	arXiv:2404.05090			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 07 2024	2024	The phenomenon of model collapse, introduced in (Shumailov et al., 2023), refers to the deterioration in performance that occurs when new models are trained on synthetic data generated from previously trained models. This recursive training loop makes the tails of the original distribution disappear, thereby making future-generation models forget about the initial (real) distribution. With the aim of rigorously understanding model collapse in language models, we consider in this paper a statistical model that allows us to characterize the impact of various recursive training scenarios. Specifically, we demonstrate that model collapse cannot be avoided when training solely on synthetic data. However, when mixing both real and synthetic data, we provide an estimate of a maximal amount of synthetic data below which model collapse can eventually be avoided. Our theoretical conclusions are further supported by empirical validations.																																	2024-04-21	PPRN:88441912		
J	Xiong, Zhitong; Zhang, Fahong; Wang, Yi; Shi, Yilei; Zhu, Xiao Xiang				Zhu, Xiao Xiang/ABE-7138-2020; Wang, Yi/GNH-2821-2022; Xiong, Zhitong/HPC-7558-2023						EarthNets: Empowering AI in Earth Observation								Arxiv											2	2;2024-04-02;https://www.arxiv.org/abs/2210.04936v3| 1;2022-10-10;https://www.arxiv.org/abs/2210.04936v2	arXiv:2210.04936			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 02 2024	2024	Earth observation (EO), aiming at monitoring the state of planet Earth using remote sensing data, is critical for improving our daily lives and living environment. With a growing number of satellites in orbit, an increasing number of datasets with diverse sensors and research domains are being published to facilitate the research of the remote sensing community. This paper presents a comprehensive review of more than 500 publicly published datasets, including research domains like agriculture, land use and land cover, disaster monitoring, scene understanding, vision-language models, foundation models, climate change, and weather forecasting. We systematically analyze these EO datasets from four aspects: volume, resolution distributions, research domains, and the correlation between datasets. Based on the dataset attributes, we propose to measure, rank, and select datasets to build a new benchmark for model evaluation. Furthermore, a new platform for EO, termed EarthNets, is released to achieve a fair and consistent evaluation of deep learning methods on remote sensing data. EarthNets supports standard dataset libraries and cutting-edge deep learning models to bridge the gap between the remote sensing and machine learning communities. Based on this platform, extensive deep-learning methods are evaluated on the new benchmark. The insightful results are beneficial to future research. 																																	2024-04-18	PPRN:25043428		
J	Liu, Chen Cecilia; Koto, Fajri; Baldwin, Timothy; Gurevych, Iryna				Koto, Fajri/ISS-6497-2023						Are Multilingual LLMs Culturally-Diverse Reasoners? An Investigation into Multicultural Proverbs and Sayings								Arxiv											2	2;2024-03-30;https://www.arxiv.org/abs/2309.08591v2| 1;2023-09-15;https://www.arxiv.org/abs/2309.08591v1	arXiv:2309.08591			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 30 2024	2024	Large language models (LLMs) are highly adept at question answering and reasoning tasks, but when reasoning in a situational context, human expectations vary depending on the relevant cultural common ground. As languages are associated with diverse cultures, LLMs should also be culturally-diverse reasoners. In this paper, we study the ability of a wide range of state-of-the-art multilingual LLMs (mLLMs) to reason with proverbs and sayings in a conversational context. Our experiments reveal that: (1) mLLMs "know" limited proverbs and memorizing proverbs does not mean understanding them within a conversational context; (2) mLLMs struggle to reason with figurative proverbs and sayings, and when asked to select the wrong answer (instead of asking it to select the correct answer); and (3) there is a "culture gap" in mLLMs when reasoning about proverbs and sayings translated from other languages. We construct and release our evaluation dataset MAPS (MulticultrAl Proverbs and Sayings) for proverb understanding with conversational context for six different languages.																																	2024-04-17	PPRN:85088700		
J	Gou, Yunhao; Chen, Kai; Liu, Zhili; Hong, Lanqing; Xu, Hang; Li, Zhenguo; Yeung, Dit-Yan; Kwok, James T.; Zhang, Yu				liu, zhili/OQJ-8195-2025; zhang, Shifeng/HPH-0217-2023						Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation								Arxiv											1	1;2024-03-22;https://www.arxiv.org/abs/2403.09572v2	arXiv:2403.09572			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 22 2024	2024	Multimodal large language models (MLLMs) have shown impressive reasoning abilities, which, however, are also more vulnerable to jailbreak attacks than their LLM predecessors. Although still capable of detecting unsafe responses, we observe that safety mechanisms of the pre-aligned LLMs in MLLMs can be easily bypassed due to the introduction of image features. To construct robust MLLMs, we propose ECSO(Eyes Closed, Safety On), a novel training-free protecting approach that exploits the inherent safety awareness of MLLMs, and generates safer responses via adaptively transforming unsafe images into texts to activate intrinsic safety mechanism of pre-aligned LLMs in MLLMs. Experiments on five state-of-the-art (SoTA) MLLMs demonstrate that our ECSO enhances model safety significantly (e.g., a 37.6% improvement on the MM-SafetyBench (SD+OCR), and 71.3% on VLSafe for the LLaVA-1.5-7B), while consistently maintaining utility results on common MLLM benchmarks. Furthermore, we show that ECSO can be used as a data engine to generate supervised-finetuning (SFT) data for MLLM alignment without extra human intervention.																																	2025-08-07	PPRN:123149813		
J	Hu, Jinyi; Yao, Yuan; Wang, Chongyi; Wang, Shan; Pan, Yinxu; Chen, Qianyu; Yu, Tianyu; Wu, Hanghao; Zhao, Yue; Zhang, Haoye; Han, Xu; Lin, Yankai; Xue, Jiao; Li, Dahai; Liu, Zhiyuan; Sun, Maosong				Liu, Zhiyuan/I-2233-2014; Li, Dahai/HCH-7167-2022; Yu, Tianyu/OFO-0197-2025; Hu, Jinyi/GXF-7296-2022						LARGE MULTILINGUAL MODELS PIVOT ZERO-SHOT MULTIMODAL LEARNING ACROSS LANGUAGES								Arxiv											3	3;2024-03-22;https://www.arxiv.org/abs/2308.12038v3| 2;2024-02-05;https://www.arxiv.org/abs/2308.12038v2| 1;2023-08-23;https://www.arxiv.org/abs/2308.12038v1	arXiv:2308.12038			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 22 2024	2024	Recently there has been a significant surge in multimodal learning in terms of both image-to-text and text-to-image generation. However, the success is typically limited to English, leaving other languages largely behind. Building a competitive counterpart in other languages is highly challenging due to the low-resource nature of non-English multimodal data (i.e., lack of large-scale, high-quality image-text data). In this work, we propose MPM, an effective training paradigm for training large multimodal models in non-English languages. MPM demonstrates that Multilingual language models can Pivot zero-shot Multimodal learning across languages. Specifically, based on a strong multilingual large language model, multimodal models pretrained on English-only image-text data can well generalize to other languages in a (quasi)-zero-shot manner, even surpassing models trained on image-text data in native languages. Taking Chinese as a practice of MPM, we build large multimodal models VisCPM in image-to-text and text-to-image generation, which achieve state-of-the-art (open-source) performance in Chinese. To facilitate future research, we open-source codes and model weights at https://github.com/OpenBMB/VisCPM.git.																																	2024-04-13	PPRN:83036684		
J	Abdali, Sara; Anarfi, Richard; Barberan, C J; He, Jia										Securing Large Language Models: Threats, Vulnerabilities and Responsible Practices								Arxiv											1	1;2024-03-19;https://www.arxiv.org/abs/2403.12503v1	arXiv:2403.12503			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 19 2024	2024	Large language models (LLMs) have significantly transformed the landscape of Natural Language Processing (NLP). Their impact extends across a diverse spectrum of tasks, revolutionizing how we approach language understanding and generations. Nevertheless, alongside their remarkable utility, LLMs introduce critical security and risk considerations. These challenges warrant careful examination to ensure responsible deployment and safeguard against potential vulnerabilities. This research paper thoroughly investigates security and privacy concerns related to LLMs from five thematic perspectives: security and privacy concerns, vulnerabilities against adversarial attacks, potential harms caused by misuses of LLMs, mitigation strategies to address these challenges while identifying limitations of current strategies. Lastly, the paper recommends promising avenues for future research to enhance the security and risk management of LLMs.1																																	2024-04-12	PPRN:88240320		
J	Chen, Aochuan; Zhang, Yimeng; Jia, Jinghan; Diffenderfer, James; Liu, Jiancheng; Parasyris, Konstantinos; Zhang, Yihua; Zhang, Zheng; Kailkhura, Bhavya; Liu, Sijia				Liu, JC/LPI-0149-2024; Zhang, Yimeng/ACD-2102-2022; Liu, Sijia/JCP-4627-2023; Zhang, Yimeng/IUQ-7269-2023						DeepZero: Scaling up Zeroth-Order Optimization for Deep Model Training								Arxiv											4	4;2024-03-15;https://www.arxiv.org/abs/2310.02025v4| 3;2024-02-04;https://www.arxiv.org/abs/2310.02025v3| 2;2023-11-05;https://www.arxiv.org/abs/2310.02025v2| 1;2023-10-03;https://www.arxiv.org/abs/2310.02025v1	arXiv:2310.02025			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 15 2024	2024	Zeroth-order (ZO) optimization has become a popular technique for solving machine learning (ML) problems when first-order (FO) information is difficult or impossible to obtain. However, the scalability of ZO optimization remains an open problem: Its use has primarily been limited to relatively small-scale ML problems, such as sample-wise adversarial attack generation. To our best knowledge, no prior work has demonstrated the effectiveness of ZO optimization in training deep neural networks (DNNs) without a significant decrease in performance. To overcome this roadblock, we develop DeepZero, a principled ZO deep learning (DL) framework that can scale ZO optimization to DNN training from scratch through three primary innovations. First, we demonstrate the advantages of coordinate-wise gradient estimation (CGE) over randomized vector-wise gradient estimation in training accuracy and computational efficiency. Second, we propose a sparsity-induced ZO training protocol that extends the model pruning methodology using only finite differences to explore and exploit the sparse DL prior in CGE. Third, we develop the methods of feature reuse and forward parallelization to advance the practical implementations of ZO training. Our extensive experiments show that DeepZero achieves state-of-the-art (SOTA) accuracy on ResNet-20 trained on CIFAR-10, approaching FO training performance for the first time. Furthermore, we show the practical utility of DeepZero in applications of certified adversarial defense and DL-based partial differential equation error correction, achieving 10-20% improvement over SOTA. We believe our results will inspire future research on scalable ZO optimization and contribute to advancing DL with black box.																																	2024-05-03	PPRN:85375996		
J	Ojewale, Victor; Steed, Ryan; Vecchione, Briana; Birhane, Abeba; Raji, Inioluwa Deborah										Towards AI Accountability Infrastructure: Gaps and Opportunities in AI Audit Tooling								Arxiv											1	1;2024-03-14;https://www.arxiv.org/abs/2402.17861v2	arXiv:2402.17861			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 14 2024	2024	Audits are critical mechanisms for identifying the risks and limitations of deployed artificial intelligence (AI) systems. However, the effective execution of AI audits remains incredibly difficult. As a result, practitioners make use of various tools to support their efforts. Drawing on interviews with 35 AI audit practitioners and a landscape analysis of 390 tools, we map the current ecosystem of available AI audit tools. While there are many tools designed to assist practitioners with setting standards and evaluating AI systems, these tools often fell short of supporting the accountability goals of AI auditing in practice. We thus highlight areas for future tool development beyond evaluation -- from harms discovery to advocacy -- and outline challenges practitioners faced in their efforts to use AI audit tools. We conclude that resources are lacking to adequately support the full scope of needs for many AI audit practitioners and recommend that the field move beyond tools for just evaluation, towards more comprehensive infrastructure for AI accountability.																																	2024-04-11	PPRN:88140658		
J	Wang, Yu; Liu, Xiaogeng; Li, Yu; Chen, Muhao; Xiao, Chaowei				Li, yu/HHZ-5236-2022; Liu, Xiaogeng/KIJ-1671-2024; Xiao, Chaowei/AAT-8772-2021; Chen, Muhao/AAA-3634-2021						AdaShield: Safeguarding Multimodal Large Language Models from Structure-based Attack via Adaptive Shield Prompting								Arxiv											1	1;2024-03-14;https://www.arxiv.org/abs/2403.09513v1	arXiv:2403.09513			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Mar 14 2024	2024	With the advent and widespread deployment of Multimodal Large Language Models (MLLMs), the imperative to ensure their safety has become increasingly pronounced. However, with the integration of additional modalities, MLLMs are exposed to new vulnerabilities, rendering them prone to structured -based jailbreak attacks, where semantic content (e.g., “harmful text”) has been injected into the images to mislead MLLMs. In this work, we aim to defend against such threats. Specifically, we propose Adaptive Shield Prompting (AdaShield), which prepends inputs with defense prompts to defend MLLMs against structure -based jailbreak attacks without fine-tuning MLLMs or training additional modules (e.g., post -stage content detector). Initially, we present a manually designed static defense prompt, which thoroughly examines the image and instruction content step by step and specifies response methods to malicious queries. Furthermore, we introduce an adaptive auto -refinement framework, consisting of a target MLLM and a LLM-based defense prompt generator (Defender). These components collaboratively and iteratively communicate to generate a defense prompt. Extensive experiments on the popular structure -based jailbreak attacks and benign datasets show that our methods can consistently improve MLLMs’ robustness against structure -based jailbreak attacks without compromising the model’s general capabilities evaluated on standard benign tasks. Our code is available at https://github.com/rain305f/AdaShield.																																	2024-04-11	PPRN:88140966		
J	Zheng, Yuhang; Chen, Xiangyu; Zheng, Yupeng; Gu, Songen; Yang, Runyi; Jin, Bu; Li, Pengfei; Zhong, Chengliang; Wang, Zengmao; Liu, Lina; Yang, Chao; Wang, Dawei; Chen, Zhen; Long, Xiaoxiao; Wang, Meiqing				Liu, Lina/MEO-9051-2025; li, pengfei/JUU-2814-2023; Zheng, Yuhang/HGA-2457-2022						GaussianGrasper: 3D Language Gaussian Splatting for Open-vocabulary Robotic Grasping								Arxiv											1	1;2024-03-14;https://www.arxiv.org/abs/2403.09637v1	arXiv:2403.09637			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 14 2024	2024	Constructing a 3D scene capable of accommodating open-ended language queries, is a pivotal pursuit, particularly within the domain of robotics. Such technology facilitates robots in executing object manipulations based on human language directives. To tackle this challenge, some research efforts have been dedicated to the development of language-embedded implicit fields. However, implicit fields (e.g. NeRF) encounter limitations due to the necessity of processing a large number of input views for reconstruction, coupled with their inherent inefficiencies in inference. Thus, we present the GaussianGrasper, which utilizes 3D Gaussian Splatting to explicitly represent the scene as a collection of Gaussian primitives. Our approach takes a limited set of RGB-D views and employs a tile-based splatting technique to create a feature field. In particular, we propose an Efficient Feature Distillation (EFD) module that employs contrastive learning to efficiently and accurately distill language embeddings derived from foundational models. With the reconstructed geometry of the Gaussian field, our method enables the pre-trained grasping model to generate collision-free grasp pose candidates. Furthermore, we propose a normal-guided grasp module to select the best grasp pose. Through comprehensive real-world experiments, we demonstrate that GaussianGrasper enables robots to accurately query and grasp objects with language instructions, providing a new solution for language-guided manipulation tasks. Data and codes can be available at https://github.com/MrSecant/GaussianGrasper.																																	2024-04-11	PPRN:88144790		
J	Jiang, Dongsheng; Liu, Yuchen; Liu, Songlin; Zhao, Jin'e; Zhang, Hao; Gao, Zhen; Zhang, Xiaopeng; Li, Jin; Xiong, Hongkai				Jiang, dongsheng/JER-6737-2023; Li, Jin/J-7532-2019; Liu, Yuchen/AAH-6098-2021						From CLIP to DINO: Visual Encoders Shout in Multi-modal Large Language Models								Arxiv											2	2;2024-03-08;https://www.arxiv.org/abs/2310.08825v3| 1;2023-10-13;https://www.arxiv.org/abs/2310.08825v1	arXiv:2310.08825			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 08 2024	2024	Multi-modal Large Language Models (MLLMs) have made significant strides in expanding the capabilities of Large Language Models (LLMs) through the incorporation of visual perception interfaces. Despite the emergence of exciting applications and the availability of diverse instruction tuning data, existing approaches often rely on CLIP or its variants as the visual branch, and merely extract features from the deep layers. However, these methods lack a comprehensive analysis of the visual encoders in MLLMs. In this paper, we conduct an extensive investigation into the effectiveness of different vision encoders within MLLMs. Our findings reveal that the shallow layer features of CLIP offer particular advantages for fine-grained tasks such as grounding and region understanding. Surprisingly, the vision-only model DINO, which is not pretrained with text-image alignment, demonstrates promising performance as a visual branch within MLLMs. By simply equipping it with an MLP layer for alignment, DINO surpasses CLIP in fine-grained related perception tasks. Building upon these observations, we propose a simple yet effective feature merging strategy, named COMM, that integrates CLIP and DINO with Multi-level features Merging, to enhance the visual capabilities of MLLMs. We evaluate COMM through comprehensive experiments on a wide range of benchmarks, including image captioning, visual question answering, visual grounding, and object hallucination. Experimental results demonstrate the superior performance of COMM compared to existing methods, showcasing its enhanced visual capabilities within MLLMs.																																	2024-04-07	PPRN:85615214		
J	Sainz, Oscar; Garcia-Ferrero, Iker; Agerri, Rodrigo; de Lacalle, Oier Lopez; Rigau, German; Agirre, Eneko				Agerri, Rodrigo/ABA-4096-2021; Rigau, German/H-7235-2015; AGIRRE, ENEKO/H-7323-2015; Lopez de Lacalle, Oier/NCV-1224-2025						GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction								Arxiv											6	6;2024-03-06;https://www.arxiv.org/abs/2310.03668v5| 5;2024-02-21;https://www.arxiv.org/abs/2310.03668v4| 4;2023-12-11;https://www.arxiv.org/abs/2310.03668v3| 3;2023-10-06;https://www.arxiv.org/abs/2310.03668v2| 2;2023-10-05;https://www.arxiv.org/abs/2310.03668v1| 1;2023-10-05;https://www.arxiv.org/abs/2310.03668v1	arXiv:2310.03668			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Mar 06 2024	2024	Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task -specific models. Typically, IE tasks are characterized by complex annotation guidelines that describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out of the box. In this paper, we propose GoLLIE (Guideline - following Large Language Model for IE), a model able to improve zero -shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero -shot information extraction. The ablation study shows that detailed guidelines are key for good results. Code, data, and models are publicly available: https://github.com/hitz-zentroa/GoLLIE.																																	2024-04-01	PPRN:85430687		
J	Zhou, Zhenhong; Xiang, Jiuyang; Chen, Haopeng; Liu, Quan; Li, Zherui; Su, Sen										Speak Out of Turn: Safety Vulnerability of Large Language Models in Multi-turn Dialogue								Arxiv											1	1;2024-02-27;https://www.arxiv.org/abs/2402.17262v1	arXiv:2402.17262			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 27 2024	2024	Large Language Models (LLMs) have been demonstrated to generate illegal or unethical responses, particularly when subjected to "jailbreak." Research on jailbreak has highlighted the safety issues of LLMs. However, prior studies have predominantly focused on single-turn dialogue, ignoring the potential complexities and risks presented by multi-turn dialogue, a crucial mode through which humans derive information from LLMs. In this paper, we argue that humans could exploit multi-turn dialogue to induce LLMs into generating harmful information. LLMs may not intend to reject cautionary or borderline unsafe queries, even if each turn is closely served for one malicious purpose in a multi-turn dialogue. Therefore, by decomposing an unsafe query into several sub-queries for multi-turn dialogue, we induced LLMs to answer harmful sub-questions incrementally, culminating in an overall harmful response. Our experiments, conducted across a wide range of LLMs, indicate current inadequacies in the safety mechanisms of LLMs in multi-turn dialogue. Our findings expose vulnerabilities of LLMs in complex scenarios involving multi-turn dialogue, presenting new challenges for the safety of LLMs.																																	2024-03-24	PPRN:87917330		
J	van Baalen, Mart; Kuzmin, Andrey; Nagel, Markus; Couperus, Peter; Bastoul, Cedric; Mahurin, Eric; Blankevoort, Tijmen; Whatmough, Paul				Kuzmin, Andrey/H-7880-2013						GPTVQ: The Blessing of Dimensionality for LLM Quantization								Arxiv											1	1;2024-02-23;https://www.arxiv.org/abs/2402.15319v1	arXiv:2402.15319			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 23 2024	2024	In this work we show that the size versus accuracy trade-off of neural network quantization can be significantly improved by increasing the quantization dimensionality. We propose the GPTVQ method, a new fast method for posttraining vector quantization (VQ) that scales well to Large Language Models (LLMs). Our method interleaves quantization of one or more columns with updates to the remaining unquantized weights, using information from the Hessian of the per -layer output reconstruction MSE. Quantization codebooks are initialized using an efficient data -aware version of the EM algorithm. The codebooks are then updated, and further compressed by using integer quantization and SVDbased compression. GPTVQ establishes a new state -of -the art in the size vs accuracy trade-offs on a wide range of LLMs such as Llama -v2 and Mistral. Furthermore, our method is efficient: on a single H100 it takes between 3 and 11 hours to process a Llamav2-70B model, depending on quantization setting. Lastly, with on -device timings for VQ decompression on a mobile CPU we show that VQ leads to improved latency compared to using a 4 -bit integer format. Our source code is available at https://github.com/ qualcomm-ai-research/gptvq.																																	2024-03-23	PPRN:87868513		
J	Cheng, Kai; Long, Xiaoxiao; Yang, Kaizhi; Yao, Yao; Yin, Wei; Ma, Yuexin; Wang, Wenping; Chen, Xuejin				zhu, xinge/LGZ-7330-2024						GaussianPro: 3D Gaussian Splatting with Progressive Propagation								Arxiv											1	1;2024-02-22;https://www.arxiv.org/abs/2402.14650v1	arXiv:2402.14650			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 22 2024	2024	The advent of 3D Gaussian Splatting (3DGS) has recently brought about a revolution in the field of neural rendering, facilitating high-quality renderings at real-time speed. However, 3DGS heavily depends on the initialized point cloud produced by Structure-from -Motion (SfM) techniques. When tackling with large-scale scenes that unavoidably contain texture-less surfaces, the SfM techniques always fail to produce enough points in these surfaces and cannot provide good initialization for 3DGS. As a result, 3DGS suffers from difficult optimization and low -quality renderings. In this paper, inspired by classical multi -view stereo (MVS) techniques, we propose GaussianPro, a novel method that applies a progressive propagation strategy to guide the densification of the 3D Gaussians. Compared to the simple split and clone strategies used in 3DGS, our method leverages the priors of the existing reconstructed geometries of the scene and patch matching techniques to produce new Gaussians with accurate positions and orientations. Experiments on both large-scale and small-scale scenes validate the effectiveness of our method, where our method significantly surpasses 3DGS on the Waymo dataset, exhibiting an improvement of 1.15dB in terms of PSNR.																																	2024-03-21	PPRN:87800395		
J	Prakash, Nikhil; Shaham, Tamar Rott; Haklay, Tal; Belinkov, Yonatan; Bau, David				Bau, David/KGM-5427-2024						Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking								Arxiv											1	1;2024-02-22;https://www.arxiv.org/abs/2402.14811v1	arXiv:2402.14811			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 22 2024	2024	Fine-tuning on generalized tasks such as instruction following, code generation, and mathematics has been shown to enhance language models' performance on a range of tasks. Nevertheless, explanations of how such fine-tuning influences the internal computations in these models remain elusive. We study how fine-tuning affects the internal mechanisms implemented in language models. As a case study, we explore the property of entity tracking, a crucial facet of language comprehension, where models fine-tuned on mathematics have substantial performance gains. We identify the mechanism that enables entity tracking and show that (i) in both the original model and its fine-tuned versions primarily the same circuit implements entity tracking. In fact, the entity tracking circuit of the original model on the fine-tuned versions performs better than the full original model. (ii) The circuits of all the models implement roughly the same functionality: Entity tracking is performed by tracking the position of the correct entity in both the original model and its fine-tuned versions. (iii) Performance boost in the fine-tuned models is primarily attributed to its improved ability to handle the augmented positional information. To uncover these findings, we employ: Patch Patching, DCM, which automatically detects model components responsible for specific semantics, and CMAP, a new approach for patching activations across models to reveal improved mechanisms. Our findings suggest that fine-tuning enhances, rather than fundamentally alters, the mechanistic operation of the model.																																	2024-03-21	PPRN:87804398		
J	Lyu, Qing; Shridhar, Kumar; Malaviya, Chaitanya; Zhang, Li; Elazar, Yanai; Tandon, Niket; Apidianaki, Marianna; Sachan, Mrinmaya; Callison-Burch, Chris				Malaviya, Chaitanya/NXC-5110-2025; Callison-Burch, Chris/A-3393-2010; Zhang, Li/IXW-4871-2023						Calibrating Large Language Models with Sample Consistency								Arxiv											1	1;2024-02-21;https://www.arxiv.org/abs/2402.13904v1	arXiv:2402.13904			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 21 2024	2024	Accurately gauging the confidence level of Large Language Models’ (LLMs) predictions is pivotal for their reliable application. However, LLMs are often uncalibrated inherently and elude conventional calibration techniques due to their proprietary nature and massive scale. In this work, we explore the potential of deriving confidence from the distribution of multiple randomly sampled model generations, via three measures of consistency. We perform an extensive evaluation across various open and closed -source models on nine reasoning datasets. Results show that consistency -based calibration methods outperform existing posthoc approaches. Meanwhile, we find that factors such as intermediate explanations, model scaling, and larger sample sizes enhance calibration, while instruction -tuning makes calibration more difficult. Moreover, confidence scores obtained from consistency have the potential to enhance model performance. Finally, we offer practical guidance on choosing suitable consistency metrics for calibration, tailored to the characteristics of various LMs.																																	2024-03-21	PPRN:87795828		
J	Kuang, Yuxuan; Lin, Hai; Jiang, Meng										OpenFMNav: Towards Open-Set Zero-Shot Object Navigation via Vision-Language Foundation Models								Arxiv											1	1;2024-02-16;https://www.arxiv.org/abs/2402.10670v1	arXiv:2402.10670			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 16 2024	2024	Object navigation (ObjectNav) requires an agent to navigate through unseen environments to find queried objects. Many previous methods attempted to solve this task by relying on supervised or reinforcement learning, where they are trained on limited household datasets with close-set objects. However, two key challenges are unsolved: understanding free-form natural language instructions that demand open-set objects, and generalizing to new environments in a zero-shot manner. Aiming to solve the two challenges, in this paper, we propose OpenFMNav, an Open-set Foundation Model based framework for zero-shot object Navigation. We first unleash the reasoning abilities of large language models (LLMs) to extract proposed objects from natural language instructions that meet the user's demand. We then leverage the generalizability of large vision language models (VLMs) to actively discover and detect candidate objects from the scene, building a Versatile Semantic Score Map (VSSM). Then, by conducting common sense reasoning on VSSM, our method can perform effective language-guided exploration and exploitation of the scene and finally reach the goal. By leveraging the reasoning and generalizing abilities of foundation models, our method can understand free-form human instructions and perform effective open-set zero-shot navigation in diverse environments. Extensive experiments on the HM3D ObjectNav benchmark show that our method surpasses all the strong baselines on all metrics, proving our method's effectiveness. Furthermore, we perform real robot demonstrations to validate our method's open-set-ness and generalizability to real-world environments.																																	2024-03-14	PPRN:87729987		
J	Shen, Tianhao; Li, Sun; Tu, Quan; Xiong, Deyi				Shen, Tianhao/OKS-3659-2025						RoleEval: A Bilingual Role Evaluation Benchmark for Large Language Models								Arxiv											2	2;2024-02-16;https://www.arxiv.org/abs/2312.16132v2| 1;2023-12-26;https://www.arxiv.org/abs/2312.16132v1	arXiv:2312.16132			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Feb 16 2024	2024	The rapid evolution of large language models necessitates effective benchmarks for evaluating their role knowledge, which is essential for establishing connections with the real world and providing more immersive interactions. This paper introduces RoleEval, a bilingual benchmark designed to assess the memorization, utilization, and reasoning capabilities of role knowledge. RoleEval comprises RoleEval-Global (including internationally recognized characters) and RoleEval-Chinese (including characters popular in China), with 6,000 Chinese-English parallel multiple-choice questions focusing on 300 influential people and fictional characters drawn from a variety of domains including celebrities, anime, comics, movies, TV series, games, and fictions. These questions cover basic knowledge and multi-hop reasoning abilities, aiming to systematically probe various aspects such as personal information, relationships, abilities, and experiences of the characters. To maintain high standards, we perform a hybrid quality check process combining both automatic and human verification, ensuring that the questions are diverse, challenging, and discriminative. Our extensive evaluations with RoleEval across various open-source and proprietary large language models, under both the zero- and few-shot settings, reveal insightful findings. Notably, while GPT-4 outperforms other models on RoleEval-Global, Chinese large language models excel on RoleEval-Chinese, highlighting significant knowledge distribution differences. We expect that RoleEval would highlight the significance of assessing role knowledge for large language models across various languages and cultural settings.																																	2024-03-14	PPRN:86827160		
J	Dong, Harry; Yang, Xinyu; Zhang, Zhenyu; Wang, Zhangyang; Chi, Yuejie; Chen, Beidi				Zhihua, Wang/AFO-5263-2022; Zhang, Zhenyu/AHD-3937-2022; Chi, Yuejie/AAG-5084-2019						Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference								Arxiv											1	1;2024-02-14;https://www.arxiv.org/abs/2402.09398v1	arXiv:2402.09398			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 14 2024	2024	Many computational factors limit broader deployment of large language models. In this paper, we focus on a memory bottleneck imposed by the key-value (KV) cache, a computational shortcut that requires storing previous KV pairs during decoding. While existing KV cache methods approach this problem by pruning or evicting large swaths of relatively less important KV pairs to dramatically reduce the memory footprint of the cache, they can have limited success in tasks that require recollecting a majority of previous tokens. To alleviate this issue, we propose LESS, a simple integration of a (nearly free) constant sized cache with eviction-based cache methods, such that all tokens can be queried at later decoding steps. Its ability to retain information throughout time shows merit on a variety of tasks where we demonstrate LESS can help reduce the performance gap from caching everything, sometimes even matching it, all while being efficient. Code can be found at https://github.com/hdong920/LESS.																																	2024-03-01	PPRN:87688703		
J	Schwinn, Leo; Dobre, David; Xhonneux, Sophie; Gidel, Gauthier; Gunnemann, Stephan				Schwinn, Leo/AGZ-7273-2022						Soft Prompt Threats: Attacking Safety Alignment and Unlearning in Open-Source LLMs through the Embedding Space								Arxiv											1	1;2024-02-14;https://www.arxiv.org/abs/2402.09063v1	arXiv:2402.09063			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 14 2024	2024	Current research in adversarial robustness of LLMs focuses on discrete input manipulations in the natural language space, which can be directly transferred to closed -source models. However, this approach neglects the steady progression of open -source models. As open -source models advance in capability, ensuring their safety also becomes increasingly imperative. Yet, attacks tailored to open -source LLMs that exploit full model access remain largely unexplored. We address this research gap and propose embedding space attack, which directly attacks the continuous embedding representation of input tokens. We find that embedding space attacks circumvent model alignments and trigger harmful behaviors more efficiently than discrete attacks or model fine-tuning. Furthermore, we present a novel threat model in the context of unlearning and show that embedding space attacks can extract supposedly deleted information from unlearned LLMs across multiple datasets and models. Our findings highlight embedding space attacks as an important threat model in open -source LLMs.																																	2024-03-01	PPRN:87688705		
J	Kabir, Samia; Udo-Imeh, David N.; Kou, Bonan; Zhang, Tianyi				Zhang, Tianyi/AAJ-6909-2020						Is Stack Overflow Obsolete? An Empirical Study of the Characteristics of ChatGPT Answers to Stack Overflow Questions								Arxiv											2	2;2024-02-07;https://www.arxiv.org/abs/2308.02312v4| 1;2023-08-07;https://www.arxiv.org/abs/2308.02312v2	arXiv:2308.02312			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 07 2024	2024	Q&A platforms have been crucial for the online help-seeking behavior of programmers. However, the recent popularity of ChatGPT is altering this trend. Despite this popularity, no comprehensive study has been conducted to evaluate the characteristics of ChatGPT's answers to programming questions. To bridge the gap, we conducted the first in-depth analysis of ChatGPT answers to 517 programming questions on Stack Overflow and examined the correctness, consistency, comprehensiveness, and conciseness of ChatGPT answers. Furthermore, we conducted a large-scale linguistic analysis, as well as a user study, to understand the characteristics of ChatGPT answers from linguistic and human aspects. Our analysis shows that 52% of ChatGPT answers contain incorrect information and 77% are verbose. Nonetheless, our user study participants still preferred ChatGPT answers 35% of the time due to their comprehensiveness and well-articulated language style. However, they also overlooked the misinformation in the ChatGPT answers 39% of the time. This implies the need to counter misinformation in ChatGPT answers to programming questions and raise awareness of the risks associated with seemingly correct answers.																																	2024-05-25	PPRN:74307012		
J	Basilakos, Spyros; Nanopoulos, Dimitri V.; Papanikolaou, Theodoros; Saridakis, Emmanuel N.; Tzerefos, Charalampos				Papanikolaou, Theodoros/AAA-2364-2022; Saridakis, Emmanuel/AAC-7172-2020; Basilakos, Spyridon/ITT-8405-2023						Gravitational wave signatures of no-scale Supergravity in NANOGrav and beyond								Arxiv											4	4;2024-02-06;https://www.arxiv.org/abs/2307.08601v5| 3;2023-10-02;https://www.arxiv.org/abs/2307.08601v4| 2;2023-09-05;https://www.arxiv.org/abs/2307.08601v3| 1;2023-07-17;https://www.arxiv.org/abs/2307.08601v1	arXiv:2307.08601			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 06 2024	2024	In this Letter, we derive for the first time a characteristic three -peaked GW signal within the framework of no -scale Supergravity, being the low -energy limit of Superstring theory. We concentrate on the primordial gravitational wave (GW) spectrum induced due to second -order gravitational interactions by inflationary curvature perturbations as well as by isocurvature energy density perturbations of primordial black holes (PBHs) both amplified due to the presence of an early matter -dominated era (eMD) era before Big Bang Nucleosythesis (BBN). In particular, we work with inflection -point inflationary potentials naturally -realised within Wess-Zumino type no -scale Supergravity and giving rise to the formation of microscopic PBHs triggering an eMD era and evaporating before BBN. Remarkably, we obtain an abundant production of gravitational waves at the frequency ranges of nHz, Hz and kHz and in strong agreement with Pulsar Time Array (PTA) GW data. Interestingly enough, a simultaneous detection of all three nHz, Hz and kHz GW peaks can constitute a potential observational signature for no -scale Supergravity.																																	2024-02-23	PPRN:73956918		
J	Kim, Sehoon; Moon, Suhong; Tabrizi, Ryan; Lee, Nicholas; Mahoney, Michael W.; Keutzer, Kurt; Gholami, Amir										An LLM Compiler for Parallel Function Calling								Arxiv											2	2;2024-02-06;https://www.arxiv.org/abs/2312.04511v2| 1;2023-12-07;https://www.arxiv.org/abs/2312.04511v1	arXiv:2312.04511			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 06 2024	2024	Recent language models have shown remarkable results on various complex reasoning benchmarks. The reasoning capabilities of LLMs enable them to execute external function calls to overcome their inherent limitations, such as knowledge cutoffs, poor arithmetic skills, or lack of access to private data. This development has allowed LLMs to select and coordinate multiple functions based on the context to tackle more complex problems. However, current methods for multiple function calling often require sequential reasoning and acting for each function which can result in high latency, cost, and sometimes inaccurate behavior. To address this, we introduce LLMCompiler, which executes functions in parallel to efficiently orchestrate multiple function calling. Drawing from the principles of classical compilers, LLMCompiler streamlines parallel function calling with three components: (i) an LLM Planner, formulating execution plans; (ii) a Task Fetching Unit, dispatching function calling tasks; and (iii) an Executor, executing these tasks in parallel. LLMCompiler automatically generates an optimized orchestration for the function calls and can be used with both open-source and closed-source models. We have benchmarked LLMCompiler on a range of tasks with different patterns of function calling. We observe consistent latency speedup of up to 3.7x, cost savings of up to 6.7x, and accuracy improvement of up to ~9% compared to ReAct.																																	2024-02-21	PPRN:86443140		
J	Lubinski, Thomas; Coffrin, Carleton; Mcgeoch, Catherine; Sathe, Pratik; Apanavicius, Joshua; Bernal Neira, David E.				Sathe, Pratik/LBH-6121-2024; Coffrin, Carleton/X-4340-2019						Optimization Applications as Quantum Performance Benchmarks								Arxiv											1	1;2024-02-01;https://www.arxiv.org/abs/2302.02278v2	arXiv:2302.02278			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 01 2024	2024	Combinatorial optimization is anticipated to be one of the primary use cases for quantum computation in the coming years. The Quantum Approximate Optimization Algorithm (QAOA) and Quantum Annealing (QA) can potentially demonstrate significant run-time performance benefits over current state-of-the-art solutions. Inspired by existing methods to characterize classical optimization algorithms, we analyze the solution quality obtained by solving Max-Cut problems using gate-model quantum devices and a quantum annealing device. This is used to guide the development of an advanced benchmarking framework for quantum computers designed to evaluate the trade-off between run-time execution performance and the solution quality for iterative hybrid quantum-classical applications. The framework generates performance profiles through compelling visualizations that show performance progression as a function of time for various problem sizes and illustrates algorithm limitations uncovered by the benchmarking approach. As an illustration, we explore the factors that influence quantum computing system throughput, using results obtained through execution on various quantum simulators and quantum hardware systems.																																	2024-02-19	PPRN:87507869		
J	Kaneko, Masahiro; Bollegala, Danushka; Okazaki, Naoaki; Baldwin, Timothy				Kaneko, Masahiro/ABH-5492-2022						Evaluating Gender Bias in Large Language Models via Chain-of-Thought Prompting								Arxiv											1	1;2024-01-28;https://www.arxiv.org/abs/2401.15585v1	arXiv:2401.15585			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 28 2024	2024	There exist both scalable tasks, like reading comprehension and fact-checking, where model performance improves with model size, and unscalable tasks, like arithmetic reasoning and symbolic reasoning, where model performance does not necessarily improve with model size. Large language models (LLMs) equipped with Chain-of-Thought (CoT) prompting are able to make accurate incremental predictions even on unscalable tasks. Unfortunately, despite their exceptional reasoning abilities, LLMs tend to internalize and reproduce discriminatory societal biases. Whether CoT can provide discriminatory or egalitarian rationalizations for the implicit information in unscalable tasks remains an open question. In this study, we examine the impact of LLMs' step-by-step predictions on gender bias in unscalable tasks. For this purpose, we construct a benchmark for an unscalable task where the LLM is given a list of words comprising feminine, masculine, and gendered occupational words, and is required to count the number of feminine and masculine words. In our CoT prompts, we require the LLM to explicitly indicate whether each word in the word list is a feminine or masculine before making the final predictions. With counting and handling the meaning of words, this benchmark has characteristics of both arithmetic reasoning and symbolic reasoning. Experimental results in English show that without step-by-step prediction, most LLMs make socially biased predictions, despite the task being as simple as counting words. Interestingly, CoT prompting reduces this unconscious social bias in LLMs and encourages fair predictions.																																	2024-05-25	PPRN:87392248		
J	Chen, Yanda; Zhao, Chen; Yu, Zhou; McKeown, Kathleen; He, He				Zhong, Tianyun/KUD-1348-2024; He, He/KIC-1868-2024						On the Relation between Sensitivity and Accuracy in In-context Learning								Arxiv											2	2;2024-01-27;https://www.arxiv.org/abs/2209.07661v3| 1;2022-09-16;https://www.arxiv.org/abs/2209.07661v1	arXiv:2209.07661			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 27 2024	2024	In-context learning (ICL) suffers from oversensitivity to the prompt, making it unreliable in real-world scenarios. We study the sensitivity of ICL with respect to multiple perturbation types. First, we find that label bias obscures the true sensitivity, and therefore prior work may have significantly underestimated ICL sensitivity. Second, we observe a strong negative correlation between ICL sensitivity and accuracy: predictions sensitive to perturbations are less likely to be correct. Motivated by these findings, we propose SENSEL, a few-shot selective prediction method that abstains from sensitive predictions. Experiments on ten classification datasets show that SENSEL consistently outperforms two commonly used confidence-based and entropy-based baselines on abstention decisions.																																	2024-05-25	PPRN:14964056		
J	Zhao, Yunpu; Zhang, Rui; Li, Wenyi; Huang, Di; Guo, Jiaming; Peng, Shaohui; Hao, Yifan; Wen, Yuanbo; Hu, Xing; Du, Zidong; Guo, Qi; Li, Ling; Chen, Yunji				黄, 笛/HPE-4754-2023; Guo, Jiaming/JTT-0166-2023; hao, yi/KHY-8135-2024; Wen, Yuanbo/NFR-9252-2025						Assessing and Understanding Creativity in Large Language Models								Arxiv											3	3;2024-01-23;https://www.arxiv.org/abs/2401.12491v1| 2;2024-01-23;https://www.arxiv.org/abs/2401.12491v1| 1;2024-01-23;https://www.arxiv.org/abs/2401.12491v1	arXiv:2401.12491			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 23 2024	2024	In the field of natural language processing, the rapid development of large language model (LLM) has attracted more and more attention. LLMs have shown a high level of creativity in various tasks, but the methods for assessing such creativity are inadequate. The assessment of LLM creativity needs to consider differences from humans, requiring multi-dimensional measurement while balancing accuracy and efficiency. This paper aims to establish an efficient framework for assessing the level of creativity in LLMs. By adapting the modified Torrance Tests of Creative Thinking, the research evaluates the creative performance of various LLMs across 7 tasks, emphasizing 4 criteria including Fluency, Flexibility, Originality, and Elaboration. In this context, we develop a comprehensive dataset of 700 questions for testing and an LLM-based evaluation method. In addition, this study presents a novel analysis of LLMs' responses to diverse prompts and role-play situations. We found that the creativity of LLMs primarily falls short in originality, while excelling in elaboration. Besides, the use of prompts and the role-play settings of the model significantly influence creativity. Additionally, the experimental results also indicate that collaboration among multiple LLMs can enhance originality. Notably, our findings reveal a consensus between human evaluations and LLMs regarding the personality traits that influence creativity. The findings underscore the significant impact of LLM design on creativity and bridges artificial intelligence and human creativity, offering insights into LLMs' creativity and potential applications.																																	2025-08-07	PPRN:87292121		
J	Deshmukh, Soham; Elizalde, Benjamin; Singh, Rita; Wang, Huaming										Pengi: An Audio Language Model for Audio Tasks								Arxiv											2	2;2024-01-19;https://www.arxiv.org/abs/2305.11834v2| 1;2023-05-19;https://www.arxiv.org/abs/2305.11834v1	arXiv:2305.11834			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jan 19 2024	2024	In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question & Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 22 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding																																	2024-05-25	PPRN:70569062		
J	Chen, Zehui; Du, Weihua; Zhang, Wenwei; Liu, Kuikun; Liu, Jiangning; Zheng, Miao; Zhuo, Jingming; Zhang, Songyang; Lin, Dahua; Chen, Kai; Zhao, Feng				Chen, Zehui/HDN-3605-2022; Lin, Dahua/W-6576-2019; Zhao, Feng/NGQ-9015-2025; Du, Weihua/JGM-9058-2023; Zhang, Songyang/GPX-5621-2022; Zhang, Wenwei/HKO-4277-2023						T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step								Arxiv											3	3;2024-01-15;https://www.arxiv.org/abs/2312.14033v3| 2;2024-01-04;https://www.arxiv.org/abs/2312.14033v2| 1;2023-12-21;https://www.arxiv.org/abs/2312.14033v1	arXiv:2312.14033			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jan 15 2024	2024	Large language models (LLM) have achieved remarkable performance on various NLP tasks and are augmented by tools for broader applications. Yet, how to evaluate and analyze the tool-utilization capability of LLMs is still under-explored. In contrast to previous works that evaluate models holistically, we comprehensively decompose the tool utilization into multiple sub-processes, including instruction following, planning, reasoning, retrieval, understanding, and review. Based on that, we further introduce T-Eval to evaluate the tool utilization capability step by step. T-Eval disentangles the tool utilization evaluation into several sub-domains along model capabilities, facilitating the inner understanding of both holistic and isolated competency of LLMs. We conduct extensive experiments on T-Eval and in-depth analysis of various LLMs. T-Eval not only exhibits consistency with the outcome-oriented evaluation but also provides a more fine-grained analysis of the capabilities of LLMs, providing a new perspective in LLM evaluation on tool-utilization ability. The benchmark will be available at https://github.com/open-compass/T-Eval.																																	2024-02-02	PPRN:86786109		
J	Wang, Weimin; Liu, Jiawei; Lin, Zhijie; Yan, Jiangqiao; Chen, Shuo; Low, Chetwin; Hoang, Tuyen; Wu, Jie; Liew, Jun Hao; Yan, Hanshu; Zhou, Daquan; Feng, Jiashi				Liu, Jiawei/JVZ-3421-2024; Lin, Zhijie/AAA-3254-2022; Feng, Jiashi/AGX-6209-2022						MagicVideo-V2: Multi-Stage High-Aesthetic Video Generation								Arxiv											1	1;2024-01-09;https://www.arxiv.org/abs/2401.04468v1	arXiv:2401.04468			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 09 2024	2024	The growing demand for high-fidelity video generation from textual descriptions has catalyzed significant research in this field. In this work, we introduce MagicVideo-V2 that integrates the text-to-image model, video motion generator, reference image embedding module and frame interpolation module into an end-to-end video generation pipeline. Benefiting from these architecture designs, MagicVideo-V2 can generate an aesthetically pleasing, high-resolution video with remarkable fidelity and smoothness. It demonstrates superior performance over leading Text-to-Video systems such as Runway, Pika 1.0, Morph, Moon Valley and Stable Video Diffusion model via user evaluation at large scale.																																	2024-01-26	PPRN:87083853		
J	Weyssow, Martin; Kamanda, Aton; Zhou, Xin; Sahraoui, Houari										CodeUltraFeedback: An LLM-as-a-Judge Dataset for Aligning Large Language Models to Coding Preferences								Arxiv											3	3;2024-12-27;https://www.arxiv.org/abs/2403.09032v3| 2;2024-08-07;https://www.arxiv.org/abs/2403.09032v2| 1;2024-03-14;https://www.arxiv.org/abs/2403.09032v1	arXiv:2403.09032			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 27 2024	2024	Evaluating the alignment of large language models (LLMs) with user-defined coding preferences is a challenging endeavour that requires a deep assessment of LLMs’ outputs. Existing methods and benchmarks rely primarily on automated metrics and static analysis tools, which often fail to capture the nuances of user instructions and LLM outputs. To address this gap, we propose using the LLM-as-a-Judge methodology to evaluate the alignment of LLMs with coding preferences. Based on this approach, we present CodeUltraFeedback, a comprehensive dataset designed to facilitate the evaluation and improvement of LLM alignment. CodeUltraFeedback consists of 10,000 coding instructions, each annotated with four responses generated from a diverse pool of 14 LLMs. These responses are ranked based on five distinct coding preferences using GPT-3.5 as a judge, providing both numerical scores and detailed textual feedback. Our analysis of CodeUltraFeedback reveals that responses from GPT-3.5 and GPT-4 are generally preferred over those from open-weight LLMs, highlighting significant differences in alignment between closed and open-weight models. In turn, we explore the usage of CodeUltraFeedback as feedback data to fine-tune and align CodeLlama-7B-Instruct using supervised fine-tuning (SFT) and reinforcement learning from AI feedback (RLAIF) with direct preference optimization (DPO). The resulting aligned CodeLlama7B-Instruct model outperforms larger LLMs in terms of alignment with coding preferences and shows improved functional correctness on the HumanEval+ benchmark compared to the original instruct model. Therefore, our contributions bridge the gap in preference tuning of LLMs for code and set the stage for further advancements in model alignment and RLAIF in automated software engineering.																																	2025-02-05	PPRN:88140613		
J	Zhang, Bingliang; Chu, Wenda; Berner, Julius; Meng, Chenlin; Anandkumar, Anima; Song, Yang				Meng, Chenlin/HKF-5727-2023						Improving Diffusion Inverse Problem Solving with Decoupled Noise Annealing								Arxiv											3	3;2025-08-15;https://www.arxiv.org/abs/2407.01521v3| 2;2024-12-18;https://www.arxiv.org/abs/2407.01521v2| 1;2024-07-01;https://www.arxiv.org/abs/2407.01521v1	arXiv:2407.01521			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 18 2024	2024	Diffusion models have recently achieved success in solving Bayesian inverse problems with learned data priors. Current methods build on top of the diffusion sampling process, where each denoising step makes small modifications to samples from the previous step. However, this process struggles to correct errors from earlier sampling steps, leading to worse performance in complicated nonlinear inverse problems, such as phase retrieval. To address this challenge, we propose a new method called Decoupled Annealing Posterior Sampling (DAPS) that relies on a novel noise annealing process. Specifically, we decouple consecutive steps in a diffusion sampling trajectory, allowing them to vary considerably from one another while ensuring their time-marginals anneal to the true posterior as we reduce noise levels. This approach enables the exploration of a larger solution space, improving the success rate for accurate reconstructions. We demonstrate that DAPS significantly improves sample quality and stability across multiple image restoration tasks, particularly in complicated nonlinear inverse problems.																																	2025-01-26	PPRN:90658196		
J	Zhou, Yangqiaoyu; Liu, Haokun; Srivastava, Tejes; Mei, Hongyuan; Tan, Chenhao										Hypothesis Generation with Large Language Models								Arxiv											3	3;2024-12-18;https://www.arxiv.org/abs/2404.04326v3| 2;2024-08-23;https://www.arxiv.org/abs/2404.04326v2| 1;2024-04-05;https://www.arxiv.org/abs/2404.04326v1	arXiv:2404.04326			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Dec 18 2024	2024	Effective generation of novel hypotheses is instrumental to scientific progress. So far, researchers have been the main powerhouse behind hypothesis generation by painstaking data analysis and thinking (also known as the Eureka moment). In this paper, we examine the potential of large language models (LLMs) to generate hypotheses. We focus on hypothesis generation based on data (i.e., labeled examples). To enable LLMs to handle arbitrarily long contexts, we generate initial hypotheses from a small number of examples and then update them iteratively to improve the quality of hypotheses. Inspired by multi-armed bandits, we design a reward function to inform the exploitation-exploration tradeoff in the update process. Our algorithm is able to generate hypotheses that enable much better predictive performance than few-shot prompting in classification tasks, improving accuracy by 31.7% on a synthetic dataset and by 13.9%, 3.3% and, 24.9% on three real-world datasets. We also outperform supervised learning by 12.8% and 11.2% on two challenging real-world datasets. Furthermore, we find that the generated hypotheses not only corroborate human-verified theories but also uncover new insights for the tasks.																																	2025-01-28	PPRN:88447450		
J	Ankile, Lars; Simeonov, Anthony; Shenfeld, Idan; Torne, Marcel; Agrawal, Pulkit										From Imitation to Refinement -- Residual RL for Precise Assembly								Arxiv											4	4;2024-12-12;https://www.arxiv.org/abs/2407.16677v4| 3;2024-11-14;https://www.arxiv.org/abs/2407.16677v3| 2;2024-11-04;https://www.arxiv.org/abs/2407.16677v2| 1;2024-07-23;https://www.arxiv.org/abs/2407.16677v1	arXiv:2407.16677			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 12 2024	2024	Recent advances in Behavior Cloning (BC) have made it easy to teach robots new tasks. However, we find that the ease of teaching comes at the cost of unreliable performance that saturates with increasing data for tasks requiring precision. The performance saturation can be attributed to two critical factors: (a) distribution shift resulting from the use of offline data and (b) the lack of closed-loop corrective control caused by action chucking (predicting a set of future actions executed open-loop) critical for BC performance. Our key insight is that by predicting action chunks, BC policies function more like trajectory "planners" than closed-loop controllers necessary for reliable execution. To address these challenges, we devise a simple yet effective method, ResiP (Residual for Precise Manipulation), that overcomes the reliability problem while retaining BC's ease of teaching and long-horizon capabilities. ResiP augments a frozen, chunked BC model with a fully closed-loop residual policy trained with reinforcement learning (RL) that addresses distribution shifts and introduces closed-loop corrections over open-loop execution of action chunks predicted by the BC trajectory planner. 																																	2025-01-20	PPRN:91037866		
J	Foerster, Jakob N; Farquhar, Gregory; Afouras, Triantafyllos; Nardelli, Nantas; Whiteson, Shimon										Counterfactual Multi-Agent Policy Gradients								Arxiv											2	2;2024-12-11;https://www.arxiv.org/abs/1705.08926v3| 1;2017-12-14;https://www.arxiv.org/abs/1705.08926v2	arXiv:1705.08926			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 11 2024	2024	Many real-world problems, such as network packet routing and the coordination of autonomous vehicles, are naturally modelled as cooperative multi-agent systems. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents’ policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent’s action, while keeping the other agents’ actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor- critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state.																																	2025-01-19	PPRN:19313407		
J	Kohl, Georg; Chen, Li-Wei; Thuerey, Nils				Thuerey, Nils/D-3709-2014						Benchmarking Autoregressive Conditional Diffusion Models for Turbulent Flow Simulation								Arxiv											3	3;2024-12-11;https://www.arxiv.org/abs/2309.01745v3| 2;2024-01-29;https://www.arxiv.org/abs/2309.01745v2| 1;2023-09-04;https://www.arxiv.org/abs/2309.01745v1	arXiv:2309.01745			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 11 2024	2024	Simulating turbulent flows is crucial for a wide range of applications, and machine learning-based solvers are gaining increasing relevance. However, achieving temporal stability when generalizing to longer rollout horizons remains a persistent challenge for learned PDE solvers. In this work, we analyze if fully data-driven fluid solvers that utilize an autoregressive rollout based on conditional diffusion models are a viable option to address this challenge. We investigate accuracy, posterior sampling, spectral behavior, and temporal stability, while requiring that methods generalize to flow parameters beyond the training regime. To quantitatively and qualitatively benchmark the performance of various flow prediction approaches, three challenging 2D scenarios including incompressible and transonic flows, as well as isotropic turbulence are employed. We find that even simple diffusion-based approaches can outperform multiple established flow prediction methods in terms of accuracy and temporal stability, while being on par with state-of-the-art stabilization techniques like unrolling at training time. Such traditional architectures are superior in terms of inference speed, however, the probabilistic nature of diffusion approaches allows for inferring multiple predictions that align with the statistics of the underlying physics. Overall, our benchmark contains three carefully chosen data sets that are suitable for probabilistic evaluation alongside various established flow prediction architectures.																																	2025-01-19	PPRN:84734220		
J	Tan, Shuai; Gong, Biao; Wang, Xiang; Zhang, Shiwei; Zheng, Dandan; Zheng, Ruobing; Zheng, Kecheng; Chen, Jingdong; Yang, Ming				Yang, Ming/MAH-4542-2025; Zheng, Dandan/JJF-7988-2023						Animate-X: Universal Character Image Animation with Enhanced Motion Representation								Arxiv											1	1;2024-12-11;https://www.arxiv.org/abs/2410.10306v2	arXiv:2410.10306			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 11 2024	2024	Character image animation, which generates high-quality videos from a reference image and target pose sequence, has seen significant progress in recent years. However, most existing methods only apply to human figures, which usually do not generalize well on anthropomorphic characters commonly used in industries like gaming and entertainment. Our in-depth analysis suggests to attribute this limitation to their insufficient modeling of motion, which is unable to comprehend the movement pattern of the driving video, thus imposing a pose sequence rigidly onto the target character. To this end, this paper proposes Animate-X, a universal animation framework based on LDM for various character types (collectively named X ), including anthropomorphic characters. To enhance motion representation, we introduce the Pose Indicator, which captures comprehensive motion pattern from the driving video through both implicit and explicit manner. The former leverages CLIP visual features of a driving video to extract its gist of motion, like the overall movement pattern and temporal relations among motions, while the latter strengthens the generalization of LDM by simulating possible inputs in advance that may arise during inference. Moreover, we introduce a new Animated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of Animate-X on universal and widely applicable animation images. Extensive experiments demonstrate the superiority and effectiveness of Animate-X compared to state-of-the-art methods.																																	2025-01-19	PPRN:119845482		
J	Qi, Xiangyu; Wei, Boyi; Carlini, Nicholas; Huang, Yangsibo; Xie, Tinghao; He, Luxi; Jagielski, Matthew; Nasr, Milad; Mittal, Prateek; Henderson, Peter				He, Luxi/KBB-8984-2024; Qi, Xiangyu/GZM-8733-2022						On Evaluating the Durability of Safeguards for Open-Weight LLMs								Arxiv											1	1;2024-12-10;https://www.arxiv.org/abs/2412.07097v1	arXiv:2412.07097			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 10 2024	2024	Stakeholders -- from model developers to policymakers -- seek to minimize the dual-use risks of large language models (LLMs). An open challenge to this goal is whether technical safeguards can impede the misuse of LLMs, even when models are customizable via fine-tuning or when model weights are fully open. In response, several recent studies have proposed methods to produce durable LLM safeguards for open-weight LLMs that can withstand adversarial modifications of the model's weights via fine-tuning. This holds the promise of raising adversaries' costs even under strong threat models where adversaries can directly fine-tune model weights. However, in this paper, we urge for more careful characterization of the limits of these approaches. Through several case studies, we demonstrate that even evaluating these defenses is exceedingly difficult and can easily mislead audiences into thinking that safeguards are more durable than they really are. We draw lessons from the evaluation pitfalls that we identify and suggest future research carefully cabin claims to more constrained, well-defined, and rigorously examined threat models, which can provide more useful and candid assessments to stakeholders.																																	2025-01-18	PPRN:119815801		
J	Cheng, Xin; Wang, Xun; Zhang, Xingxing; Ge, Tao; Chen, Si-Qing; Wei, Furu; Zhang, Huishuai; Zhao, Dongyan				Zhang, Xingxing/KYQ-3478-2024						xRAG: Extreme Context Compression for Retrieval-augmented Generation with One Token								Arxiv											2	2;2024-12-09;https://www.arxiv.org/abs/2405.13792v2| 1;2024-05-22;https://www.arxiv.org/abs/2405.13792v1	arXiv:2405.13792			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 09 2024	2024	This paper introduces xRAG, a novel context compression method designed specifically for retrieval-augmented generation. xRAG redefines the use of document embeddings in dense retrieval—traditionally limited to retrieval purposes—by integrating them as features from the retrieval modality. Through a modality fusion approach, xRAG effectively merges these embeddings into the language model’s representation space, eliminating the need for their textual counterparts and achieving an extreme compression rate. In xRAG, the modality bridge is the only trainable component, while the retriever and language model remain frozen. This design choice allows for the reuse of offline-constructed document embeddings and preserves the plug-and-play nature of retrieval augmentation. Experimental results demonstrate that xRAG achieves an average improvement of over 10% across six knowledge-intensive tasks, compatible with various language model back bones, ranging from a dense 7B model to an 8x7B Mixture of Experts configuration. xRAG not only significantly outperforms previous context compression methods but also matches the performance of uncompressed models on several benchmarks, while reducing overall FLOPs by a factor of 3.53. This work pioneers new avenues in retrieval-augmented generation through multimodal fusion, potentially setting a groundwork for future developments in efficient and scalable retrieval systems.																																	2025-01-17	PPRN:88989858		
J	Viteritti, Luciano Loris; Rende, Riccardo; Parola, Alberto; Goldt, Sebastian; Becca, Federico				Goldt, Sebastian/AAQ-9486-2021; Parola, alberto/AAK-3748-2020						Transformer Wave Function for two dimensional frustrated magnets: emergence of a Spin-Liquid Phase in the Shastry-Sutherland Model								Arxiv											3	3;2024-11-28;https://www.arxiv.org/abs/2311.16889v3| 2;2024-02-12;https://www.arxiv.org/abs/2311.16889v2| 1;2023-11-28;https://www.arxiv.org/abs/2311.16889v1	arXiv:2311.16889			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 28 2024	2024	Understanding quantum magnetism in two-dimensional systems represents a lively branch in modern condensed-matter physics. In the presence of competing super-exchange couplings, magnetic order is frustrated and can be suppressed down to zero temperature. Still, capturing the correct nature of the exact ground state is a highly complicated task, since energy gaps in the spectrum may be very small and states with different physical properties may have competing energies. Here, we introduce a variational Ansatz for two-dimensional frustrated magnets by leveraging the power of representation learning. The key idea is to use a particular deep neural network with real-valued parameters, a so-called Transformer, to map physical spin configurations into a high-dimensional feature space. Within this abstract space, the determination of the ground-state properties is simplified and requires only a shallow output layer with complex-valued parameters. We illustrate the efficacy of this variational Ansatz by studying the ground-state phase diagram of the ShastrySutherland model, which captures the low-temperature behavior of SrCu2(BO3)2 with its intriguing properties. With highly accurate numerical simulations, we provide strong evidence for the stabilization of a spin-liquid between the plaquette and antiferromagnetic phases. In addition, a direct calculation of the triplet excitation at the Γ point provides compelling evidence for a gapless spin liquid. Our findings underscore the potential of Neural-Network Quantum States as a valuable tool for probing uncharted phases of matter, and open up new possibilities for establishing the properties of many-body systems.																																	2025-01-21	PPRN:86308443		
J	Wijk, Hjalmar; Lin, Tao; Becker, Joel; Jawhar, Sami; Parikh, Neev; Broadley, Thomas; Chan, Lawrence; Chen, Michael; Clymer, Josh; Dhyani, Jai; Ericheva, Elena; Garcia, Katharyn; Goodrich, Brian; Jurkovic, Nikola; Kinniment, Megan; Lajko, Aron; Nix, Seraphina; Sato, Lucas; Saunders, William; Taran, Maksym; West, Ben; Barnes, Elizabeth										RE-Bench: Evaluating frontier AI R&D capabilities of language model agents against human experts								Arxiv											1	1;2024-11-22;https://www.arxiv.org/abs/2411.15114v1	arXiv:2411.15114			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 22 2024	2024	Frontier AI safety policies highlight automation of AI research and development (R&D) by AI agents as an important capability to anticipate. However, there exist few evaluations for AI R&D capabilities, and none that are highly realistic and have a direct comparison to human performance. We introduce RE-Bench (Research Engineering Benchmark, v1), which consists of 7 challenging, open-ended ML research engineering environments and data from 71 8-hour attempts by 61 distinct human experts. We confirm that our experts make progress in the environments given 8 hours, with 82% of expert attempts achieving a non-zero score and 24% matching or exceeding our strong reference solutions. We compare humans to several public frontier models through best-of-k with varying time budgets and agent designs, and find that the best AI agents achieve a score 4x higher than human experts when both are given a total time budget of 2 hours per environment. However, humans currently display better returns to increasing time budgets, narrowly exceeding the top AI agent scores given an 8-hour budget, and achieving 2x the score of the top AI agent when both are given 32 total hours (across different attempts). Qualitatively, we find that modern AI agents possess significant expertise in many ML topics -- e.g. an agent wrote a faster custom Triton kernel than any of our human experts' -- and can generate and test solutions over ten times faster than humans, at much lower cost. We open-source the evaluation environments, human expert data, analysis code and agent trajectories to facilitate future research.1																																	2025-01-24	PPRN:119359661		
J	Chen, Xiangyu; Wang, Xintao; Zhang, Wenlong; Kong, Xiangtao; Qiao, Yu; Zhou, Jiantao; Dong, Chao				yu, qiao/GXH-3197-2022; Chen, Xiangyu/AEY-9113-2022						HAT: Hybrid Attention Transformer for Image Restoration								Arxiv											2	2;2024-11-17;https://www.arxiv.org/abs/2309.05239v2| 1;2023-09-11;https://www.arxiv.org/abs/2309.05239v1	arXiv:2309.05239			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 17 2024	2024	Transformer-based methods have shown impressive performance in image restoration tasks, such as image super-resolution and denoising. However, we find that these networks can only utilize a limited spatial range of input information through attribution analysis. This implies that the potential of Transformer is still not fully exploited in existing networks. In order to activate more input pixels for better restoration, we propose a new Hybrid Attention Transformer (HAT). It combines both channel attention and window-based self-attention schemes, thus making use of their complementary advantages. Moreover, to better aggregate the cross-window information, we introduce an overlapping cross-attention module to enhance the interaction between neighboring window features. In the training stage, we additionally adopt a same-task pre-training strategy to further exploit the potential of the model for further improvement. Extensive experiments have demonstrated the effectiveness of the proposed modules. We further scale up the model to show that the performance of the SR task can be greatly improved. Besides, we extend HAT to more image restoration applications, including real-world image super-resolution, Gaussian image denoising and image compression artifacts reduction. Experiments on benchmark and real-world datasets demonstrate that our HAT achieves state-of-the-art performance both quantitatively and qualitatively. 																																	2024-12-28	PPRN:84960374		
J	Bhardwaj, Lakshya; Pajer, Daniel; Schafer-Nameki, Sakura; Tiwari, Apoorv; Warman, Alison; Wu, Jingxiang				Bhardwaj, Lakshya/ISU-5186-2023; Wu, Jingxiang/IRZ-9481-2023						Gapped Phases in (2+1)d with Non-Invertible Symmetries: Part I								Arxiv											1	1;2024-11-14;https://www.arxiv.org/abs/2408.05266v2	arXiv:2408.05266			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 14 2024	2024	We use the Symmetry Topological Field Theory (SymTFT) to study and classify gapped phases in (2+1)d for a class of categorical symmetries, referred to as being of bosonic type. The SymTFTs for these symmetries are given by twisted and untwisted (3+1)d Dijkgraaf-Witten (DW) theories for finite groups G. A finite set of boundary conditions (BCs) of these DW theories is well-known: these simply involve imposing Dirichlet and Neumann conditions on the (3+1)d gauge fields. We refer to these as minimal BCs. The key new observation here is that for each DW theory, there exists an infinite number of other BCs, that we call non-minimal BCs. These non-minimal BCs are all obtained by a ‘theta construction’, which involves stacking the Dirichlet BC with 3d TFTs having G 0-form symmetry, and gauging the diagonal G symmetry. On the one hand, using the non-minimal BCs as symmetry BCs gives rise to an infinite number of non-invertible symmetries having the same SymTFT, while on the other hand, using the non-minimal BCs as physical BCs in the sandwich construction gives rise to an infinite number of (2+1)d gapped phases for each such non-invertible symmetry. Our analysis is thoroughly exemplified for G = Z2 and more generally any finite abelian group, for which the resulting non-invertible symmetries and their gapped phases already reveal an immensely rich structure.																																	2024-12-27	PPRN:119244124		
J	Xu, Zhi-Qin John; Zhang, Yaoyu; Luo, Tao										Overview frequency principle/spectral bias in deep learning								Arxiv											2	2;2024-11-12;https://www.arxiv.org/abs/2201.07395v4| 1;2022-01-19;https://www.arxiv.org/abs/2201.07395v1	arXiv:2201.07395			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Nov 12 2024	2024	Understanding deep learning is increasingly emergent as it penetrates more and more into industry and science. In recent years, a research line from Fourier analysis sheds lights on this magical “black box” by showing a Frequency Principle (F-Principle or spectral bias) of the training behavior of deep neural networks (DNNs) — DNNs often fit functions from low to high frequencies during the training. The F-Principle is first demonstrated by onedimensional synthetic data followed by the verification in high-dimensional real datasets. A series of works subsequently enhance the validity of the F-Principle. This low-frequency implicit bias reveals the strength of neural network in learning low-frequency functions as well as its deficiency in learning high-frequency functions. Such understanding inspires the design of DNN-based algorithms in practical problems, explains experimental phenomena emerging in various scenarios, and further advances the study of deep learning from the frequency perspective. Although incomplete, we provide an overview of F-Principle and propose some open problems for future research.																																	2024-12-18	PPRN:12055055		
J	Schwarzschild, Avi; Feng, Zhili; Maini, Pratyush; Lipton, Zachary C.; Kolter, J.Zico										Rethinking LLM Memorization through the Lens of Adversarial Compression								Arxiv											3	3;2024-11-11;https://www.arxiv.org/abs/2404.15146v3| 2;2024-07-01;https://www.arxiv.org/abs/2404.15146v2| 1;2024-04-23;https://www.arxiv.org/abs/2404.15146v1	arXiv:2404.15146			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 11 2024	2024	Large language models (LLMs) trained on web-scale datasets raise substantial concerns regarding permissible data usage. One major question is whether these models "memorize" all their training data or they integrate many data sources in some way more akin to how a human would learn and synthesize information. The answer hinges, to a large degree, on how we define memorization. In this work, we propose the Adversarial Compression Ratio (ACR) as a metric for assessing memorization in LLMs. A given string from the training data is considered memorized if it can be elicited by a prompt (much) shorter than the string itself - in other words, if these strings can be "compressed" with the model by computing adversarial prompts of fewer tokens. The ACR overcomes the limitations of existing notions of memorization by (i) offering an adversarial view of measuring memorization, especially for monitoring unlearning and compliance; and (ii) allowing for the flexibility to measure memorization for arbitrary strings at a reasonably low compute. Our definition serves as a practical tool for determining when model owners may be violating terms around data usage, providing a potential legal tool and a critical lens through which to address such scenarios. [GRAPHICS]																																	2024-12-18	PPRN:88622516		
J	Vasconcelos, Helena; Bansal, Gagan; Fourney, Adam; Liao, Q.Vera; Vaughan, Jennifer Wortman										Generation Probabilities Are Not Enough: Uncertainty Highlighting in AI Code Completions								Arxiv											2	2;2024-11-09;https://www.arxiv.org/abs/2302.07248v3| 1;2024-10-28;https://www.arxiv.org/abs/2302.07248v2	arXiv:2302.07248			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 09 2024	2024	Large-scale generative models have enabled the development of AI-powered code completion tools to assist programmers in writing code. Like all AI-powered tools, these code completion tools are not always accurate and can introduce bugs or even security vulnerabilities into code if not properly detected and corrected by a human programmer. One technique that has been proposed and implemented to help programmers locate potential errors is to highlight uncertain tokens. However, little is known about the effectiveness of this technique. Through a mixed-methods study with 30 programmers, we compare three conditions: providing the AI system’s code completion alone, highlighting tokens with the lowest likelihood of being generated by the underlying generative model, and highlighting tokens with the highest predicted likelihood of being edited by a programmer. We find that highlighting tokens with the highest predicted likelihood of being edited leads to faster task completion and more targeted edits, and is subjectively preferred by study participants. In contrast, highlighting tokens according to their probability of being generated does not provide any benefit over the baseline with no highlighting. We further explore the design space of how to convey uncertainty in AI-powered code completion tools and find that programmers prefer highlights that are granular, informative, interpretable, and not overwhelming. This work contributes to building an understanding of what uncertainty means for generative models and how to convey it effectively.																																	2024-12-19	PPRN:118902261		
J	Liu, Ryan; Geng, Jiayi; Wu, Addison J.; Sucholutsky, Ilia; Lombrozo, Tania; Griffiths, Thomas L.				Sucholutsky, Ilia/AAE-6498-2021						Mind Your Step (by Step): Chain-of-Thought can Reduce Performance on Tasks where Thinking Makes Humans Worse								Arxiv											3	3;2024-11-08;https://www.arxiv.org/abs/2410.21333v3| 2;2024-11-05;https://www.arxiv.org/abs/2410.21333v2| 1;2024-10-27;https://www.arxiv.org/abs/2410.21333v1	arXiv:2410.21333			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Nov 08 2024	2024	Chain-of-thought (CoT) prompting has become a widely used strategy for working with large language and multimodal models. While CoT has been shown to improve performance across many tasks, determining the settings in which it is effective remains an ongoing effort. In particular, it is still an open question in what settings CoT systematically reduces model performance. In this paper, we seek to identify the characteristics of tasks where CoT reduces performance by drawing inspiration from cognitive psychology, looking at cases where (i) verbal thinking or deliberation hurts performance in humans, and (ii) the constraints governing human performance generalize to language models. Three such cases are implicit statistical learning, visual recognition, and classifying with patterns containing exceptions. In extensive experiments across all three settings, we find that a diverse collection of state-of-the-art models exhibit significant drop-offs in performance (e.g., up to 36.3% absolute accuracy for OpenAI o1-preview compared to GPT-4o) when using inference-time reasoning compared to zero-shot counterparts. We also identify three tasks that satisfy condition (i) but not (ii), and find that while verbal thinking reduces human performance in these tasks, CoT retains or increases model performance. Overall, our results show that while there is not an exact parallel between the cognitive processes of models and those of humans, considering cases where thinking has negative consequences for human performance can help us identify settings where it negatively impacts models. By connecting the literature on human deliberation with evaluations of CoT, we offer a new tool that can be used in understanding the impact of prompt choices and inference-time reasoning.																																	2024-12-18	PPRN:118909719		
J	Fu, Tianyu; Huang, Haofeng; Ning, Xuefei; Zhang, Genghan; Chen, Boju; Wu, Tianqi; Wang, Hongyi; Huang, Zixiao; Li, Shiyao; Yan, Shengen; Dai, Guohao; Yang, Huazhong; Wang, Yu				Zheng, Shuangjia/JXR-6276-2024; Wang, Hongyi/KMA-5952-2024; Fu, Tianyu/KHY-8364-2024; Li, Shiyao/OYE-4903-2025; wu, tianqi/AAE-5548-2022						MoA: Mixture of Sparse Attention for Automatic Large Language Model Compression								Arxiv											2	2;2024-11-01;https://www.arxiv.org/abs/2406.14909v2| 1;2024-06-21;https://www.arxiv.org/abs/2406.14909v1	arXiv:2406.14909			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 01 2024	2024	Sparse attention can effectively mitigate the significant memory and throughput demands of Large Language Models (LLMs) in long contexts. Existing methods typically employ a uniform sparse attention mask, applying the same sparse pattern across different attention heads and input lengths. However, this uniform approach fails to capture the diverse attention patterns inherent in LLMs, ignoring their distinct accuracy-latency trade-offs. To address this challenge, we propose the Mixture of Attention (MoA), which automatically tailors distinct sparse attention configurations to different heads and layers. MoA constructs and navigates a search space of various attention patterns and their scaling rules relative to input sequence lengths. It profiles the model, evaluates potential configurations, and pinpoints the optimal sparse attention compression plan. MoA adapts to varying input sizes, revealing that some attention heads expand their focus to accommodate longer sequences, while other heads consistently concentrate on fixed-length local contexts. Experiments show that MoA increases the effective context length by 3.9× with the same average attention span, boosting retrieval accuracy by 1.5−7.1× over the uniform-attention baseline across Vicuna-{7B,13B}, and Llama3-{8B,70B} models. Moreover, MoA narrows the capability gaps between sparse and dense models, reducing the maximum relative performance drop from 9%−36% to within 5% across two long-context understanding benchmarks. MoA achieves a 1.2−1.4× GPU memory reduction, boosting decode throughput by 6.6−8.2× and 1.7−1.9× compared to FlashAttention2 and vLLM, with minimal impact on performance. 																																	2024-12-06	PPRN:89400983		
J	Li, Tianhong; Katabi, Dina; He, Kaiming										Return of Unconditional Generation: A Self-supervised Representation Generation Method								Arxiv											4	4;2024-11-01;https://www.arxiv.org/abs/2312.03701v4| 3;2024-03-13;https://www.arxiv.org/abs/2312.03701v3| 2;2023-12-08;https://www.arxiv.org/abs/2312.03701v2| 1;2023-12-06;https://www.arxiv.org/abs/2312.03701v1	arXiv:2312.03701			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 01 2024	2024	Unconditional generation -- the problem of modeling data distribution without relying on human-annotated labels -- is a long-standing and fundamental challenge in generative models, creating a potential of learning from large-scale unlabeled data. In the literature, the generation quality of an unconditional method has been much worse than that of its conditional counterpart. This gap can be attributed to the lack of semantic information provided by labels. In this work, we show that one can close this gap by generating semantic representations in the representation space produced by a self-supervised encoder. These representations can be used to condition the image generator. This framework, called Representation-Conditioned Generation (RCG), provides an effective solution to the unconditional generation problem without using labels. Through comprehensive experiments, we observe that RCG significantly improves unconditional generation quality: e.g., it achieves a new state-of-the-art FID of 2.15 on ImageNet 256x256, largely reducing the previous best of 5.91 by a relative 64%. Our unconditional results are situated in the same tier as the leading class-conditional ones. We hope these encouraging observations will attract the community's attention to the fundamental problem of unconditional generation. 																																	2024-12-09	PPRN:86419675		
J	Yan, Zhiyuan; Yao, Taiping; Chen, Shen; Zhao, Yandan; Fu, Xinghe; Zhu, Junwei; Luo, Donghao; Wang, Chengjie; Ding, Shouhong; Wu, Yunsheng; Yuan, Li				Shan, Caifeng/W-6178-2019						DF40: Toward Next-Generation Deepfake Detection								Arxiv											2	2;2024-10-31;https://www.arxiv.org/abs/2406.13495v2| 1;2024-06-19;https://www.arxiv.org/abs/2406.13495v1	arXiv:2406.13495			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Oct 31 2024	2024	We propose a new comprehensive benchmark to revolutionize the current deepfake detection field to the next generation. Predominantly, existing works identify top-notch detection algorithms and models by adhering to the common practice: training detectors on one specific dataset (e.g., FF++) and testing them on other prevalent deepfake datasets. This protocol is often regarded as a "golden compass" for navigating SoTA detectors. But can these stand-out "winners" be truly applied to tackle the myriad of realistic and diverse deepfakes lurking in the real world? If not, what underlying factors contribute to this gap? In this work, we found the dataset (both train and test) can be the "primary culprit" due to: (1) forgery diversity: Deepfake techniques are commonly referred to as both face forgery and entire image synthesis. Most existing datasets only contain partial types of them, with limited forgery methods implemented; (2) forgery realism: The dominated training dataset, FF++, contains out-of-date forgery techniques from the past four years. "Honing skills" on these forgeries makes it difficult to guarantee effective detection generalization toward nowadays' SoTA deepfakes; (3) evaluation protocol: Most detection works perform evaluations on one type, which hinders the development of universal deepfake detectors. To address this dilemma, we construct a highly diverse deepfake detection dataset called DF40, which comprises 40 distinct deepfake techniques. We then conduct comprehensive evaluations using 4 standard evaluation protocols and 8 representative detection methods, resulting in over 2,000 evaluations. Through these evaluations, we provide an extensive analysis from various perspectives, leading to 7 new insightful findings. We also open up 4 valuable yet previously underexplored research questions to inspire future works.  																																	2024-12-06	PPRN:89378070		
J	Zhang, Xuan; Du, Chao; Pang, Tianyu; Liu, Qian; Gao, Wei; Lin, Min				Tianyu, Pang/AAW-2653-2020						Chain of Preference Optimization: Improving Chain-of-Thought Reasoning in LLMs								Arxiv											2	2;2024-10-31;https://www.arxiv.org/abs/2406.09136v2| 1;2024-06-13;https://www.arxiv.org/abs/2406.09136v1	arXiv:2406.09136			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 31 2024	2024	The recent development of chain-of-thought (CoT) decoding has enabled large language models (LLMs) to generate explicit logical reasoning paths for complex problem-solving. However, research indicates that these paths are not always deliberate and optimal. The tree-of-thought (ToT) method employs tree-searching to extensively explore the reasoning space and find better reasoning paths that CoT decoding might overlook. This deliberation, however, comes at the cost of significantly increased inference complexity. In this work, we demonstrate that fine-tuning LLMs leveraging the search tree constructed by ToT allows CoT to achieve similar or better performance, thereby avoiding the substantial inference burden. This is achieved through Chain of Preference Optimization (CPO), where LLMs are fine-tuned to align each step of the CoT reasoning paths with those of ToT using the inherent preference information in the tree-search process. Extensive experimental results show that CPO significantly improves LLM performance in solving a variety of complex problems, including question answering, fact verification, and arithmetic reasoning, demonstrating its effectiveness. Our code is available at https://github.com/sail-sg/CPO.																																	2024-12-05	PPRN:89294131		
J	Brantner, Lukas; Mathew, Akhil										Deformation Theory and Partition Lie Algebras								Arxiv											2	2;2024-10-29;https://www.arxiv.org/abs/1904.07352v4| 1;2019-05-15;https://www.arxiv.org/abs/1904.07352v2	arXiv:1904.07352			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 29 2024	2024	A theorem of Lurie and Pridham establishes a correspondence between formal moduli problems and differential graded Lie algebras in characteristic zero, thereby formalising a wellknown principle in deformation theory. We introduce a variant of differential graded Lie algebras, called partition Lie algebras, in arbitrary characteristic. We then explicitly compute the homotopy groups of free algebras, which parametrise operations. Finally, we prove generalisations of the Lurie–Pridham correspondence classifying formal moduli problems via partition Lie algebras over an arbitrary field, as well as over a complete local base.																																	2024-12-03	PPRN:19383210		
J	Liu, Yantao; Yao, Zijun; Min, Rui; Cao, Yixin; Hou, Lei; Li, Juanzi				cao, yixin/ABV-6408-2022						RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style								Arxiv											1	1;2024-10-21;https://www.arxiv.org/abs/2410.16184v1	arXiv:2410.16184			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 21 2024	2024	Reward models are critical in techniques like Reinforcement Learning from Human Feedback (RLHF) and Inference Scaling Laws, where they guide language model alignment and select optimal responses. Despite their importance, existing reward model benchmarks often evaluate models by asking them to distinguish between responses generated by models of varying power. However, this approach fails to assess reward models on subtle but critical content changes and variations in style, resulting in a low correlation with policy model performance. To this end, we introduce RM-BENCH, a novel benchmark designed to evaluate reward models based on their sensitivity to subtle content differences and resistance to style biases. Extensive experiments demonstrate that RM-BENCH strongly correlates with policy model performance, making it a reliable reference for selecting reward models to align language models effectively. We evaluate nearly 40 reward models on RM-BENCH. Our results reveal that even state-of-the-art models achieve an average performance of only 46.6%, which falls short of random-level accuracy (50%) when faced with style bias interference. These findings highlight the significant room for improvement in current reward models. Related code and data are available at https://github.com/THU-KEG/RM-Bench.																																	2024-11-20	PPRN:118752788		
J	Krishna, Satyapriya; Krishna, Kalpesh; Mohananey, Anhad; Schwarcz, Steven; Stambler, Adam; Upadhyay, Shyam; Faruqui, Manaal										Fact, Fetch, and Reason: A Unified Evaluation of Retrieval-Augmented Generation								Arxiv											2	2;2024-10-18;https://www.arxiv.org/abs/2409.12941v2| 1;2024-09-19;https://www.arxiv.org/abs/2409.12941v1	arXiv:2409.12941			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 18 2024	2024	Large Language Models (LLMs) have demonstrated significant performance improvements across various cognitive tasks. An emerging application is using LLMs to enhance retrieval-augmented generation (RAG) capabilities. These systems require LLMs to understand user queries, retrieve relevant information, and synthesize coherent and accurate responses. Given the increasing real-world deployment of such systems, comprehensive evaluation becomes crucial. To this end, we propose FRAMES (Factuality, Retrieval, And reasoning MEasurement Set), a high-quality evaluation dataset designed to test LLMs' ability to provide factual responses, assess retrieval capabilities, and evaluate the reasoning required to generate final answers. While previous work has provided datasets and benchmarks to evaluate these abilities in isolation, FRAMES offers a unified framework that provides a clearer picture of LLM performance in end-to-end RAG scenarios. Our dataset comprises challenging multi-hop questions that require the integration of information from multiple sources. We present baseline results demonstrating that even state-of-the-art LLMs struggle with this task, achieving 0.40 accuracy with no retrieval. The accuracy is significantly improved with our proposed multi-step retrieval pipeline, achieving an accuracy of 0.66 (>50% improvement). We hope our work will help bridge evaluation gaps and assist in developing more robust and capable RAG systems.																																	2024-11-20	PPRN:92377559		
J	De, Arinjoy; Lerose, Alessio; Luo, De; Surace, Federica M.; Schuckert, Alexander; Bennewitz, Elizabeth R.; Ware, Brayden; Morong, William; Collins, Kate S.; Davoudi, Zohreh; Gorshkov, Alexey V.; Katz, Or; Monroe, Christopher				Gorshkov, Alexey/A-9848-2008; Surace, FedericaMaria/KRQ-7506-2024; Katz, Or/IQV-2714-2023; Monroe, Christopher/G-8105-2011						Observation of string-breaking dynamics in a quantum simulator								Arxiv											1	1;2024-10-17;https://www.arxiv.org/abs/2410.13815v1	arXiv:2410.13815			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 17 2024	2024	The spontaneous formation of particle pairs is one of the most intriguing phenomena in nature. A canonical example is when the potential energy between two elementary particles increases with their separation, as if the particles were confined to one another by a tense string. When the separation exceeds a critical value, new particle pairs can form, which causes the string to break. String-breaking dynamics in quantum chromodynamics, the theory of the strong force, play a fundamental role in high-energy particle collisions and the evolution of matter in the early universe. Simulating the evolution of strings and the formation of composite particles, or hadrons, is a grand challenge of modern physics. Quantum simulators are well suited to study dynamical processes. They are, therefore, expected to provide an edge over conventional methods based on classical computing. However, the experimental capabilities required to simulate the string-breaking phenomenon have not yet been demonstrated, even for simpler prototypical models of the strong force. In this work, we probe, for the first time on a quantum simulator, the spatiotemporally-resolved dynamics of string breaking in a (1 + 1)-dimensional Z2 lattice gauge theory, a theory that also exhibits confinement of charges. We employ a fully programmable trapped-ion quantum simulator, and emulate the effects of external static charges and strings via site-dependent control of magnetic fields, using a dual array of tightly focused laser beams targeting individual ions. First, we study the effect of confinement on the evolution of isolated charges. We find that these charges freely spread in the absence of string tension, but exhibit localized coherent oscillations as the string tension is increased. Then, we observe and characterize the breaking dynamics of a string initially stretched between two static charges, following an abrupt increase of the string tension. We find that charge pairs appear near the string edges and then spread out into the bulk, thereby identifying a route to dynamical string breaking that is distinct from the conventional Schwinger mechanism. This work, therefore, demonstrates that analog quantum simulators have achieved the control needed to uncover features of stringbreaking dynamics, which may ultimately be relevant to nuclear and high-energy physics.																																	2024-11-15	PPRN:115571547		
J	Wang, Xinyou; Zheng, Zaixiang; Ye, Fei; Xue, Dongyu; Huang, Shujian; Gu, Quanquan				Xue, Dongyu/JDC-4393-2023; El-Ashram, Saeed/AAC-6060-2021						Diffusion Language Models Are Versatile Protein Learners								Arxiv											2	2;2024-10-16;https://www.arxiv.org/abs/2402.18567v2| 1;2024-02-28;https://www.arxiv.org/abs/2402.18567v1	arXiv:2402.18567			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Oct 16 2024	2024	This paper introduces diffusion protein language model (DPLM), a versatile protein language model that demonstrates strong generative and predictive capabilities for protein sequences. We first pre-train scalable DPLMs from evolutionary-scale protein sequences within a generative self-supervised discrete diffusion probabilistic framework, which generalizes language modeling for proteins in a principled way. After pre-training, DPLM exhibits the ability to generate structurally plausible, novel, and diverse protein sequences for unconditional generation. We further demonstrate the proposed diffusion generative pre-training makes DPLM possess a better understanding of proteins, making it a superior representation learner, which can be fine-tuned for various predictive tasks, comparing favorably to ESM2 (Lin et al., 2022). Moreover, DPLM can be tailored for various needs, which showcases its prowess of conditional generation in several ways: (1) conditioning on partial peptide sequences, e.g., generating scaffolds for functional motifs with high success rate; (2) incorporating other modalities as conditioner, e.g., structure-conditioned generation for inverse folding; and (3) steering sequence generation towards desired properties, e.g., satisfying specified secondary structures, through a plug-and-play classifier guidance. 																																	2024-11-07	PPRN:88006493		
J	Li, Jiachen; Feng, Weixi; Fu, Tsu-Jui; Wang, Xinyi; Basu, Sugato; Chen, Wenhu; Wang, William Yang				Feng, Weixi/MGV-0350-2025						T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model with Mixed Reward Feedback								Arxiv											2	2;2024-10-11;https://www.arxiv.org/abs/2405.18750v2| 1;2024-05-29;https://www.arxiv.org/abs/2405.18750v1	arXiv:2405.18750			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 11 2024	2024	Diffusion-based text-to-video (T2V) models have achieved significant success but continue to be hampered by the slow sampling speed of their iterative sampling processes. To address the challenge, consistency models have been proposed to facilitate fast inference, albeit at the cost of sample quality. In this work, we aim to break the quality bottleneck of a video consistency model (VCM) to achieve both fast and high-quality video generation. We introduce T2V-Turbo, which integrates feedback from a mixture of differentiable reward models into the consistency distillation (CD) process of a pre-trained T2V model. Notably, we directly optimize rewards associated with single-step generations that arise naturally from computing the CD loss, effectively bypassing the memory constraints imposed by backpropagating gradients through an iterative sampling process. Remarkably, the 4-step generations from our T2V-Turbo achieve the highest total score on VBench [Huang et al., 2024], even surpassing Gen-2 [Esser et al., 2023] and Pika [Pika Labs, 2023]. We further conduct human evaluations to corroborate the results, validating that the 4-step generations from our T2V-Turbo are preferred over the 50-step DDIM samples from their teacher models, representing more than a tenfold acceleration while improving video generation quality.																																	2025-01-08	PPRN:89103427		
J	Capano, Collin D.; Abedi, Jahed; Kastha, Shilpa; Nitz, Alexander H.; Westerweck, Julian; Wang, Yi-Fan; Cabero, Miriam; Nielsen, Alex B.; Krishnan, Badri										Estimating False Alarm Rates of Sub-Dominant Quasi-normal Modes in GW190521								Arxiv											3	3;2024-10-07;https://www.arxiv.org/abs/2209.00640v4| 2;2023-10-05;https://www.arxiv.org/abs/2209.00640v3| 1;2022-09-01;https://www.arxiv.org/abs/2209.00640v1	arXiv:2209.00640			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 07 2024	2024	A major aim of gravitational wave astronomy is to test observationally the Kerr nature of black holes. The strongest such test, with minimal additional assumptions, is provided by observations of multiple ringdown modes, also known as black hole spectroscopy. For the gravitational wave merger event GW190521, we have previously claimed the detection of two ringdown modes emitted by the remnant black hole. In this paper we provide further evidence for the detection of multiple ringdown modes from this event. We analyse the recovery of simulated gravitational wave signals designed to replicate the ringdown properties of GW190521. We quantify how often our detection statistic reports strong evidence for a sub-dominant (ℓ, m, n) = (3, 3, 0) ringdown mode, even when no such mode is present in the simulated signal. We find this only occurs with a probability ∼ 0.02, which is consistent with a Bayes factor of 56 ± 1 (1σ uncertainty) found for GW190521. We also quantify our agnostic analysis of GW190521, in which no relationship is assumed between ringdown modes, and find that only 1 in 250 simulated signals without a (3, 3, 0) mode yields a result as significant as GW190521. Conversely, we verify that when simulated signals do have an observable (3, 3, 0) mode they consistently yield a strong evidence and significant agnostic results. We also find that constraints on deviations from the (3, 3, 0) mode on GW190521-like signals with a (3, 3, 0) mode are consistent with what was obtained from our previous analysis of GW190521. Our results support our previous conclusion that the gravitational wave signal from GW190521 contains an observable sub-dominant (ℓ, m, n) = (3, 3, 0) mode.																																	2024-10-24	PPRN:12881917		
J	Shen, Zhuocheng										LLM With Tools: A Survey								Arxiv											1	1;2024-09-24;https://www.arxiv.org/abs/2409.18807v1	arXiv:2409.18807			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 24 2024	2024	The integration of tools in augmenting large language models presents a novel approach toward enhancing the efficiency and accuracy of these models in handling specific, complex tasks. This paper delves into the methodology,challenges, and developments in the realm of teaching LLMs to use external tools, thereby pushing the boundaries of their capabilities beyond pre-existing knowledge bases. We introduce a standardized paradigm for tool integration guided by a series of functions that map user instructions to actionable plans and their execution, emphasizing the significance of understanding user intent, tool selection, and dynamic plan adjustment. Our exploration reveals the various challenges encountered, such as tool invocation timing, selection accuracy, and the need for robust reasoning processes. In addressing these challenges, we investigate techniques within the context of fine-tuning and incontext learning paradigms, highlighting innovative approaches to ensure diversity, augment datasets, and improve generalization.Furthermore, we investigate a perspective on enabling LLMs to not only utilize but also autonomously create tools, which may redefine their role from mere tool users to tool creators. Finally,we reproduced Chameleon's results on ScienceQA and analyzed the code structure.																																	2024-10-09	PPRN:100707680		
J	Eskimez, Sefik Emre; Wang, Xiaofei; Thakker, Manthan; Li, Canrun; Tsai, Chung-Hsien; Xiao, Zhen; Yang, Hemin; Zhu, Zirun; Tang, Min; Tan, Xu; Liu, Yanqing; Zhao, Sheng; Kanda, Naoyuki				Thakker, Manthan/KVY-3021-2024; Eskimez, Sefik Emre/AAB-3665-2022; Wang, Xiaofei/HGU-0957-2022; Yang, Hemin/ISU-1794-2023						E2TTS: Embarrassingly Easy Fully Non-Autoregressive Zero-Shot TTS								Arxiv											2	2;2024-09-12;https://www.arxiv.org/abs/2406.18009v2| 1;2024-06-26;https://www.arxiv.org/abs/2406.18009v1	arXiv:2406.18009			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 12 2024	2024	This paper introduces Embarrassingly Easy Text-to-Speech (E2 TTS), a fully non-autoregressive zero-shot text-to-speech system that offers human-level naturalness and state-of-the-art speaker similarity and intelligibility. In the E2 TTS framework, the text input is converted into a character sequence with filler tokens. The flow-matching-based mel spectrogram generator is then trained based on the audio infilling task. Unlike many previous works, it does not require additional components (e.g., duration model, grapheme-to-phoneme) or complex techniques (e.g., monotonic alignment search). Despite its simplicity, E2 TTS achieves state-of-the-art zero-shot TTS capabilities that are comparable to or surpass previous works, including Voicebox and NaturalSpeech 3. The simplicity of E2 TTS also allows for flexibility in the input representation. We propose several variants of E2 TTS to improve usability during inference. See https://aka.ms/e2tts/ for demo samples.																																	2024-09-27	PPRN:89878758		
J	Weibel, Andrea; de Graaff, Anna; Setton, David J.; Miller, Tim B.; Oesch, Pascal A.; Brammer, Gabriel; Lagos, Claudia D.P.; Whitaker, Katherine E.; Williams, Christina C.; Baggen, Josephine F.W.; Bezanson, Rachel; Boogaard, Leindert A.; Cleri, Nikko J.; Greene, Jenny E.; Hirschmann, Michaela; Hviding, Raphael E.; Kuruvanthodi, Adarsh; Labbe, Ivo; Leja, Joel; Maseda, Michael V.; Matthee, Jorryt; McConachie, Ian; Naidu, Rohan P.; Roberts-Borsani, Guido; Schaerer, Daniel; Suess, Katherine A.; Valentino, Francesco; van Dokkum, Pieter; Wang, Bingjie				Oesch, Pascal/AEF-7028-2022; Wang, Bingjie/GRR-9044-2022; Matthee, Jorryt/KHD-9384-2024; Brammer, Gabriel/AAB-4859-2020; Valentino, Francesco/NPI-4170-2025; Leja, Joel/JPL-7942-2023; Labbe, Ivo/B-1408-2016						RUBIES Reveals a Massive Quiescent Galaxy at z=7.3								Arxiv											1	1;2024-09-05;https://www.arxiv.org/abs/2409.03829v1	arXiv:2409.03829			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 05 2024	2024	We report the spectroscopic discovery of a massive quiescent galaxy at zspec = 7 . 29 ± 0 . 01, just ∼ 700 Myr after the Big Bang. RUBIES-UDS-QG-z7 was selected from public JWST/NIRCam and MIRI imaging from the PRIMER survey and observed with JWST/NIRSpec as part of RUBIES. The NIRSpec/PRISM spectrum reveals one of the strongest Balmer breaks observed thus far at z > 6, no emission lines, but tentative Balmer and Ca absorption features, as well as a Lyman break. Simultaneous modeling of the NIRSpec/PRISM spectrum and NIRCam and MIRI photometry (spanning 0 . 9 − 18 µm) shows that the galaxy formed a stellar mass of log(M∗/M⊙) = 10 . 23− 0.04+0.04 in a rapid ∼ 100 − 200 Myr burst of star formation at z ∼ 8 − 9, and ceased forming stars by z ∼ 8 resulting in log sSFR/yr−1 < −10. We measure a small physical size of 209−24+33 pc, which implies a high stellar mass surface density within the effective radius of log(Σ∗,e/M⊙ kpc−2) = 10.85− 0.12+0 . 11 comparable to the densities measured in quiescent galaxies at z ∼ 2 − 5. The 3D stellar mass density profile of RUBIESUDS-QG-z7 is remarkably similar to the central densities of local massive ellipticals, suggesting that at least some of their cores may have already been in place at z > 7. The discovery of RUBIES-UDSQG-z7 has strong implications for galaxy formation models: the estimated number density of quiescent galaxies at z ∼ 7 is > 100× larger than predicted from any model to date, indicating that quiescent galaxies have formed earlier than previously expected.																																	2024-12-16	PPRN:91787438		
J	Cendes, Yvette; Berger, Edo; Alexander, Kate D.; Chornock, Ryan; Margutti, Raffaella; Metzger, Brian; Wieringa, Mark H.; Bietenholz, Michael F.; Hajela, Aprajita; Laskar, Tanmoy; Stroh, Michael C.; Terreran, Giacomo				Metzger, Brian D./JQJ-5988-2023						Ubiquitous Late Radio Emission from Tidal Disruption Events								Arxiv											2	2;2024-09-04;https://www.arxiv.org/abs/2308.13595v2| 1;2023-08-25;https://www.arxiv.org/abs/2308.13595v1	arXiv:2308.13595			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Sep 04 2024	2024	We present radio observations of 23 optically-discovered tidal disruption events (TDEs) on timescales of ∼ 500 − 3200 days post-discovery. We detect 9 new TDEs that did not have detectable radio emission at earlier times, indicating a late-time brightening after several hundred (and up to 2300) days; an additional 7 TDEs exhibit radio emission whose origin is ambiguous or may be attributed to the host galaxy or an AGN. We also report a new rising component in one TDE previously detected in the radio at ∼ 103 days. While the radio emission in some of the detected TDEs peaked on a timescale ≈ 2 − 4 years, over half of the sample still shows rising emission. The range of luminosities for the sample is ∼ 1037 − 1039 erg s−1, about two orders of magnitude below the radio luminosity of the relativistic TDE Sw1644+57. Our data set indicates ∼40% of all optical TDEs are detected in radio hundreds to thousands of days after discovery, and that this is probably more common than early radio emission peaking at ∼ 102 days. Using an equipartition analysis, we find evidence for a delayed launch of the radio-emitting outflows, with delay timescales of ∼ 500 − 2000 days, inferred velocities of ≈ 0 .02 − 0 .15 c , and kinetic energies of ∼ 1047 − 1049 erg. We rule out off-axis relativistic jets as a viable explanation for this population, and conclude delayed outflows are a more likely explanation, possibly from delayed disk formation. We conclude late radio emission marks a fairly ubiquitous but heretofore overlooked phase of TDE evolution.																																	2024-09-13	PPRN:84364203		
J	Ribar, Luka; Chelombiev, Ivan; Hudlass-Galley, Luke; Blake, Charlie; Luschi, Carlo; Orr, Douglas										SparQ Attention: Bandwidth-Efficient LLM Inference								Arxiv											4	4;2024-09-04;https://www.arxiv.org/abs/2312.04985v6| 3;2024-07-19;https://www.arxiv.org/abs/2312.04985v5| 2;2024-07-15;https://www.arxiv.org/abs/2312.04985v4| 1;2023-12-08;https://www.arxiv.org/abs/2312.04985v1	arXiv:2312.04985			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Sep 04 2024	2024	The computational difficulties of large language model (LLM) inference remain a significant obstacle to their widespread deployment. The need for many applications to support long input sequences and process them in large batches typically causes token-generation to be bottlenecked by data transfer. For this reason, we introduce SparQ Attention, a technique for increasing the inference throughput of LLMs by utilising memory bandwidth more efficiently within the attention layers, through selective fetching of the cached history. Our proposed technique can be applied directly to off-the-shelf LLMs during inference, without requiring any modification to the pre-training setup or additional fine-tuning. We show that SparQ Attention brings up to 8x savings in attention data transfers without substantial drops in accuracy, by evaluating Llama 2 and 3, Mistral, Gemma and Pythia models on a wide range of downstream tasks.																																	2024-09-13	PPRN:86524687		
J	Lones, Michael A.										How to avoid machine learning pitfalls: a guide for academic researchers								Arxiv											3	3;2024-08-29;https://www.arxiv.org/abs/2108.02497v5| 2;2024-01-03;https://www.arxiv.org/abs/2108.02497v4| 1;2021-08-05;https://www.arxiv.org/abs/2108.02497v1	arXiv:2108.02497			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 29 2024	2024	Mistakes in machine learning practice are commonplace, and can result in a loss of confidence in the findings and products of machine learning. This guide outlines common mistakes that occur when using machine learning, and what can be done to avoid them. Whilst it should be accessible to anyone with a basic understanding of machine learning techniques, it focuses on issues that are of particular concern within academic research, such as the need to do rigorous comparisons and reach valid conclusions. It covers five stages of the machine learning process: what to do before model building, how to reliably build models, how to robustly evaluate models, how to compare models fairly, and how to report results.																																	2024-09-19	PPRN:12825318		
J	Liang, Xun; Wang, Hanyu; Wang, Yezhaohui; Song, Shichao; Yang, Jiawei; Niu, Simin; Hu, Jie; Liu, Dan; Yao, Shunyu; Xiong, Feiyu; Li, Zhiyu				Hu, Jie/JQI-6149-2023; Song, Shichao/GZA-6212-2022; Yang, Jiawei/AGH-2199-2022; Yao, Shunyu/GON-3893-2022						Controllable Text Generation for Large Language Models: A Survey								Arxiv											1	1;2024-08-22;https://www.arxiv.org/abs/2408.12599v1	arXiv:2408.12599			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 22 2024	2024	In Natural Language Processing (NLP), Large Language Models (LLMs) have demonstrated high text generation quality. However, in real-world applications, LLMs must meet increasingly complex requirements. Beyond avoiding misleading or inappropriate content, LLMs are also expected to cater to specific user needs, such as imitating particular writing styles or generating text with poetic richness. These varied demands have driven the development of Controllable Text Generation (CTG) techniques, which ensure that outputs adhere to predefined control conditions—such as safety, sentiment, thematic consistency, and linguistic style—while maintaining high standards of helpfulness, fluency, and diversity. This paper systematically reviews the latest advancements in CTG for LLMs, offering a comprehensive definition of its core concepts and clarifying the requirements for control conditions and text quality. We categorize CTG tasks into two primary types: content control and attribute control. The key methods are discussed, including model retraining, fine-tuning, reinforcement learning, prompt engineering, latent space manipulation, and decoding-time intervention. We analyze each method’s characteristics, advantages, and limitations, providing nuanced insights for achieving generation control. Additionally, we review CTG evaluation methods, summarize its applications across domains, and address key challenges in current research, including reduced fluency and practicality. We also propose several appeals, such as placing greater emphasis on real-world applications in future research. This paper aims to offer valuable guidance to researchers and developers in the field. .																																	2024-08-31	PPRN:91505875		
J	Spiess, Claudio; Gros, David; Pai, Kunal Suresh; Pradel, Michael; Rabin, Md Rafiqul Islam; Alipour, Amin; Jha, Susmit; Devanbu, Prem; Ahmed, Toufique				Spiess, Claudio/LNP-2362-2024; Jha, Susmit/B-4838-2013; Rabin, Md Rafiqul Islam/IZE-4194-2023						Calibration and Correctness of Language Models for Code								Arxiv											3	3;2024-08-21;https://www.arxiv.org/abs/2402.02047v4| 2;2024-02-16;https://www.arxiv.org/abs/2402.02047v3| 1;2024-02-03;https://www.arxiv.org/abs/2402.02047v1	arXiv:2402.02047			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Aug 21 2024	2024	Machine learning models are widely used, but can also often be wrong. Users would benefit from a reliable indication of whether a given output from a given model should be trusted, so a rational decision can be made whether to use the output or not. For example, outputs can be associated with a confidence measure; if this confidence measure is strongly associated with likelihood of correctness, then the model is said to be well-calibrated. A well-calibrated confidence measure can serve as a basis for rational, graduated decision-making on how much review and care is needed when using generated code. Calibration has so far been studied in mostly non-generative (e.g. classification) settings, especially in software engineering. However, generated code can quite often be wrong: Given generated code, developers must decide whether to use directly, use after varying intensity of careful review, or discard model-generated code. Thus, calibration is vital in generative settings. We make several contributions. We develop a framework for evaluating the calibration of code-generating models. We consider several tasks, correctness criteria, datasets, and approaches, and find that, by and large, generative code models we test are not well-calibrated out of the box. We then show how calibration can be improved using standard methods, such as Platt scaling. Since Platt scaling relies on the prior availability of correctness data, we evaluate the applicability and generalizability of Platt scaling in software engineering, discuss settings where it has good potential for practical use, and settings where it does not. Our contributions will lead to better-calibrated decision-making in the current use of code generated by language models, and offers a framework for future research to further improve calibration methods for generative models in software engineering.																																	2024-08-31	PPRN:87523807		
J	Teknium, Ryan; Quesnelle, Jeffrey; Guang, Chen										Hermes 3 Technical Report								Arxiv											1	1;2024-08-15;https://www.arxiv.org/abs/2408.11857v1	arXiv:2408.11857			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 15 2024	2024	Instruct (or “chat”) tuned models have become the primary way in which most people interact with large language models. As opposed to “base” or “foundation” models, instruct-tuned models are optimized to respond to imperative statements. We present Hermes 3, a neutrally-aligned generalist instruct and tool use model with strong reasoning and creative abilities. Its largest version, Hermes 3 405B, achieves state of the art performance among open weight models on several public benchmarks. The weights for all models are available at https://huggingface.co/NousResearch .																																	2024-08-31	PPRN:91505964		
J	Ning, Boyu; Yang, Songjie; Wu, Yafei; Wang, Peilan; Mei, Weidong; Yuen, Chau; Bjornson, Emil				Mei, Weidong/AFJ-9654-2022; Yang, Songjie/IRY-9429-2023; Yuen, Chau/C-5493-2013; Wu, Ya/L-8962-2019; Björnson, Emil/AAD-4840-2019						Movable Antenna-Enhanced Wireless Communications: General Architectures and Implementation Methods								Arxiv											1	1;2024-08-08;https://www.arxiv.org/abs/2407.15448v2	arXiv:2407.15448			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 08 2024	2024	Movable antennas (MAs), traditionally explored in antenna design, have recently garnered significant attention in wireless communications due to their ability to dynamically adjust the antenna positions to changes in the propagation environment. However, previous research has primarily focused on characterizing the performance limits of various MA-assisted wireless communication systems, with less emphasis on their practical implementation. To address this gap, in this article, we propose several general MA architectures that extend existing designs by varying several key aspects to cater to different application scenarios and tradeoffs between cost and performance. Additionally, we draw from fields such as antenna design and mechanical control to provide an overview of candidate implementation methods for the proposed MA architectures, utilizing either direct mechanical or equivalent electronic control. Simulation results are finally presented to support our discussion.																																	2024-08-17	PPRN:91291991		
J	Xu, Hongshen; Zhu, Zichen; Zhang, Situo; Ma, Da; Fan, Shuai; Chen, Lu; Yu, Kai				Yu, Kai/M-2934-2019; XU, Hongshen/HNS-5930-2023						Rejection Improves Reliability: Training LLMs to Refuse Unknown Questions Using RL from Knowledge Feedback								Arxiv											3	3;2024-08-08;https://www.arxiv.org/abs/2403.18349v3| 2;2024-04-07;https://www.arxiv.org/abs/2403.18349v2| 1;2024-03-27;https://www.arxiv.org/abs/2403.18349v1	arXiv:2403.18349			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 08 2024	2024	Large Language Models (LLMs) often generate erroneous outputs, known as hallucinations, due to their limitations in discerning questions beyond their knowledge scope. While addressing hallucination has been a focal point in research, previous efforts primarily concentrate on enhancing correctness without giving due consideration to the significance of rejection mechanisms. In this paper, we conduct a comprehensive examination of the role of rejection, introducing the notion of model reliability along with corresponding metrics. These metrics measure the model's ability to provide accurate responses while adeptly rejecting questions exceeding its knowledge boundaries, thereby minimizing hallucinations. To improve the inherent reliability of LLMs, we present a novel alignment framework called Reinforcement Learning from Knowledge Feedback (RLKF). RLKF leverages knowledge feedback to dynamically determine the model's knowledge boundary and trains a reliable reward model to encourage the refusal of out-of-knowledge questions. Experimental results on mathematical questions affirm the substantial efficacy of RLKF in significantly enhancing LLM reliability.																																	2024-08-21	PPRN:88335967		
J	Katz, Harley; Cameron, Alex J.; Saxena, Aayush; Barrufet, Laia; Choustikov, Nicholas; Cleri, Nikko J.; Graaff, Anna de; Ellis, Richard S.; Fosbury, Robert A.E.; Heintz, Kasper E.; Maseda, Michael; Matthee, Jorryt; McConchie, Ian; Oesch, Pascal A.				Matthee, Jorryt/KHD-9384-2024; Ellis, Richard/ABL-1310-2022; Oesch, Pascal/AFN-4775-2022						21 Balmer Jump Street: The Nebular Continuum at High Redshift and Implications for the Bright Galaxy Problem, UV Continuum Slopes, and Early Stellar Populations								Arxiv											1	1;2024-08-07;https://www.arxiv.org/abs/2408.03189v2	arXiv:2408.03189			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 07 2024	2024	We study, from both a theoretical and observational perspective, the physical origin and spectroscopic impact of extreme nebular emission in high-redshift galaxies. The nebular continuum, which can appear during an extreme starburst, is of particular importance as it tends to redden UV slopes and has a significant contribution to the UV luminosities of galaxies. Furthermore, its shape can be used to infer the gas density and temperature of the interstellar medium. First, we provide a theoretical background, showing how different stellar populations (SPS models, initial mass functions (IMFs), and stellar temperatures) and nebular conditions impact observed galaxy spectra. We demonstrate that, for systems with strong nebular continuum emission, 1)UV fluxes can increase by up to 0.7 magnitudes (or more in the case of hot/massive stars) above the stellar continuum, which may help reconcile the surprising abundance of bright high-redshift galaxies and the elevated UV luminosity density at z ≳ 10, 2) at high gas densities, UV slopes can redden from β ≲ −2.5 to β∼ −1, 3) observational measurements of ξion are grossly underestimated, and 4) UV downturns from two-photon emission can masquerade as damped Lyα systems. Second, we present a dataset of 58 galaxies observed with NIRSpec on JWST at 2.5 < z < 9.0 that are selected to have strong nebular continuum emission via the detection of the Balmer jump. Five of the 58 spectra are consistent with being dominated by nebular emission, exhibiting both a Balmer jump and a UV downturn consistent with two-photon emission. For some galaxies, this may imply the presence of hot massive stars and a top-heavy IMF. We conclude by exploring the properties of spectroscopically confirmed z > 10 galaxies, finding that UV slopes and UV downturns are in some cases redder or steeper than expected from SPS models, which may hint at more exotic (e.g. hotter/more massive stars or AGN) ionizing sources.																																	2024-08-23	PPRN:91273604		
J	Wan, Weilin; Dou, Zhiyang; Komura, Taku; Wang, Wenping; Jayaraman, Dinesh; Liu, Lingjie				Komura, Taku/ODJ-6678-2025; Dou, Zhiyang/JED-8952-2023; Liu, Lingjie/LIC-0932-2024; Jayaraman, Dinesh/AAI-2527-2021						TLControl: Trajectory and Language Control for Human Motion Synthesis								Arxiv											3	3;2024-07-24;https://www.arxiv.org/abs/2311.17135v4| 2;2023-12-12;https://www.arxiv.org/abs/2311.17135v3| 1;2023-11-30;https://www.arxiv.org/abs/2311.17135v2	arXiv:2311.17135			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jul 24 2024	2024	Controllable human motion synthesis is essential for applications in AR/VR, gaming and embodied AI. Existing methods often focus solely on either language or full trajectory control, lacking precision in synthesizing motions aligned with user-specified trajectories, especially for multi-joint control. To address these issues, we present TLControl, a novel method for realistic human motion synthesis, incorporating both low-level Trajectory and high-level Language semantics controls, through the integration of neural-based and optimization-based techniques. Specifically, we begin with training a VQ-VAE for a compact and well-structured latent motion space organized by body parts. We then propose a Masked Trajectories Transformer (MTT) for predicting a motion distribution conditioned on language and trajectory. Once trained, we use MTT to sample initial motion predictions given user-specified partial trajectories and text descriptions as conditioning. Finally, we introduce a test-time optimization to refine these coarse predictions for precise trajectory control, which offers flexibility by allowing users to specify various optimization goals and ensures high runtime efficiency. Comprehensive experiments show that TLControl significantly outperforms the state-of-the-art in trajectory accuracy and time efficiency, making it practical for interactive and high-quality animation generation.																																	2024-08-01	PPRN:86373218		
J	Wang, Junjie; Fang, Jiemin; Zhang, Xiaopeng; Xie, Lingxi; Tian, Qi				Wang, Junjie/PBU-8326-2025; Xie, Lingxi/ABF-6996-2020						GaussianEditor: Editing 3D Gaussians Delicately with Text Instructions								Arxiv											2	2;2024-07-24;https://www.arxiv.org/abs/2311.16037v2| 1;2023-11-27;https://www.arxiv.org/abs/2311.16037v1	arXiv:2311.16037			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 24 2024	2024	Recently, impressive results have been achieved in 3D scene editing with text instructions based on a 2D diffusion model. However, current diffusion models primarily generate images by predicting noise in the latent space, and the editing is usually applied to the whole image, which makes it challenging to perform delicate, especially localized, editing for 3D scenes. Inspired by recent 3D Gaussian splatting, we propose a systematic framework, named GaussianEditor, to edit 3D scenes delicately via 3D Gaussians with text instructions. Benefiting from the explicit property of 3D Gaussians, we design a series of techniques to achieve delicate editing. Specifically, we first extract the region of interest (RoI) corresponding to the text instruction, aligning it to 3D Gaussians. The Gaussian RoI is further used to control the editing process. Our framework can achieve more delicate and precise editing of 3D scenes than previous methods while enjoying much faster training speed, i.e. within 20 minutes on a single V100 GPU, more than twice as fast as Instruct-NeRF2NeRF (45 minutes -2 hours).																																	2024-07-31	PPRN:86295900		
J	Liu, Haisong; Chen, Yang; Wang, Haiguang; Yang, Zetong; Li, Tianyu; Zeng, Jia; Chen, Li; Li, Hongyang; Wang, Limin				Li, Hongyang/ABD-7455-2020; CHEN, Li/HIZ-5543-2022; Wang, Limin/AAE-3419-2019						Fully Sparse 3D Occupancy Prediction								Arxiv											4	4;2024-07-19;https://www.arxiv.org/abs/2312.17118v5| 3;2024-07-18;https://www.arxiv.org/abs/2312.17118v4| 2;2024-04-08;https://www.arxiv.org/abs/2312.17118v3| 1;2023-12-28;https://www.arxiv.org/abs/2312.17118v1	arXiv:2312.17118			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 19 2024	2024	Occupancy prediction plays a pivotal role in autonomous driving. Previous methods typically construct dense 3D volumes, neglecting the inherent sparsity of the scene and suffering from high computational costs. To bridge the gap, we introduce a novel fully sparse occupancy network, termed SparseOcc. SparseOcc initially reconstructs a sparse 3D representation from camera-only inputs and subsequently predicts semantic/instance occupancy from the 3D sparse representation by sparse queries. A mask-guided sparse sampling is designed to enable sparse queries to interact with 2D features in a fully sparse manner, thereby circumventing costly dense features or global attention. Additionally, we design a thoughtful ray-based evaluation metric, namely RayIoU, to solve the inconsistency penalty along the depth axis raised in traditional voxel-level mIoU criteria. SparseOcc demonstrates its effectiveness by achieving a RayIoU of 34.0, while maintaining a real-time inference speed of 17.3 FPS, with 7 history frames inputs. By incorporating more preceding frames to 15, SparseOcc continuously improves its performance to 35.1 RayIoU without bells and whistles.																																	2024-07-27	PPRN:86851639		
J	Chen, Chi-Fang; Haah, Jeongwan; Haferkamp, Jonas; Liu, Yunchao; Metger, Tony; Tan, Xinyu				Tan, Xinyu/AAX-9273-2021						Incompressibility and spectral gaps of random circuits								Arxiv											2	2;2024-07-09;https://www.arxiv.org/abs/2406.07478v2| 1;2024-06-11;https://www.arxiv.org/abs/2406.07478v1	arXiv:2406.07478			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 09 2024	2024	Random reversible and quantum circuits form random walks on the alternating group Alt(2n) and unitary group SU(2n), respectively. Known bounds on the spectral gap for the t-th moment of these random walks have inverse-polynomial dependence in both n and t. We prove that the gap for random reversible circuits is Ω(n−3) for all t≥1, and the gap for random quantum circuits is Ω(n−3) for t≤Θ(2n/2). These gaps are independent of t in the respective regimes. We can further improve both gaps to n−1/polylog(n,t) for t≤2Θ(n), which is tight up to polylog factors. Our spectral gap results have a number of consequences:<br /> 1) Random reversible circuits with O(n4t) gates form multiplicative-error t-wise independent (even) permutations for all t≥1; for t≤Θ(2n/6.1), we show that O~(n2t) gates suffice.<br /> 2) Random quantum circuits with O(n4t) gates form multiplicative-error unitary t-designs for t≤Θ(2n/2); for t≤Θ(22n/5), we show that O~(n2t) gates suffice.<br /> 3) The robust quantum circuit complexity of random circuits grows linearly for an exponentially long time, proving the robust Brown--Susskind conjecture [BS18,BCHJ+21].<br /> Our spectral gap bounds are proven by reducing random quantum circuits to a more structured walk: a modification of the "PFC ensemble'' from [MPSY24] together with an expander on the alternating group due to Kassabov [Kas07a], for which we give an efficient implementation using reversible circuits. In our reduction, we approximate the structured walk with local random circuits without losing the gap, which uses tools from the study of frustration-free Hamiltonians.																																	2024-07-21	PPRN:89279439		
J	Sun, Weisong; Miao, Yun; Li, Yuekang; Zhang, Hongyu; Fang, Chunrong; Liu, Yi; Deng, Gelei; Liu, Yang; Chen, Zhenyu				Fang, Chunrong/GPW-9872-2022; Sun, Weisong/AAU-9503-2020; Liu, Yang/D-2306-2013; Li, Yuekang/U-9646-2019; LIU, YI/LUY-0513-2024						Source Code Summarization in the Era of Large Language Models								Arxiv											2	2;2025-08-23;https://www.arxiv.org/abs/2407.07959v2| 1;2024-07-09;https://www.arxiv.org/abs/2407.07959v1	arXiv:2407.07959			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 09 2024	2024	To support software developers in understanding and maintaining programs, various automatic (source) code summarization techniques have been proposed to generate a concise natural language summary (i.e., comment) for a given code snippet. Recently, the emergence of large language models (LLMs) has led to a great boost in the performance of code-related tasks. In this paper, we undertake a systematic and comprehensive study on code summarization in the era of LLMs, which covers multiple aspects involved in the workflow of LLM-based code summarization. Specifically, we begin by examining prevalent automated evaluation methods for assessing the quality of summaries generated by LLMs and find that the results of the GPT-4 evaluation method are most closely aligned with human evaluation. Then, we explore the effectiveness of five prompting techniques (zero-shot, few-shot, chain-of-thought, critique, and expert) in adapting LLMs to code summarization tasks. Contrary to expectations, advanced prompting techniques may not outperform simple zero-shot prompting. Next, we investigate the impact of LLMs’ model settings (including top p and temperature parameters) on the quality of generated summaries. We find the impact of the two parameters on summary quality varies by the base LLM and programming language, but their impacts are similar. Moreover, we canvass LLMs’ abilities to summarize code snippets in distinct types of programming languages. The results reveal that LLMs perform suboptimally when summarizing code written in logic programming languages compared to other language types (e.g., procedural and object-oriented programming languages). Finally, we unexpectedly find that CodeLlamaInstruct with 7B parameters can outperform advanced GPT-4 in generating summaries describing code implementation details and asserting code properties. We hope that our findings can provide a comprehensive understanding of code summarization in the era of LLMs.																																	2024-07-25	PPRN:90839739		
J	Cauchois, Maxime; Gupta, Suyash; Ali, Alnur; Duchi, John C.				Gupta, Suyash/JZD-8659-2024						Robust Validation: Confident Predictions Even When Distributions Shift								Arxiv											2	2;2024-07-04;https://www.arxiv.org/abs/2008.04267v3| 1;2020-08-10;https://www.arxiv.org/abs/2008.04267v1	arXiv:2008.04267			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jul 04 2024	2024	While the traditional viewpoint in machine learning and statistics assumes training and testing samples come from the same population, practice belies this fiction. One strategy -- coming from robust statistics and optimization -- is thus to build a model robust to distributional perturbations. In this paper, we take a different approach to describe procedures for robust predictive inference, where a model provides uncertainty estimates on its predictions rather than point predictions. We present a method that produces prediction sets (almost exactly) giving the right coverage level for any test distribution in an $f$-divergence ball around the training population. The method, based on conformal inference, achieves (nearly) valid coverage in finite samples, under only the condition that the training data be exchangeable. An essential component of our methodology is to estimate the amount of expected future data shift and build robustness to it; we develop estimators and prove their consistency for protection and validity of uncertainty estimates under shifts. By experimenting on several large-scale benchmark datasets, including Recht et al.'s CIFAR-v4 and ImageNet-V2 datasets, we provide complementary empirical results that highlight the importance of robust predictive validity.																																	2024-07-20	PPRN:13154948		
J	Di Vecchia, Paolo; Heissenberg, Carlo; Russo, Rodolfo; Veneziano, Gabriele				Heissenberg, Carlo/IRZ-7872-2023						The gravitational eikonal: from particle, string and brane collisions to black-hole encounters								Arxiv											2	2;2024-07-04;https://www.arxiv.org/abs/2306.16488v2| 1;2023-06-28;https://www.arxiv.org/abs/2306.16488v1	arXiv:2306.16488			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jul 04 2024	2024	Motivated by conceptual problems in quantum theories of gravity, the gravitational eikonal approach, inspired by its electromagnetic predecessor, has been successfully applied to the transplanckian energy collisions of elementary particles and strings since the late eighties, and to string-brane collisions in the past decade. After the direct detection of gravitational waves from black-hole mergers, most of the attention has shifted towards adapting these methods to the physics of black-hole encounters. For such systems, the eikonal exponentiation provides an amplitude-based approach to calculate classical gravitational observables, thus complementing more traditional analytic methods such as the Post-Newtonian expansion, the worldline formalism, or the Effective-One-Body approach. In this review we summarize the main ideas and techniques behind the gravitational eikonal formalism. We discuss how it can be applied in various different physical setups involving particles, strings and branes and then we mainly concentrate on the most recent developments, focusing on massive scalars minimally coupled to gravity, for which we aim at being as self-contained and comprehensive as possible.																																	2024-07-21	PPRN:73646179		
J	Kollias, Dimitrios; Zafeiriou, Stefanos; Kotsia, Irene; Dhall, Abhinav; Ghosh, Shreya; Shao, Chunchang; Hu, Guanyu				KOLLIAS, DIMITRIOS/AAX-3397-2020; Hu, Guanyu/KHX-2301-2024; Ghosh, Shreya/AAG-3510-2020						7th ABAW Competition: Multi-Task Learning and Compound Expression Recognition								Arxiv											1	1;2024-07-01;	arXiv:2407.03835			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jul 01 2024	2024	This paper describes the 7th Affective Behavior Analysis in-the-wild (ABAW) Competition, which is part of the respective Workshop held in conjunction with ECCV 2024. The 7th ABAW Competition addresses novel challenges in understanding human expressions and behaviors, crucial for the development of human-centered technologies. The Competition comprises of two sub-challenges: i) Multi-Task Learning (the goal is to learn at the same time, in a multi-task learning setting, to estimate two continuous affect dimensions, valence and arousal, to recognise between the mutually exclusive classes of the 7 basic expressions and 'other'), and to detect 12 Action Units); and ii) Compound Expression Recognition (the target is to recognise between the 7 mutually exclusive compound expression classes). s-Aff-Wild2, which is a static version of the A/V Aff-Wild2 database and contains annotations for valence-arousal, expressions and Action Units, is utilized for the purposes of the Multi-Task Learning Challenge; a part of C-EXPR-DB, which is an A/V in-the-wild database with compound expression annotations, is utilized for the purposes of the Compound Expression Recognition Challenge. In this paper, we introduce the two challenges, detailing their datasets and the protocols followed for each. We also outline the evaluation metrics, and highlight the baseline systems and their results. 																																	2024-11-17	PPRN:118689369		
J	Liang, Aobo; Jiang, Xingguo; Sun, Yan; Shi, Xiaohou; Li, Ke										Bi-Mamba+: Bidirectional Mamba for Time Series Forecasting								Arxiv											3	3;2024-06-27;https://www.arxiv.org/abs/2404.15772v3| 2;2024-05-17;https://www.arxiv.org/abs/2404.15772v2| 1;2024-04-24;https://www.arxiv.org/abs/2404.15772v1	arXiv:2404.15772			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 27 2024	2024	Long-term time series forecasting (LTSF) provides longer insights into future trends and patterns. Over the past few years, deep learning models especially Transformers have achieved advanced performance in LTSF tasks. However, LTSF faces inherent challenges such as long-term dependencies capturing and sparse semantic characteristics. Recently, a new state space model (SSM) named Mamba is proposed. With the selective capability on input data and the hardware -aware parallel computing algorithm, Mamba has shown great potential in balancing predicting performance and computational efficiency compared to Transformers. To enhance Mamba’s ability to preserve historical information in a longer range, we design a novel Mamba+ block by adding a forget gate inside Mamba to selectively combine the new features with the historical features in a complementary manner. Furthermore, we apply Mamba+ both forward and backward and propose Bi-Mamba+, aiming to promote the model’s ability to capture interactions among time series elements. Additionally, multivariate time series data in different scenarios may exhibit varying emphasis on intra- or inter -series dependencies. Therefore, we propose a series -relation -aware decider that controls the utilization of channel -independent or channel -mixing tokenization strategy for specific datasets. Extensive experiments on 8 real -world datasets show that our model achieves better predictions compared with state-of-the-art methods. Our code is available at https://github.com/Leopold2333/Bi-Mamba+.																																	2024-07-17	PPRN:88635459		
J	Fang, Meng; Wan, Xiangpeng; Lu, Fei; Xing, Fei; Zou, Kai										MathOdyssey: Benchmarking Mathematical Problem-Solving Skills in Large Language Models Using Odyssey Math Data								Arxiv											1	1;2024-06-26;https://www.arxiv.org/abs/2406.18321v1	arXiv:2406.18321			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 26 2024	2024	Large language models (LLMs) have significantly advanced natural language understanding and demonstrated strong problem-solving abilities. Despite these successes, most LLMs still struggle with solving mathematical problems due to the intricate reasoning required. This paper investigates the mathematical problem-solving capabilities of LLMs using the newly developed "MathOdyssey" dataset. The dataset includes diverse mathematical problems at high school and university levels, created by experts from notable institutions to rigorously test LLMs in advanced problem-solving scenarios and cover a wider range of subject areas. By providing the MathOdyssey dataset as a resource to the AI community, we aim to contribute to the understanding and improvement of AI capabilities in complex mathematical problem-solving. We conduct benchmarking on open-source models, such as Llama-3 and DBRX-Instruct, and closed-source models from the GPT series and Gemini models. Our results indicate that while LLMs perform well on routine and moderately difficult tasks, they face significant challenges with Olympiad-level problems and complex university-level questions. Our analysis shows a narrowing performance gap between open-source and closed-source models, yet substantial challenges remain, particularly with the most demanding problems. This study highlights the ongoing need for research to enhance the mathematical reasoning of LLMs. 																																	2024-07-15	PPRN:89906864		
J	Yuan, Weizhe; Kulikov, Ilia; Yu, Ping; Cho, Kyunghyun; Sukhbaatar, Sainbayar; Weston, Jason; Xu, Jing										Following Length Constraints in Instructions								Arxiv											1	1;2024-06-25;https://www.arxiv.org/abs/2406.17744v1	arXiv:2406.17744			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 25 2024	2024	Aligned instruction following models can better fulfill user requests than their unaligned counterparts. However, it has been shown that there is a length bias in evaluation of such models, and that training algorithms tend to exploit this bias by learning longer responses. In this work we show how to train models that can be controlled at inference time with instructions containing desired length constraints. Such models are superior in length instructed evaluations, outperforming standard instruction following models such as GPT4, Llama 3 and Mixtral.																																	2024-07-15	PPRN:89543918		
J	Wang, Yuxuan; Wang, Yueqian; Zhao, Dongyan; Xie, Cihang; Zheng, Zilong										VideoHallucer: Evaluating Intrinsic and Extrinsic Hallucinations in Large Video-Language Models								Arxiv											1	1;2024-06-24;https://www.arxiv.org/abs/2406.16338v1	arXiv:2406.16338			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Jun 24 2024	2024	Recent advancements in Multimodal Large Language Models (MLLMs) have extended their capabilities to video understanding. Yet, these models are often plagued by “hallucinations”, where irrelevant or nonsensical content is generated, deviating from the actual video context. This work introduces VideoHallucer, the first comprehensive benchmark for hallucination detection in large video-language models (LVLMs). VideoHallucer categorizes hallucinations into two main types: intrinsic and extrinsic, offering further subcategories for detailed analysis, including object-relation, temporal, semantic detail, extrinsic factual, and extrinsic non-factual hallucinations. We adopt an adversarial binary VideoQA method for comprehensive evaluation, where pairs of basic and hallucinated questions are crafted strategically. By evaluating eleven LVLMs on VideoHallucer, we reveal that i) the majority of current models exhibit significant issues with hallucinations; ii) while scaling datasets and parameters improves models’ ability to detect basic visual cues and counterfactuals, it provides limited benefit for detecting extrinsic factual hallucinations; iii) existing models are more adept at detecting facts than identifying hallucinations. As a byproduct, these analyses further instruct the development of our self-PEP framework, achieving an average of 5.38% improvement in hallucination resistance across all model architectures.																																	2024-07-12	PPRN:89407195		
J	Cheon, Minjong				Cheon, Minjong/GWQ-4723-2022						Demonstrating the Efficacy of Kolmogorov-Arnold Networks in Vision Tasks								Arxiv											1	1;2024-06-21;https://www.arxiv.org/abs/2406.14916v1	arXiv:2406.14916			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jun 21 2024	2024	In the realm of deep learning, the Kolmogorov-Arnold Network (KAN) has emerged as a potential alternative to multilayer projections (MLPs). However, its applicability to vision tasks has not been extensively validated. In our study, we demonstrated the effectiveness of KAN for vision tasks through multiple trials on the MNIST, CIFAR10, and CIFAR100 datasets, using a training batch size of 32. Our results showed that while KAN outperformed the original MLP-Mixer on CIFAR10 and CIFAR100, it performed slightly worse than the state-of-the-art ResNet-18. These findings suggest that KAN holds significant promise for vision tasks, and further modifications could enhance its performance in future evaluations.Our contributions are threefold: first, we showcase the efficiency of KAN-based algorithms for visual tasks; second, we provide extensive empirical assessments across various vision benchmarks, comparing KAN's performance with MLP-Mixer, CNNs, and Vision Transformers (ViT); and third, we pioneer the use of natural KAN layers in visual tasks, addressing a gap in previous research. This paper lays the foundation for future studies on KANs, highlighting their potential as a reliable alternative for image classification tasks.																																	2025-08-07	PPRN:123172154		
J	Behrouz, Ali; Santacatterina, Michele; Zabih, Ramin				Santacatterina, Michele/AAL-5050-2020						MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection								Arxiv											3	3;2024-06-20;https://www.arxiv.org/abs/2403.19888v3| 2;2024-05-23;https://www.arxiv.org/abs/2403.19888v2| 1;2024-03-29;https://www.arxiv.org/abs/2403.19888v1	arXiv:2403.19888			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 20 2024	2024	Recent advances in deep learning have mainly relied on Transformers due to their data dependency and ability to learn at scale. The attention module in these architectures, however, exhibits quadratic time and space in input size, limiting their scalability for long-sequence modeling. Recently, State Space Models (SSMs), and more specifically Selective SSMs (S6), with e ffi cient hardware-aware implementation, have shown promising potential for long causal sequence modeling. They, however, use separate blocks for each channel and fail to filter irrelevant channels and capture inter-channel dependencies. Natural attempt to mix information across channels using MLP, attention, or SSMs results in further instability in the training of SSMs for large networks and / or nearly double the number of parameters. We present the MambaMixer block, a new SSM-based architecture with data-dependent weights that uses a dual selection mechanism across tokens and channels–called Selective Token and Channel Mixer. To mitigate doubling the number of parameters, we present a new non -causal heuristic of the S6 block using quasi-separable kernels with a hardware-friendly implementation that is nearly × 1 . 8 faster than its original implementation. Using this formulation, we further present an e ffi cient variant of MambaMixer, called QSMixer, that mixes information along both sequence and embedding dimensions. As a proof of concept, we design Vision MambaMixer (ViM2) and Vision QSMixer (ViQS) architectures. To enhance their ability to capture spatial information in images, we present the Switch of Scans (SoS) that dynamically uses a set of useful image scans to traverse image patches. They further use a gating mechanism that employs a stack of multi-resolution convolutions to enhance the multi-resolution receptive fields. We evaluate the performance of our methods in image classification, segmentation, and object detection. Our results underline the importance of selectively mixing across both tokens and channels and show the competitive (resp. superior) performance of our methods with well-established vision (resp. SSM-based) models.																																	2024-07-10	PPRN:88346302		
J	Liu, Xin; Zhu, Yichen; Lan, Yunshi; Yang, Chao; Qiao, Yu				Liu, Xin/MCX-7244-2025						Safety of Multimodal Large Language Models on Images and Texts								Arxiv											3	3;2024-06-20;https://www.arxiv.org/abs/2402.00357v3| 2;2024-02-25;https://www.arxiv.org/abs/2402.00357v2| 1;2024-02-01;https://www.arxiv.org/abs/2402.00357v1	arXiv:2402.00357			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 20 2024	2024	Attracted by the impressive power of Multimodal Large Language Models (MLLMs), the public is increasingly utilizing them to improve the efficiency of daily work. Nonetheless, the vulnerabilities of MLLMs to unsafe instructions bring huge safety risks when these models are deployed in real -world scenarios. In this paper, we systematically survey current efforts on the evaluation, attack, and defense of MLLMs’ safety on images and text. We begin with introducing the overview of MLLMs on images and text and understanding of safety, which helps researchers know the detailed scope of our survey. Then, we review the evaluation datasets and metrics for measuring the safety of MLLMs. Next, we comprehensively present attack and defense techniques related to MLLMs’ safety. Finally, we analyze several unsolved issues and discuss promising research directions. The relevant papers are collected at https://github.com/isXinLiu/AwesomeMLLM-Safety.																																	2024-07-10	PPRN:87455315		
J	He, Qianyu; Zeng, Jie; He, Qianxi; Liang, Jiaqing; Xiao, Yanghua				He, Qianxi/GON-5219-2022; Zeng, Jie/R-8591-2017; He, Qianyu/HNP-3602-2023						From Complex to Simple: Enhancing Multi-Constraint Complex Instruction Following Ability of Large Language Models								Arxiv											2	2;2024-06-18;https://www.arxiv.org/abs/2404.15846v2| 1;2024-04-24;https://www.arxiv.org/abs/2404.15846v1	arXiv:2404.15846			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 18 2024	2024	It is imperative for Large language models (LLMs) to follow instructions with elaborate requirements (i.e. Complex Instructions Following). Yet, it remains under-explored how to enhance the ability of LLMs to follow complex instructions with multiple constraints. To bridge the gap, we initially study what training data is effective in enhancing complex constraints following abilities. We found that training LLMs with instructions containing multiple constraints enhances their understanding of complex instructions, especially those with lower complexity levels. The improvement can even generalize to compositions of out-of-domain constraints. Additionally, we further propose methods addressing how to obtain and utilize the effective training data. Finally, we conduct extensive experiments to prove the effectiveness of our methods in terms of overall performance and training efficiency. We also demonstrate that our methods improve models' ability to follow instructions generally and generalize effectively across out-of-domain, in-domain, and adversarial settings, while maintaining general capabilities.																																	2024-07-04	PPRN:88635707		
J	Jin, Yiqiao; Zhao, Qinlin; Wang, Yiyang; Chen, Hao; Zhu, Kaijie; Xiao, Yijia; Wang, Jindong				Zhu, Kaijie/HTR-9850-2023; wang, jindong/ACD-8485-2022; XIAO, YIJIA/OLR-2697-2025; Jin, Yiqiao/ABD-3071-2022; Wang, Yiyang/OHU-7540-2025						AgentReview: Exploring Peer Review Dynamics with LLM Agents								Arxiv											2	2;2024-10-13;https://www.arxiv.org/abs/2406.12708v2| 1;2024-06-18;https://www.arxiv.org/abs/2406.12708v1	arXiv:2406.12708			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 18 2024	2024	Peer review is fundamental to the integrity and advancement of scientific publication. Traditional methods of peer review analyses often rely on exploration and statistics of existing peer review data, which do not adequately address the multivariate nature of the process, account for the latent variables, and are further constrained by privacy concerns due to the sensitive nature of the data. We introduce AgentReview, the first large language model (LLM) based peer review simulation framework, which effectively disentangles the impacts of multiple latent factors and addresses the privacy issue. Our study reveals significant insights, including a notable 37.1% variation in paper decisions due to reviewers' biases, supported by sociological theories such as the social influence theory, altruism fatigue, and authority bias. We believe that this study could offer valuable insights to improve the design of peer review mechanisms.																																	2025-08-07	PPRN:89358136		
J	Han, Bing; Zhou, Long; Liu, Shujie; Chen, Sanyuan; Meng, Lingwei; Qian, Yanming; Liu, Yanqing; Zhao, Sheng; Li, Jinyu; Wei, Furu				Chen, Sanyuan/GLR-3754-2022; jinyu, Li/JQV-7729-2023						VALL-E R: Robust and Efficient Zero-Shot Text-to-Speech Synthesis via Monotonic Alignment								Arxiv											1	1;2024-06-12;https://www.arxiv.org/abs/2406.07855v1	arXiv:2406.07855			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 12 2024	2024	With the help of discrete neural audio codecs, large language models (LLM) have increasingly been recognized as a promising methodology for zero-shot Text-to-Speech (TTS) synthesis. However, sampling based decoding strategies bring astonishing diversity to generation, but also pose robustness issues such as typos, omissions and repetition. In addition, the high sampling rate of audio also brings huge computational overhead to the inference process of autoregression. To address these issues, we propose VALL-E R, a robust and efficient zero-shot TTS system, building upon the foundation of VALL-E. Specifically, we introduce a phoneme monotonic alignment strategy to strengthen the connection between phonemes and acoustic sequence, ensuring a more precise alignment by constraining the acoustic tokens to match their associated phonemes. Furthermore, we employ a codec-merging approach to downsample the discrete codes in shallow quantization layer, thereby accelerating the decoding speed while preserving the high quality of speech output. Benefiting from these strategies, VALL-E R obtains controllablity over phonemes and demonstrates its strong robustness by approaching the WER of ground truth. In addition, it requires fewer autoregressive steps, with over 60% time reduction during inference. This research has the potential to be applied to meaningful projects, including the creation of speech for those affected by aphasia. [GRAPHIC]																																	2024-07-04	PPRN:89289807		
J	Dippel, Jonas; Feulner, Barbara; Winterhoff, Tobias; Milbich, Timo; Tietz, Stephan; Schallenberg, Simon; Dernbach, Gabriel; Kunft, Andreas; Heinke, Simon; Eich, Marie-Lisa; Ribbat-Idel, Julika; Krupar, Rosemarie; Anders, Philipp; Prenissl, Niklas; Jurmeister, Philipp; Horst, David; Ruff, Lukas; Mueller, Klaus-Robert; Klauschen, Frederick; Alber, Maximilian				Milbich, Timo/AAB-1249-2021; Mueller, Klaus-Robert/C-3196-2013; Klauschen, Frederick/OJS-9192-2025; Klauschen, Frederick/C-5637-2015; Jurmeister, Philipp/OIS-2772-2025						RudolfV: A Foundation Model by Pathologists for Pathologists								Arxiv											4	4;2024-06-11;https://www.arxiv.org/abs/2401.04079v4| 3;2024-03-12;https://www.arxiv.org/abs/2401.04079v3| 2;2024-01-23;https://www.arxiv.org/abs/2401.04079v2| 1;2024-01-08;https://www.arxiv.org/abs/2401.04079v1	arXiv:2401.04079			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Jun 11 2024	2024	Artificial intelligence has started to transform histopathology impacting clinical diagnostics and biomedical research. However, while many computational pathology approaches have been proposed, most current AI models are limited with respect to generalization, application variety, and handling rare diseases. Recent efforts introduced self-supervised foundation models to address these challenges, yet existing approaches do not leverage pathologist knowledge by design. In this study, we present a novel approach to designing foundation models for computational pathology, incorporating pathologist expertise, semi-automated data curation, and a diverse dataset from over 15 laboratories, including 58 tissue types, and encompassing 129 different histochemical and immunohistochemical staining modalities. We demonstrate that our model "RudolfV" surpasses existing state-of-the-art foundation models across different benchmarks focused on tumor microenvironment profiling, biomarker evaluation, and reference case search while exhibiting favorable robustness properties. Our study shows how domain-specific knowledge can increase the efficiency and performance of pathology foundation models and enable novel application areas.																																	2024-07-04	PPRN:87031584		
J	Khan, Mohammad Emtiyaz; Rue, Havard				Rue, Havard/OHR-8035-2025						The Bayesian Learning Rule								Arxiv											2	2;2024-06-08;https://www.arxiv.org/abs/2107.04562v4| 1;2022-03-18;https://www.arxiv.org/abs/2107.04562v2	arXiv:2107.04562			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jun 08 2024	2024	We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. . The rule, derived from Bayesian principles, yields a wide-range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton’s method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic-gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.																																	2024-07-04	PPRN:12113372		
J	Zheng, Xiaosen; Pang, Tianyu; Du, Chao; Liu, Qian; Jiang, Jing; Lin, Min				Zheng, Xiaosen/KFA-4269-2024; Tianyu, Pang/AAW-2653-2020; Wang, Jingjing/B-7476-2016						Improved Few-Shot Jailbreaking Can Circumvent Aligned Language Models and Their Defenses								Arxiv											1	1;2024-06-03;https://www.arxiv.org/abs/2406.01288v1	arXiv:2406.01288			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jun 03 2024	2024	Recently, Anil et al. [5] show that many-shot (up to hundreds of) demonstrations can jailbreak state-of-the-art LLMs by exploiting their long-context capability. Nevertheless, is it possible to use few-shot demonstrations to efficiently jailbreak LLMs within limited context sizes? While the vanilla few-shot jailbreaking may be inefficient, we propose improved techniques such as injecting special system tokens like [/INST] and employing demo-level random search from a collected demo pool. These simple techniques result in surprisingly effective jailbreaking against aligned LLMs (even with advanced defenses). For examples, our method achieves > 80% (mostly > 95%) ASRs on Llama-2-7B and Llama-3-8B without multiple restarts, even if the models are enhanced by strong defenses such as perplexity detection and/or SmoothLLM, which is challenging for suffix-based jailbreaking. In addition, we conduct comprehensive and elaborate (e.g., making sure to use correct system prompts) evaluations against other aligned LLMs and advanced defenses, where our method consistently achieves nearly 100% ASRs. 																																	2024-06-22	PPRN:89173544		
J	Cui, Mingyao; Dai, Linglong				Dai, Linglong/D-3023-2016						Near-Field Wideband Beamforming for Extremely Large Antenna Arrays								Arxiv											2	2;2024-06-01;https://www.arxiv.org/abs/2109.10054v4| 1;2023-08-22;https://www.arxiv.org/abs/2109.10054v3	arXiv:2109.10054			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Jun 01 2024	2024	The natural integration of extremely large antenna arrays (ELAAs) and terahertz (THz) communications can potentially achieve Tbps data rates in 6G networks. However, due to the extremely large array aperture and wide bandwidth, a new phenomenon called "near-field beam split" emerges. This phenomenon causes beams at different frequencies to focus on distinct physical locations, leading to a significant gain loss of beamforming. To address this challenging problem, we first harness a piecewise-far-field channel model to approximate the complicated near-field wideband channel. In this model, the entire large array is partitioned into several small sub-arrays. While the wireless channel's phase discrepancy across the entire array is modeled as near-field spherical, the phase discrepancy within each sub-array is approximated as far-field planar. Built on this approximation, a phase-delay focusing (PDF) method employing delay phase precoding (DPP) architecture is proposed. Our PDF method could compensate for the intra-array far-field phase discrepancy and the inter-array near-field phase discrepancy via the joint control of phase shifters and time delayers, respectively. Theoretical and numerical results are provided to demonstrate the efficiency of the proposed PDF method in mitigating the near-field beam split effect.Finally, we define and derive a novel metric termed the "effective Rayleigh distance" by the evaluation of beamforming gain loss. Compared to classical Rayleigh distance, the effective Rayleigh distance is more accurate in determining the near-field range for practical communications.																																	2024-11-09	PPRN:82340793		
J	Lin, Jessy; Du, Yuqing; Watkins, Olivia; Hafner, Danijar; Abbeel, Pieter; Klein, Dan; Dragan, Anca										Learning to Model the World with Language								Arxiv											2	2;2024-05-31;https://www.arxiv.org/abs/2308.01399v2| 1;2023-07-31;https://www.arxiv.org/abs/2308.01399v1	arXiv:2308.01399			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 31 2024	2024	To interact with humans and act in the world, agents need to understand the range of language that people use and relate it to the visual world. While current agents can learn to execute simple language instructions, we aim to build agents that leverage diverse language - language like "this button turns on the TV" or "I put the bowls away" - that conveys general knowledge, describes the state of the world, provides interactive feedback, and more. Our key idea is that agents should interpret such diverse language as a signal that helps them predict the future: what they will observe, how the world will behave, and which situations will be rewarded. This perspective unifies language understanding with future prediction as a powerful self-supervised learning objective. We instantiate this in Dynalang, an agent that learns a multimodal world model to predict future text and image representations, and learns to act from imagined model rollouts. While current methods that learn language-conditioned policies degrade in performance with more diverse types of language, we show that Dynalang learns to leverage environment descriptions, game rules, and instructions to excel on tasks ranging from game-playing to navigating photorealistic home scans. Finally, we show that our method enables additional capabilities due to learning a generative model: Dynalang can be pretrained on text-only data, enabling learning from offline datasets, and generate language grounded in an environment.																																	2024-06-19	PPRN:74242574		
J	Wang, Yuqing; Zhao, Yun				Wang, Yuqing/MCJ-1317-2025						TRAM: Benchmarking Temporal Reasoning for Large Language Models								Arxiv											2	2;2024-05-31;https://www.arxiv.org/abs/2310.00835v3| 1;2023-10-03;https://www.arxiv.org/abs/2310.00835v2	arXiv:2310.00835			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	May 31 2024	2024	Reasoning about time is essential for understanding the nuances of events described in natural language. Previous research on this topic has been limited in scope, characterized by a lack of standardized benchmarks that would allow for consistent evaluations across different studies. In this paper, we introduce TRAM, a temporal reasoning benchmark composed of ten datasets, encompassing various temporal aspects of events such as order, arithmetic, frequency, and duration, designed to facilitate a comprehensive evaluation of the TeR capabilities of large language models (LLMs). We evaluate popular LLMs like GPT-4 and Llama2 in zero-shot and few-shot scenarios, and establish baselines with BERT-based and domain-specific models. Our findings indicate that the best-performing model lags significantly behind human performance. It is our aspiration that TRAM will spur further progress in enhancing the TeR capabilities of LLMs.																																	2024-06-19	PPRN:85378460		
J	Hua, Wenyue; Ge, Yingqiang; Xu, Shuyuan; Ji, Jianchao; Zhang, Yongfeng				Xu, Shuyuan/KBP-9666-2024						UP5: Unbiased Foundation Model for Fairness-aware Recommendation								Arxiv											2	2;2024-05-29;https://www.arxiv.org/abs/2305.12090v2| 1;2023-05-20;https://www.arxiv.org/abs/2305.12090v1	arXiv:2305.12090			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 29 2024	2024	Recent advances in Foundation Models such as Large Language Models (LLMs) have propelled them to the forefront of Recommender Systems (RS). Despite their utility, there is a growing concern that LLMs might inadvertently perpetuate societal stereotypes, resulting in unfair recommendations. Since fairness is critical for RS as many users take it for decision-making and demand fulfillment, this paper focuses on user-side fairness for LLMbased recommendation where the users may require a recommender system to be fair on specific sensitive features such as gender or age. In this paper, we dive into the extent of unfairness exhibited by LLM-based recommender models based on both T5 and LLaMA backbones, and discuss appropriate methods for promoting equitable treatment of users in LLM-based recommendation models. We introduce a novel Counterfactually-Fair-Prompt (CFP) method towards Unbiased Foundation mOdels (UFO) for fairness-aware LLM-based recommendation. Experiments are conducted on two real-world datasets, MovieLens-1M and Insurance, and compared with both matchingbased and sequential-based fairness-aware recommendation models. Results show that CFP achieves better recommendation performance with a high level of fairness. Source code is anonymously released for reproducibility1.																																	2024-06-16	PPRN:70821245		
J	Zhang, Yuhui; Unell, Alyssa; Wang, Xiaohan; Ghosh, Dhruba; Su, Yuchang; Schmidt, Ludwig; Yeung-Levy, Serena				Su, Yuchang/LEN-0594-2024; Zhang, Yuhui/IST-0722-2023						Why are Visually-Grounded Language Models Bad at Image Classification?								Arxiv											1	1;2024-05-28;https://www.arxiv.org/abs/2405.18415v1	arXiv:2405.18415			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 28 2024	2024	Image classification is one of the most fundamental capabilities of machine vision intelligence. In this work, we revisit the image classification task using visuallygrounded language models (VLMs) such as GPT-4V and LLaVA. We find that existing proprietary and public VLMs, despite often using CLIP as a vision encoder and having many more parameters, significantly underperform CLIP on standard image classification benchmarks like ImageNet. To understand the reason, we explore several hypotheses concerning the inference algorithms, training objectives, and data processing in VLMs. Our analysis reveals that the primary cause is datarelated: critical information for image classification is encoded in the VLM’s latent space but can only be effectively decoded with enough training data. Specifically, there is a strong correlation between the frequency of class exposure during VLM training and instruction -tuning and the VLM’s performance in those classes; when trained with sufficient data, VLMs can match the accuracy of state-of-the-art classification models. Based on these findings, we enhance a VLM by integrating classification -focused datasets into its training, and demonstrate that the enhanced classification performance of the VLM transfers to its general capabilities, resulting in an improvement of 11.8% on the newly collected ImageWikiQA dataset.																																	2024-06-12	PPRN:89086764		
J	Xie, Sirui; Xiao, Zhisheng; Kingma, Diederik P; Hou, Tingbo; Wu, Ying Nian; Murphy, Kevin; Salimans, Tim; Poole, Ben; Gao, Ruiqi				Gao, Rui-Qi/GRF-3082-2022; Hou, Tingbo/H-6978-2012; Murphy, Kevin/ITV-7419-2023						EM Distillation for One-step Diffusion Models								Arxiv											1	1;2024-05-27;https://www.arxiv.org/abs/2405.16852v1	arXiv:2405.16852			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 27 2024	2024	While diffusion models can learn complex distributions, sampling requires a computationally expensive iterative process. Existing distillation methods enable efficient sampling, but have notable limitations, such as performance degradation with very few sampling steps, reliance on training data access, or mode-seeking optimization that may fail to capture the full distribution. We propose EM Distillation (EMD), a maximum likelihood-based approach that distills a diffusion model to a one-step generator model with minimal loss of perceptual quality. Our approach is derived through the lens of Expectation-Maximization (EM), where the generator parameters are updated using samples from the joint distribution of the diffusion teacher prior and inferred generator latents. We develop a reparametrized sampling scheme and a noise cancellation technique that together stabilizes the distillation process. We further reveal an interesting connection of our method with existing methods that minimize mode-seeking KL. EMD outperforms existing one-step generative methods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares favorably with prior work on distilling text-to-image diffusion models.																																	2024-06-11	PPRN:89074604		
J	Shaikovski, George; Casson, Adam; Severson, Kristen; Zimmermann, Eric; Wang, Yi Kan; Kunz, Jeremy D.; Retamero, Juan A.; Oakley, Gerard; Klimstra, David; Kanan, Christopher; Hanna, Matthew; Zelechowski, Michal; Viret, Julian; Tenenholtz, Neil; Hall, James; Fusi, Nicolo; Yousfi, Razik; Hamilton, Peter; Moye, William A.; Vorontsov, Eugene; Liu, Siqi; Fuchs, Thomas J.				liu, siqi/HPF-1938-2023						PRISM: A Multi-Modal Generative Foundation Model for Slide-Level Histopathology								Arxiv											1	1;2024-05-22;https://www.arxiv.org/abs/2405.10254v2	arXiv:2405.10254			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	May 22 2024	2024	Foundation models in computational pathology promise to unlock the development of new clinical decision support systems and models for precision medicine. However, there is a mismatch between most clinical analysis, which is defined at the level of one or more whole slide images, and foundation models to date, which process the thousands of image tiles contained in a whole slide image separately. The requirement to train a network to aggregate information across a large number of tiles in multiple whole slide images limits these models’ impact. In this work, we present a slide-level foundation model for H&E-stained histopathology, PRISM, , that builds on Virchow tile embeddings and leverages clinical report text for pre-training. Using the tile embeddings, PRISM produces slide-level embeddings with the ability to generate clinical reports, resulting in several modes of use. Using text prompts, PRISM achieves zero-shot cancer detection and sub-typing performance approaching and surpassing that of a supervised aggregator model. Using the slide embeddings with linear classifiers, PRISM surpasses supervised aggregator models. Furthermore, we demonstrate that fine-tuning of the PRISM slide encoder yields label-efficient training for biomarker prediction, a task that typically suffers from low availability of training data; an aggregator initialized with PRISM and trained on as little as 10% of the training data can outperform a supervised baseline that uses all of the data.																																	2024-06-05	PPRN:88989370		
J	Alonso, Eloi; Jelley, Adam; Micheli, Vincent; Kanervisto, Anssi; Storkey, Amos; Pearce, Tim; Fleuret, Francois										Diffusion for World Modeling: Visual Details Matter in Atari								Arxiv											1	1;2024-05-20;https://www.arxiv.org/abs/2405.12399v1	arXiv:2405.12399			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 20 2024	2024	World models constitute a promising approach for training reinforcement learning agents in a safe and sample-efficient manner. Recent world models predominantly operate on sequences of discrete latent variables to model environment dynamics. However, this compression into a compact discrete representation may ignore visual details that are important for reinforcement learning. Concurrently, diffusion models have become a dominant approach for image generation, challenging wellestablished methods modeling discrete latents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a Model Of eNvironment Dreams), a reinforcement learning agent trained in a diffusion world model. We analyze the key design choices that are required to make diffusion suitable for world modeling, and demonstrate how improved visual details can lead to improved agent performance. DIA-- MOND achieves a mean human normalized score of 1.46 on the competitive Atari 100k benchmark; a new best for agents trained entirely within a world model. To foster future research on diffusion for world modeling, we release our code, agents and playable world models at https://github.com/eloialonso/diamond. .																																	2024-08-24	PPRN:91460492		
J	Chen, Zoey; Walsman, Aaron; Memmel, Marius; Mo, Kaichun; Fang, Alex; Vemuri, Karthikeya; Wu, Alan; Fox, Dieter; Gupta, Abhishek										URDFormer: A Pipeline for Constructing Articulated Simulation Environments from Real-World Images								Arxiv											2	2;2024-05-31;https://www.arxiv.org/abs/2405.11656v3| 1;2024-05-19;https://www.arxiv.org/abs/2405.11656v1	arXiv:2405.11656			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 19 2024	2024	Constructing simulation scenes that are both visually and physically realistic is a problem of practical interest in domains ranging from robotics to computer vision. This problem has become even more relevant as researchers wielding large data-hungry learning methods seek new sources of training data for physical decision-making systems. However, building simulation models is often still done by hand. A graphic designer and a simulation engineer work with predefined assets to construct rich scenes with realistic dynamic and kinematic properties. While this may scale to small numbers of scenes, to achieve the generalization properties that are required for data-driven robotic control, we require a pipeline that is able to synthesize large numbers of realistic scenes, complete with 'natural' kinematic and dynamic structures. To attack this problem, we develop models for inferring structure and generating simulation scenes from natural images, allowing for scalable scene generation from web-scale datasets. To train these image-to-simulation models, we show how controllable text-to-image generative models can be used in generating paired training data that allows for modeling of the inverse problem, mapping from realistic images back to complete scene models. We show how this paradigm allows us to build large datasets of scenes in simulation with semantic and physical realism. We present an integrated end-to-end pipeline that generates simulation scenes complete with articulated kinematic and dynamic structures from real-world images and use these for training robotic control policies. We then robustly deploy in the real world for tasks like articulated object manipulation. In doing so, our work provides both a pipeline for large-scale generation of simulation environments and an integrated system for training robust robotic control policies in the resulting environments.																																	2024-08-23	PPRN:89115795		
J	Wu, Chengyue; Ge, Yixiao; Guo, Qiushan; Wang, Jiahao; Liang, Zhixuan; Lu, Zeyu; Shan, Ying; Luo, Ping				Guo, Qiushan/KYP-2884-2024; Luo, Ping/HGE-7623-2022						Plot2Code: A Comprehensive Benchmark for Evaluating Multi-modal Large Language Models in Code Generation from Scientific Plots								Arxiv											1	1;2024-05-13;https://www.arxiv.org/abs/2405.07990v1	arXiv:2405.07990			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 13 2024	2024	The remarkable progress of Multi-modal Large Language Models (MLLMs) has attracted significant attention due to their superior performance in visual contexts. However, their capabilities in turning visual figure to executable code, have not been evaluated thoroughly. To address this, we introduce Plot2Code, a comprehensive visual coding benchmark designed for a fair and in-depth assessment of MLLMs. We carefully collect 132 manually selected high-quality matplotlib plots across six plot types from publicly available matplotlib galleries. For each plot, we carefully offer its source code, and an descriptive instruction summarized by GPT-4. This approach enables Plot2Code to extensively evaluate MLLMs' code capabilities across various input modalities. Furthermore, we propose three automatic evaluation metrics, including code pass rate, text-match ratio, and GPT-4V overall rating, for a fine-grained assessment of the output code and rendered images. Instead of simply judging pass or fail, we employ GPT-4V to make an overall judgement between the generated and reference images, which has been shown to be consistent with human evaluation. The evaluation results, which include analyses of 14 MLLMs such as the proprietary GPT-4V, Gemini-Pro, and the open-sourced Mini-Gemini, highlight the substantial challenges presented by Plot2Code. With Plot2Code, we reveal that most existing MLLMs struggle with visual coding for text-dense plots, heavily relying on textual instruction. We hope that the evaluation results from Plot2Code on visual coding will guide the future development of MLLMs.																																	2024-06-08	PPRN:89041754		
J	Chao, Rong; Cheng, Wen-Huang; La Quatra, Moreno; Siniscalchi, Sabato Marco; Yang, Chao-Han Huck; Fu, Szu-Wei; Tsao, Yu				La Quatra, Moreno/AET-2693-2022; Cheng, Wen-Huang/AAK-2774-2020; Siniscalchi, Sabato/I-3423-2012						An Investigation of Incorporating Mamba for Speech Enhancement								Arxiv											1	1;2024-05-10;https://www.arxiv.org/abs/2405.06573v1	arXiv:2405.06573			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 10 2024	2024	This work aims to study a scalable state-space model (SSM), Mamba, for the speech enhancement (SE) task. We exploit a Mamba-based regression model to characterize speech signals and build an SE system upon Mamba, termed SEMamba. We explore the properties of Mamba by integrating it as the core model in both basic and advanced SE systems, along with utilizing signal-level distances as well as metric-oriented loss functions. SEMamba demonstrates promising results and attains a PESQ score of 3.55 on the VoiceBank-DEMAND dataset. When combined with the perceptual contrast stretching technique, the proposed SEMamba yields a new state-of-the-art PESQ score of 3.69.																																	2024-06-06	PPRN:88996881		
J	Han, Seungwook; Shenfeld, Idan; Srivastava, Akash; Kim, Yoon; Agrawal, Pulkit										Value Augmented Sampling for Language Model Alignment and Personalization								Arxiv											1	1;2024-05-10;https://www.arxiv.org/abs/2405.06639v1	arXiv:2405.06639			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	May 10 2024	2024	Aligning Large Language Models (LLMs) to cater to different human preferences, learning new skills, and unlearning harmful behavior is an important problem. Search-based methods, such as Best-of-N or Monte-Carlo Tree Search, are performant, but impractical for LLM adaptation due to their high inference cost. On the other hand, using Reinforcement Learning (RL) for adaptation is computationally efficient, but performs worse due to the optimization challenges in co-training the value function and the policy. We present a new framework for reward optimization, Value Augmented Sampling (VAS), that can maximize different reward functions using data sampled from only the initial, frozen LLM. VAS solves for the optimal reward-maximizing policy without co-training the policy and the value function, making the optimization stable, outperforming established baselines, such as PPO and DPO, on standard benchmarks, and achieving comparable results to Best-of-128 with lower inference cost. Unlike existing RL methods that require changing the weights of the LLM, VAS does not require access to the weights of the pre-trained LLM. Thus, it can even adapt LLMs (e.g., ChatGPT), which are available only as APIs. In addition, our algorithm unlocks the new capability of composing several rewards and controlling the extent of each one during deployment time, paving the road ahead for the future of aligned, personalized LLMs.																																	2024-06-06	PPRN:88998773		
J	Li, Zhoubo; Zhang, Ningyu; Yao, Yunzhi; Wang, Mengru; Chen, Xi; Chen, Huajun				Zhang, Ningyu/AAQ-7391-2021; Huajun, Chen/B-6340-2013						UNVEILING THE PITFALLS OF KNOWLEDGE EDITING FOR LARGE LANGUAGE MODELS								Arxiv											4	4;2024-05-10;https://www.arxiv.org/abs/2310.02129v5| 3;2024-03-12;https://www.arxiv.org/abs/2310.02129v3| 2;2023-11-21;https://www.arxiv.org/abs/2310.02129v2| 1;2023-10-03;https://www.arxiv.org/abs/2310.02129v1	arXiv:2310.02129			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	May 10 2024	2024	As the cost associated with fine-tuning Large Language Models (LLMs) continues to rise, recent research efforts have pivoted towards developing methodologies to edit implicit knowledge embedded within LLMs. Yet, there's still a dark cloud lingering overhead -- will knowledge editing trigger butterfly effect? since it is still unclear whether knowledge editing might introduce side effects that pose potential risks or not. This paper pioneers the investigation into the potential pitfalls associated with knowledge editing for LLMs. To achieve this, we introduce new benchmark datasets and propose innovative evaluation metrics. Our results underline two pivotal concerns: (1) Knowledge Conflict: Editing groups of facts that logically clash can magnify the inherent inconsistencies in LLMs-a facet neglected by previous methods. (2) Knowledge Distortion: Altering parameters with the aim of editing factual knowledge can irrevocably warp the innate knowledge structure of LLMs. Experimental results vividly demonstrate that knowledge editing might inadvertently cast a shadow of unintended consequences on LLMs, which warrant attention and efforts for future works. Code and data are available at https://github.com/zjunlp/PitfallsKnowledgeEditing.																																	2024-06-08	PPRN:85378047		
J	Wan, Yixin; Subramonian, Arjun; Ovalle, Anaelia; Lin, Zongyu; Suvarna, Ashima; Chance, Christina; Bansal, Hritik; Pattichis, Rebecca; Chang, Kai-Wei				Chang, Kai-Wei/AAJ-7874-2020						Survey of Bias In Text-to-Image Generation: Definition, Evaluation, and Mitigation								Arxiv											2	2;2024-05-01;https://www.arxiv.org/abs/2404.01030v3| 1;2024-04-02;https://www.arxiv.org/abs/2404.01030v2	arXiv:2404.01030			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	May 01 2024	2024	The recent advancement of large and powerful models with Text-to-Image (T2I) generation abilities -- such as OpenAI's DALLE-3 and Google's Gemini -- enables users to generate high-quality images from textual prompts. However, it has become increasingly evident that even simple prompts could cause T2I models to exhibit conspicuous social bias in generated images. Such bias might lead to both allocational and representational harms in society, further marginalizing minority groups. Noting this problem, a large body of recent works has been dedicated to investigating different dimensions of bias in T2I systems. However, an extensive review of these studies is lacking, hindering a systematic understanding of current progress and research gaps. We present the first extensive survey on bias in T2I generative models. In this survey, we review prior studies on dimensions of bias: Gender, Skintone, and Geo-Culture. Specifically, we discuss how these works define, evaluate, and mitigate different aspects of bias. We found that: (1) while gender and skintone biases are widely studied, geo-cultural bias remains under-explored; (2) most works on gender and skintone bias investigated occupational association, while other aspects are less frequently studied; (3) almost all gender bias works overlook non-binary identities in their studies; (4) evaluation datasets and metrics are scattered, with no unified framework for measuring biases; and (5) current mitigation methods fail to resolve biases comprehensively. Based on current limitations, we point out future research directions that contribute to human-centric definitions, evaluations, and mitigation of biases. We hope to highlight the importance of studying biases in T2I systems, as well as encourage future efforts to holistically understand and tackle biases, building fair and trustworthy T2I technologies for everyone.																																	2024-07-04	PPRN:88378450		
J	Shankar, Shreya; Zamfirescu-Pereira, J.D.; Hartmann, Bjorn; Parameswaran, Aditya G.; Arawjo, Ian										Who Validates the Validators? Aligning LLM-Assisted Evaluation of LLM Outputs with Human Preferences								Arxiv											1	1;2024-04-18;https://www.arxiv.org/abs/2404.12272v1	arXiv:2404.12272			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 18 2024	2024	Due to the cumbersome nature of human evaluation and limitations of code-based evaluation, Large Language Models (LLMs) are increasingly being used to assist humans in evaluating LLM outputs. Yet LLM-generated evaluators simply inherit all the problems of the LLMs they evaluate, requiring further human validation. We present a mixed-initiative approach to "validate the validators'' -- aligning LLM-generated evaluation functions (be it prompts or code) with human requirements. Our interface, EvalGen, provides automated assistance to users in generating evaluation criteria and implementing assertions. While generating candidate implementations (Python functions, LLM grader prompts), EvalGen asks humans to grade a subset of LLM outputs; this feedback is used to select implementations that better align with user grades. A qualitative study finds overall support for EvalGen but underscores the subjectivity and iterative process of alignment. In particular, we identify a phenomenon we dub emph{criteria drift}: users need criteria to grade outputs, but grading outputs helps users define criteria. What is more, some criteria appears emph{dependent} on the specific LLM outputs observed (rather than independent criteria that can be defined emph{a priori}), raising serious questions for approaches that assume the independence of evaluation from observation of model outputs. We present our interface and implementation details, a comparison of our algorithm with a baseline approach, and implications for the design of future LLM evaluation assistants.																																	2024-04-28	PPRN:88562337		
J	Liu, Zhiheng; Ouyang, Hao; Wang, Qiuyu; Cheng, Ka Leong; Xiao, Jie; Zhu, Kai; Xue, Nan; Liu, Yu; Shen, Yujun; Cao, Yang				Wang, qiuyu/LDO-6178-2024; Xue, Nan/HCI-0300-2022; Cheng, Ka/AEP-8030-2022						InFusion: Inpainting 3D Gaussians via Learning Depth Completion from Diffusion Prior								Arxiv											1	1;2024-04-17;https://www.arxiv.org/abs/2404.11613v1	arXiv:2404.11613			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 17 2024	2024	3D Gaussians have recently emerged as an efficient representation for novel view synthesis. This work studies its editability with a particular focus on the inpainting task, which aims to supplement an incomplete set of 3D Gaussians with additional points for visually harmonious rendering. Compared to 2D inpainting, the crux of inpainting 3D Gaussians is to figure out the rendering -relevant properties of the introduced points, whose optimization largely benefits from their initial 3D positions. To this end, we propose to guide the point initialization with an image -conditioned depth completion model, which learns to directly restore the depth map based on the observed image. Such a design allows our model to fill in depth values at an aligned scale with the original depth, and also to harness strong generalizability from largescale diffusion prior. Thanks to the more accurate depth completion, our approach, dubbed InFusion, surpasses existing alternatives with sufficiently better fidelity and efficiency (i.e., ∼ 20× faster) under various complex scenarios. We further demonstrate the effectiveness of InFusion with several practical applications, such as inpainting with user -specific texture or with novel object insertion. Our code is public available at https://johanan528.github.io/Infusion/.																																	2024-04-27	PPRN:88555721		
J	Kokorev, Vasily; Caputi, Karina I.; Greene, Jenny E.; Dayal, Pratika; Trebitsch, Maxime; Cutler, Sam E.; Fujimoto, Seiji; Labbe, Ivo; Miller, Tim B.; Iani, Edoardo; Navarro-Carrera, Rafael; Rinaldi, Pierluigi				Labbe, Ivo/B-1408-2016; Kokorev, Vasily/GPK-2541-2022; dayal, Pratika/AAD-4237-2019; Leja, Joel/JPL-7942-2023						A Census of Photometrically Selected Little Red Dots at 4 < z < 9 in JWST Blank Fields								Arxiv											4	4;2024-04-14;https://www.arxiv.org/abs/2401.09981v4| 3;2024-02-17;https://www.arxiv.org/abs/2401.09981v3| 2;2024-01-24;https://www.arxiv.org/abs/2401.09981v2| 1;2024-01-18;https://www.arxiv.org/abs/2401.09981v1	arXiv:2401.09981			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 14 2024	2024	Observations with the James Webb Space Telescope (JWST) have uncovered numerous faint active galactic nuclei (AGN) at z ∼ 5 and beyond. These objects are key to our understanding of the formation of supermassive black holes (SMBHs), their co-evolution with host galaxies, as well as the role of AGN in cosmic reionization. Using photometric colors and size measurements, we perform a search for compact red objects in an array of blank deep JWST/NIRCam fields totaling ∼ 640 arcmin2. Our careful selection yields 260 reddened AGN candidates at 4 < zphot < 9, dominated by a point-source like central component (⟨reff⟩ < 130 pc) and displaying a dichotomy in their rest-frame colors (blue UV and red optical slopes). Quasar model fitting reveals our objects to be moderately dust extincted (AV ∼ 1.6), which is reflected in their inferred bolometric luminosities of Lbol = 1044−47 erg/s, and fainter UV magnitudes MUV ≃ −17 to −22. Thanks to the large areas explored, we extend the existing dusty AGN luminosity functions to both fainter and brighter magnitudes, estimating their number densities to be ×100 higher than for UV-selected quasars of similar magnitudes. At the same time they constitute only a small fraction of all UV-selected galaxies at similar redshifts, but this percentage rises to ∼10% for MUV ∼ −22 at z ∼ 7. Finally, assuming a conservative case of accretion at the Eddington rate, we place a lower limit on the SMBH mass function at z ∼ 5, finding it to be consistent with both theory and previous JWST observations.																																	2024-04-25	PPRN:87222969		
J	Kar, Oguzhan Fatih; Tonioni, Alessio; Poklukar, Petra; Kulshrestha, Achin; Zamir, Amir; Tombari, Federico										BRAVE: Broadening the visual encoding of vision-language models								Arxiv											1	1;2024-04-10;https://www.arxiv.org/abs/2404.07204v1	arXiv:2404.07204			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 10 2024	2024	Vision-language models (VLMs) are typically composed of a vision encoder, e.g. CLIP, and a language model (LM) that interprets the encoded features to solve downstream tasks. Despite remarkable progress, VLMs are subject to several shortcomings due to the limited capabilities of vision encoders, e.g. “blindness” to certain image features, visual hallucination, etc. To address these issues, we study broadening the visual encoding capabilities of VLMs. We first comprehensively benchmark several vision encoders with different inductive biases for solving VLM tasks. We observe that there is no single encoding configuration that consistently achieves top performance across different tasks, and encoders with different biases can perform surprisingly similarly. Motivated by this, we introduce a method, named BRAVE, that consolidates features from multiple frozen encoders into a more versatile representation that can be directly fed as the input to a frozen LM. BRAVE achieves state-of-the-art performance on a broad range of captioning and VQA benchmarks and significantly reduces the aforementioned issues of VLMs, while requiring a smaller number of trainable parameters than existing methods and having a more compressed representation. Our results highlight the potential of incorporating different visual biases for a more broad and contextualized visual understanding of VLMs.																																	2024-04-24	PPRN:88478746		
J	Bulo, Samuel Rota; Porzi, Lorenzo; Kontschieder, Peter				Bulò, Samuel/G-1014-2010						Revising Densification in Gaussian Splatting								Arxiv											1	1;2024-04-09;https://www.arxiv.org/abs/2404.06109v1	arXiv:2404.06109			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Apr 09 2024	2024	In this paper, we address the limitations of Adaptive Density Control (ADC) in 3D Gaussian Splatting (3DGS), a scene representation method achieving high-quality, photorealistic results for novel view synthesis. ADC has been introduced for automatic 3D point primitive management, controlling densification and pruning, however, with certain limitations in the densification logic. Our main contribution is a more principled, pixel-error driven formulation for density control in 3DGS, leveraging an auxiliary, per-pixel error function as the criterion for densification. We further introduce a mechanism to control the total number of primitives generated per scene and correct a bias in the current opacity handling strategy of ADC during cloning operations. Our approach leads to consistent quality improvements across a variety of benchmark scenes, without sacrificing the method's efficiency.																																	2024-05-22	PPRN:88477268		
J	Zhang, Kexin; Wen, Qingsong; Zhang, Chaoli; Cai, Rongyao; Jin, Ming; Liu, Yong; Zhang, James; Liang, Yuxuan; Pang, Guansong; Song, Dongjin; Pan, Shirui				ZHANG, Kexin/OGO-5493-2025; Pang, Guansong/ABD-7725-2021; Zhang, James/B-2343-2017; Liang, Yuxuan/KXR-3882-2024; Wen, Qingsong/LTF-7625-2024						Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects								Arxiv											3	3;2024-04-08;https://www.arxiv.org/abs/2306.10125v4| 2;2024-02-29;https://www.arxiv.org/abs/2306.10125v3| 1;2023-07-22;https://www.arxiv.org/abs/2306.10125v2	arXiv:2306.10125			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 08 2024	2024	Self-supervised learning (SSL) has recently achieved impressive performance on various time series tasks. The most prominent advantage of SSL is that it reduces the dependence on labeled data. Based on the pre-training and fine-tuning strategy, even a small amount of labeled data can achieve high performance. Compared with many published self-supervised surveys on computer vision and natural language processing, a comprehensive survey for time series SSL is still missing. To fill this gap, we review current state-of-the-art SSL methods for time series data in this article. To this end, we first comprehensively review existing surveys related to SSL and time series, and then provide a new taxonomy of existing time series SSL methods by summarizing them from three perspectives: generative-based, contrastive-based, and adversarial-based. These methods are further divided into ten subcategories with detailed reviews and discussions about their key intuitions, main frameworks, advantages and disadvantages. To facilitate the experiments and validation of time series SSL methods, we also summarize datasets commonly used in time series forecasting, classification, anomaly detection, and clustering tasks. Finally, we present the future directions of SSL for time series analysis.																																	2024-04-21	PPRN:74290204		
J	Tang, Yehui; Wang, Yunhe; Guo, Jianyuan; Tu, Zhijun; Han, Kai; Hu, Hailin; Tao, Dacheng				Han, Kai/AAC-7659-2019; tu, zhijun/OEN-3007-2025; Shen, Li/AEZ-9528-2022; Guo, Jianyuan/KYQ-6536-2024; Hu, Hailin/X-7955-2019						A Survey on Transformer Compression								Arxiv											2	2;2024-04-07;https://www.arxiv.org/abs/2402.05964v2| 1;2024-02-05;https://www.arxiv.org/abs/2402.05964v1	arXiv:2402.05964			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 07 2024	2024	Transformer plays a vital role in the realms of natural language processing (NLP) and computer vision (CV), specially for constructing large language models (LLM) and large vision models (LVM). Model compression methods reduce the memory and computational cost of Transformer, which is a necessary step to implement large language/vision models on practical devices. Given the unique architecture of Transformer, featuring alternative attention and feedforward neural network (FFN) modules, specific compression techniques are usually required. The efficiency of these compression methods is also paramount, as retraining large models on the entire training dataset is usually impractical. This survey provides a comprehensive review of recent compression methods, with a specific focus on their application to Transformer-based models. The compression methods are primarily categorized into pruning, quantization, knowledge distillation, and efficient architecture design (Mamba, RetNet, RWKV, etc.). In each category, we discuss compression methods for both language and vision tasks, highlighting common underlying principles. Finally, we delve into the relation between various compression methods, and discuss further directions in this domain.																																	2024-04-21	PPRN:87608928		
J	Fei, Zhengcong; Fan, Mingyuan; Yu, Changqian; Li, Debang; Huang, Junshi				Li, Debang/AAA-7378-2019; Yu, Changqian/V-7618-2019						<italic>Diffusion</italic>-<italic>RWKV</italic>: Scaling RWKV-Like Architectures for Diffusion Models								Arxiv											1	1;2024-04-06;https://www.arxiv.org/abs/2404.04478v1	arXiv:2404.04478			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 06 2024	2024	Transformers have catalyzed advancements in computer vision and natural language processing (NLP) fields. However, substantial computational complexity poses limitations for their application in long-context tasks, such as high-resolution image generation. This paper introduces a series of architectures adapted from the RWKV model used in the NLP, with requisite modifications tailored for diffusion model applied to image generation tasks, referred to as Diffusion-RWKV. Similar to the diffusion with Transformers, our model is designed to efficiently handle patchnified inputs in a sequence with extra conditions, while also scaling up effectively, accommodating both large-scale parameters and extensive datasets. Its distinctive advantage manifests in its reduced spatial aggregation complexity, rendering it exceptionally adept at processing high-resolution images, thereby eliminating the necessity for windowing or group cached operations. Experimental results on both condition and unconditional image generation tasks demonstrate that Diffison-RWKV achieves performance on par with or surpasses existing CNN or Transformer-based diffusion models in FID and IS metrics while significantly reducing total computation FLOP usage.																																	2024-04-21	PPRN:88447683		
J	Grewal, Sabee; Iyer, Vishnu; Kretschmer, William; Liang, Daniel										Efficient Learning of Quantum States Prepared With Few Non-Clifford Gates								Arxiv											3	3;2024-04-05;https://www.arxiv.org/abs/2305.13409v4| 2;2023-09-11;https://www.arxiv.org/abs/2305.13409v3| 1;2023-05-22;https://www.arxiv.org/abs/2305.13409v1	arXiv:2305.13409			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 05 2024	2024	We give a pair of algorithms that efficiently learn a quantum state prepared by Clifford gates and O(log n) non -Clifford gates. Specifically, for an n-qubit state 0ψ) prepared with at most t non -Clifford gates, our algorithms use poly(n, 2t, 1/ε) time and copies of 0ψ) to learn 0ψ) to trace distance at most ε. The first algorithm for this task is more efficient, but requires entangled measurements across two copies of 0ψ). The second algorithm uses only single -copy measurements at the cost of polynomial factors in runtime and sample complexity. Our algorithms more generally learn any state with sufficiently large stabilizer dimension, where a quantum state has stabilizer dimension k if it is stabilized by an abelian group of 2k Pauli operators. We also develop an efficient property testing algorithm for stabilizer dimension, which may be of independent interest.																																	2024-04-20	PPRN:71592825		
J	Tang, Xiangru; Zong, Yiming; Phang, Jason; Zhao, Yilun; Zhou, Wangchunshu; Cohan, Arman; Gerstein, Mark				Wang, Benyou/Y-5146-2019; Zong, Yi Ming/OEO-8990-2025; Gerstein, Mark/HSC-3904-2023; Zhao, Ziang/IAR-5845-2023						Struc-Bench: Are Large Language Models Really Good at Generating Complex Structured Data?								Arxiv											2	2;2024-04-04;https://www.arxiv.org/abs/2309.08963v3| 1;2023-09-19;https://www.arxiv.org/abs/2309.08963v2	arXiv:2309.08963			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Apr 04 2024	2024	Despite the remarkable capabilities of Large Language Models (LLMs) like GPT-4, producing complex, structured tabular data remains challenging. Our study assesses LLMs' proficiency in structuring tables and introduces a novel fine-tuning method, cognizant of data structures, to bolster their performance. We unveil Struc-Bench, a comprehensive benchmark featuring prominent LLMs (GPT-NeoX-20B, GPT-3.5, GPT-4, and Vicuna), which spans text tables, HTML, and LaTeX formats. Our proposed FormatCoT aids in crafting format-specific instructions from the intended outputs to populate this benchmark. Addressing the gap in task-centered evaluation, we propose two innovative metrics, P-Score (Prompting Score) and H-Score (Heuristical Score), to more accurately gauge LLM performance. Our experiments show that applying our structure-aware fine-tuning to LLaMA-7B leads to substantial performance gains, outshining its LLM counterparts across most measures. In-depth error analysis and creating an ability map across six dimensions - coverage, formatting, reasoning, comprehension, pragmatics, and hallucination - highlight areas for future enhancements and suggest forthcoming research trajectories. 																																	2024-04-20	PPRN:85052915		
J	Cai, Yuzhe; Mao, Shaoguang; Wu, Wenshan; Wang, Zehua; Liang, Yaobo; Ge, Tao; Wu, Chenfei; You, Wang; Song, Ting; Xia, Yan; Tien, Jonathan; Duan, Nan; Wei, Furu				Duan, Nan/AAR-2231-2020; Wu, Chenfei/AAJ-5232-2020						Low-code LLM: Graphical User Interface over Large Language Models								Arxiv											2	2;2024-04-01;https://www.arxiv.org/abs/2304.08103v3| 1;2023-04-17;https://www.arxiv.org/abs/2304.08103v2	arXiv:2304.08103			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Apr 01 2024	2024	Utilizing Large Language Models (LLMs) for complex tasks is challenging, often involving a time-consuming and uncontrollable prompt engineering process. This paper introduces a novel human-LLM interaction framework, Low-code LLM. It incorporates six types of simple low-code visual programming interactions to achieve more controllable and stable responses. Through visual interaction with a graphical user interface, users can incorporate their ideas into the process without writing trivial prompts. The proposed Low-code LLM framework consists of a Planning LLM that designs a structured planning workflow for complex tasks, which can be correspondingly edited and confirmed by users through low-code visual programming operations, and an Executing LLM that generates responses following the user-confirmed workflow. We highlight three advantages of the low-code LLM: user-friendly interaction, controllable generation, and wide applicability. We demonstrate its benefits using four typical applications. By introducing this framework, we aim to bridge the gap between humans and LLMs, enabling more effective and efficient utilization of LLMs for complex tasks. 																																	2024-04-17	PPRN:63697273		
J	Huang, Jie; Chang, Kevin Chen-Chuan				Chang, Kevin/ITR-8409-2023						Citation: A Key to Building Responsible and Accountable Large Language Models								Arxiv											3	3;2024-03-31;https://www.arxiv.org/abs/2307.02185v3| 2;2023-11-15;https://www.arxiv.org/abs/2307.02185v2| 1;2023-07-05;https://www.arxiv.org/abs/2307.02185v1	arXiv:2307.02185			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 31 2024	2024	Large Language Models (LLMs) bring transformative benefits alongside unique challenges, including intellectual property (IP) and ethical concerns. This position paper explores a novel angle to mitigate these risks, drawing parallels between LLMs and established web systems. We identify "citation"— the acknowledgement or reference to a source or evidence - as a crucial yet missing component in LLMs. Incorporating citation could enhance content transparency and verifiability, thereby confronting the IP and ethical issues in the deployment of LLMs. We further propose that a comprehensive citation mechanism for LLMs should account for both non-parametric and parametric content. Despite the complexity of implementing such a citation mechanism, along with the potential pitfalls, we advocate for its development. Building on this foundation, we outline several research problems in this area, aiming to guide future explorations towards building more responsible and accountable LLMs.																																	2024-04-18	PPRN:73801316		
J	Cordova, Clay; Dumitrescu, Thomas T.										Candidate Phases for SU(2) Adjoint QCD4 with Two Flavors from N = 2 Supersymmetric Yang-Mills Theory								Arxiv											2	2;2024-03-30;https://www.arxiv.org/abs/1806.09592v2| 1;2018-06-25;https://www.arxiv.org/abs/1806.09592v1	arXiv:1806.09592			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 30 2024	2024	Let Fq be a finite field, where q is an odd prime power. Let R = Fq+uFq+vFq+ uvFq with u2 = u, v2 = v, uv = vu. In this paper, we study the algebraic structure of (0 , Θ)-cyclic codes of block length (r, s) over FqR. Specifically, we analyze the structure of these codes as left R[x : Θ]-submodules of Rr,s = Fqhxr[x:θ−1>] × R[x:Θ] hxs−1i. Our investigation involves determining generator polynomials and minimal generating sets for this family of codes. Further, we discuss the algebraic structure of separable codes. A relationship between the generator polynomials of (0 , Θ)-cyclic codes over FqR and their duals is established. Moreover, we calculate the generator polynomials of dual of (0 , Θ)-cyclic codes. As an application of our study, we provide a construction of quantum error-correcting codes (QECCs) from (0 , Θ)cyclic codes of block length (r, s) over FqR. We support our theoretical results with illustrative examples. Keywords: (0 , Θ)-cyclic code, Generator polynomials, Dual codes, Separable Codes, QECCs. 1 Introduction Cyclic codes have been extensively researched and analyzed by researchers due to their abundant algebraic structure. This inherent mathematical richness makes cyclic codes one of the most significant classes of error-correcting codes. In 1994, Hammon et al. [11] presented a novel viewpoint by constructing non -linear codes over Z2 using the Gray map derived from codes over Z4. Over the last three decades, scholars have dedicated significant attention to the exploration of the characteristics of cyclic codes, particularly their generator polynomials. In 1997, Rifáand Pojul [30] pioneered introducing codes over mixed alphabets. Subsequently, Browers et al. [10] examined the codes over the mixed alphabets Z2 and Z3, focusing																																	2024-05-03	PPRN:22701320		
J	Khaki, Saeed; Li, Jinjin; Ma, Lan; Yang, Liu; Ramachandra, Prathap				Khaki, Saeed/AAO-3265-2020						RS-DPO: A Hybrid Rejection Sampling and Direct Preference Optimization Method for Alignment of Large Language Models								Arxiv											1	1;2024-03-30;https://www.arxiv.org/abs/2402.10038v2	arXiv:2402.10038			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 30 2024	2024	Reinforcement learning from human feedback (RLHF) has been extensively employed to align large language models with user intent. However, proximal policy optimization (PPO) based RLHF is occasionally unstable requiring significant hyperparameter finetuning, and computationally expensive to maximize the estimated reward during alignment. Recently, direct preference optimization (DPO) is proposed to address those challenges. However, DPO relies on contrastive responses generated from human annotator and alternative LLM, instead of the policy model, limiting the effectiveness of the RLHF. In this paper, we addresses both challenges by systematically combining rejection sampling (RS) and DPO. Our proposed method, RS-DPO, initiates with the development of a supervised fine-tuned policy model (SFT). A varied set of k responses per prompt are sampled directly from the SFT model. RS-DPO identifies pairs of contrastive samples based on their reward distribution. Finally, we apply DPO with the contrastive samples to align the model to human preference. Our experiments indicate that our proposed method effectively fine-tunes LLMs with limited resource environments, leading to improved alignment with user intent. Furthermore, it outperforms existing methods, including RS, PPO, and DPO.																																	2024-04-18	PPRN:88366979		
J	Li, Junlong; Wang, Jinyuan; Zhang, Zhuosheng; Zhao, Hai				Zhang, Zhuosheng/AAF-4919-2020						Self-Prompting Large Language Models for Zero-Shot Open-Domain QA								Arxiv											2	2;2024-03-28;https://www.arxiv.org/abs/2212.08635v3| 1;2022-12-16;https://www.arxiv.org/abs/2212.08635v1	arXiv:2212.08635			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Mar 28 2024	2024	Open-Domain Question Answering (ODQA) aims to answer questions without explicitly providing specific background documents. This task becomes notably challenging in a zero-shot setting where no data is available to train tailored retrieval-reader models. While recent Large Language Models (LLMs) like GPT-3 have demonstrated their effectiveness in zero-shot ODQA using direct prompting methods, these methods still fall short of fully harnessing the potential of LLMs when implicitly invoked. In this paper, we propose a Self-Prompting framework to explicitly utilize the massive knowledge encoded in the parameters of LLMs and their strong instruction understanding abilities. Concretely, we prompt LLMs step by step to generate multiple pseudo QA pairs with background passages and explanations entirely from scratch. These generated elements are then utilized for in-context learning. Experimental results show that our method significantly surpasses previous state-of-the-art zero-shot methods on three widely-used ODQA datasets and even achieves comparable performance with various customized fine-tuned models on full training data.																																	2024-04-14	PPRN:35855266		
J	Huang, De-An; Liao, Shijia; Radhakrishnan, Subhashree; Yin, Hongxu; Molchanov, Pavlo; Yu, Zhiding; Kautz, Jan				Yin, Hongxu/AAZ-3328-2020						LITA: Language Instructed Temporal-Localization Assistant								Arxiv											1	1;2024-03-27;https://www.arxiv.org/abs/2403.19046v1	arXiv:2403.19046			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 27 2024	2024	There has been tremendous progress in multimodal Large Language Models (LLMs). Recent works have extended these models to video input with promising instruction following capabilities. However, an important missing piece is temporal localization. These models cannot accurately answer the "When?" questions. We identify three key aspects that limit their temporal localization capabilities: (i) time representation, (ii) architecture, and (iii) data. We address these shortcomings by proposing Language Instructed Temporal-Localization Assistant (LITA) with the following features: (1) We introduce time tokens that encode timestamps relative to the video length to better represent time in videos. (2) We introduce SlowFast tokens in the architecture to capture temporal information at fine temporal resolution. (3) We emphasize temporal localization data for LITA. In addition to leveraging existing video datasets with timestamps, we propose a new task, Reasoning Temporal Localization (RTL), along with the dataset, ActivityNet-RTL, for learning and evaluating this task. Reasoning temporal localization requires both the reasoning and temporal localization of Video LLMs. LITA demonstrates strong performance on this challenging task, nearly doubling the temporal mean intersection-over-union (mIoU) of baselines. In addition, we show that our emphasis on temporal localization also substantially improves video-based text generation compared to existing Video LLMs, including a 36% relative improvement of Temporal Understanding. 																																	2024-04-14	PPRN:88331179		
J	Zheng, Longtao; Huang, Zhiyuan; Xue, Zhenghai; Wang, Xinrun; An, Bo; Yan, Shuicheng				Huang, Zhiyuan/LBI-2209-2024; yan, shuicheng/HCH-9860-2022						AgentStudio: A Toolkit for Building General Virtual Agents								Arxiv											3	3;2025-02-14;https://www.arxiv.org/abs/2403.17918v3| 2;2024-10-02;https://www.arxiv.org/abs/2403.17918v2| 1;2024-03-26;https://www.arxiv.org/abs/2403.17918v1	arXiv:2403.17918			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 26 2024	2024	Creating autonomous virtual agents capable of using arbitrary software on any digital device remains a major challenge for artificial intelligence. Two key obstacles hinder progress: insufficient infrastructure for building virtual agents in real-world environments, and the need for in-the-wild evaluation of fundamental agent abilities. To address this, we introduce AgentStudio, an online, realistic, and multimodal toolkit that covers the entire lifecycle of agent development. This includes environment setups, data collection, agent evaluation, and visualization. The observation and action spaces are highly generic, supporting both function calling and human-computer interfaces. This versatility is further enhanced by AgentStudio's graphical user interfaces, which allow efficient development of datasets and benchmarks in real-world settings. To illustrate, we introduce a visual grounding dataset and a real-world benchmark suite, both created with our graphical interfaces. Furthermore, we present several actionable insights derived from AgentStudio, e.g., general visual grounding, open-ended tool creation, learning from videos, etc. We have open-sourced the environments, datasets, benchmarks, and interfaces to promote research towards developing general virtual agents for the future.																																	2025-08-07	PPRN:88295940		
J	Xue, Hanyu; Lee, Jong Yeon; Bao, Yimu				Xue, Hanyu/HQY-8564-2023; Lee, jongyeon/HJP-3141-2023						Tensor network formulation of symmetry protected topological phases in mixed states								Arxiv											2	2;2024-05-16;https://www.arxiv.org/abs/2403.17069v2| 1;2024-03-25;https://www.arxiv.org/abs/2403.17069v1	arXiv:2403.17069			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 25 2024	2024	We define and classify symmetry-protected topological (SPT) phases in mixed states based on the tensor network formulation of the density matrix. In one dimension, we introduce strong injective matrix product density operators (MPDO), which describe a broad class of short-range correlated mixed states, including the locally decohered SPT states. We map strong injective MPDO to a pure state in the doubled Hilbert space and define the SPT phases according to the cohomology class of the symmetry group in the doubled state. Although the doubled state exhibits an enlarged symmetry, the possible SPT phases are also constrained by the Hermiticity and the semi-positivity of the density matrix. We here obtain a complete classification of SPT phases with a direct product of strong $G$ and weak $K$ unitary symmetry given by the cohomology group $mathcal{H}^2(G, text{U}(1))oplusmathcal{H}^1(K, mathcal{H}^1(G, text{U}(1)))$. The SPT phases in our definition are preserved under symmetric local circuits consisting of non-degenerate channels. This motivates an alternative definition of SPT phases according to the equivalence class of mixed states under a ``one-way" connection using symmetric non-degenerate channels. In locally purifiable MPDO with strong symmetry, we prove that this alternative definition reproduces the cohomology classification. We further extend our results to two-dimensional mixed states described by strong semi-injective tensor network density operators and classify the possible SPT phases.																																	2025-08-07	PPRN:88291807		
J	Ren, Allen Z.; Clark, Jaden; Dixit, Anushri; Itkina, Masha; Majumdar, Anirudha; Sadigh, Dorsa										Explore until Confident: Efficient Exploration for Embodied Question Answering								Arxiv											3	3;2024-07-07;https://www.arxiv.org/abs/2403.15941v3| 2;2024-05-27;https://www.arxiv.org/abs/2403.15941v2| 1;2024-03-23;https://www.arxiv.org/abs/2403.15941v1	arXiv:2403.15941			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 23 2024	2024	We consider the problem of Embodied Question Answering (EQA), which refers to settings where an embodied agent such as a robot needs to actively explore an environment to gather information until it is confident about the answer to a question. In this work, we leverage the strong semantic reasoning capabilities of large vision-language models (VLMs) to efficiently explore and answer such questions. However, there are two main challenges when using VLMs in EQA: they do not have an internal memory for mapping the scene to be able to plan how to explore over time, and their confidence can be miscalibrated and can cause the robot to prematurely stop exploration or over-explore. We propose a method that first builds a semantic map of the scene based on depth information and via visual prompting of a VLM - leveraging its vast knowledge of relevant regions of the scene for exploration. Next, we use conformal prediction to calibrate the VLM's question answering confidence, allowing the robot to know when to stop exploration - leading to a more calibrated and efficient exploration strategy. To test our framework in simulation, we also contribute a new EQA dataset with diverse, realistic human-robot scenarios and scenes built upon the Habitat-Matterport 3D Research Dataset (HM3D). Both simulated and real robot experiments show our proposed approach improves the performance and efficiency over baselines that do no leverage VLM for exploration or do not calibrate its confidence. Webpage with experiment videos and code: https://explore-eqa.github.io/																																	2025-08-07	PPRN:88278156		
J	Guo, Jun; Ma, Xiaojian; Fan, Yue; Liu, Huaping; Li, Qing				Li, Qing/JMH-1365-2023						Semantic Gaussians: Open-Vocabulary Scene Understanding with 3D Gaussian Splatting								Arxiv											2	2;2024-08-23;https://www.arxiv.org/abs/2403.15624v2| 1;2024-03-22;https://www.arxiv.org/abs/2403.15624v1	arXiv:2403.15624			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 22 2024	2024	Open-vocabulary 3D scene understanding presents a significant challenge in computer vision, withwide-ranging applications in embodied agents and augmented reality systems. Previous approaches haveadopted Neural Radiance Fields (NeRFs) to analyze 3D scenes. In this paper, we introduce SemanticGaussians, a novel open-vocabulary scene understanding approach based on 3D Gaussian Splatting. Our keyidea is distilling pre-trained 2D semantics into 3D Gaussians. We design a versatile projection approachthat maps various 2Dsemantic features from pre-trained image encoders into a novel semantic component of 3D Gaussians, withoutthe additional training required by NeRFs. We further build a 3D semantic network that directly predictsthe semantic component from raw 3D Gaussians for fast inference. We explore several applications ofSemantic Gaussians: semantic segmentation on ScanNet-20, where our approach attains a 4.2% mIoU and 4.0%mAcc improvement over prior open-vocabulary scene understanding counterparts; object part segmentation,sceneediting, and spatial-temporal segmentation with better qualitative results over 2D and 3D baselines,highlighting its versatility and effectiveness on supporting diverse downstream tasks.																																	2025-08-07	PPRN:88278286		
J	Josse, Julie; Chen, Jacob M.; Prost, Nicolas; Scornet, Erwan; Varoquaux, Gael				Varoquaux, Gael/ABQ-5456-2022						On the consistency of supervised learning with missing values								Arxiv											3	3;2024-03-21;https://www.arxiv.org/abs/1902.06931v5| 2;2024-03-07;https://www.arxiv.org/abs/1902.06931v4| 1;2020-07-03;https://www.arxiv.org/abs/1902.06931v3	arXiv:1902.06931			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 21 2024	2024	In many application settings, the data have missing entries which make analysis challenging. An abundant literature addresses missing values in an inferential framework: estimating parameters and their variance from incomplete tables. Here, we consider supervised-learning settings: predicting a target when missing values appear in both training and testing data. We show the consistency of two approaches in prediction. A striking result is that the widely-used method of imputing with a constant, such as the mean prior to learning is consistent when missing values are not informative. This contrasts with inferential settings where mean imputation is pointed at for distorting the distribution of the data. That such a simple approach can be consistent is important in practice. We also show that a predictor suited for complete observations can predict optimally on incomplete data, through multiple imputation. Finally, to compare imputation with learning directly with a model that accounts for missing values, we analyze further decision trees. These can naturally tackle empirical risk minimization with missing values, due to their ability to handle the half-discrete nature of incomplete variables. After comparing theoretically and empirically different missing values strategies in trees, we recommend using the "missing incorporated in attribute" method as it can handle both non-informative and informative missing values.																																	2024-04-13	PPRN:50881410		
J	Ahn, Kwangjun; Cheng, Xiang; Song, Minhak; Yun, Chulhee; Jadbabaie, Ali; Sra, Suvrit				Yun, Chulhee/LFT-4623-2024; Pappas, George/J-5774-2016						Linear attention is (maybe) all you need (to understand transformer optimization)								Arxiv											2	2;2024-03-13;https://www.arxiv.org/abs/2310.01082v2| 1;2023-10-02;https://www.arxiv.org/abs/2310.01082v1	arXiv:2310.01082			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 13 2024	2024	Transformer training is notoriously difficult, requiring a careful design of optimizers and use of various heuristics. We make progress towards understanding the subtleties of training Transformers by carefully studying a simple yet canonical linearized shallow Transformer model. Specifically, we train linear Transformers to solve regression tasks, inspired by J. von Oswald et al. (ICML 2023), and K. Ahn et al. (NeurIPS 2023). Most importantly, we observe that our proposed linearized models can reproduce several prominent aspects of Transformer training dynamics. Consequently, the results obtained in this paper suggest that a simple linearized Transformer model could actually be a valuable, realistic abstraction for understanding Transformer optimization.																																	2024-04-08	PPRN:85355401		
J	Huang, Quzhe; An, Zhenwei; Zhuang, Nan; Tao, Mingxu; Zhang, Chen; Jin, Yang; Xu, Kun; Chen, Liwei; Huang, Songfang; Feng, Yansong				Chen, Li-Wei/GVT-8217-2022						Harder Tasks Need More Experts: Dynamic Routing in MoE Models								Arxiv											1	1;2024-03-12;https://www.arxiv.org/abs/2403.07652v1	arXiv:2403.07652			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 12 2024	2024	In this paper, we introduce a novel dynamic expert selection framework for Mixture of Experts (MoE) models, aiming to enhance computational efficiency and model performance by adjusting the number of activated experts based on input difficulty. Unlike traditional MoE approaches that rely on fixed Top-K routing, which activates a predetermined number of experts regardless of the input's complexity, our method dynamically selects experts based on the confidence level in expert selection for each input. This allows for a more efficient utilization of computational resources, activating more experts for complex tasks requiring advanced reasoning and fewer for simpler tasks. Through extensive evaluations, our dynamic routing method demonstrates substantial improvements over conventional Top-2 routing across various benchmarks, achieving an average improvement of 0.7% with less than 90% activated parameters. Further analysis shows our model dispatches more experts to tasks requiring complex reasoning skills, like BBH, confirming its ability to dynamically allocate computational resources in alignment with the input's complexity. Our findings also highlight a variation in the number of experts needed across different layers of the transformer model, offering insights into the potential for designing heterogeneous MoE frameworks. 																																	2024-04-08	PPRN:88113286		
J	Shi, Shaoshuai; Jiang, Li; Dai, Dengxin; Schiele, Bernt				Shi, Shaoshuai/AAV-3211-2021						MTR++: Multi-Agent Motion Prediction with Symmetric Scene Modeling and Guided Intention Querying								Arxiv											2	2;2024-03-09;https://www.arxiv.org/abs/2306.17770v2| 1;2023-06-30;https://www.arxiv.org/abs/2306.17770v1	arXiv:2306.17770			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Mar 09 2024	2024	Motion prediction is crucial for autonomous driving systems to understand complex driving scenarios and make informed decisions. However, this task is challenging due to the diverse behaviors of traffic participants and complex environmental contexts. In this paper, we propose Motion TRansformer (MTR) frameworks to address these challenges. The initial MTR framework utilizes a transformer encoder -decoder structure with learnable intention queries, enabling efficient and accurate prediction of future trajectories. By customizing intention queries for distinct motion modalities, MTR improves multimodal motion prediction while reducing reliance on dense goal candidates. The framework comprises two essential processes: global intention localization, identifying the agent’s intent to enhance overall efficiency, and local movement refinement, adaptively refining predicted trajectories for improved accuracy. Moreover, we introduce an advanced MTR++ framework, extending the capability of MTR to simultaneously predict multimodal motion for multiple agents. MTR++ incorporates symmetric context modeling and mutually -guided intention querying modules to facilitate future behavior interaction among multiple agents, resulting in scene -compliant future trajectories. Extensive experimental results demonstrate that the MTR framework achieves state-of-the-art performance on the highly -competitive motion prediction benchmarks, while the MTR++ framework surpasses its precursor, exhibiting enhanced performance and efficiency in predicting accurate multimodal future trajectories for multiple agents.																																	2024-04-07	PPRN:73727431		
J	Li, Gen; Shi, Laixi; Chen, Yuxin; Chi, Yuejie; Wei, Yuting				Chen, Yuxin/HOH-1234-2023; Shi, Laixi/NGR-4397-2025; Chi, Yuejie/AAG-5084-2019						Settling the Sample Complexity of Model-Based Offline Reinforcement Learning								Arxiv											3	3;2024-03-08;https://www.arxiv.org/abs/2204.05275v4| 2;2024-03-03;https://www.arxiv.org/abs/2204.05275v3| 1;2022-04-11;https://www.arxiv.org/abs/2204.05275v2	arXiv:2204.05275			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Mar 08 2024	2024	This paper is concerned with offline reinforcement learning (RL), which learns using pre -collected data without further exploration. Effective offline RL would be able to accommodate distribution shift and limited data coverage. However, prior algorithms or analyses either suffer from suboptimal sample complexities or incur high burn -in cost to reach sample optimality, thus posing an impediment to efficient offline RL in sample -starved applications. We demonstrate that the model -based (or “plug-in”) approach achieves minimax-optimal sample complexity without burn -in cost for tabular Markov decision processes (MDPs). Concretely, consider a γ- discounted infinite -horizon (resp. finite -horizon) MDP with S states and effective horizon 1/1−γ (resp. horizon H), and suppose the distribution shift of data is reflected by some single -policy clipped concentrability coefficient C⋆clipped. We prove that model -based offline RL yields ε-accuracy with a sample complexity of {SC⋆clipped /(1−γ )3ε2 (infinite -horizon MDPs) {H4SC⋆ clipped /ε2 (finite -horizon MDPs) up to log factor, which is minimax optimal for the entire ε-range. The proposed algorithms are “pessimistic” variants of value iteration with Bernstein -style penalties, and do not require sophisticated variance reduction. Our analysis framework is established upon delicate leave -one -out decoupling arguments in conjunction with careful self -bounding techniques tailored to MDPs.																																	2024-04-07	PPRN:38491532		
J	van de Ven, Gido M.; Soures, Nicholas; Kudithipudi, Dhireesha				van de Ven, Gido/ABY-5626-2022; Kudithipudi, Dhireesha/KOC-8348-2024						CONTINUAL LEARNING AND CATASTROPHIC FORGETTING								Arxiv											1	1;2024-03-08;https://www.arxiv.org/abs/2403.05175v1	arXiv:2403.05175			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 08 2024	2024	This book chapter delves into the dynamics of continual learning, which is the process of incrementally learning from a non-stationary stream of data. Although continual learning is a natural skill for the human brain, it is very challenging for artificial neural networks. An important reason is that, when learning something new, these networks tend to quickly and drastically forget what they had learned before, a phenomenon known as catastrophic forgetting. Especially in the last decade, continual learning has become an extensively studied topic in deep learning. This book chapter reviews the insights that this field has generated.																																	2024-04-07	PPRN:88086198		
J	Adams, Nathan J.; Conselice, Christopher J.; Austin, Duncan; Harvey, Thomas; Ferreira, Leonardo; Trussler, James; Juodzbalis, Ignas; Li, Qiong; Windhorst, Rogier; Cohen, Seth H.; Jansen, Rolf; Summers, Jake; Tompkins, Scott; Driver, Simon P.; Robotham, Aaron; D'Silva, Jordan C.J.; Yan, Haojing; Coe, Dan; Frye, Brenda; Grogin, Norman A.; Koekemoer, Anton M.; Marshall, Madeline A.; Pirzkal, Nor; Ryan, Russell E.; Peter Maksym, W.; Rutkowski, Michael J.; Willmer, Christopher N.A.; Hammel, Heidi B.; Nonino, Mario; Bhatawdekar, Rachana; Wilkins, Stephen M.; Bradley, Larry D.; Broadhurst, Tom; Cheng, Cheng; Dole, Herve; Hathi, Nimish P.; Zitrin, Adi				Zitrin, Adi/M-3402-2018; Koekemoer, Anton/F-8400-2014; Driver, Simon/H-9115-2014; rutkowski, michael/AGR-7626-2022; Hathi, Nimish/N-4156-2019; Adams, Nathan/ABH-2690-2021; FERREIRA, LEONARDO/ABC-3716-2021; Conselice, Christopher/B-4348-2013; Jimenez-Teja, Yolanda/D-5933-2011; Marshall, Madeline/ABE-7430-2021; Cohen, Seth/AFC-6644-2022; Robotham, Aaron/H-5733-2014; Harvey, Thomas/NES-2363-2025						EPOCHS Paper II: The Ultraviolet Luminosity Function from 7.5 < z < 13.5 using 180 square arcminutes of deep, blank-fields from the PEARLS Survey and Public JWST data								Arxiv											3	3;2024-03-06;https://www.arxiv.org/abs/2304.13721v3| 2;2024-02-14;https://www.arxiv.org/abs/2304.13721v2| 1;2023-04-26;https://www.arxiv.org/abs/2304.13721v1	arXiv:2304.13721			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 06 2024	2024	We present an analysis of the ultraviolet luminosity function (UV LF) and star formation rate density of distant galaxies (7.5 < z < 13.5) in the ‘blank’ fields of the Prime Extragalactic Areas for Reionization Science (PEARLS) survey combined with Early Release Science (ERS) data from the CEERS, GLASS, NGDEEP surveys/fields and the first data release of JADES. We use strict quality cuts on EAZY photometric redshifts to obtain a reliable selection and characterisation of high-redshift (z > 6.5) galaxies from a consistently processed set of deep, near-infrared imaging. Within an area of 180 arcmin2, we identify 1046 candidate galaxies at redshifts z > 6.5 and we use this sample to study the ultraviolet luminosity function (UV LF) in four redshift bins between 7.5 < z < 13.5. The measured number density of galaxies at z = 8 and z = 9 match those of past observations undertaken by the Hubble Space Telescope (HST). Our z = 10.5 measurements lie between early JWST results and past HST results, indicating cosmic variance may be the cause of previous high density measurements. However, number densities of UV luminous galaxies at z = 12.5 are high compared to predictions from simulations. When examining the star formation rate density of galaxies at this time period, our observations are still largely consistent with a constant star formation efficiency, are slightly lower than previous early estimations using JWST and support galaxy driven reionization at z ≤ 8.																																	2024-04-04	PPRN:65567858		
J	Chen, Huanran; Zhang, Yichi; Dong, Yinpeng; Yang, Xiao; Su, Hang; Zhu, Jun				Zhang, Yichi/AAV-2870-2021; Dong, Yinpeng/KBA-4751-2024; su, hang/KEH-2976-2024						Rethinking Model Ensemble in Transfer-based Adversarial Attacks								Arxiv											2	2;2024-03-04;https://www.arxiv.org/abs/2303.09105v2| 1;2023-03-16;https://www.arxiv.org/abs/2303.09105v1	arXiv:2303.09105			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 04 2024	2024	It is widely recognized that deep learning models lack robustness to adversarial examples. An intriguing property of adversarial examples is that they can transfer across different models, which enables black-box attacks without any knowledge of the victim model. An effective strategy to improve the transferability is attacking an ensemble of models. However, previous works simply average the outputs of different models, lacking an in-depth analysis on how and why model ensemble methods can strongly improve the transferability. In this paper, we rethink the ensemble in adversarial attacks and define the common weakness of model ensemble with two properties: 1) the flatness of loss landscape; and 2) the closeness to the local optimum of each model. We empirically and theoretically show that both properties are strongly correlated with the transferability and propose a Common Weakness Attack (CWA) to generate more transferable adversarial examples by promoting these two properties. Experimental results on both image classification and object detection tasks validate the effectiveness of our approach to improving the adversarial transferability, especially when attacking adversarially trained models. We also successfully apply our method to attack a black-box large vision-language model – Google's Bard, showing the practical effectiveness. 																																	2024-04-02	PPRN:46906225		
J	Ye, Zhenhui; Zhong, Tianyun; Ren, Yi; Yang, Jiaqi; Li, Weichuang; Huang, Jiawei; Jiang, Ziyue; He, Jinzheng; Huang, Rongjie; Liu, Jinglin; Zhang, Chen; Yin, Xiang; Ma, Zejun; Zhao, Zhou				jiang, ziyue/GSI-9122-2022; Liu, Jing-Lin/P-9835-2017; Yang, Jiaqi/JCE-9742-2023; Zhong, Tianyun/KUD-1348-2024						Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis								Arxiv											3	3;2024-01-20;https://www.arxiv.org/abs/2401.08503v2| 2;2024-01-16;https://www.arxiv.org/abs/2401.08503v1| 1;2024-03-01;	arXiv:2401.08503			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Mar 01 2024	2024	One-shot 3D talking portrait generation aims to reconstruct a 3D avatar from an unseen image, and then animate it with a reference video or audio to generate a talking portrait video. The existing methods fail to simultaneously achieve the goals of accurate 3D avatar reconstruction and stable talking face animation. Besides, while the existing works mainly focus on synthesizing the head part, it is also vital to generate natural torso and background segments to obtain a realistic talking portrait video. To address these limitations, we present Real3D-Potrait, a framework that (1) improves the one-shot 3D reconstruction power with a large image-to-plane model that distills 3D prior knowledge from a 3D face generative model; (2) facilitates accurate motion-conditioned animation with an efficient motion adapter; (3) synthesizes realistic video with natural torso movement and switchable background using a head-torso-background super-resolution model; and (4) supports one-shot audio-driven talking face generation with a generalizable audio-to-motion model. Extensive experiments show that Real3D-Portrait generalizes well to unseen identities and generates more realistic talking portrait videos compared to previous methods. Video samples and source code are available at https://real3dportrait.github.io .																																	2025-11-07	PPRN:87188267		
J	Liu, Ming-Sheng; Liu, Feng-Xiao; Zhong, Xian-Hui; Zhao, Qiang				ming, liu/ABC-9262-2021; zhao, huiying/HKO-3636-2023						Fully-heavy tetraquark states and their evidences in the LHC observations								Arxiv											2	2;2024-02-29;https://www.arxiv.org/abs/2006.11952v3| 1;2020-06-22;https://www.arxiv.org/abs/2006.11952v1	arXiv:2006.11952			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 29 2024	2024	Stimulated by the exciting progress on the observations of the fully-charmed tetraquarks at LHC, we carry out a combined analysis of the mass spectra and fall-apart decays of the 1S-, 2S -, and 1P-wave cccc states in a nonrelativistic quark model (NRQM). It is found that the X(6600) structure observed in the di-J/ψ invariant mass spectrum can be explained by the 1S -wave state T(4c)0++(6550). This structure may also bear some feeddown effects from the higher 2S and/or 1P tetraquark states. The X(6900) structure observed in both the di-J/ψ and J/ψψ(2S ) channels can be naturally explained by the 2S -wave state T(4c)0++(6957). The small shoulder structure around 6.2 − 6.4 GeV observed at CMS and ATLAS may be due to the feed-down effects from some 1P-wave states with C = −1 and/or some 2S -wave states with JPC = 0++. Other decay channels are implied in such a scenario and they can be investigated by future experimental analyses. Considering the large discovery potential at LHC, we also present predictions for the bbbbstates which can be searched for in the future.																																	2024-03-28	PPRN:22087072		
J	Biroli, Giulio; Bonnaire, Tony; de Bortoli, Valentin; Mezard, Marc				Bonnaire, Tony/JGC-7163-2023						Dynamical Regimes of Diffusion Models								Arxiv											2	2;2024-02-28;https://www.arxiv.org/abs/2402.18491v1| 1;2024-02-28;https://www.arxiv.org/abs/2402.18491v1	arXiv:2402.18491			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 28 2024	2024	Using statistical physics methods, we study generative diffusion models in the regime where the dimension of space and the number of data are large, and the score function has been trained optimally. Our analysis reveals three distinct dynamical regimes during the backward generative diffusion process. The generative dynamics, starting from pure noise, encounters first a 'speciation' transition where the gross structure of data is unraveled, through a mechanism similar to symmetry breaking in phase transitions. It is followed at later time by a 'collapse' transition where the trajectories of the dynamics become attracted to one of the memorized data points, through a mechanism which is similar to the condensation in a glass phase. For any dataset, the speciation time can be found from a spectral analysis of the correlation matrix, and the collapse time can be found from the estimation of an 'excess entropy' in the data. The dependence of the collapse time on the dimension and number of data provides a thorough characterization of the curse of dimensionality for diffusion models. Analytical solutions for simple models like high-dimensional Gaussian mixtures substantiate these findings and provide a theoretical framework, while extensions to more complex scenarios and numerical validations with real datasets confirm the theoretical predictions.																																	2025-02-22	PPRN:87985582		
J	Deng, Hanqiu; Zhang, Zhaoxiang; Bao, Jinan; Li, Xingyu				Li, Xingyu/JGD-0649-2023; Zhang, Zhao-xiang/R-2819-2018						Bootstrap Fine-Grained Vision-Language Alignment for Unified Zero-Shot Anomaly Localization								Arxiv											2	2;2024-02-27;https://www.arxiv.org/abs/2308.15939v2| 1;2023-08-30;https://www.arxiv.org/abs/2308.15939v1	arXiv:2308.15939			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Feb 27 2024	2024	Contrastive Language-Image Pre-training (CLIP) models have shown promising performance on zero-shot visual recognition tasks by learning visual representations under natural language supervision. Recent studies attempt the use of CLIP to tackle zero-shot anomaly detection by matching images with normal and abnormal state prompts. However, since CLIP focuses on building correspondence between paired text prompts and global image-level representations, the lack of fine-grained patch-level vision to text alignment limits its capability on precise visual anomaly localization. In this work, we propose AnoCLIP for zero-shot anomaly localization. In the visual encoder, we introduce a training-free value-wise attention mechanism to extract intrinsic local tokens of CLIP for patch-level local description. From the perspective of text supervision, we particularly design a unified domain-aware contrastive state prompting template for fine-grained vision-language matching. On top of the proposed AnoCLIP, we further introduce a test-time adaptation (TTA) mechanism to refine visual anomaly localization results, where we optimize a lightweight adapter in the visual encoder using AnoCLIP's pseudo-labels and noise-corrupted tokens. With both AnoCLIP and TTA, we significantly exploit the potential of CLIP for zero-shot anomaly localization and demonstrate the effectiveness of AnoCLIP on various datasets.																																	2024-03-24	PPRN:84571078		
J	Kuratov, Yuri; Bulatov, Aydar; Anokhin, Petr; Sorokin, Dmitry; Sorokin, Artyom; Burtsev, Mikhail				Burtsev, Mikhail/G-6293-2010; Kuratov, Yuri/LTY-5852-2024						In Search of Needles in a 10M Haystack: Recurrent Memory Finds What LLMs Miss								Arxiv											2	2;2024-02-21;https://www.arxiv.org/abs/2402.10790v2| 1;2024-02-16;https://www.arxiv.org/abs/2402.10790v1	arXiv:2402.10790			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 16 2024	2024	This paper addresses the challenge of processing long documents using generative transformer models. To evaluate different approaches, we introduce BABILong, a new benchmark designed to assess model capabilities in extracting and processing distributed facts within extensive texts. Our evaluation, which includes benchmarks for GPT-4 and RAG, reveals that common methods are effective only for sequences up to 104 elements. In contrast, fine-tuning GPT-2 with recurrent memory augmentations enables it to handle tasks involving up to 107 elements. This achievement marks a substantial leap, as it is by far the longest input processed by any open neural network model to date, demonstrating a significant improvement in the processing capabilities for long sequences.																																	2024-11-09	PPRN:87795786		
J	Zheng, Zhuoran; Wu, Chen										U-shaped Vision Mamba for Single Image Dehazing								Arxiv											4	4;2024-02-16;https://www.arxiv.org/abs/2402.04139v4| 3;2024-02-14;https://www.arxiv.org/abs/2402.04139v3| 2;2024-02-08;https://www.arxiv.org/abs/2402.04139v2| 1;2024-02-06;https://www.arxiv.org/abs/2402.04139v1	arXiv:2402.04139			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 16 2024	2024	Currently, Transformer is the most popular architecture for image dehazing, but due to its large computational complexity, its ability to handle long-range dependency is limited on resource-constrained devices. To tackle this challenge, we introduce the U-shaped Vision Mamba (UVM-Net), an efficient single-image dehazing network. Inspired by the State Space Sequence Models (SSMs), a new deep sequence model known for its power to handle long sequences, we design a Bi-SSM block that integrates the local feature extraction ability of the convolutional layer with the ability of the SSM to capture long-range dependencies. Extensive experimental results demonstrate the effectiveness of our method. Our method provides a more highly efficient idea of long-range dependency modeling for image dehazing as well as other image restoration tasks. 																																	2024-11-09	PPRN:87529400		
J	Delcamp, Clement; Tiwari, Apoorv										Higher categorical symmetries and gauging in two-dimensional spin systems								Arxiv											1	1;2024-02-15;https://www.arxiv.org/abs/2301.01259v2	arXiv:2301.01259			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 15 2024	2024	We present a framework to systematically investigate higher categorical symmetries in two-dimensional spin systems. Though exotic, such generalised symmetries have been shown to naturally arise as dual symmetries upon gauging invertible symmetries. Our framework relies on an approach to dualities whereby dual quantum lattice models only differ in a choice of module 2-category over some input fusion 2-category. Given an arbitrary two-dimensional spin system with an ordinary symmetry, we explain how to perform the (twisted) gauging of any of its sub-symmetries. We then demonstrate that the resulting model has a symmetry structure encoded into the Morita dual of the input fusion 2-category with respect to the corresponding module 2-category. We exemplify this approach by specialising to certain finite group generalisations of the transverse-field Ising model, for which we explicitly define lattice symmetry operators organised into fusion 2-categories of higher representations of higher groups.																																	2024-03-08	PPRN:87698925		
J	Lewis, Martha; Mitchell, Melanie				Lewis, Martha/AAA-8293-2022						Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models								Arxiv											1	1;2024-02-14;https://www.arxiv.org/abs/2402.08955v1	arXiv:2402.08955			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Feb 14 2024	2024	Large language models (LLMs) have performed well on several reasoning benchmarks, including ones that test analogical reasoning abilities. However, it has been debated whether they are actually performing humanlike abstract reasoning or instead employing less general processes that rely on similarity to what has been seen in their training data. Here we investigate the generality of analogy-making abilities previously claimed for LLMs (Webb, Holyoak, & Lu, 2023). We take one set of analogy problems used to evaluate LLMs and create a set of “counterfactual” variants—versions that test the same abstract reasoning abilities but that are likely dissimilar from any pre-training data. We test humans and three GPT models on both the original and counterfactual problems, and show that, while the performance of humans remains high for all the problems, the GPT models’ performance declines sharply on the counterfactual set. This work provides evidence that, despite previously reported successes of LLMs on analogical reasoning, these models lack the robustness and generality of human analogy-making.																																	2024-05-25	PPRN:87683768		
J	Antunes, Luis M.; Butler, Keith T.; Grau-Crespo, Ricardo				Grau-Crespo, Ricardo/A-1661-2008						Crystal Structure Generation with Autoregressive Large Language Modeling								Arxiv											2	2;2024-02-12;https://www.arxiv.org/abs/2307.04340v3| 1;2023-07-10;https://www.arxiv.org/abs/2307.04340v1	arXiv:2307.04340			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 12 2024	2024	The generation of plausible crystal structures is often the first step in predicting the structure and properties of a material from its chemical composition. Quickly generating and predicting inorganic crystal structures is important for the discovery of new materials, which can target applications such as energy or electronic devices. However, most current methods for crystal structure prediction are computationally expensive, slowing the pace of innovation. Seeding structure prediction algorithms with quality generated candidates can overcome a major bottleneck. Here, we introduce CrystaLLM, a methodology for the versatile generation of crystal structures, based on the autoregressive large language modeling (LLM) of the Crystallographic Information File (CIF) format. Trained on millions of CIF files, CrystaLLM focuses on modeling crystal structures through text. CrystaLLM can produce plausible crystal structures for a wide range of inorganic compounds unseen in training, as demonstrated by ab initio simulations. The integration with predictors of formation energy permits the use of a Monte Carlo Tree Search algorithm to improve the generation of meaningful structures. Our approach challenges conventional representations of crystals, and demonstrates the potential of LLMs for learning effective 'world models' of crystal chemistry, which will lead to accelerated discovery and innovation in materials science.																																	2024-02-27	PPRN:73858514		
J	Dery, Lucio; Kolawole, Steven; Kagy, Jean-Francois; Smith, Virginia; Neubig, Graham; Talwalkar, Ameet										Everybody Prune Now: Structured Pruning of LLMs with only Forward Passes								Arxiv											2	2;2024-02-09;https://www.arxiv.org/abs/2402.05406v2| 1;2024-02-08;https://www.arxiv.org/abs/2402.05406v1	arXiv:2402.05406			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 09 2024	2024	Given the generational gap in available hardware between lay practitioners and the most endowed institutions, LLMs are becoming increasingly inaccessible as they grow in size. Whilst many approaches have been proposed to compress LLMs to make their resource consumption manageable, these methods themselves tend to be resource intensive, putting them out of the reach of the very user groups they target. In this work, we explore the problem of structured pruning of LLMs using only forward passes. We seek to empower practitioners to prune models so large that their available hardware has just enough memory to run inference. We develop Bonsai, a gradient-free, perturbative pruning method capable of delivering small, fast, and accurate pruned models. We observe that Bonsai outputs pruned models that (i) outperform those generated by more expensive gradient-based structured pruning methods, and (ii) are twice as fast (with comparable accuracy) as those generated by semi-structured pruning methods requiring comparable resources as Bonsai. We also leverage Bonsai to produce a new sub-2B model using a single A6000 that yields state-of-the-art performance on 4/6 tasks on the Huggingface Open LLM leaderboard.																																	2024-05-25	PPRN:87568967		
J	Bianchi, Federico; Chia, Patrick John; Yuksekgonul, Mert; Tagliabue, Jacopo; Jurafsky, Dan; Zou, James				Yuksekgonul, Mert/KHU-0698-2024; Bianchi, Federico/JZT-6891-2024						How Well Can LLMs Negotiate? NegotiationArena Platform and Analysis								Arxiv											2	2;2024-02-08;https://www.arxiv.org/abs/2402.05863v1| 1;2024-02-08;https://www.arxiv.org/abs/2402.05863v1	arXiv:2402.05863			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 08 2024	2024	Negotiation is the basis of social interactions; humans negotiate everything from the price of cars to how to share common resources. With rapidly growing interest in using large language models (LLMs) to act as agents on behalf of human users, such LLM agents would also need to be able to negotiate. In this paper, we study how well LLMs can negotiate with each other. We develop NEGOTIATIONARENA: a flexible framework for evaluating and probing the negotiation abilities of LLM agents. We implemented three types of scenarios in NEGOTIATIONARENA to assess LLM’s behaviors in allocating shared resources (ultimatum games), aggregate resources (trading games) and buy/sell goods (price negotiations). Each scenario allows for multiple turns of flexible dialogues between LLM agents to allow for more complex negotiations. Interestingly, LLM agents can significantly boost their negotiation outcomes by employing certain behavioral tactics. For example, by pretending to be desolate and desperate, LLMs can improve their payoffs by 20% when negotiating against the standard GPT-4. We also quantify irrational negotiation behaviors exhibited by the LLM agents, many of which also appear in humans. Together, NEGOTIATIONARENA offers a new environment to investigate LLM interactions, enabling new insights into LLM’s theory of mind, irrationality, and reasoning abilities.																																	2024-05-25	PPRN:87572774		
J	Thakur, Amitayush; Tsoukalas, George; Wen, Yeming; Xin, Jimmy; Chaudhuri, Swarat										An In-Context Learning Agent for Formal Theorem-Proving								Arxiv											5	5;2024-02-08;https://www.arxiv.org/abs/2310.04353v4| 4;2023-12-13;https://www.arxiv.org/abs/2310.04353v3| 3;2023-12-11;https://www.arxiv.org/abs/2310.04353v2| 2;2023-10-06;https://www.arxiv.org/abs/2310.04353v1| 1;2023-10-06;https://www.arxiv.org/abs/2310.04353v1	arXiv:2310.04353			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Feb 08 2024	2024	We present an in-context learning agent for formal theorem-proving in environments like Lean and Coq. Current state-of-the-art models for the problem are finetuned on environment-specific proof data. By contrast, our approach, called COPRA, repeatedly asks a high-capacity, general-purpose large language model (GPT-4) to propose tactic applications from within a stateful backtracking search. Proposed tactics are executed in the underlying proof environment. Feedback from the execution is used to build the prompt for the next model query, along with selected information from the search history and lemmas retrieved from an external database. We evaluate our implementation of COPRA on the miniF2F benchmark for Lean and a set of Coq tasks from the CompCert project. On these benchmarks, COPRA significantly outperforms few-shot invocations of GPT-4. It also compares favorably against finetuning-based approaches, outperforming REPROVER, a state-of-the-art finetuned approach for Lean, in terms of the pass@1 metric. Our code and data are available at https://github.com/trishullab/copra.																																	2024-02-24	PPRN:85518973		
J	Weller, Orion; Marone, Marc; Weir, Nathaniel; Lawrie, Dawn; Khashabi, Daniel; Van Durme, Benjamin										<italic>"According to</italic> ...<italic>"</italic>: Prompting Language Models Improves Quoting from Pre-Training Data								Arxiv											2	2;2023-05-22;https://www.arxiv.org/abs/2305.13252v1| 1;2024-02-01;	arXiv:2305.13252			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Feb 01 2024	2024	Large Language Models (LLMs) may hallucinate and generate fake information, despite pre-training on factual data. Inspired by the journalistic device of "according to sources", we propose according-to prompting: directing LLMs to ground responses against previously observed text. To quantify this grounding, we propose a novel evaluation metric (QUIP-Score) that measures the extent to which model-produced answers are directly found in underlying text corpora. We illustrate with experiments on three corpora (Wikipedia, PubMed, and the U.S. legal tax code) that these prompts improve grounding under our metrics, with the additional benefit of often improving end-task performance. Furthermore, prompts that ask the model to decrease grounding (or to ground to other corpora) indeed decrease QUIP-Score, indicating the ability of LLMs to increase or decrease grounded generations on request.																																	2024-11-16	PPRN:70810422		
J	Wang, Yan; Chu, Zhixuan; Ouyang, Xin; Wang, Simeng; Hao, Hongyan; Shen, Yue; Gu, Jinjie; Xue, Siqiao; Zhang, James Y; Cui, Qing; Li, Longfei; Zhou, Jun; Li, Sheng				HAO, HAO/KFS-0258-2024; xin, ouyang/JBI-6762-2023; li, longfei/IQT-5184-2023						Enhancing Recommender Systems with Large Language Model Reasoning Graphs								Arxiv											2	2;2024-01-25;https://www.arxiv.org/abs/2308.10835v2| 1;2023-08-21;https://www.arxiv.org/abs/2308.10835v1	arXiv:2308.10835			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 25 2024	2024	Recommendation systems aim to provide users with relevant suggestions, but often lack interpretability and fail to capture higher-level semantic relationships between user behaviors and profiles. In this paper, we propose a novel approach that leverages large language models (LLMs) to construct personalized reasoning graphs. These graphs link a user's profile and behavioral sequences through causal and logical inferences, representing the user's interests in an interpretable way. Our approach, LLM reasoning graphs (LLMRG), has four components: chained graph reasoning, divergent extension, self-verification and scoring, and knowledge base self-improvement. The resulting reasoning graph is encoded using graph neural networks, which serves as additional input to improve conventional recommender systems, without requiring extra user or item information. Our approach demonstrates how LLMs can enable more logical and interpretable recommender systems through personalized reasoning graphs. LLMRG allows recommendations to benefit from both engineered recommendation systems and LLM-derived reasoning graphs. We demonstrate the effectiveness of LLMRG on benchmarks and real-world scenarios in enhancing base recommendation models.																																	2024-02-12	PPRN:81771677		
J	Qu, Xing-Zhou; Qu, Dai-Wei; Chen, Jialin; Wu, Congjun; Yang, Fan; Li, Wei; Su, Gang				Su, Gang/ABI-1851-2020; Qu, Xing-Zhou/MEP-3599-2025						Bilayer<italic> t-J-J⊥</italic> Model and Magnetically Mediated Pairing in the Pressurized Nickelate La3Ni2O7								Arxiv											2	2;2024-01-20;https://www.arxiv.org/abs/2307.16873v2| 1;2023-07-31;https://www.arxiv.org/abs/2307.16873v1	arXiv:2307.16873			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 20 2024	2024	The recently discovered nickelate superconductor La3Ni2O7 has a high transition temperature near 80 K un-der pressure, providing an additional avenue for exploring unconventional superconductivity. Here with state-of-the-art tensor-network methods, we study a bilayer t-J-J⊥ model for La3Ni2O7 and find a robust s-wave superconductive (SC) order mediated by interlayer magnetic couplings. Large-scale density matrix renormaliza-tion group calculations find algebraic pairing correlations with Luttinger parameter KSC ≲ 1. Infinite projected entangled-pair state method obtains a nonzero SC order directly in the thermodynamic limit, and estimates a strong pairing strength temperature evolution of SC pairing and further determine a high SC temperature Tc∗ /J O(0.1). Because of the intriguing orbital selective behaviors and strong Hund’s rule coupling in the compound, t-J-J⊥ model has strong interlayer spin exchange (while negligible interlayer hopping), which greatly enhances the SC pairing in the bilayer system. Such a magnetically mediated pairing has also been observed recently in the optical lattice of ultracold atoms. Our accurate and comprehensive tensor-network calculations reveal a robust SC order in the bilayer t-J-J⊥ model and shed light on the pairing mechanism of the high-Tc nickelate superconductor. Δ¯z O(0.1). Tangent-space tensor renormalization group simulations elucidate the																																	2024-05-25	PPRN:74186759		
J	Motlagh, Danial; Wiebe, Nathan										Generalized Quantum Signal Processing								Arxiv											2	2;2024-01-19;https://www.arxiv.org/abs/2308.01501v2| 1;2023-08-03;https://www.arxiv.org/abs/2308.01501v1	arXiv:2308.01501			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Jan 19 2024	2024	Quantum Signal Processing (QSP) and Quantum Singular Value Transformation (QSVT) currently stand as the most efficient techniques for implementing functions of block encoded matrices, a central task that lies at the heart of most prominent quantum algorithms. However, current QSP approaches face several challenges, such as the restrictions imposed on the family of achievable poly-nomials and the difficulty of calculating the required phase angles for specific transformations. In this paper, we present a Generalized Quantum Signal Processing (GQSP) approach, employing gen-eral SU(2) rotations as our signal processing operators, rather than relying solely on rotations in a single basis. Our approach lifts all practical restrictions on the family of achievable transformations, with the sole remaining condition being that |P| ≤ 1, a restriction necessary due to the unitary nature of quantum computation. Furthermore, GQSP provides a straightforward recursive formula for determining the rotation angles needed to construct the polynomials in cases where P and Q are known. In cases where only P is known, we provide an efficient optimization algorithm capable of identifying in under a minute of GPU time, a corresponding Q for polynomials of degree on the or-der of 107. We further illustrate GQSP simplifies QSP-based strategies for Hamiltonian simulation, offer an optimal solution to the ϵ-approximate fractional query problem that requires O (1/δ + log(1/ϵ )) queries to perform where O(1/δ) is a proved lower bound, and introduces novel approaches for im-plementing bosonic operators. Moreover, we propose a novel framework for the implementation of normal matrices, demonstrating its applicability through synthesis of diagonal matrices, as well as the development of a new algorithm for convolution through synthesis of circulant matrices using only O(d log N + log2 N) 1 and 2-qubit gates for a filter of lengths d.																																	2024-05-25	PPRN:74238445		
J	Thulke, David; Gao, Yingbo; Pelser, Petrus; Brune, Rein; Jalota, Rricha; Fok, Floris; Ramos, Michael; van Wyk, Ian; Nasir, Abdallah; Goldstein, Hayden; Tragemann, Taylor; Nguyen, Katie; Fowler, Ariana; Stanco, Andrew; Gabriel, Jon; Taylor, Jordan; Moro, Dean; Tsymbalov, Evgenii; de Waal, Juliette; Matusov, Evgeny; Yaghi, Mudar; Shihadah, Mohammad; Ney, Hermann; Dugast, Christian; Dotan, Jonathan; Erasmus, Daniel				Gao, Yingbo/KLC-9216-2024						ClimateGPT: Towards AI Synthesizing Interdisciplinary Research on Climate Change								Arxiv											1	1;2024-01-17;https://www.arxiv.org/abs/2401.09646v1	arXiv:2401.09646			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Jan 17 2024	2024	This paper introduces ClimateGPT, a model family of domain-specific large language models that synthesize interdisciplinary research on climate change. We trained two 7B models from scratch on a science-oriented dataset of 300B tokens. For the first model, the 4.2B domain-specific tokens were included during pre-training and the second was adapted to the climate domain after pre-training. Additionally, ClimateGPT-7B, 13B and 70B are continuously pre-trained from Llama~2 on a domain-specific dataset of 4.2B tokens. Each model is instruction fine-tuned on a high-quality and human-generated domain-specific dataset that has been created in close cooperation with climate scientists. To reduce the number of hallucinations, we optimize the model for retrieval augmentation and propose a hierarchical retrieval strategy. To increase the accessibility of our model to non-English speakers, we propose to make use of cascaded machine translation and show that this approach can perform comparably to natively multilingual models while being easier to scale to a large number of languages. Further, to address the intrinsic interdisciplinary aspect of climate change we consider different research perspectives. Therefore, the model can produce in-depth answers focusing on different perspectives in addition to an overall answer. We propose a suite of automatic climate-specific benchmarks to evaluate LLMs. On these benchmarks, ClimateGPT-7B performs on par with the ten times larger Llama-2-70B Chat model while not degrading results on general domain benchmarks. Our human evaluation confirms the trends we saw in our benchmarks. All models were trained and evaluated using renewable energy and are released publicly1.																																	2024-02-03	PPRN:87224385		
J	Qin, Zhen; Sun, Weigao; Li, Dong; Shen, Xuyang; Sun, Weixuan; Zhong, Yiran				Yang, Yifan/JTV-1487-2023						Lightning Attention-2: A Free Lunch for Handling Unlimited Sequence Lengths in Large Language Models								Arxiv											2	2;2024-01-15;https://www.arxiv.org/abs/2401.04658v2| 1;2024-01-09;https://www.arxiv.org/abs/2401.04658v1	arXiv:2401.04658			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 15 2024	2024	Linear attention is an efficient attention mechanism that has recently emerged as a promising alternative to conventional softmax attention. With its ability to process tokens in linear computational complexities, linear attention, in theory, can handle sequences of unlimited length without sacrificing speed, i.e., maintaining a constant training speed for various sequence lengths with a fixed memory consumption. However, due to the issue with cumulative summation (cumsum), current Linear Attention algorithms cannot demonstrate their theoretical advantage in a casual setting. In this paper, we present Lightning Attention-2, the first linear attention implementation that enables linear attention to realize its theoretical computational benefits. To achieve this, we leverage the thought of tiling, separately handling the intrablock and inter-block components in linear attention calculation. Specifically, we utilize the conventional attention computation mechanism for the intra-blocks and apply linear attention kernel tricks for the inter-blocks. A tiling technique is adopted through both forward and backward procedures to take full advantage of the GPU hardware. We implement our algorithm in Triton to make it IO-aware and hardware-friendly. Various experiments are conducted on different model sizes and sequence lengths. Lightning Attention-2 retains consistent training and inference speed regardless of input sequence length and is significantly faster than other attention mechanisms. The source code is available at Lightning Attention-2.																																	2024-05-25	PPRN:87077907		
J	Wu, Jay Zhangjie; Fang, Guian; Wu, Haoning; Wang, Xintao; Ge, Yixiao; Cun, Xiaodong; Zhang, David Junhao; Liu, Jia-Wei; Gu, Yuchao; Zhao, Rui; Lin, Weisi; Hsu, Wynne; Shan, Ying; Shou, Mike Zheng				Shou, Mike Zheng/LXW-9197-2024; Cun, Xiaodong/AAA-4674-2022; Gu, Yuchao/JOZ-3846-2023; Lin, Weisi/A-8011-2012; Wu, Zhangjie/LUY-7529-2024						Towards A Better Metric for Text-to-Video Generation								Arxiv											1	1;2024-01-15;https://www.arxiv.org/abs/2401.07781v1	arXiv:2401.07781			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 15 2024	2024	Generative models have demonstrated remarkable capability in synthesizing high-quality text, images, and videos. For video generation, contemporary text-to-video models exhibit impressive capabilities, crafting visually stunning videos. Nonetheless, evaluating such videos poses significant challenges. Current research predominantly employs automated metrics such as FVD, IS, and CLIP Score. However, these metrics provide an incomplete analysis, particularly in the temporal assessment of video content, thus rendering them unreliable indicators of true video quality. Furthermore, while user studies have the potential to reflect human perception accurately, they are hampered by their time-intensive and laborious nature, with outcomes that are often tainted by subjective bias. In this paper, we investigate the limitations inherent in existing metrics and introduce a novel evaluation pipeline, the Text-to-Video Score (T2VScore). This metric integrates two pivotal criteria: (1) Text-Video Alignment, which scrutinizes the fidelity of the video in representing the given text description, and (2) Video Quality, which evaluates the video’s overall production caliber with a mixture of experts. Moreover, to evaluate the proposed metrics and facilitate future improvements on them, we present the TVGE dataset, collecting human judgements of 2,543 text-to-video generated videos on the two criteria. Experiments on the TVGE dataset demonstrate the superiority of the proposed T2VScore on offering a better metric for text-to-video generation. The code and dataset will be open-sourced.																																	2024-05-25	PPRN:87187111		
J	Tang, Chuanming; Wang, Xiao; Huang, Ju; Jiang, Bo; Zhu, Lin; Zhang, Jianlin; Wang, Yaowei; Tian, Yonghong				zhu, lin/AEC-6241-2022; Tang, Chuanming/KXR-6065-2024; TIAN, Yonghong/M-4937-2013						Revisiting Color-Event based Tracking: A Unified Network, Dataset, and Metric								Arxiv											1	1;2024-01-08;https://www.arxiv.org/abs/2211.11010v2	arXiv:2211.11010			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Jan 08 2024	2024	Combining Color and Event cameras (also called Dynamic Vision Sensors, DVS) for robust object tracking is a newly emerging research topic in recent years. Existing color-event tracking frameworks usually contain multiple scattered modules which may lead to low efficiency and high computational complexity, including feature extraction, fusion, matching, interactive learning, etc. In this paper, we propose a single-stage backbone network for Color-Event Unified Tracking (CEUTrack) that achieves the above functions simultaneously. Given the event points and color frames, we first transform the points into voxels and crop the template and search regions for both modalities, respectively. Then, these regions are projected into tokens and jointly fed into the adaptive vision transformer network. The output features will be fed into a tracking head for target object localization. Our proposed CEUTrack is simple, effective, and efficient, achieving over 75 FPS and new SOTA performance. To better validate the effectiveness of our model and address the data deficiency of the color-event tracking task, we propose a generic and large-scale benchmark dataset for color-event tracking, termed COESOT, which contains 90 categories and 1354 video sequences. Furthermore, a new evaluation criterion has been proposed, aiming to better assess tracking results by measuring the difficulty level of video frames. We hope the newly proposed method and dataset provide a better platform for color-event-based tracking. The dataset, toolkit, and source code have been released on https://github.com/Event-AHU/COESOT.																																	2024-01-25	PPRN:87048854		
J	Chen, Wenxi; Ma, Ziyang; Yan, Ruiqi; Liang, Yuzhe; Li, Xiquan; Xu, Ruiyang; Niu, Zhikang; Zhu, Yanqiao; Yang, Yifan; Liu, Zhanxun; Yu, Kai; Hu, Yuxuan; Li, Jinyu; Lu, Yan; Liu, Shujie; Chen, Xie				jinyu, Li/JQV-7729-2023; Xu, Ruiyang/LDF-6394-2024; Yu, Kai/M-2934-2019; hu, yuxuan/LNQ-2150-2024						SLAM-Omni: Timbre-Controllable Voice Interaction System with Single-Stage Training								Arxiv											1	1;2024-12-20;https://www.arxiv.org/abs/2412.15649v1	arXiv:2412.15649			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 20 2024	2024	Recent advancements highlight the potential of end-to-end real-time spoken dialogue systems, showcasing their low latency and high quality. In this paper, we introduce SLAM- Omni, a timbre-controllable, end-to-end voice interaction system with single-stage training. SLAM-Omni achieves zero-shot timbre control by modeling spoken language with semantic tokens and decoupling speaker information to a vocoder. By predicting grouped speech semantic tokens at each step, our method significantly reduces the sequence length of audio tokens, accelerating both training and inference. Additionally, we propose historical text prompting to compress dialogue history, facilitating efficient multi-round interactions. Comprehensive evaluations reveal that SLAM-Omni outperforms prior models of similar scale, requiring only 15 hours of training on 4 GPUs with limited data. Notably, it is the first spoken dialogue system to achieve competitive performance with a single-stage training approach, eliminating the need for pre-training on TTS or ASR tasks. Further experiments validate its multilingual and multi-turn dialogue capabilities on larger datasets.1																																	2025-01-24	PPRN:120117288		
J	Liu, Jiachen; Chung, Jae-Won; Wu, Zhiyu; Lai, Fan; Lee, Myungjin; Chowdhury, Mosharaf										Andes: Defining and Enhancing Quality-of-Experience in LLM-Based Text Streaming Services								Arxiv											2	2;2024-12-13;https://www.arxiv.org/abs/2404.16283v2| 1;2024-04-25;https://www.arxiv.org/abs/2404.16283v1	arXiv:2404.16283			http://creativecommons.org/publicdomain/zero/1.0/	http://creativecommons.org/publicdomain/zero/1.0/			preprint	Dec 13 2024	2024	Large language models (LLMs) are now at the core of conversational AI services such as real-time translation and chatbots, which provide live user interaction by incrementally streaming text to the user. However, existing LLM serving systems fail to provide good user experience because their optimization metrics are not always aligned with user experience. In this paper, we first introduce and define the notion of Quality-of-Experience (QoE) for text streaming services by considering each user’s end-to-end interaction timeline. Based on this, we propose Andes, a QoE-aware LLM serving system that enhances user experience by ensuring that users receive the first token promptly and subsequent tokens at a smooth, digestible pace, even during surge periods. This is enabled by Andes’s preemptive request scheduler that dynamically prioritizes requests at the token granularity based on each request’s expected QoE gain and GPU resource usage. Our evaluations demonstrate that, compared to state-of-the-art LLM serving systems, Andes improves the average QoE by up to 4.7× given the same GPU resource, or saves up to 61% GPU resources while maintaining the same high QoE.																																	2025-01-21	PPRN:88650934		
J	Lin, Luyang; Wang, Lingzhi; Guo, Jinsong; Wong, Kam-Fai				WANG, Lingzhi/GNM-9660-2022						Investigating Bias in LLM-Based Bias Detection: Disparities between LLMs and Human Perception								Arxiv											2	2;2024-12-10;https://www.arxiv.org/abs/2403.14896v2| 1;2024-03-22;https://www.arxiv.org/abs/2403.14896v1	arXiv:2403.14896			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Dec 10 2024	2024	The pervasive spread of misinformation and disinformation in social media underscores the critical importance of detecting media bias. While robust Large Language Models (LLMs) have emerged as foundational tools for bias prediction, concerns about inherent biases within these models persist. In this work, we investigate the presence and nature of bias within LLMs and its consequential impact on media bias detection. Departing from conventional approaches that focus solely on bias detection in media content, we delve into biases within the LLM systems themselves. Through meticulous examination, we probe whether LLMs exhibit biases, particularly in political bias prediction and text continuation tasks. Additionally, we explore bias across diverse topics, aiming to uncover nuanced variations in bias expression within the LLM framework. Importantly, we propose debiasing strategies, including prompt engineering and model fine-tuning. Extensive analysis of bias tendencies across different LLMs sheds light on the broader landscape of bias propagation in language models. This study advances our understanding of LLM bias, offering critical insights into its implications for bias detection tasks and paving the way for more robust and equitable AI systems1.																																	2025-01-19	PPRN:88263715		
J	Liu, Shansong; Hussain, Atin Sakkeer; Wu, Qilong; Sun, Chenshuo; Shan, Ying				Wu, Qilong/LWJ-3253-2024						M2UGen: Multi-modal Music Understanding and Generation with the Power of Large Language Models								Arxiv											5	5;2024-12-09;https://www.arxiv.org/abs/2311.11255v5| 4;2024-03-05;https://www.arxiv.org/abs/2311.11255v4| 3;2024-01-05;https://www.arxiv.org/abs/2311.11255v3| 2;2023-11-28;https://www.arxiv.org/abs/2311.11255v2| 1;2023-11-19;https://www.arxiv.org/abs/2311.11255v1	arXiv:2311.11255			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 09 2024	2024	The current landscape of research leveraging large language models (LLMs) is experiencing a surge. Many works harness the powerful reasoning capabilities of these models to comprehend various modalities, such as text, speech, images, videos, etc. They also utilize LLMs to understand human intention and generate desired outputs like images, videos and music. However, research that combines both understanding and generation using LLMs is still limited and in its nascent stage. To address this gap, we introduce a Multi-modal Music Understanding and Generation (M2UGen) framework that integrates LLM’s abilities to comprehend and generate music for different modalities. The M2UGen framework is purpose-built to unlock creative potential from diverse sources of inspiration, encompassing music, image and video through the use of pretrained MERT, ViT, and ViViT models, respectively. To enable music generation, we explore the use of AudioLDM 2 and MusicGen. Bridging multi-modal understanding and music generation is accomplished through the integration of the LLaMA 2 model. Furthermore, we make use of the MULLaMA model to generate extensive datasets that support text/image/video-to-music generation, facilitating the training of our M2UGen framework. We conduct a thorough evaluation of our proposed framework. The experimental results demonstrate that our model achieves or surpasses the performance of the current state-of-the-art models.																																	2025-01-17	PPRN:86214747		
J	Chattopadhyay, Ashesh; Sun, Y. Qiang; Hassanzadeh, Pedram				Hassanzadeh, Pedram/A-7489-2008						Challenges of learning multi-scale dynamics with AI weather models: Implications for stability and one solution								Arxiv											2	2;2024-12-07;https://www.arxiv.org/abs/2304.07029v2| 1;2023-04-14;https://www.arxiv.org/abs/2304.07029v1	arXiv:2304.07029			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 07 2024	2024	Long-term stability and physical consistency are critical properties for AI-based weather models if they are going to be used for subseasonal-to-seasonal forecasts or beyond, e.g., climate change projection. However, current AI-based weather models can only provide short-term forecasts accurately since they become unstable or physically inconsistent when time-integrated beyond a few weeks or a few months. Either they exhibit numerical blow-up or hallucinate unrealistic dynamics of the atmospheric variables, akin to the current class of autoregressive large language models. The cause of the instabilities is unknown, and the methods that are used to improve their stability horizons are ad-hoc and lack rigorous theory. In this paper, we reveal that the universal causal mechanism for these instabilities in any turbulent flow is due to spectral bias wherein, any deep learning architecture is biased to learn only the large-scale dynamics and ignores the small scales completely. We further elucidate how turbulence physics and the absence of convergence in deep learning-based time-integrators amplify this bias, leading to unstable error propagation. Finally, using the quasi-geostrophic flow and European Center for Medium-Range Weather Forecasting (ECMWF) Reanalysis data as test cases, we bridge the gap between deep learning theory and numerical analysis to propose one mitigative solution to such unphysical behavior. We develop long-term physically-consistent data-driven models for the climate system and demonstrate accurate short-term forecasts, and hundreds of years of time-integration with accurate mean and variability.																																	2025-01-17	PPRN:62684298		
J	Wang, Fu-Yun; Huang, Zhaoyang; Bergman, Alexander William; Shen, Dazhong; Gao, Peng; Lingelbach, Michael; Sun, Keqiang; Bian, Weikang; Song, Guanglu; Liu, Yu; Wang, Xiaogang; Li, Hongsheng				Wang, Xiaogang/L-4369-2014; Huang, Zhaoyang/IUN-1167-2023; Gao, Peng/B-4675-2012						Phased Consistency Models								Arxiv											2	2;2024-12-04;https://www.arxiv.org/abs/2405.18407v2| 1;2024-05-28;https://www.arxiv.org/abs/2405.18407v1	arXiv:2405.18407			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 04 2024	2024	Consistency Models (CMs) have made significant progress in accelerating the generation of diffusion models. However, their application to high-resolution, text-conditioned image generation in the latent space remains unsatisfactory. In this paper, we identify three key flaws in the current design of Latent Consistency Models (LCMs). We investigate the reasons behind these limitations and propose Phased Consistency Models (PCMs), which generalize the design space and address the identified limitations. Our evaluations demonstrate that PCMs outperform LCMs across 1--16 step generation settings. While PCMs are specifically designed for multi-step refinement, they achieve comparable 1-step generation results to previously state-of-the-art specifically designed 1-step methods. Furthermore, we show the methodology of PCMs is versatile and applicable to video generation, enabling us to train the state-of-the-art few-step text-to-video generator.  [GRAPHICS]																																	2025-01-15	PPRN:89091615		
J	Waczynska, Joanna; Borycki, Piotr; Tadeja, Slawomir; Tabor, Jacek; Spurek, Przemyslaw				Tadeja, Sławomir Konrad/ABB-9669-2021						GaMeS: Mesh-Based Adapting and Modification of Gaussian Splatting								Arxiv											4	4;2024-12-02;https://www.arxiv.org/abs/2402.01459v4| 3;2024-02-15;https://www.arxiv.org/abs/2402.01459v3| 2;2024-02-06;https://www.arxiv.org/abs/2402.01459v2| 1;2024-02-02;https://www.arxiv.org/abs/2402.01459v1	arXiv:2402.01459			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Dec 02 2024	2024	Gaussian Splatting (GS) is a novel, state-of-the-art technique for rendering points in a 3D scene by approximating their contribution to image pixels through Gaussian distributions, warranting fast training and real-time rendering. The main drawback of GS is the absence of a well-defined approach for its conditioning due to the necessity of conditioning several hundred thousand Gaussian components. To solve this, we introduce the Gaussian Mesh Splatting (GaMeS) model, which allows modification of Gaussian components in a similar way as meshes. We parameterize each Gaussian component by the vertices of the mesh face. Furthermore, our model needs mesh initialization on input or estimated mesh during training. We also define Gaussian splats solely based on their location on the mesh, allowing for automatic adjustments in position, scale, and rotation during animation. As a result, we obtain a real-time rendering of editable GS.																																	2025-01-15	PPRN:87508962		
J	Ren, Tianhe; Chen, Yihao; Jiang, Qing; Zeng, Zhaoyang; Xiong, Yuda; Liu, Wenlong; Ma, Zhengyu; Shen, Junyi; Gao, Yuan; Jiang, Xiaoke; Chen, Xingyu; Song, Zhuheng; Zhang, Yuhong; Huang, Hongjie; Gao, Han; Liu, Shilong; Zhang, Hao; Li, Feng; Yu, Kent; Zhang, Lei				huang, hongjie/HNP-3924-2023; Song, Zhuheng/JTT-0379-2023; Chen, Xingyu/KYQ-1091-2024; Zeng, Zhao/D-1959-2010; Liu, Wenlong/LWJ-5695-2024; ma, zhengyu/IRZ-4027-2023; Liu, Shilong/GVS-1257-2022						DINO-X: A Unified Vision Model for Open-World Object Detection and Understanding								Arxiv											1	1;2024-11-21;https://www.arxiv.org/abs/2411.14347v1	arXiv:2411.14347			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 21 2024	2024	In this paper, we introduce DINO-X, which is a unified object-centric vision model developed by IDEA Research with the best open-world object detection performance to date. DINO-X employs the same Transformer-based encoder-decoder architecture as Grounding DINO 1.5 [47] to pursue an object-level representation for open-world object understanding. To make long-tailed object detection easy, DINO-X extends its input options to support text prompt, visual prompt, and customized prompt. With such flexible prompt options, we develop a universal object prompt to support prompt-free open-world detection, making it possible to detect anything in an image without requiring users to provide any prompt. To enhance the model’s core grounding capability, we have constructed a largescale dataset with over 100 million high-quality grounding samples, referred to as Grounding-100M, for advancing the model’s open-vocabulary detection performance. Pre-training on such a large-scale grounding dataset leads to a foundational object-level representation, which enables DINO-X to integrate multiple perception heads to simultaneously support multiple object perception and understanding tasks, including detection, segmentation, pose estimation, object captioning, object- based QA, etc. DINO-X encompasses two models: the Pro model, which provides enhanced perception capabilities for various scenarios, and the Edge model, which is optimized for faster inference speed and better suited for deployment on edge devices. Experimental results demonstrate the superior performance of DINO-X. Specifically, the DINO-X Pro model achieves 56.0 AP, 59.8 AP, and 52.4 AP on the COCO, LVIS-minival, and LVIS-val zero-shot object detection benchmarks, respectively. Notably, it scores 63.3 AP and 56.5 AP on the rare classes of LVIS-minival and LVIS-val benchmarks, both improving the previous SOTA performance by 5.8 AP. Such a result underscores its significantly improved capacity for recognizing long-tailed objects. Our demo and API will be released at https://github.com/IDEAResearch/DINO-X-API.																																	2025-01-24	PPRN:119320401		
J	Ye, Chenlu; Xiong, Wei; Zhang, Yuheng; Dong, Hanze; Jiang, Nan; Zhang, Tong				Zhang, Tong/HGC-1090-2022; Ye, Chenlu/JUV-1872-2023						Online Iterative Reinforcement Learning from Human Feedback with General Preference Model								Arxiv											3	3;2024-11-12;https://www.arxiv.org/abs/2402.07314v3| 2;2024-04-25;https://www.arxiv.org/abs/2402.07314v2| 1;2024-02-11;https://www.arxiv.org/abs/2402.07314v1	arXiv:2402.07314			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Nov 12 2024	2024	We investigate Reinforcement Learning from Human Feedback (RLHF) in the context of a general preference oracle. In particular, we do not assume the existence of a reward function and an oracle preference signal drawn from the Bradley-Terry model as most of the prior works do. We consider a standard mathematical formulation, the reverse-KL regularized minimax game between two LLMs for RLHF under general preference oracle. The learning objective of this formulation is to find a policy so that it is consistently preferred by the KL-regularized preference oracle over any competing LLMs. We show that this framework is strictly more general than the reward-based one, and propose sample-efficient algorithms for both the offline learning from a pre-collected preference dataset and online learning where we can query the preference oracle along the way of training. Empirical studies verify the effectiveness of the proposed framework.																																	2024-12-18	PPRN:87648534		
J	Brantner, Lukas; Campos, Ricardo; Nuiten, Joost				Campos, Ricardo/NXY-3225-2025						PD Operads and Explicit Partition Lie Algebras								Arxiv											3	3;2024-11-11;https://www.arxiv.org/abs/2104.03870v6| 2;2023-12-18;https://www.arxiv.org/abs/2104.03870v5| 1;2022-08-25;https://www.arxiv.org/abs/2104.03870v3	arXiv:2104.03870			http://creativecommons.org/licenses/by-nc-nd/4.0/	http://creativecommons.org/licenses/by-nc-nd/4.0/			preprint	Nov 11 2024	2024	Infinitesimal deformations are governed by partition Lie algebras. In characteristic 0, these higher categorical structures are modelled by differential graded Lie algebras, but in characteristic p, they are more subtle. We give explicit models for partition Lie algebras over general coherent rings, both in the setting of spectral and derived algebraic geometry. For the spectral case, we refine operadic Koszul duality to a functor from operads to divided power operads, by taking ‘refined linear duals’ of Σn-representations. The derived case requires a further refinement of Koszul duality to a more genuine setting.																																	2024-12-19	PPRN:12426859		
J	Li, Xiang; Zhao, Lin; Zhang, Lu; Wu, Zihao; Liu, Zhengliang; Jiang, Hanqi; Cao, Chao; Xu, Shaochen; Li, Yiwei; Dai, Haixing; Yuan, Yixuan; Liu, Jun; Li, Gang; Zhu, Dajiang; Yan, Pingkun; Li, Quanzheng; Liu, Wei; Liu, Tianming; Shen, Dinggang				Wu, Zihao/HTS-4421-2023; Liu, Wei/JYQ-6082-2024; Zhao, Lin/ABM-7665-2022; yuan, yixuan/KLZ-6092-2024; Quanzheng, Li/OHU-0205-2025; wu, zihao/R-8745-2019; Liu, Tianming/GLS-1211-2022						Artificial General Intelligence for Medical Imaging Analysis								Arxiv											3	3;2024-11-04;https://www.arxiv.org/abs/2306.05480v3| 2;2023-07-03;https://www.arxiv.org/abs/2306.05480v2| 1;2023-06-08;https://www.arxiv.org/abs/2306.05480v1	arXiv:2306.05480			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 04 2024	2024	Large-scale Artificial General Intelligence (AGI) models, including Large Language Models (LLMs) such as ChatGPT/GPT-4, have achieved unprecedented success in a variety of general domain tasks. Yet, when applied directly to specialized domains like medical imaging, which require in-depth expertise, these models face notable challenges arising from the medical field's inherent complexities and unique characteristics. In this review, we delve into the potential applications of AGI models in medical imaging and healthcare, with a primary focus on LLMs, Large Vision Models, and Large Multimodal Models. We provide a thorough overview of the key features and enabling techniques of LLMs and AGI, and further examine the roadmaps guiding the evolution and implementation of AGI models in the medical sector, summarizing their present applications, potentialities, and associated challenges. In addition, we highlight potential future research directions, offering a holistic view on upcoming ventures. This comprehensive review aims to offer insights into the future implications of AGI in medical imaging, healthcare, and beyond.																																	2025-04-19	PPRN:73266563		
J	Masry, Ahmed; Thakkar, Megh; Bajaj, Aayush; Kartha, Aaryaman; Hoque, Enamul; Joty, Shafiq										ChartGemma: Visual Instruction-tuning for Chart Reasoning in the Wild								Arxiv											2	2;2024-11-04;https://www.arxiv.org/abs/2407.04172v2| 1;2024-07-04;https://www.arxiv.org/abs/2407.04172v1	arXiv:2407.04172			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Nov 04 2024	2024	Given the ubiquity of charts as a data analysis, visualization, and decision-making tool across industries and sciences, there has been a growing interest in developing pre-trained foundation models as well as general purpose instruction-tuned models for chart understanding and reasoning. However, existing methods suffer crucial drawbacks across two critical axes affecting the performance of chart representation models: they are trained on data generated from underlying data tables of the charts, ignoring the visual trends and patterns in chart images, and use weakly aligned vision-language backbone models for domain-specific training, limiting their generalizability when encountering charts in the wild. We address these important drawbacks and introduce ChartGemma, a novel chart understanding and reasoning model developed over PaliGemma. Rather than relying on underlying data tables, ChartGemma is trained on instruction- tuning data generated directly from chart images, thus capturing both high-level trends and low-level visual information from a diverse set of charts. Our simple approach achieves stateof-the-art results across 5 benchmarks spanning chart summarization, question answering, and fact-checking, and our elaborate qualitative studies on real-world charts show that ChartGemma generates more realistic and factually correct summaries compared to its contemporaries. We release the code, model checkpoints, dataset, and demos at https://github.com/visnlp/ChartGemma.																																	2024-12-16	PPRN:90726300		
J	Kim, Jihwan; Kang, Junoh; Choi, Jinyoung; Han, Bohyung				Han, Bohyung/NOF-1581-2025						FIFO-Diffusion: Generating Infinite Videos from Text without Training								Arxiv											4	4;2024-11-03;https://www.arxiv.org/abs/2405.11473v4| 3;2024-06-12;https://www.arxiv.org/abs/2405.11473v3| 2;1800-01-01;https://www.arxiv.org/abs/2405.11473v2| 1;2024-05-19;https://www.arxiv.org/abs/2405.11473v1	arXiv:2405.11473			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Nov 03 2024	2024	We propose a novel inference technique based on a pretrained diffusion model for text-conditional video generation. Our approach, called FIFO-Diffusion, is conceptually capable of generating infinitely long videos without additional training. This is achieved by iteratively performing diagonal denoising, which simultaneously processes a series of consecutive frames with increasing noise levels in a queue; our method dequeues a fully denoised frame at the head while enqueuing a new random noise frame at the tail. However, diagonal denoising is a double-edged sword as the frames near the tail can take advantage of cleaner frames by forward reference but such a strategy induces the discrepancy between training and inference. Hence, we introduce latent partitioning to reduce the training-inference gap and lookahead denoising to leverage the benefit of forward referencing. Practically, FIFO-Diffusion consumes a constant amount of memory regardless of the target video length given a baseline model, while well-suited for parallel inference on multiple GPUs. We have demonstrated the promising results and effectiveness of the proposed methods on existing text-to-video generation baselines. 																																	2024-12-09	PPRN:89098105		
J	Kulhanek, Jonas; Peng, Songyou; Kukelova, Zuzana; Pollefeys, Marc; Sattler, Torsten				Kukelova, Zuzana/AAM-9096-2020; Sattler, Torsten/AAM-3155-2021						WildGaussians: 3D Gaussian Splatting in the Wild								Arxiv											2	2;2024-10-31;https://www.arxiv.org/abs/2407.08447v2| 1;2024-07-11;https://www.arxiv.org/abs/2407.08447v1	arXiv:2407.08447			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 31 2024	2024	While the field of 3D scene reconstruction is dominated by NeRFs due to their photorealistic quality, 3D Gaussian Splatting (3DGS) has recently emerged, offering similar quality with real-time rendering speeds. However, both methods primarily excel with well-controlled 3D scenes, while in-the-wild data - characterized by occlusions, dynamic objects, and varying illumination - remains challenging. NeRFs can adapt to such conditions easily through per-image embedding vectors, but 3DGS struggles due to its explicit representation and lack of shared parameters. To address this, we introduce WildGaussians, a novel approach to handle occlusions and appearance changes with 3DGS. By leveraging robust DINO features and integrating an appearance modeling module within 3DGS, our method achieves state-of-the-art results. We demonstrate that WildGaussians matches the real-time rendering speed of 3DGS while surpassing both 3DGS and NeRF baselines in handling in-the-wild data, all within a simple architectural framework.																																	2024-12-06	PPRN:90770957		
J	Diao, Haiwen; Cui, Yufeng; Li, Xiaotong; Wang, Yueze; Lu, Huchuan; Wang, Xinlong				Chen, Xiangyu/P-7839-2018; Xiaotong, Li/KDM-9760-2024; Diao, Haiwen/JJC-5475-2023						Unveiling Encoder-Free Vision-Language Models								Arxiv											2	2;2024-10-29;https://www.arxiv.org/abs/2406.11832v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11832v1	arXiv:2406.11832			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 29 2024	2024	Existing vision-language models (VLMs) mostly rely on vision encoders to extract visual features followed by large language models (LLMs) for visual-language tasks. However, the vision encoders set a strong inductive bias in abstracting visual representation, e.g ., resolution, aspect ratio, and semantic priors, which could impede the flexibility and efficiency of the VLMs. Training pure VLMs that accept the seamless vision and language inputs, i.e ., without vision encoders, remains challenging and rarely explored. Empirical observations reveal that direct training without encoders results in slow convergence and large performance gaps. In this work, we bridge the gap between encoder-based and encoder-free models, and present a simple yet effective training recipe towards pure VLMs. Specifically, we unveil the key aspects of training encoder-free VLMs efficiently via thorough experiments: (1) Bridging vision-language representation inside one unified decoder; (2) Enhancing visual recognition capability via extra supervision. With these strategies, we launch EVE, an encoder-free vision-language model that can be trained and forwarded efficiently. Notably, solely utilizing 35M publicly accessible data, EVE can impressively rival the encoder-based VLMs of similar capacities across multiple vision-language benchmarks. It significantly outperforms the counterpart Fuyu-8B [3] with mysterious training procedures and undisclosed training data. We believe that EVE provides a transparent and efficient route for developing pure decoder-only architecture across modalities.																																	2024-12-03	PPRN:89343005		
J	Huang, Tiansheng; Hu, Sihao; Ilhan, Fatih; Tekin, Selim Furkan; Liu, Ling				İlhan, Fatih/AAC-4591-2021						Lisa: Lazy Safety Alignment for Large Language Models against Harmful Fine-tuning Attack								Arxiv											5	5;2024-10-29;https://www.arxiv.org/abs/2405.18641v5| 4;2024-06-26;https://www.arxiv.org/abs/2405.18641v4| 3;2024-06-24;https://www.arxiv.org/abs/2405.18641v3| 2;2024-05-30;https://www.arxiv.org/abs/2405.18641v2| 1;2024-05-28;https://www.arxiv.org/abs/2405.18641v1	arXiv:2405.18641			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 29 2024	2024	Recent studies show that Large Language Models (LLMs) with safety alignment can be jail-broken by fine-tuning on a dataset mixed with harmful data. For the first time in the literature, we show that the jail-break effect can be mitigated by separating two states in the fine-tuning stage to respectively optimize over the alignment and user datasets. Unfortunately, our subsequent study shows that this simple Bi-State Optimization (BSO) solution experiences convergence instability when steps invested in its alignment state is too small, leading to downgraded alignment performance. By statistical analysis, we show that the excess drift towards the switching iterates of the two states could be a probable reason for the instability. To remedy this issue, we propose L azy(i) safety alignment (Lisa), which introduces a proximal term to constraint the drift of each state. Theoretically, the benefit of the proximal term is supported by the convergence analysis, wherein we show that a sufficient large proximal factor is necessary to guarantee Lisa’s convergence. Empirically, our results on four downstream fine-tuning tasks show that Lisa with a proximal term can significantly increase alignment performance while maintaining the LLM’s accuracy on the user tasks. 																																	2024-12-03	PPRN:89125023		
J	Garg, Roopal; Burns, Andrea; Ayan, Burcu Karagol; Bitton, Yonatan; Montgomery, Ceslee; Onoe, Yasumasa; Bunner, Andrew; Krishna, Ranjay; Baldridge, Jason; Soricut, Radu										ImageInWords: Unlocking Hyper-Detailed Image Descriptions								Arxiv											2	2;2024-10-28;https://www.arxiv.org/abs/2405.02793v2| 1;2024-05-05;https://www.arxiv.org/abs/2405.02793v1	arXiv:2405.02793			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 28 2024	2024	Despite the longstanding adage “an image is worth a thousand words,” generating accurate hyper-detailed image descriptions remains unsolved. Trained on short web-scraped imagetext, vision-language models often generate incomplete descriptions with visual inconsistencies. We address this via a novel data-centric approach with ImageInWords (IIW), a carefully designed human-in-the-loop framework for curating hyper-detailed image descriptions. Human evaluations on IIW data show major gains compared to recent datasets (+66%) and GPT4V (+48%) across comprehensiveness, specificity, hallucinations, and more. We also show that fine-tuning with IIW data improves these metrics by +31% against models trained with prior work, even with only 9k samples. Lastly, we evaluate IIW models with text-to-image generation and vision-language reasoning tasks. Our generated descriptions result in the highest fidelity images, and boost compositional reasoning by up to 6% on ARO, SVO-Probes, and Winoground datasets. We release the IIWEval benchmark with human judgement labels, object and image-level annotations from our framework, and existing image caption datasets enriched via IIW-model.																																	2024-11-30	PPRN:88791406		
J	Shi, Ruizhe; Chen, Yifang; Hu, Yushi; Liu, Alisa; Hajishirzi, Hannaneh; Smith, Noah A.; Du, Simon S.				Hu, Yushi/MGV-6188-2025						Decoding-Time Language Model Alignment with Multiple Objectives								Arxiv											3	3;2024-10-28;https://www.arxiv.org/abs/2406.18853v3| 2;2024-06-29;https://www.arxiv.org/abs/2406.18853v2| 1;2024-06-27;https://www.arxiv.org/abs/2406.18853v1	arXiv:2406.18853			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 28 2024	2024	Aligning language models (LMs) to human preferences has emerged as a critical pursuit, enabling these models to better serve diverse user needs. Existing methods primarily focus on optimizing LMs for a single reward function, limiting their adaptability to varied objectives. Here, we propose multi-objective decoding (MOD), a decoding-time algorithm that outputs the next token from a linear combination of predictions of all base models, for any given weighting over different objectives. We exploit a common form among a family of f-divergence regularized alignment approaches (such as PPO, DPO, and their variants) to identify a closed-form solution by Legendre transform, and derive an efficient decoding strategy. Theoretically, we show why existing approaches can be sub-optimal even in natural settings and obtain optimality guarantees for our method. Empirical results demonstrate the effectiveness of the algorithm. For example, compared to a parameter-merging baseline, MOD achieves 12.8% overall reward improvement when equally optimizing towards 3 objectives. Moreover, we experiment with MOD on combining three fully-finetuned LMs of different model sizes, each aimed at different objectives such as safety, coding, and general user preference. Unlike traditional methods that require careful curation of a mixture of datasets to achieve comprehensive improvement, we can quickly experiment with preference weightings using MOD to find the best combination of models. Our best combination reduces toxicity on Toxigen to nearly 0% and achieves 7.9–33.3% improvement across three other metrics ( i.e. , Codex@1, GSM-COT, BBH-COT).																																	2024-12-06	PPRN:90119010		
J	Cui, Jiequan; Tian, Zhuotao; Zhong, Zhisheng; Qi, Xiaojuan; Yu, Bei; Zhang, Hanwang				Cui, Jiequan/GPG-3132-2022; Yu, Bei/ABB-3824-2020; Qi, Xiaojuan/MVV-7776-2025; Tian, Zhuotao/HJP-1597-2023						Decoupled Kullback-Leibler Divergence Loss								Arxiv											3	3;2024-10-27;https://www.arxiv.org/abs/2305.13948v3| 2;2024-10-13;https://www.arxiv.org/abs/2305.13948v2| 1;2023-05-23;https://www.arxiv.org/abs/2305.13948v1	arXiv:2305.13948			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Oct 27 2024	2024	In this paper, we delve deeper into the Kullback-Leibler (KL) Divergence loss and mathematically prove that it is equivalent to the Decoupled Kullback-Leibler (DKL) Divergence loss that consists of 1) a weighted Mean Square Error (wMSE) loss and 2) a Cross-Entropy loss incorporating soft labels. Thanks to the decomposed formulation of DKL loss, we have identified two areas for improvement. Firstly, we address the limitation of KL/DKL in scenarios like knowledge distillation by breaking its asymmetric optimization property. This modification ensures that the $mathbf{w}$MSE component is always effective during training, providing extra constructive cues. Secondly, we introduce class-wise global information into KL/DKL to mitigate bias from individual samples. With these two enhancements, we derive the Improved Kullback-Leibler (IKL) Divergence loss and evaluate its effectiveness by conducting experiments on CIFAR-10/100 and ImageNet datasets, focusing on adversarial training, and knowledge distillation tasks. The proposed approach achieves new state-of-the-art adversarial robustness on the public leaderboard - RobustBench and competitive performance on knowledge distillation, demonstrating the substantial practical merits.																																	2024-12-06	PPRN:71594057		
J	Fountas, Zafeirios; Benfeghoul, Martin A; Oomerjee, Adnan; Christopoulou, Fenia; Lampouras, Gerasimos; Bou-Ammar, Haitham; Wang, Jun				Fountas, Zafeirios/J-9589-2019; Christopoulou, Efstathia/AAS-3177-2020						Human-like Episodic Memory for Infinite Context LLMs								Arxiv											2	2;2024-10-25;https://www.arxiv.org/abs/2407.09450v2| 1;2024-07-12;https://www.arxiv.org/abs/2407.09450v1	arXiv:2407.09450			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 25 2024	2024	Large language models (LLMs) have shown remarkable capabilities, but still struggle with processing extensive contexts, limiting their ability to maintain coherence and accuracy over long sequences. In contrast, the human brain excels at organising and retrieving episodic experiences across vast temporal scales, spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that integrates key aspects of human episodic memory and event cognition into LLMs with no fine-tuning, enabling them to handle practically infinite context lengths while maintaining computational efficiency. EM-LLM organises sequences of tokens into coherent episodic events using a combination of Bayesian surprise and graph-theoretic boundary refinement in an online fashion. When needed, these events are retrieved through a two-stage memory process, combining similarity-based and temporally contiguous retrieval for efficient and human-like access to relevant information. Experiments on the LongBench and InfiniteBench benchmarks demonstrate EM-LLM's superior performance, consistently outperforming the state-of-the-art retrieval model InfLLM across various baseline LLMs. In addition, EM-LLM outperforms its popular counterpart, RAG, in a wide range of tasks, while requiring similar resources. Notably, EM-LLM's performance even surpasses full-context models in most tasks, while successfully performing retrieval across 10 million tokens - a scale computationally infeasible for such models. Finally, our analysis reveals strong correlations between EM-LLM's event segmentation and human-perceived events, suggesting a bridge between this artificial system and its biological counterpart, thereby offering a novel computational framework for exploring human memory mechanisms.																																	2024-11-30	PPRN:90794002		
J	Zhu, Guanyu; Sikander, Shehryar; Portnoy, Elia; Cross, Andrew W.; Brown, Benjamin J.				Brown, Benjamin/J-7893-2017; Zhu, Guanyu/U-4083-2019						Non-Clifford and parallelizable fault-tolerant logical gates on constant and almost-constant rate homological quantum LDPC codes via higher symmetries								Arxiv											2	2;2024-10-23;https://www.arxiv.org/abs/2310.16982v2| 1;2023-10-25;https://www.arxiv.org/abs/2310.16982v1	arXiv:2310.16982			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 23 2024	2024	We study parallel fault-tolerant quantum computing for families of homological quantum lowdensity parity-check (LDPC) codes defined on 3-manifolds with constant or almost-constant enco ding rate. We derive generic formula for a transversal T gate on color codes defined on general 3-manifolds, which acts as collective non-Clifford logical CCZ gates on any triplet of logical qubits with their logical- X membranes having a Z2 triple intersection at a single point. The triple intersection number is a topological invariant, which also arises in the path integral of the emergent higher symmetry operator in a topological quantum field theory (TQFT): the Z32 gauge theory. Moreover, the transversal S gate of the color code corresponds to a higher-form symmetry in TQFT supported on a codimension-1 submanifold, giving rise to exponentially many addressable and parallelizable logical CZ gates. A construction of constant-depth circuits of the above logical gates via cup product cohomology operation is also presented for three copies of identical toric codes on arbitrary 3-manifolds. We have developed a generic formalism to compute the triple intersection invariants for 3-manifolds, with the structure encoded into an interaction hypergraph which determines the logical gate property and also corresponds to the hypergraph magic state that can be injected into the code. We also study the scaling of the Betti number and systoles with volume for various 3manifolds, which translates to the encoding rate and distance. We further develop three types of LDPC codes supporting such logical gates: (1) A quasi-hyperbolic code from the product of 2D hyperbolic surface and a circle, with almost-constant rate k/n = O (1 / log( n )) and O (log( n )) distance; (2) A homological fibre bundle code from twisting the product by an isometry of the surface based  on the construction by Freedman-Meyer-Luo, with O (1 / log 1/2 ( n )) rate and O (log 1/2 ( n )) distance; (3) A specific family of 3D hyperbolic codes: the Torelli mapping torus code, constructed from mapping tori of a pseudo-Anosov element in the Torelli subgroup, which has constant rate while the distance scaling is currently unknown. We then show a generic constant-overhead scheme for applying a parallelizable universal gate set with the aid of logical- X measurements.																																	2024-11-26	PPRN:85822980		
J	Ruoss, Anian; Deletang, Gregoire; Medapati, Sourabh; Grau-Moya, Jordi; Wenliang, Li Kevin; Catt, Elliot; Reid, John; Lewis, Cannada A.; Veness, Joel; Genewein, Tim										Amortized Planning with Large-Scale Transformers: A Case Study on Chess								Arxiv											2	2;2024-10-21;https://www.arxiv.org/abs/2402.04494v2| 1;2024-02-07;https://www.arxiv.org/abs/2402.04494v1	arXiv:2402.04494			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 21 2024	2024	This paper uses chess, a landmark planning problem in AI, to assess transformers' performance on a planning task where memorization is futile $unicode{x2013}$ even at a large scale. To this end, we release ChessBench, a large-scale benchmark dataset of 10 million chess games with legal move and value annotations (15 billion data points) provided by Stockfish 16, the state-of-the-art chess engine. We train transformers with up to 270 million parameters on ChessBench via supervised learning and perform extensive ablations to assess the impact of dataset size, model size, architecture type, and different prediction targets (state-values, action-values, and behavioral cloning). Our largest models learn to predict action-values for novel boards quite accurately, implying highly non-trivial generalization. Despite performing no explicit search, our resulting chess policy solves challenging chess puzzles and achieves a surprisingly strong Lichess blitz Elo of 2895 against humans (grandmaster level). We also compare to Leela Chess Zero and AlphaZero (trained without supervision via self-play) with and without search. We show that, although a remarkably good approximation of Stockfish's search-based algorithm can be distilled into large-scale transformers via supervised learning, perfect distillation is still beyond reach, thus making ChessBench well-suited for future research.																																	2024-11-20	PPRN:87562018		
J	Bowen, Dillon; Murphy, Brendan; Cai, Will; Khachaturov, David; Gleave, Adam; Pelrine, Kellin				Pelrine, Kellin/JMC-4554-2023; Gleave, Adam/ABG-1220-2020						Scaling Laws for Data Poisoning in LLMs								Arxiv											3	3;2024-10-17;https://www.arxiv.org/abs/2408.02946v3| 2;2024-08-30;https://www.arxiv.org/abs/2408.02946v2| 1;2024-08-06;https://www.arxiv.org/abs/2408.02946v1	arXiv:2408.02946			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 17 2024	2024	Recent work shows that LLMs are vulnerable to data poisoning, in which they are trained on partially corrupted or harmful data. Poisoned data is hard to detect, breaks guardrails, and leads to undesirable and harmful behavior. Given the intense efforts by leading labs to train and deploy increasingly larger and more capable LLMs, it is critical to ask if the risk of data poisoning will be naturally mitigated by scale, or if it is an increasing threat. We consider three threat models by which data poisoning can occur: malicious fine-tuning, imperfect data curation, and intentional data contamination. Our experiments evaluate the effects of data poisoning on 23 frontier LLMs ranging from 1.5-72 billion parameters, on three datasets which speak to each of our threat models. We find that larger LLMs are increasingly vulnerable, learning harmful behavior significantly quicker than smaller LLMs with even minimal data poisoning. Additionally, we demonstrate that even frontier GPT models, despite additional moderation systems, remain susceptible to data poisoning. These results underscore the need for robust safeguards against data poisoning in larger LLMs.																																	2024-11-13	PPRN:91269793		
J	Li, Zhuowan; Li, Cheng; Zhang, Mingyang; Mei, Qiaozhu; Bendersky, Michael										Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach								Arxiv											2	2;2024-10-17;https://www.arxiv.org/abs/2407.16833v2| 1;2024-07-23;https://www.arxiv.org/abs/2407.16833v1	arXiv:2407.16833			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 17 2024	2024	Retrieval Augmented Generation (RAG) has been a powerful tool for Large Language Models (LLMs) to efficiently process overly lengthy contexts. However, recent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to understand long contexts directly. We conduct a comprehensive comparison between RAG and long-context (LC) LLMs, aiming to leverage the strengths of both. We benchmark RAG and LC across various public datasets using three latest LLMs. Results reveal that when resourced sufficiently, LC consistently outperforms RAG in terms of average performance. However, RAG's significantly lower cost remains a distinct advantage. Based on this observation, we propose Self-Route, a simple yet effective method that routes queries to RAG or LC based on model self-reflection. Self-Route significantly reduces the computation cost while maintaining a comparable performance to LC. Our findings provide a guideline for long-context applications of LLMs using RAG and LC.																																	2024-11-12	PPRN:91057439		
J	Fang, Guangchi; Wang, Bing										Mini-Splatting: Representing Scenes with a Constrained Number of Gaussians								Arxiv											3	3;2024-10-16;https://www.arxiv.org/abs/2403.14166v3| 2;2024-05-18;https://www.arxiv.org/abs/2403.14166v2| 1;2024-03-21;https://www.arxiv.org/abs/2403.14166v1	arXiv:2403.14166			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 16 2024	2024	In this study, we explore the challenge of efficiently representing scenes with a constrained number of Gaussians. Our analysis shifts from traditional graphics and 2D computer vision to the perspective of point clouds, highlighting the inefficient spatial distribution of Gaussian representation as a key limitation in model performance. To address this, we introduce strategies for densification including blur split and depth reinitialization, and simplification through intersection preserving and sampling. These techniques reorganize the spatial positions of the Gaussians, resulting in significant improvements across various datasets and benchmarks in terms of rendering quality, resource consumption, and storage compression. Our Mini-Splatting integrates seamlessly with the original rasterization pipeline, providing a strong baseline for future research in Gaussian-Splatting-based works. 																																	2024-11-07	PPRN:88258236		
J	Liang, Yingyu; Liu, Heshan; Shi, Zhenmei; Song, Zhao; Xu, Zhuoyan; Yin, Junze				Shi, Zhenmei/KBA-9650-2024; Xu, Zhuoyan/LLM-5715-2024						Conv-Basis: A New Paradigm for Efficient Attention Inference and Gradient Computation in Transformers								Arxiv											2	2;2024-10-16;https://www.arxiv.org/abs/2405.05219v2| 1;2024-05-08;https://www.arxiv.org/abs/2405.05219v1	arXiv:2405.05219			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 16 2024	2024	The self-attention mechanism is the key to the success of transformers in recent Large Language Models (LLMs). However, the quadratic computational cost O(n2) in the input sequence length n is a notorious obstacle for further improvement and scalability in longer contexts. In this work, we leverage the convolution-like structure of attention matrices to develop an efficient approximation method for attention computation using convolution matrices. We propose a conv basis system, analogous to the rank basis, and show that any lower triangular matrix can always be decomposed as a sum of structured convolution matrices in this basis. We then design a fast algorithm to approximate the attention matrix via a sum of such k convolution matrices. This allows us to compute the attention inference via Fast Fourier Transforms (FFT) in O(kndlogn) time, where d is the hidden dimension, and thus achieve almost linear time n1+o(1) in the practical scenario where kd = no(1). Furthermore, the attention training forward and backward gradient can be computed in n1+o(1) as well. We provide theoretical guarantees on the run time and approximation error and conduct preliminary experiments to evaluate its effectiveness. We hope our new paradigm for accelerating attention computation in transformer models can help their application to longer contexts.																																	2024-11-12	PPRN:88974807		
J	Cui, Jiahao; Li, Hui; Yao, Yao; Zhu, Hao; Shang, Hanlin; Cheng, Kaihui; Zhou, Hang; Zhu, Siyu; Wang, Jingdong				Shang, Han/J-6155-2019; cui, jiahao/JED-8422-2023						Hallo2: Long-Duration and High-Resolution Audio-Driven Portrait Image Animation								Arxiv											2	2;2024-10-14;https://www.arxiv.org/abs/2410.07718v2| 1;2024-10-10;https://www.arxiv.org/abs/2410.07718v1	arXiv:2410.07718			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 14 2024	2024	Recent advances in latent diffusion-based generative models for portrait image animation, such as Hallo, have achieved impressive results in short-duration video synthesis. In this paper, we present updates to Hallo, introducing several design enhancements to extend its capabilities. First, we extend the method to produce long-duration videos. To address substantial challenges such as appearance drift and temporal artifacts, we investigate augmentation strategies within the image space of conditional motion frames. Specifically, we introduce a patch-drop technique augmented with Gaussian noise to enhance visual consistency and temporal coherence over long duration. Second, we achieve 4K resolution portrait video generation. To accomplish this, we implement vector quantization of latent codes and apply temporal alignment techniques to maintain coherence across the temporal dimension. By integrating a high-quality decoder, we realize visual synthesis at 4K resolution. Third, we incorporate adjustable semantic textual labels for portrait expressions as conditional inputs. This extends beyond traditional audio cues to improve controllability and increase the diversity of the generated content. To the best of our knowledge, Hallo2, proposed in this paper, is the first method to achieve 4K resolution and generate hour-long, audio-driven portrait image animations enhanced with textual prompts. We have conducted extensive experiments to evaluate our method on publicly available datasets, including HDTF, CelebV, and our introduced "Wild" dataset. The experimental results demonstrate that our approach achieves state-of-the-art performance in long-duration portrait video animation, successfully generating rich and controllable content at 4K resolution for duration extending up to tens of minutes. 																																	2024-11-05	PPRN:105774012		
J	Liang, Yingyu; Shi, Zhenmei; Song, Zhao; Zhou, Yufa				Shi, Zhenmei/KBA-9650-2024; Zhou, Yufa/MIP-8150-2025						Tensor Attention Training: Provably Efficient Learning of Higher-order Transformers								Arxiv											2	2;2024-10-14;https://www.arxiv.org/abs/2405.16411v2| 1;2024-05-26;https://www.arxiv.org/abs/2405.16411v1	arXiv:2405.16411			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 14 2024	2024	Tensor Attention, a multi-view attention that is able to capture high-order correlations among multiple modalities, can overcome the representational limitations of classical matrix attention. However, the O(n3) time complexity of tensor attention poses a significant obstacle to its utilization in transformers, where n is the input sequence length. In this work, we prove that the backward gradient of tensor attention training can be computed in almost linear time n1+o(1), the same complexity as its forward computation under the bounded entries assumption. We provide a closed-form solution for the gradient and propose a fast computation method utilizing polynomial approximation methods and tensor algebraic techniques. Furthermore, we prove the necessity and tightness of our assumption through hardness analysis, showing that slightly weakening it renders the gradient problem unsolvable in truly subcubic time. Our theoretical results establish the feasibility of efficient higher-order transformer training and may facilitate practical applications of tensor attention architectures.																																	2024-11-06	PPRN:89057130		
J	Cao, Alec; Eckner, William J.; Yelin, Theodor Lukin; Young, Aaron W.; Jandura, Sven; Yan, Lingfeng; Kim, Kyungtae; Pupillo, Guido; Ye, Jun; Oppong, Nelson Darkwah; Kaufman, Adam M.										Multi-qubit gates and Schrödinger cat states in an optical clock								Arxiv											3	3;2024-10-13;https://www.arxiv.org/abs/2402.16289v3| 2;2024-07-24;https://www.arxiv.org/abs/2402.16289v2| 1;2024-02-26;https://www.arxiv.org/abs/2402.16289v1	arXiv:2402.16289			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 13 2024	2024	Many-particle entanglement is a key resource for achieving the fundamental precision limits of a quantum sensor [1]. Optical atomic clocks [2], the current state-of-the-art in frequency precision, are a rapidly emerging area of focus for entanglement-enhanced metrology [3–6]. Augmenting tweezerbased clocks featuring microscopic control and detection [7–10] with the high-fidelity entangling gates developed for atom-array information processing [11, 12] offers a promising route towards leveraging highly entangled quantum states for improved optical clocks. Here we develop and employ a family of multi-qubit Rydberg gates to generate Schro¨dinger cat states of the Greenberger-HorneZeilinger (GHZ) type with up to 9 optical clock qubits in a programmable atom array. In an atomlaser comparison at sufficiently short dark times, we demonstrate a fractional frequency instability below the standard quantum limit using GHZ states of up to 4 qubits. However, due to their reduced dynamic range, GHZ states of a single size fail to improve the achievable clock precision at the optimal dark time compared to unentangled atoms [13]. Towards overcoming this hurdle, we simultaneously prepare a cascade of varying-size GHZ states to perform unambiguous phase estimation over an extended interval [14–17]. These results demonstrate key building blocks for approaching Heisenberg-limited scaling of optical atomic clock precision.																																	2024-11-05	PPRN:87934400		
J	Piet, Julien; Sitawarin, Chawin; Fang, Vivian; Mu, Norman; Wagner, David				Sitawarin, Chawin/KIB-4488-2024						Mark My Words: Analyzing and Evaluating Language Model Watermarks								Arxiv											3	3;2024-10-11;https://www.arxiv.org/abs/2312.00273v3| 2;2023-12-07;https://www.arxiv.org/abs/2312.00273v2| 1;2023-12-01;https://www.arxiv.org/abs/2312.00273v1	arXiv:2312.00273			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Oct 11 2024	2024	The capabilities of large language models have grown significantly in recent years and so too have concerns about their misuse. It is important to be able to distinguish machine-generated text from human-authored content. Prior works have proposed numerous schemes to watermark text, which would benefit from a systematic evaluation framework. This work focuses on LLM output watermarking techniques - as opposed to image or model watermarks - and proposes Mark My Words, a comprehensive benchmark for them under different natural language tasks. We focus on three main metrics: quality, size (i.e., the number of tokens needed to detect a watermark), and tamper resistance (i.e., the ability to detect a watermark after perturbing marked text). Current watermarking techniques are nearly practical enough for real-world use: Kirchenbauer et al. [33]'s scheme can watermark models like Llama 2 7B-chat or Mistral-7B-Instruct with no perceivable loss in quality on natural language tasks, the watermark can be detected with fewer than 100 tokens, and their scheme offers good tamper resistance to simple perturbations. However, they struggle to efficiently watermark code generations.																																	2024-11-05	PPRN:86357874		
J	Mele, Antonio Anna; Angrisani, Armando; Ghosh, Soumik; Khatri, Sumeet; Eisert, Jens; Franca, Daniel Stilck; Quek, Yihui				Khatri, Sumeet/AAE-8376-2020; Eisert, Jens/D-9640-2017						Noise-induced shallow circuits and absence of barren plateaus								Arxiv											2	2;2024-10-10;https://www.arxiv.org/abs/2403.13927v2| 1;2024-03-20;https://www.arxiv.org/abs/2403.13927v1	arXiv:2403.13927			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 10 2024	2024	Motivated by realistic hardware considerations of the pre-fault-tolerant era, we comprehensively study the impact of uncorrected noise on quantum circuits. We first show that any noise 'truncates' most quantum circuits to effectively logarithmic depth, in the task of estimating observable expectation values. We then prove that quantum circuits under any non-unital noise exhibit lack of barren plateaus for cost functions composed of local observables. But, by leveraging the effective shallowness, we also design an efficient classical algorithm to estimate observable expectation values within any constant additive accuracy, with high probability over the choice of the circuit, in any circuit architecture. The runtime of the algorithm is independent of circuit depth, and for any inverse-polynomial target accuracy, it operates in polynomial time in the number of qubits for one-dimensional architectures and quasi-polynomial time for higher-dimensional ones. Taken together, our results showcase that, unless we carefully engineer the circuits to take advantage of the noise, it is unlikely that noisy quantum circuits are preferable over shallow quantum circuits for algorithms that output observable expectation value estimates, like many variational quantum machine learning proposals. Moreover, we anticipate that our work could provide valuable insights into the fundamental open question about the complexity of sampling from (possibly non-unital) noisy random circuits.																																	2024-11-01	PPRN:88257790		
J	Zhao, Canyu; Liu, Mingyu; Wang, Wen; Chen, Weihua; Wang, Fan; Chen, Hao; Zhang, Bo; Shen, Chunhua				Zhang, Bo/ABF-8476-2021						MovieDreamer: Hierarchical Generation for Coherent Long Visual Sequence								Arxiv											1	1;2024-10-09;https://www.arxiv.org/abs/2407.16655v2	arXiv:2407.16655			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 09 2024	2024	Recent advancements in video generation have primarily leveraged diffusion models for short-duration content. However, these approaches often fall short in modeling complex narratives and maintaining character consistency over extended periods, which is essential for long-form video production like movies. We propose MovieDreamer, a novel hierarchical framework that integrates the strengths of autoregressive models with diffusion-based rendering to pioneer long-duration video generation with intricate plot progressions and high visual fidelity. Our approach utilizes autoregressive models for global narrative coherence, predicting sequences of visual tokens that are subsequently transformed into high-quality video frames through diffusion rendering. This method is akin to traditional movie production processes, where complex stories are factorized down into manageable scene capturing. Further, we employ a multimodal script that enriches scene descriptions with detailed character information and visual style, enhancing continuity and character identity across scenes. We present extensive experiments across various movie genres, demonstrating that our approach not only achieves superior visual and narrative quality but also effectively extends the duration of generated content significantly beyond current capabilities. 																																	2024-10-29	PPRN:105760588		
J	Zheng, Mingqian; Pei, Jiaxin; Logeswaran, Lajanugen; Lee, Moontae; Jurgens, David				Pei, Jiaxin/ACL-2462-2022						When "A Helpful Assistant" Is Not Really Helpful: Personas in System Prompts Do Not Improve Performances of Large Language Models								Arxiv											3	3;2024-10-09;https://www.arxiv.org/abs/2311.10054v3| 2;2024-10-07;https://www.arxiv.org/abs/2311.10054v2| 1;2023-11-16;https://www.arxiv.org/abs/2311.10054v1	arXiv:2311.10054			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 09 2024	2024	Prompting serves as the major way humans interact with Large Language Models (LLM). Commercial AI systems commonly define the role of the LLM in system prompts. For example, ChatGPT uses “You are a helpful assistant” as part of its default system prompt. Despite current practices of adding personas to system prompts, it remains unclear how different personas affect a model’s performance on objective tasks. In this study, we present a systematic evaluation of personas in system prompts. We curate a list of 162 roles covering 6 types of interpersonal relationships and 8 domains of expertise. Through extensive analysis of 4 popular families of LLMs and 2,410 factual questions, we demonstrate that adding personas in system prompts does not improve model performance across a range of questions compared to the control setting where no persona is added. Nevertheless, further analysis suggests that the gender, type, and domain of the persona can all influence the resulting prediction accuracies. We further experimented with a list of persona search strategies and found that, while aggregating results from the best persona for each question significantly improves prediction accuracy, automatically identifying the best persona is challenging, with predictions often performing no better than random selection. Overall, our findings suggest that while adding a persona may lead to performance gains in certain settings, the effect of each persona can be largely random. Code and data are available at https://github.com/Jiaxin-Pei/ Prompting-with-Social-Roles .																																	2024-10-30	PPRN:86176891		
J	Dohmatob, Elvis; Feng, Yunzhen; Subramonian, Arjun; Kempe, Julia										Strong Model Collapse								Arxiv											2	2;2024-10-08;https://www.arxiv.org/abs/2410.04840v2| 1;2024-10-07;https://www.arxiv.org/abs/2410.04840v1	arXiv:2410.04840			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 08 2024	2024	Within the scaling laws paradigm, which underpins the training of large neural networks like ChatGPT and Llama, we consider a supervised regression setting and establish the existance of a strong form of the model collapse phenomenon, a critical performance degradation due to synthetic data in the training corpus. Our results show that even the smallest fraction of synthetic data (e.g., as little as 1% of the total training dataset) can still lead to model collapse: larger and larger training sets do not enhance performance. We further investigate whether increasing model size, an approach aligned with current trends in training large language models, exacerbates or mitigates model collapse. In a simplified regime where neural networks are approximated via random projections of tunable size, we both theoretically and empirically show that larger models can amplify model collapse. Interestingly, our theory also indicates that, beyond the interpolation threshold (which can be extremely high for very large datasets), larger models may mitigate the collapse, although they do not entirely prevent it. Our theoretical findings are empirically verified through experiments on language models and feed-forward neural networks for images.																																	2024-10-24	PPRN:104456056		
J	Calvello, Edoardo; Reich, Sebastian; Stuart, Andrew M.										Ensemble Kalman Methods: A Mean Field Perspective								Arxiv											3	3;2024-10-07;https://www.arxiv.org/abs/2209.11371v3| 2;2024-08-16;https://www.arxiv.org/abs/2209.11371v2| 1;2022-09-23;https://www.arxiv.org/abs/2209.11371v1	arXiv:2209.11371			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 07 2024	2024	Ensemble Kalman methods are widely used for state estimation in the geophysical sciences. Their success stems from the fact that they take an underlying (possibly noisy) dynamical system as a black box to provide a systematic, derivative-free methodology for incorporating noisy, partial and possibly indirect observations to update estimates of the state; furthermore the ensemble approach allows for sensitivities and uncertainties to be calculated. The methodology was introduced in 1994 in the context of ocean state estimation. Soon thereafter it was adopted by the numerical weather prediction community and is now a key component of the best weather prediction systems worldwide. Furthermore the methodology is starting to be widely adopted for numerous problems in the geophysical sciences and is being developed as the basis for general purpose derivative-free inversion methods that show great promise. Despite this empirical success, analysis of the accuracy of ensemble Kalman methods, in terms of their capabilities as both state estimators and quantifiers of uncertainty, is lagging. The purpose of this paper is to provide a unifying mean field based framework for the derivation and analysis of ensemble Kalman methods. Both state estimation and parameter estimation problems (inverse problems) are considered, and formulations in both discrete and continuous time are employed. For state estimation problems, both the control and filtering approaches are considered; analogously for parameter estimation problems, the optimization and Bayesian perspectives are both studied. The mean field perspective provides an elegant framework, suitable for analysis; furthermore, a variety of methods used in practice can be derived from mean field systems by using interacting particle system approximations. The approach taken also unifies a wide-ranging literature in the field and suggests open problems.																																	2024-10-24	PPRN:17048074		
J	Paul, Debjit; West, Robert; Bosselut, Antoine; Faltings, Boi				West, Robert/B-5414-2009						Making Reasoning Matter: Measuring and Improving Faithfulness of Chain-of-Thought Reasoning								Arxiv											4	4;2024-10-06;https://www.arxiv.org/abs/2402.13950v4| 3;2024-07-18;https://www.arxiv.org/abs/2402.13950v3| 2;2024-02-23;https://www.arxiv.org/abs/2402.13950v2| 1;2024-02-21;https://www.arxiv.org/abs/2402.13950v1	arXiv:2402.13950			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 06 2024	2024	Large language models (LLMs) have been shown to perform better when asked to reason step-by-step before answering a question. However, it is unclear to what degree the model's final answer is faithful to the stated reasoning steps. In this paper, we perform a causal mediation analysis on twelve LLMs to examine how intermediate reasoning steps generated by the LLM influence the final outcome and find that LLMs do not reliably use their intermediate reasoning steps when generating an answer. To address this issue, we introduce FRODO, a framework to tailor small-sized LMs to generate correct reasoning steps and robustly reason over these steps. FRODO consists of an inference module that learns to generate correct reasoning steps using an implicit causal reward function and a reasoning module that learns to faithfully reason over these intermediate inferences using a counterfactual and causal preference objective. Our experiments show that FRODO significantly outperforms four competitive baselines. Furthermore, FRODO improves the robustness and generalization ability of the reasoning LM, yielding higher performance on out-of-distribution test sets. Finally, we find that FRODO's rationales are more faithful to its final answer predictions than standard supervised fine-tuning.																																	2024-10-27	PPRN:87787835		
J	Wu, Qi; Zhao, Yubo; Wang, Yifan; Liu, Xinhang; Tai, Yu-Wing; Tang, Chi-Keung										Motion-Agent: A Conversational Framework for Human Motion Generation with LLMs								Arxiv											2	2;2024-10-06;https://www.arxiv.org/abs/2405.17013v3| 1;2024-05-28;https://www.arxiv.org/abs/2405.17013v2	arXiv:2405.17013			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Oct 06 2024	2024	While previous approaches to 3D human motion generation have achieved notable success, they often rely on extensive training and are limited to specific tasks. To address these challenges, we introduce Motion-Agent,an efficient conversational framework designed for general human motion generation, editing, and understanding. Motion-Agent employs an open-source pre-trained language model to develop a generative agent, MotionLLM, , that bridges the gap between motion and text. This is accomplished by encoding and quantizing motions into discrete tokens that align with the language model’s vocabulary. With only 1–3% of the model’s parameters fine-tuned using adapters, MotionLLM delivers performance on par with diffusion models and other transformerbased methods trained from scratch. By integrating MotionLLM with GPT4 without additional training, Motion-Agent is able to generate highly complex motion sequences through multi-turn conversations, a capability that previous models have struggled to achieve. Motion-Agent supports a wide range of motion-language tasks, offering versatile capabilities for generating and customizing human motion through interactive conversational exchanges. Project page: https://knoxzhao.github.io/Motion-Agent																																	2024-10-28	PPRN:89087542		
J	Li, Binxu; Yan, Tiankai; Pan, Yuanting; Luo, Jie; Ji, Ruiyang; Ding, Jiayuan; Xu, Zhe; Liu, Shilong; Dong, Haoyu; Lin, Zihao; Wang, Yixin				lin, zihao/GWZ-7028-2022; Liu, Shilong/GVS-1257-2022; Li, Binxu/KDO-3273-2024						MMedAgent: Learning to Use Medical Tools with Multi-modal Agent								Arxiv											2	2;2024-10-05;https://www.arxiv.org/abs/2407.02483v2| 1;1800-01-01;https://www.arxiv.org/abs/2407.02483v1	arXiv:2407.02483			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Oct 05 2024	2024	Multi-Modal Large Language Models (MLLMs), despite being successful, exhibit limited generality and often fall short when compared to specialized models. Recently, LLM-based agents have been developed to address these challenges by selecting appropriate specialized models as tools based on user inputs. However, such advancements have not been extensively explored within the medical domain. To bridge this gap, this paper introduces the first agent explicitly designed for the medical field, named M ulti-modal Med ical Agent (MMedAgent). We curate an instruction-tuning dataset comprising six medical tools solving seven tasks across five modalities, enabling the agent to choose the most suitable tools for a given task. Comprehensive experiments demonstrate that MMedAgent achieves superior performance across a variety of medical tasks compared to state-of-the-art open-source methods and even the closed-source model, GPT-4o. Furthermore, MMedAgent exhibits efficiency in updating and integrating new medical tools.																																	2024-10-24	PPRN:90674484		
J	Jiang, Bowen; Xie, Yangxinyu; Hao, Zhuoqun; Wang, Xiaomeng; Mallick, Tanwi; Su, Weijie J.; Taylor, Camillo J.; Roth, Dan				Mallick, Tanwi/AAC-1785-2021; Jiang, Bowen/KLD-7923-2024; Xie, Yangxinyu/LFB-8794-2024						A Peek into Token Bias: Large Language Models Are Not Yet Genuine Reasoners								Arxiv											2	2;2024-10-04;https://www.arxiv.org/abs/2406.11050v2| 1;2024-06-16;https://www.arxiv.org/abs/2406.11050v1	arXiv:2406.11050			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 04 2024	2024	This study introduces a hypothesis-testing framework to assess whether large language models (LLMs) possess genuine reasoning abilities or primarily depend on token bias. We go beyond evaluating LLMs on accuracy; rather, we aim to investigate their token bias in solving logical reasoning tasks. Specifically, we develop carefully controlled synthetic datasets, featuring conjunction fallacy and syllogistic problems. Our framework outlines a list of hypotheses where token biases are readily identifiable, with all null hypotheses assuming genuine reasoning capabilities of LLMs. The findings in this study suggest, with statistical guarantee, that most LLMs still struggle with logical reasoning. While they may perform well on classic problems, their success largely depends on recognizing superficial patterns with strong token bias, thereby raising concerns about their actual reasoning and generalization abilities. Codes and data are open-sourced at https://github.com/bowen-upenn/llm_token_bias.																																	2024-10-25	PPRN:89343740		
J	Wang, Haibo; Xu, Zhiyang; Cheng, Yu; Diao, Shizhe; Zhou, Yufan; Cao, Yixin; Wang, Qifan; Ge, Weifeng; Huang, Lifu				Diao, Shizhe/JXY-7398-2024; cao, yixin/ABV-6408-2022; Wang, Haibo/ABF-0773-2022						Grounded-VideoLLM: Sharpening Fine-grained Temporal Grounding in Video Large Language Models								Arxiv											1	1;2024-10-04;https://www.arxiv.org/abs/2410.03290v1	arXiv:2410.03290			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 04 2024	2024	Video Large Language Models (Video-LLMs) have demonstrated remarkable capabilities in coarse-grained video understanding, however, they struggle with fine-grained temporal grounding. In this paper, we introduce Grounded-VideoLLM, a novel Video-LLM adept at perceiving and reasoning over specific video moments in a fine-grained manner. We identify that current Video-LLMs have limitations for fine-grained video understanding since they lack effective temporal modeling and timestamp representation. In light of this, we sharpen our model by incorporating (1) an additional temporal stream to encode the relationships between frames and (2) discrete temporal tokens enriched with specific time knowledge to represent timestamps. To optimize the training of Grounded-VideoLLM, we employ a multi-stage training scheme, beginning with simple video-captioning tasks and progressively introducing video temporal grounding tasks of increasing complexity. To further enhance Grounded-VideoLLM's temporal reasoning capability, we also curate a grounded VideoQA dataset by an automatic annotation pipeline. Extensive experiments demonstrate that Grounded-VideoLLM not only excels in fine-grained grounding tasks such as temporal sentence grounding, dense video captioning, and grounded VideoQA, but also shows great potential as a versatile video assistant for general video understanding.																																	2024-10-27	PPRN:104011788		
J	Echterhoff, Jessica; Liu, Yao; Alessa, Abeer; McAuley, Julian; He, Zexue										Cognitive Bias in Decision-Making with LLMs								Arxiv											3	3;2024-10-03;https://www.arxiv.org/abs/2403.00811v3| 2;2024-07-19;https://www.arxiv.org/abs/2403.00811v2| 1;2024-02-25;https://www.arxiv.org/abs/2403.00811v1	arXiv:2403.00811			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Oct 03 2024	2024	Large language models (LLMs) offer significant potential as tools to support an expanding range of decision-making tasks. Given their training on human (created) data, LLMs have been shown to inherit societal biases against protected groups, as well as be subject to bias functionally resembling cognitive bias. Human-like bias can impede fair and explainable decisions made with LLM assistance. Our work introduces BiasBuster, a framework designed to uncover, evaluate, and mitigate cognitive bias in LLMs, particularly in high-stakes decision-making tasks. Inspired by prior research in psychology and cognitive science, we develop a dataset containing 13,465 prompts to evaluate LLM decisions on different cognitive biases (e.g., prompt-induced, sequential, inherent). We test various bias mitigation strategies, while proposing a novel method utilizing LLMs to debias their own human-like cognitive bias within prompts. Our analysis provides a comprehensive picture of the presence and effects of cognitive bias across commercial and open-source models. We demonstrate that our selfhelp debiasing effectively mitigates model answers that display patterns akin to human cognitive bias without having to manually craft examples for each bias.																																	2024-10-25	PPRN:88023515		
J	Duan, Jiafei; Pumacay, Wilbert; Kumar, Nishanth; Wang, Yi Ru; Tian, Shulin; Yuan, Wentao; Krishna, Ranjay; Fox, Dieter; Mandlekar, Ajay; Guo, Yijie				Wang, Yiru/JGV-0940-2023						AHA: A Vision-Language-Model for Detecting and Reasoning Over Failures in Robotic Manipulation								Arxiv											1	1;2024-10-01;https://www.arxiv.org/abs/2410.00371v1	arXiv:2410.00371			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Oct 01 2024	2024	Robotic manipulation in open-world settings requires not only task execution but also the ability to detect and learn from failures. While recent advances in vision-language models (VLMs) and large language models (LLMs) have improved robots' spatial reasoning and problem-solving abilities, they still struggle with failure recognition, limiting their real-world applicability. We introduce AHA, an open-source VLM designed to detect and reason about failures in robotic manipulation using natural language. By framing failure detection as a free-form reasoning task, AHA identifies failures and provides detailed, adaptable explanations across different robots, tasks, and environments. We fine-tuned AHA using FailGen, a scalable framework that generates the first large-scale dataset of robotic failure trajectories, the AHA dataset. FailGen achieves this by procedurally perturbing successful demonstrations from simulation. Despite being trained solely on the AHA dataset, AHA generalizes effectively to real-world failure datasets, robotic systems, and unseen tasks. It surpasses the second-best model (GPT-4o in-context learning) by 10.3% and exceeds the average performance of six compared models including five state-of-the-art VLMs by 35.3% across multiple metrics and datasets. We integrate AHA into three manipulation frameworks that utilize LLMs/VLMs for reinforcement learning, task and motion planning, and zero-shot trajectory generation. AHA's failure feedback enhances these policies' performances by refining dense reward functions, optimizing task planning, and improving sub-task verification, boosting task success rates by an average of 21.4% across all three tasks compared to GPT-4 models.																																	2024-10-12	PPRN:100751146		
J	Tang, Jiaxiang; Li, Zhaoshuo; Hao, Zekun; Liu, Xian; Zeng, Gang; Liu, Ming-Yu; Zhang, Qinsheng				Liu, Mingyu/ABC-4695-2020; Hao, Zekun/ISU-6670-2023; Z, ZQS/IVH-1491-2023						EdgeRunner: Auto-regressive Auto-encoder for Artistic Mesh Generation								Arxiv											1	1;2024-09-26;https://www.arxiv.org/abs/2409.18114v1	arXiv:2409.18114			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 26 2024	2024	Current auto-regressive mesh generation methods suffer from issues such as incompleteness, insufficient detail, and poor generalization. In this paper, we propose an Auto-regressive Auto-encoder (ArAE) model capable of generating highquality 3D meshes with up to 4,000 faces at a spatial resolution of 5123 . We introduce a novel mesh tokenization algorithm that efficiently compresses triangular meshes into 1D token sequences, significantly enhancing training efficiency. Furthermore, our model compresses variable-length triangular meshes into a fixed length latent space, enabling training latent diffusion models for better generalization. Extensive experiments demonstrate the superior quality, diversity, and generalization capabilities of our model in both point cloud and image-conditioned mesh generation tasks.																																	2024-10-09	PPRN:100649373		
J	Zhuang, Wenwen; Huang, Xin; Zhang, Xiantao; Zeng, Jin				Zhuang, Wenwen/GXG-4417-2022						Math-PUMA: Progressive Upward Multimodal Alignment to Enhance Mathematical Reasoning								Arxiv											2	2;2024-09-25;https://www.arxiv.org/abs/2408.08640v2| 1;2024-08-16;https://www.arxiv.org/abs/2408.08640v1	arXiv:2408.08640			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 25 2024	2024	Multimodal Large Language Models (MLLMs) excel in solving text-based mathematical problems, but they struggle with mathematical diagrams since they are primarily trained on natural scene images. For humans, visual aids generally enhance problem-solving, but MLLMs perform worse as information shifts from textual to visual modality. This decline is mainly due to their shortcomings in aligning images and text. To tackle aforementioned challenges, we propose Math-PUMA, a methodology focused on Progressive Upward Multimodal Alignment. This approach is designed to improve the mathematical reasoning skills of MLLMs through a three-stage training process, with the second stage being the critical alignment stage. We first enhance the language model's mathematical reasoning capabilities with extensive set of textual mathematical problems. We then construct a multimodal dataset with varying degrees of textual and visual information, creating data pairs by presenting each problem in at least two forms. By leveraging the Kullback-Leibler (KL) divergence of next-token prediction distributions to align visual and textual modalities, consistent problem-solving abilities are ensured. Finally, we utilize multimodal instruction tuning for MLLMs with high-quality multimodal data. Experimental results on multiple mathematical reasoning benchmarks demonstrate that the MLLMs trained with Math-PUMA surpass most open-source MLLMs. Our approach effectively narrows the performance gap for problems presented in different modalities. The code and data are available at: url{https://github.com/wwzhuang01/Math-PUMA}.																																	2024-10-08	PPRN:91470421		
J	Geier, Max; Davydova, Margarita; Fu, Liang				Fu, Liang/LTC-7906-2024						Chiral and topological superconductivity in isospin polarized multilayer graphene								Arxiv											1	1;2024-09-20;https://www.arxiv.org/abs/2409.13829v1	arXiv:2409.13829			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Sep 20 2024	2024	A microscopic mechanism for chiral superconductivity from Coulomb repulsion is proposed for spin- and valley-polarized state of rhombohedral multilayer graphene. The superconducting state occurs at low density, has chiral p-wave pairing symmetry, and exhibits highest Tc close to a Lifshitz transition from annular to simply-connected Fermi sea. This Lifshitz transition also marks a topological phase transition from a trivial to a topological superconducting phase hosting Majorana fermions. The chirality of the superconducting order parameter is selected by the chirality of the valley-polarized Bloch electrons. Our results are in reasonable agreement with observations in a recent experiment on tetralayer graphene [arXiv:2408.15233[1]]																																	2024-10-03	PPRN:95867632		
J	Guo, Yanjiang; Wang, Yen-Jen; Zha, Lihan; Chen, Jianyu										DoReMi: Grounding Language Model by Detecting and Recovering from Plan-Execution Misalignment								Arxiv											4	4;2024-09-14;https://www.arxiv.org/abs/2307.00329v4| 3;2023-09-30;https://www.arxiv.org/abs/2307.00329v3| 2;2023-08-24;https://www.arxiv.org/abs/2307.00329v2| 1;2023-07-01;https://www.arxiv.org/abs/2307.00329v1	arXiv:2307.00329			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 14 2024	2024	Large language models (LLMs) encode a vast amount of semantic knowledge and possess remarkable understanding and reasoning capabilities. Previous work has explored how to ground LLMs in robotic tasks to generate feasible and executable textual plans. However, low-level execution in the physical world may deviate from the high-level textual plan due to environmental perturbations or imperfect controller design. In this paper, we propose textbf{DoReMi}, a novel language model grounding framework that enables immediate Detection and Recovery from Misalignments between plan and execution. Specifically, we leverage LLMs to play a dual role, aiding not only in high-level planning but also generating constraints that can indicate misalignment during execution. Then vision language models (VLMs) are utilized to detect constraint violations continuously. Our pipeline can monitor the low-level execution and enable timely recovery if certain plan-execution misalignment occurs. Experiments on various complex tasks including robot arms and humanoid robots demonstrate that our method can lead to higher task success rates and shorter task completion times. Videos of DoReMi are available at url{https://sites.google.com/view/doremi-paper}.																																	2024-12-24	PPRN:83521873		
J	Li, Qinbin; Hong, Junyuan; Xie, Chulin; Tan, Jeffrey; Xin, Rachel; Hou, Junyi; Yin, Xavier; Wang, Zhun; Hendrycks, Dan; Wang, Zhangyang; Li, Bo; He, Bingsheng; Song, Dawn				Wang, zhuqing/JYO-9755-2024; Li, Qinbin/JVN-4491-2024; Zhihua, Wang/AFO-5263-2022						LLM-PBE: Assessing Data Privacy in Large Language Models								Arxiv											2	2;2024-09-06;https://www.arxiv.org/abs/2408.12787v2| 1;2024-08-23;https://www.arxiv.org/abs/2408.12787v1	arXiv:2408.12787			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 06 2024	2024	Large Language Models (LLMs) have become integral to numerous domains, significantly advancing applications in data management, mining, and analysis. Their profound capabilities in processing and interpreting complex language data, however, bring to light pressing concerns regarding data privacy, especially the risk of unintentional training data leakage. Despite the critical nature of this issue, there has been no existing literature to offer a comprehensive assessment of data privacy risks in LLMs. Addressing this gap, our paper introduces LLM-PBE, a toolkit crafted specifically for the systematic evaluation of data privacy risks in LLMs. LLM-PBE is designed to analyze privacy across the entire lifecycle of LLMs, incorporating diverse attack and defense strategies, and handling various data types and metrics. Through detailed experimentation with multiple LLMs, LLM-PBE facilitates an in-depth exploration of data privacy concerns, shedding light on influential factors such as model size, data characteristics, and evolving temporal dimensions. This study not only enriches the understanding of privacy issues in LLMs but also serves as a vital resource for future research in the field. Aimed at enhancing the breadth of knowledge in this area, the findings, resources, and our full technical report are made available at https://llm-pbe.github.io/, providing an open platform for academic and practical advancements in LLM privacy assessment.																																	2024-09-23	PPRN:91526336		
J	Chen, Jintai; Hu, Yaojun; Lu, Yingzhou; Wang, Yue; Huang, Kexin; Cao, Xu; Lin, Miao; Xu, Hongxia; Wu, Jian; Xiao, Cao; Sun, Jimeng; Glass, Lucas; Zitnik, Marinka; Fu, Tianfan				Cao, Xu/AAT-7553-2021; Huang, Kexin/AAU-2699-2021						TrialBench: Multi-Modal Artificial Intelligence-Ready Clinical Trial Datasets								Arxiv											2	2;2024-09-03;https://www.arxiv.org/abs/2407.00631v2| 1;2024-06-30;https://www.arxiv.org/abs/2407.00631v1	arXiv:2407.00631			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Sep 03 2024	2024	Clinical trials are pivotal for developing new medical treatments, yet they typically pose some risks such as patient mortality, adverse events, and enrollment failure that waste immense efforts spanning over a decade. Applying artificial intelligence (AI) to forecast or simulate key events in clinical trials holds great potential for providing insights to guide trial designs. However, complex data collection and question definition requiring medical expertise and a deep understanding of trial designs have hindered the involvement of AI thus far. This paper tackles these challenges by presenting a comprehensive suite of meticulously curated AIready datasets covering multi-modal data (e.g., drug molecule, disease code, text, categorical/numerical features) and 8 crucial prediction challenges in clinical trial design, encompassing prediction of trial duration, patient dropout rate, serious adverse event, mortality rate, trial approval outcome, trial failure reason, drug dose finding, design of eligibility criteria. Furthermore, we provide basic validation methods for each task to ensure the datasets' usability and reliability. We anticipate that the availability of such open-access datasets will catalyze the development of advanced AI approaches for clinical trial design, ultimately advancing clinical trial research and accelerating medical solution development. 																																	2024-09-12	PPRN:90658699		
J	Zhang, Yao; Ma, Zijian; Ma, Yunpu; Han, Zhen; Wu, Yu; Tresp, Volker				Ma, Zijian/HMV-9460-2023; Han, Zhen/LZH-2322-2025						WebPilot: A Versatile and Autonomous Multi-Agent System for Web Task Execution with Strategic Exploration								Arxiv											1	1;2024-08-28;https://www.arxiv.org/abs/2408.15978v1	arXiv:2408.15978			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 28 2024	2024	LLM-based autonomous agents often fail to execute complex web tasks that require dynamic interaction due to the inherent uncertainty and complexity of these environments. Existing LLM-based web agents typically rely on rigid, expert-designed policies specific to certain states and actions, which lack the flexibility and generalizability needed to adapt to unseen tasks. In contrast, humans excel by exploring unknowns, continuously adapting strategies, and resolving ambiguities through exploration. To emulate human-like adaptability, web agents need strategic exploration and complex decision-making. Monte Carlo Tree Search (MCTS) is well-suited for this, but classical MCTS struggles with vast action spaces, unpredictable state transitions, and incomplete information in web tasks. In light of this, we develop WebPilot, a multi-agent system with a dual optimization strategy that improves MCTS to better handle complex web environments. Specifically, the Global Optimization phase involves generating a high-level plan by breaking down tasks into manageable subtasks and continuously refining this plan, thereby focusing the search process and mitigating the challenges posed by vast action spaces in classical MCTS. Subsequently, the Local Optimization phase executes each subtask using a tailored MCTS designed for complex environments, effectively addressing uncertainties and managing incomplete information. Experimental results on WebArena and MiniWoB++ demonstrate the effectiveness of WebPilot. Notably, on WebArena, WebPilot achieves SOTA performance with GPT-4, achieving a 93% relative increase in success rate over the concurrent tree search-based method. WebPilot marks a significant advancement in general autonomous agent capabilities, paving the way for more advanced and reliable decision-making in practical environments.																																	2024-09-19	PPRN:91782092		
J	Ta, Hoang-Thang				Ta, Thang/AAW-7174-2021						BSRBF-KAN: A combination of B-splines and Radial Basis Functions in Kolmogorov-Arnold Networks								Arxiv											4	4;2024-08-14;https://www.arxiv.org/abs/2406.11173v4| 3;2024-08-05;https://www.arxiv.org/abs/2406.11173v3| 2;2024-06-19;https://www.arxiv.org/abs/2406.11173v2| 1;2024-06-17;https://www.arxiv.org/abs/2406.11173v1	arXiv:2406.11173			http://creativecommons.org/licenses/by-sa/4.0/	http://creativecommons.org/licenses/by-sa/4.0/			preprint	Aug 14 2024	2024	In this paper, we introduce BSRBF-KAN, a Kolmogorov Arnold Network (KAN) that combines B-splines and radial basis functions (RBFs) to fit input vectors during data training. We perform experiments with BSRBF-KAN, multi-layer perception (MLP), and other popular KANs, including EfficientKAN, FastKAN, FasterKAN, and GottliebKAN over the MNIST and Fashion-MNIST datasets. BSRBF-KAN shows stability in 5 training runs with a competitive average accuracy of 97.55% on MNIST and 89.33% on Fashion-MNIST and obtains convergence better than other networks. We expect BSRBF-KAN to open many combinations of mathematical functions to design KANs.																																	2024-08-22	PPRN:89347421		
J	Jiang, Bei; Hu, Mingzhe; Bai, Jianli; Song, Ziyin; Mu, Chao; Qu, Gexing; Li, Wan; Zhu, Wenliang; Pi, Hanqi; Wei, Zhongxu; Sun, Yujie; Huang, Yaobo; Zheng, Xiquan; Peng, Yingying; He, Lunhua; Li, Shiliang; Luo, Jianlin; Li, Zheng; Chen, Genfu; Li, Hang; Weng, Hongming; Qian, Tian				peng, yingying/K-1805-2015; Hu, Yong/GRJ-3794-2022; Li, Hang/AAZ-8070-2021; Weng, Hongming/F-2948-2011; Hu, Mingzhe/AAS-1874-2021; Li, Shiliang/LDG-5540-2024; LUO, Jianlin/AAY-1652-2021						Discovery of a metallic room-temperature d-wave altermagnet KV2Se2O								Arxiv											2	2;2024-08-13;https://www.arxiv.org/abs/2408.00320v2| 1;2024-08-01;https://www.arxiv.org/abs/2408.00320v1	arXiv:2408.00320			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 13 2024	2024	Beyond conventional ferromagnetism and antiferromagnetism, altermagnetism is a recently discovered unconventional magnetic phase characterized by time-reversal symmetry breaking and spin-split band structures in materials with zero net magnetization. This novel phase not only enhances our understanding of fundamental physical concepts but will also have a significant impact on condensed-matter physics research and practical device applications. Recently, spinpolarized band structures were observed in semiconductors with vanishing net magnetization, confirming this unconventional magnetic order. Metallic altermagnets offer unique advantages for exploring novel physical phenomena related to low-energy quasiparticle excitations and for applications in spintronics as electrical conductivity in metals allows direct manipulation of spin current through electric field. Here, through comprehensive characterization and analysis of the magnetic and electronic structures of KV2Se2O,  we have unambiguously demonstrated a metallic room-temperature altermaget with d-wave spin-momentum locking. The highly anisotropic spinpolarized Fermi surfaces and the emergence of a spin-density-wave order in the altermagnetic phase make it an exceptional platform for developing high-performance spintronic devices and studying many-body effects coupled with unconventional magnetism.																																	2024-08-22	PPRN:91197365		
J	Wan, Alexander; Wallace, Eric; Klein, Dan										What Evidence Do Language Models Find Convincing?								Arxiv											2	2;2024-08-09;https://www.arxiv.org/abs/2402.11782v2| 1;2024-02-19;https://www.arxiv.org/abs/2402.11782v1	arXiv:2402.11782			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 09 2024	2024	Retrieval-augmented language models are being increasingly tasked with subjective, contentious, and conflicting queries such as "is aspartame linked to cancer". To resolve these ambiguous queries, one must search through a large range of websites and consider "which, if any, of this evidence do I find convincing?". In this work, we study how LLMs answer this question. In particular, we construct ConflictingQA, a dataset that pairs controversial queries with a series of real-world evidence documents that contain different facts (e.g., quantitative results), argument styles (e.g., appeals to authority), and answers (Yes or No). We use this dataset to perform sensitivity and counterfactual analyses to explore which text features most affect LLM predictions. Overall, we find that current models rely heavily on the relevance of a website to the query, while largely ignoring stylistic features that humans find important such as whether a text contains scientific references or is written with a neutral tone. Taken together, these results highlight the importance of RAG corpus quality (e.g., the need to filter misinformation), and possibly even a shift in how LLMs are trained to better align with human judgements.																																	2024-08-21	PPRN:87754982		
J	Ma, Jun; Kim, Sumin; Li, Feifei; Baharoon, Mohammed; Asakereh, Reza; Lyu, Hongwei; Wang, Bo				Wang, Bo/HDO-6738-2022; Ma, Jun/LHA-0128-2024						Segment Anything in Medical Images and Videos: Benchmark and Deployment								Arxiv											1	1;2024-08-06;https://www.arxiv.org/abs/2408.03322v1	arXiv:2408.03322			http://creativecommons.org/licenses/by-nc-sa/4.0/	http://creativecommons.org/licenses/by-nc-sa/4.0/			preprint	Aug 06 2024	2024	Recent advances in segmentation foundation models have enabled accurate and efficient segmentation across a wide range of natural images and videos, but their utility to medical data remains unclear. In this work, we first present a comprehensive benchmarking of the Segment Anything Model 2 (SAM2) across 11 medical image modalities and videos and point out its strengths and weaknesses by comparing it to SAM1 and MedSAM. Then, we develop a transfer learning pipeline and demonstrate SAM2 can be quickly adapted to medical domain by fine-tuning. Furthermore, we implement SAM2 as a 3D slicer plugin and Gradio API for efficient 3D image and video segmentation. 																																	2024-08-17	PPRN:91270189		
J	Xu, Yingxue; Wang, Yihui; Zhou, Fengtao; Ma, Jiabo; Yang, Shu; Lin, Huangjing; Wang, Xin; Wang, Jiguang; Liang, Li; Han, Anjia; Chan, Ronald Cheong Kin; Chen, Hao				Wang, Jiguang/B-2717-2012; Wang, Yihui/OLQ-4655-2025; MA, Jiabo/NQF-7416-2025; Yang, Shu/I-2051-2014; Chen, Hao/JHU-3470-2023						A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model								Arxiv											2	2;2024-08-05;https://www.arxiv.org/abs/2407.15362v2| 1;2024-07-22;https://www.arxiv.org/abs/2407.15362v1	arXiv:2407.15362			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 05 2024	2024	Remarkable strides in computational pathology have been made in the task-agnostic foundation model that advances the performance of a wide array of downstream clinical tasks. Despite the promising performance, there are still several challenges. First, prior works have resorted to either vision-only or vision-captions data, disregarding invaluable pathology reports and gene expression profiles which respectively offer distinct knowledge for versatile clinical applications. Second, the current progress in pathology FMs predominantly concentrates on the patch level, where the restricted context of patch-level pretraining fails to capture whole-slide patterns. Here we curated the largest multimodal dataset consisting of H&E diagnostic whole slide images and their associated pathology reports and RNA-Seq data, resulting in 26,169 slide-level modality pairs from 10,275 patients across 32 cancer types. To leverage these data for CPath, we propose a novel whole-slide pretraining paradigm which injects multimodal knowledge at the whole-slide context into the pathology FM, called Multimodal Self-TAught PRetraining (mSTAR). The proposed paradigm revolutionizes the workflow of pretraining for CPath, which enables the pathology FM to acquire the whole-slide context. To our knowledge, this is the first attempt to incorporate multimodal knowledge at the slide level for enhancing pathology FMs, expanding the modelling context from unimodal to multimodal knowledge and from patch-level to slide-level. To systematically evaluate the capabilities of mSTAR, extensive experiments including slide-level unimodal and multimodal applications, are conducted across 7 diverse types of tasks on 43 subtasks, resulting in the largest spectrum of downstream tasks. The average performance in various slide-level applications consistently demonstrates significant performance enhancements for mSTAR compared to SOTA FMs.																																	2024-08-09	PPRN:91029167		
J	Li, Xiangtai; Ding, Henghui; Yuan, Haobo; Zhang, Wenwei; Pang, Jiangmiao; Cheng, Guangliang; Chen, Kai; Liu, Ziwei; Loy, Chen Change				Zhang, Wenwei/HKO-4277-2023; Ding, Henghui/C-7486-2019; Cheng, Guangliang/IUP-0024-2023; Liu, Ziwei/AAG-6939-2021						Transformer-Based Visual Segmentation: A Survey								Arxiv											3	3;2024-08-04;https://www.arxiv.org/abs/2304.09854v4| 2;2023-12-20;https://www.arxiv.org/abs/2304.09854v3| 1;2023-04-19;https://www.arxiv.org/abs/2304.09854v1	arXiv:2304.09854			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 04 2024	2024	Visual segmentation seeks to partition images, video frames, or point clouds into multiple segments or groups. This technique has numerous real-world applications, such as autonomous driving, image editing, robot sensing, and medical analysis. Over the past decade, deep learning-based methods have made remarkable strides in this area. Recently, transformers, a type of neural network based on self-attention originally designed for natural language processing, have considerably surpassed previous convolutional or recurrent approaches in various vision processing tasks. Specifically, vision transformers offer robust, unified, and even simpler solutions for various segmentation tasks. This survey provides a thorough overview of transformer-based visual segmentation, summarizing recent advancements. We first review the background, encompassing problem definitions, datasets, and prior convolutional methods. Next, we summarize a meta-architecture that unifies all recent transformer-based approaches. Based on this meta-architecture, we examine various method designs, including modifications to the meta-architecture and associated applications. We also present several closely related settings, including 3D point cloud segmentation, foundation model tuning, domain-aware segmentation, efficient segmentation, and medical segmentation. Additionally, we compile and re-evaluate the reviewed methods on several well-established datasets. Finally, we identify open challenges in this field and propose directions for future research. 																																	2024-08-11	PPRN:64392429		
J	Wang, Zige; Zhong, Wanjun; Wang, Yufei; Zhu, Qi; Mi, Fei; Wang, Baojun; Shang, Lifeng; Jiang, Xin; Liu, Qun				SHANG, LIFENG/KIC-9695-2024						Data Management For Training Large Language Models: A Survey								Arxiv											3	3;2024-08-02;https://www.arxiv.org/abs/2312.01700v3| 2;2023-12-26;https://www.arxiv.org/abs/2312.01700v2| 1;2023-12-04;https://www.arxiv.org/abs/2312.01700v1	arXiv:2312.01700			http://arxiv.org/licenses/nonexclusive-distrib/1.0/	http://arxiv.org/licenses/nonexclusive-distrib/1.0/			preprint	Aug 02 2024	2024	Data plays a fundamental role in training Large Language Models (LLMs). Efficient data management, particularly in formulating a well-suited training dataset, is significant for enhancing model performance and improving training efficiency during pretraining and supervised fine-tuning stages. Despite the considerable importance of data management, the underlying mechanism of current prominent practices are still unknown. Consequently, the exploration of data management has attracted more and more attention among the research community. This survey aims to provide a comprehensive overview of current research in data management within both the pretraining and supervised fine-tuning stages of LLMs, covering various aspects of data management strategy design. Looking into the future, we extrapolate existing challenges and outline promising directions for development in this field. Therefore, this survey serves as a guiding resource for practitioners aspiring to construct powerful LLMs through efficient data management practices.																																	2024-08-08	PPRN:86370494		
J	Inoue, Susumu; Cerruti, Matteo; Murase, Kohta; Liu, Ruo-Yu				Murase, Kohta/AAP-8390-2020; Inoue, Susumu/AAY-7385-2020; Cerruti, Matteo/AAA-6400-2020						High-energy neutrinos and gamma rays from winds and tori in active galactic nuclei								Arxiv											2	2;2024-08-01;https://www.arxiv.org/abs/2207.02097v4| 1;2022-07-05;https://www.arxiv.org/abs/2207.02097v1	arXiv:2207.02097			http://creativecommons.org/licenses/by/4.0/	http://creativecommons.org/licenses/by/4.0/			preprint	Aug 01 2024	2024	Powerful winds with wide opening angles, likely driven by accretion disks around black holes (BHs), are observed in the majority of active galactic nuclei (AGN) and can play a crucial role in AGN and galaxy evolution. If protons are accelerated in the wind near the BH via diffusive shock acceleration, pp and pγ processes generate neutrinos as well as pair cascade emission from the gamma-ray to radio bands. The TeV neutrinos detected by IceCube from the obscured Seyfert galaxy NGC 1068 may arise from collisionless shocks in a failed, line-driven wind that is physically well motivated. Although the cascade emission is γγ-attenuated above a few MeV, it can still contribute significantly to the sub-GeV gamma rays and the sub-millimeter emission observed from NGC 1068. At higher energies, gamma rays can occur via pp processes from a shock where an outgoing wind impacts the obscuring torus, along with some observable GHz-band emission. Tests and implications of this model are discussed. Neutrinos and gamma rays may offer unique probes of AGN wind launching sites, particularly for objects obscured in other forms of radiation.																																	2024-08-08	PPRN:12207429		
